version: '3.8'

services:
  backend:
    build: ./backend
    container_name: sfl-backend
    env_file:
      - ./backend/.env
    ports:
      - "4000:4000"
    volumes:
      - /app/node_modules # Avoids overwriting container node_modules
    depends_on:
      - migration
      - cache
    environment:
      - DATABASE_URL=postgres://user:password@db:5432/sfl_db
      - REDIS_URL=redis://cache:6379
      - NODE_ENV=production
    networks:
      - sfl-network

  frontend:
    build: ./frontend
    container_name: sfl-frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - sfl-network

  migration:
    build: ./backend
    container_name: sfl-migration
    env_file:
      - ./backend/.env
    environment:
      - DATABASE_URL=postgres://user:password@db:5432/sfl_db
      - NODE_ENV=development
    depends_on:
      db:
        condition: service_healthy
    command: npm run migrate:up
    networks:
      - sfl-network
    volumes:
      - ./backend:/app
      - ./database:/app/database
      - /app/node_modules

  db:
    image: docker.io/pgvector/pgvector:pg16 # Use an image with pgvector pre-installed
    container_name: sfl-db
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=sfl_db
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - sfl-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d sfl_db"]
      interval: 5s
      timeout: 5s
      retries: 5

  cache:
    image: docker.io/library/redis:7-alpine
    container_name: sfl-cache
    ports:
      - "6379:6379"
    networks:
      - sfl-network

  # Database Backup Service - Strategy A
  db-backup:
    image: docker.io/pgvector/pgvector:pg16
    container_name: sfl-db-backup
    environment:
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=sfl_db
      - BACKUP_PATH=/backups
      - BACKUP_RETENTION_DAYS=30
    volumes:
      - ./scripts:/scripts:ro
      - backup-data:/backups
      - ./logs:/logs
    depends_on:
      db:
        condition: service_healthy
    networks:
      - sfl-network
    # Run backup daily at 2 AM
    command: >
      sh -c "
        # Install cron
        apt-get update && apt-get install -y cron && 
        # Create cron job
        echo '0 2 * * * cd /scripts && ./backup.sh >> /logs/cron.log 2>&1' | crontab - &&
        # Run cron in foreground
        cron -f
      "
    restart: unless-stopped
    # Optionally run backup immediately on startup (uncomment next line)
    # command: sh -c "cd /scripts && ./backup.sh && cron -f"

volumes:
  pgdata:
  backup-data:

networks:
  sfl-network:
    driver: bridge