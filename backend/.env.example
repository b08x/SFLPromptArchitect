# SFL Prompt Studio Backend Environment Configuration
# =================================================
# This configuration supports the modern unified architecture using Vercel AI SDK
# All AI providers are now integrated through @ai-sdk/* packages for consistency
# 
# Configuration Layers:
# 1. Development: Uses .env file (this template)
# 2. Production: Uses HashiCorp Vault + environment fallback
# 3. Testing: Uses .env.test for isolated test environment

# Database Configuration
DATABASE_URL=postgresql://username:password@localhost:5432/sfl_prompt_studio
DB_HOST=localhost
DB_PORT=5432
DB_NAME=sfl_prompt_studio
DB_USER=your_username
DB_PASSWORD=your_password

# JWT Authentication
JWT_SECRET=your-super-secret-jwt-key-at-least-32-characters-long
JWT_EXPIRES_IN=24h

# Password Hashing
BCRYPT_SALT_ROUNDS=12

# Session Configuration
SESSION_SECRET=your-session-secret-key-at-least-32-characters-long

# Server Configuration
NODE_ENV=development
PORT=3001
FRONTEND_URL=http://localhost:3000

# Redis Configuration (if using Redis for sessions)
REDIS_URL=redis://localhost:6379

# AI Provider API Keys (encrypted in session)
# These keys are stored securely and only used server-side
# Modern unified AI SDK configuration using Vercel AI SDK providers
# All providers are integrated through @ai-sdk/* packages for consistency
GEMINI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
OPENROUTER_API_KEY=your_openrouter_api_key
GROQ_API_KEY=your_groq_api_key
COHERE_API_KEY=your_cohere_api_key
MISTRAL_API_KEY=your_mistral_api_key

# Ollama Configuration (self-hosted)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=30000

# Provider-specific Configuration
# OpenRouter Settings
OPENROUTER_SITE_URL=http://localhost:3000
OPENROUTER_APP_NAME=SFL-Prompt-Studio

# Anthropic Settings
ANTHROPIC_VERSION=2023-06-01

# Google AI (Gemini) Settings
# Note: Unified @ai-sdk/google handles authentication and configuration automatically
# GOOGLE_AI_PROJECT_ID=your_google_project_id  # Optional for advanced use cases
# GOOGLE_AI_LOCATION=us-central1                # Optional for specific regions

# Groq Settings
GROQ_MODEL_DEFAULT=llama3-8b-8192

# Provider Rate Limiting (requests per minute)
RATE_LIMIT_OPENAI=60
RATE_LIMIT_ANTHROPIC=50
RATE_LIMIT_GOOGLE=60
RATE_LIMIT_OPENROUTER=200
RATE_LIMIT_GROQ=30
RATE_LIMIT_COHERE=1000
RATE_LIMIT_MISTRAL=60
RATE_LIMIT_OLLAMA=unlimited

# Logging
LOG_LEVEL=info