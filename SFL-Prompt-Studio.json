{
  "files": [
    {
      "content": "File: SFL-Prompt-Studio/backend/Dockerfile\n\n# Stage 1: Build\nFROM docker.io/library/node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build # Compiles TypeScript to dist/\n\n# Stage 2: Production\nFROM docker.io/library/node:20-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install --only=production\nCOPY --from=builder /app/dist ./dist\nCMD [\"node\", \"dist/index.js\"]\n",
      "metadata": {
        "filename": "Dockerfile",
        "path": "/backend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/geminiController.js\n\n\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst unifiedAIService_1 = __importDefault(require(\"../../services/unifiedAIService\"));\nclass GeminiController {\n    testPrompt(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { promptText, provider, model, parameters, apiKey, baseUrl } = req.body;\n                if (!promptText) {\n                    return res.status(400).json({ message: 'promptText is required' });\n                }\n                // Create provider configuration from request\n                const providerConfig = {\n                    provider: provider,\n                    model,\n                    parameters,\n                    apiKey,\n                    baseUrl\n                };\n                const result = yield unifiedAIService_1.default.testPrompt(promptText, providerConfig);\n                res.status(200).json({ text: result });\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    generateSFLFromGoal(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                console.log('POST /api/gemini/generate-sfl received');\n                console.log('Request body:', JSON.stringify(req.body, null, 2));\n                const { goal, sourceDocContent, provider, model, parameters, apiKey, baseUrl } = req.body;\n                if (!goal) {\n                    console.log('Error: Goal is required but not provided');\n                    return res.status(400).json({ message: 'Goal is required' });\n                }\n                // Create provider configuration from request\n                const providerConfig = {\n                    provider: provider,\n                    model,\n                    parameters,\n                    apiKey,\n                    baseUrl\n                };\n                console.log('Calling UnifiedAIService.generateSFLFromGoal...');\n                const result = yield unifiedAIService_1.default.generateSFLFromGoal(goal, sourceDocContent, providerConfig);\n                console.log('Generated SFL result:', JSON.stringify(result, null, 2));\n                res.status(200).json(result);\n            }\n            catch (error) {\n                console.error('Error in generateSFLFromGoal controller:', error);\n                next(error);\n            }\n        });\n    }\n    regenerateSFLFromSuggestion(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { currentPrompt, suggestion, provider, model, parameters, apiKey, baseUrl } = req.body;\n                if (!currentPrompt || !suggestion) {\n                    return res.status(400).json({ message: 'Current prompt and suggestion are required' });\n                }\n                // Create provider configuration from request\n                const providerConfig = {\n                    provider: provider,\n                    model,\n                    parameters,\n                    apiKey,\n                    baseUrl\n                };\n                const result = yield unifiedAIService_1.default.regenerateSFLFromSuggestion(currentPrompt, suggestion, providerConfig);\n                res.status(200).json(result);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    generateWorkflowFromGoal(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { goal, provider, model, parameters, apiKey, baseUrl } = req.body;\n                if (!goal) {\n                    return res.status(400).json({ message: 'Goal is required' });\n                }\n                // Create provider configuration from request\n                const providerConfig = {\n                    provider: provider,\n                    model,\n                    parameters,\n                    apiKey,\n                    baseUrl\n                };\n                const result = yield unifiedAIService_1.default.generateWorkflowFromGoal(goal, providerConfig);\n                res.status(200).json(result);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n}\nexports.default = new GeminiController();\n",
      "metadata": {
        "filename": "geminiController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/modelController.js\n\n\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst modelService_1 = __importDefault(require(\"../../services/modelService\"));\n/**\n * @class ModelController\n * @description Controller for handling model-related requests.\n */\nclass ModelController {\n    /**\n     * @method getModels\n     * @description Retrieves a list of all available models.\n     * @param {Request} req - The Express request object.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    getModels(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const models = yield modelService_1.default.getModels();\n                res.status(200).json(models);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n}\nexports.default = new ModelController();\n",
      "metadata": {
        "filename": "modelController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/promptController.js\n\n\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst promptService_1 = __importDefault(require(\"../../services/promptService\"));\nrequire(\"../../types/express\");\n/**\n * @class PromptController\n * @description Controller for handling prompt-related requests.\n */\nclass PromptController {\n    /**\n     * @method createPrompt\n     * @description Creates a new prompt.\n     * @param {Request} req - The Express request object, containing the prompt data in the body and user info.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    createPrompt(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a;\n            try {\n                if (!((_a = req.user) === null || _a === void 0 ? void 0 : _a.id)) {\n                    return res.status(401).json({ message: 'Authentication required' });\n                }\n                const prompt = yield promptService_1.default.createPrompt(req.body, req.user.id);\n                res.status(201).json(prompt);\n            }\n            catch (error) {\n                console.error('Create prompt error:', error);\n                if (error instanceof Error) {\n                    res.status(400).json({ message: error.message });\n                }\n                else {\n                    next(error);\n                }\n            }\n        });\n    }\n    /**\n     * @method getPrompts\n     * @description Retrieves a list of prompts, with optional filtering.\n     * @param {Request} req - The Express request object, containing query parameters for filtering.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    getPrompts(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const prompts = yield promptService_1.default.getPrompts(req.query);\n                res.status(200).json(prompts);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * @method getPromptById\n     * @description Retrieves a single prompt by its ID.\n     * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    getPromptById(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const prompt = yield promptService_1.default.getPromptById(req.params.id);\n                if (!prompt) {\n                    return res.status(404).json({ message: 'Prompt not found' });\n                }\n                res.status(200).json(prompt);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * @method updatePrompt\n     * @description Updates an existing prompt.\n     * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter, update data in the body, and user info.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    updatePrompt(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a;\n            try {\n                if (!((_a = req.user) === null || _a === void 0 ? void 0 : _a.id)) {\n                    return res.status(401).json({ message: 'Authentication required' });\n                }\n                const prompt = yield promptService_1.default.updatePrompt(req.params.id, req.body, req.user.id);\n                if (!prompt) {\n                    return res.status(404).json({ message: 'Prompt not found' });\n                }\n                res.status(200).json(prompt);\n            }\n            catch (error) {\n                console.error('Update prompt error:', error);\n                if (error instanceof Error) {\n                    res.status(400).json({ message: error.message });\n                }\n                else {\n                    next(error);\n                }\n            }\n        });\n    }\n    /**\n     * @method deletePrompt\n     * @description Deletes a prompt by its ID.\n     * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function.\n     * @returns {Promise<void>} - A promise that resolves when the response is sent.\n     */\n    deletePrompt(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const success = yield promptService_1.default.deletePrompt(req.params.id);\n                if (!success) {\n                    return res.status(404).json({ message: 'Prompt not found' });\n                }\n                res.status(204).send();\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n}\nexports.default = new PromptController();\n",
      "metadata": {
        "filename": "promptController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/providerController.js\n\n\"use strict\";\n/**\n * @file providerController.ts\n * @description Controller for AI provider validation and status endpoints\n * @since 0.6.0\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst providerValidationService_1 = require(\"../../services/providerValidationService\");\n/**\n * Controller class for managing AI provider validation and configuration\n */\nclass ProviderController {\n    /**\n     * Get the status of all available providers\n     * @route GET /api/providers/status\n     */\n    static getProviderStatus(req, res) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const providers = yield (0, providerValidationService_1.validateAllProviders)();\n                const hasAnyValid = providers.some(p => { var _a; return ((_a = p.validationResult) === null || _a === void 0 ? void 0 : _a.success) === true; });\n                const preferredProvider = yield (0, providerValidationService_1.getPreferredProvider)();\n                res.json({\n                    success: true,\n                    data: {\n                        providers,\n                        hasValidProvider: hasAnyValid,\n                        preferredProvider,\n                    },\n                });\n            }\n            catch (error) {\n                console.error('Error checking provider status:', error);\n                res.status(500).json({\n                    success: false,\n                    error: 'Failed to check provider status',\n                    details: error instanceof Error ? error.message : String(error),\n                });\n            }\n        });\n    }\n    /**\n     * Get available providers without validation (faster)\n     * @route GET /api/providers/available\n     */\n    static getAvailableProviders(req, res) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const providers = (0, providerValidationService_1.detectAvailableProviders)();\n                res.json({\n                    success: true,\n                    data: {\n                        providers,\n                    },\n                });\n            }\n            catch (error) {\n                console.error('Error getting available providers:', error);\n                res.status(500).json({\n                    success: false,\n                    error: 'Failed to get available providers',\n                    details: error instanceof Error ? error.message : String(error),\n                });\n            }\n        });\n    }\n    /**\n     * Check if at least one provider is valid and ready\n     * @route GET /api/providers/health\n     */\n    static checkProviderHealth(req, res) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const isHealthy = yield (0, providerValidationService_1.hasValidProvider)();\n                const preferredProvider = yield (0, providerValidationService_1.getPreferredProvider)();\n                res.json({\n                    success: true,\n                    data: {\n                        healthy: isHealthy,\n                        preferredProvider,\n                        requiresSetup: !isHealthy,\n                    },\n                });\n            }\n            catch (error) {\n                console.error('Error checking provider health:', error);\n                res.status(500).json({\n                    success: false,\n                    error: 'Failed to check provider health',\n                    details: error instanceof Error ? error.message : String(error),\n                });\n            }\n        });\n    }\n    /**\n     * Validate a specific provider's API key\n     * @route POST /api/providers/validate\n     * @body { provider: string, apiKey: string, baseUrl?: string }\n     */\n    static validateProvider(req, res) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { provider, apiKey, baseUrl } = req.body;\n                if (!provider || !apiKey) {\n                    res.status(400).json({\n                        success: false,\n                        error: 'Provider and API key are required',\n                    });\n                    return;\n                }\n                // Validate provider type\n                const validProviders = ['google', 'openai', 'openrouter', 'anthropic'];\n                if (!validProviders.includes(provider)) {\n                    res.status(400).json({\n                        success: false,\n                        error: `Invalid provider. Must be one of: ${validProviders.join(', ')}`,\n                    });\n                    return;\n                }\n                const result = yield (0, providerValidationService_1.validateProviderApiKey)(provider, apiKey, baseUrl);\n                res.json({\n                    success: true,\n                    data: {\n                        provider,\n                        validation: result,\n                    },\n                });\n            }\n            catch (error) {\n                console.error('Error validating provider:', error);\n                res.status(500).json({\n                    success: false,\n                    error: 'Failed to validate provider',\n                    details: error instanceof Error ? error.message : String(error),\n                });\n            }\n        });\n    }\n    /**\n     * Get the preferred provider based on configuration\n     * @route GET /api/providers/preferred\n     */\n    static getPreferredProvider(req, res) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const preferredProvider = yield (0, providerValidationService_1.getPreferredProvider)();\n                if (!preferredProvider) {\n                    res.status(404).json({\n                        success: false,\n                        error: 'No valid provider available',\n                        data: {\n                            preferredProvider: null,\n                            requiresSetup: true,\n                        },\n                    });\n                    return;\n                }\n                res.json({\n                    success: true,\n                    data: {\n                        preferredProvider,\n                        requiresSetup: false,\n                    },\n                });\n            }\n            catch (error) {\n                console.error('Error getting preferred provider:', error);\n                res.status(500).json({\n                    success: false,\n                    error: 'Failed to get preferred provider',\n                    details: error instanceof Error ? error.message : String(error),\n                });\n            }\n        });\n    }\n}\nexports.default = ProviderController;\n",
      "metadata": {
        "filename": "providerController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/workflowController.js\n\n\"use strict\";\n/**\n * @file workflowController.ts\n * @description Controller for handling HTTP requests related to workflows.\n * Provides REST API endpoints for CRUD operations on workflow entities.\n * All methods follow Express.js controller patterns and include proper error handling.\n *\n * @requires express\n * @requires ../../services/workflowService\n * @since 0.5.1\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst workflowService_1 = __importDefault(require(\"../../services/workflowService\"));\nconst orchestratorService_1 = __importDefault(require(\"../../services/orchestratorService\"));\n/**\n * @class WorkflowController\n * @description Controller for handling workflow-related HTTP requests.\n * Provides REST API endpoints for creating, reading, updating, and deleting workflows.\n * Each method handles request validation, service calls, and appropriate HTTP responses.\n *\n * @since 0.5.1\n */\nclass WorkflowController {\n    /**\n     * Creates a new workflow from the request body.\n     * Expects workflow data including name, user_id, and graph_data in the request body.\n     *\n     * @param {Request} req - The Express request object, containing the workflow data in the body.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes validation or database errors to the error handler middleware.\n     *\n     * @example\n     * POST /api/workflows\n     * Content-Type: application/json\n     * {\n     *   \"user_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n     *   \"name\": \"Document Processing Workflow\",\n     *   \"graph_data\": { \"tasks\": [...], \"connections\": [...] }\n     * }\n     *\n     * @since 0.5.1\n     */\n    createWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const workflow = yield workflowService_1.default.createWorkflow(req.body);\n                res.status(201).json(workflow);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * Retrieves all workflows from the database.\n     * Returns workflows ordered by most recently updated first.\n     *\n     * @param {Request} req - The Express request object.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes database errors to the error handler middleware.\n     *\n     * @example\n     * GET /api/workflows\n     * Response: 200 OK\n     * [\n     *   {\n     *     \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n     *     \"name\": \"Workflow 1\",\n     *     \"graph_data\": {...},\n     *     \"created_at\": \"2024-01-01T00:00:00Z\",\n     *     \"updated_at\": \"2024-01-01T00:00:00Z\"\n     *   }\n     * ]\n     *\n     * @since 0.5.1\n     */\n    getWorkflows(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const workflows = yield workflowService_1.default.getWorkflows();\n                res.status(200).json(workflows);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * Retrieves a single workflow by its UUID.\n     * Returns 404 if the workflow is not found.\n     *\n     * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes database errors to the error handler middleware.\n     *\n     * @example\n     * GET /api/workflows/123e4567-e89b-12d3-a456-426614174000\n     * Response: 200 OK\n     * {\n     *   \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n     *   \"name\": \"My Workflow\",\n     *   \"graph_data\": {...}\n     * }\n     *\n     * @since 0.5.1\n     */\n    getWorkflowById(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const workflow = yield workflowService_1.default.getWorkflowById(req.params.id);\n                if (!workflow) {\n                    return res.status(404).json({ message: 'Workflow not found' });\n                }\n                res.status(200).json(workflow);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * Updates an existing workflow with partial data.\n     * Performs a partial update, merging the request body with existing workflow data.\n     * Returns 404 if the workflow is not found.\n     *\n     * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter and the update data in the body.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes validation or database errors to the error handler middleware.\n     *\n     * @example\n     * PUT /api/workflows/123e4567-e89b-12d3-a456-426614174000\n     * Content-Type: application/json\n     * {\n     *   \"name\": \"Updated Workflow Name\",\n     *   \"graph_data\": { \"tasks\": [...] }\n     * }\n     *\n     * @since 0.5.1\n     */\n    updateWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const workflow = yield workflowService_1.default.updateWorkflow(req.params.id, req.body);\n                if (!workflow) {\n                    return res.status(404).json({ message: 'Workflow not found' });\n                }\n                res.status(200).json(workflow);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * Deletes a workflow by its UUID.\n     * Returns 404 if the workflow is not found, otherwise returns 204 No Content.\n     *\n     * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes database errors to the error handler middleware.\n     *\n     * @example\n     * DELETE /api/workflows/123e4567-e89b-12d3-a456-426614174000\n     * Response: 204 No Content (if successful)\n     * Response: 404 Not Found (if workflow doesn't exist)\n     *\n     * @since 0.5.1\n     */\n    deleteWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const success = yield workflowService_1.default.deleteWorkflow(req.params.id);\n                if (!success) {\n                    return res.status(404).json({ message: 'Workflow not found' });\n                }\n                res.status(204).send();\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    /**\n     * Orchestrates a new workflow from a high-level user request using AI.\n     * Takes a natural language description and automatically generates a complete,\n     * executable workflow with proper task dependencies and data flow.\n     *\n     * @param {Request} req - The Express request object, containing the user request in the body.\n     * @param {Response} res - The Express response object.\n     * @param {NextFunction} next - The Express next middleware function for error handling.\n     * @returns {Promise<void>} A promise that resolves when the response is sent.\n     *\n     * @throws {Error} Passes orchestration or validation errors to the error handler middleware.\n     *\n     * @example\n     * POST /api/workflows/orchestrate\n     * Content-Type: application/json\n     * {\n     *   \"request\": \"Analyze customer feedback for sentiment and generate a summary report\"\n     * }\n     *\n     * Response: 200 OK\n     * {\n     *   \"success\": true,\n     *   \"workflow\": {\n     *     \"id\": \"orchestrated-1234567890-abcdef\",\n     *     \"name\": \"Customer Feedback Analysis\",\n     *     \"description\": \"Analyzes customer feedback for sentiment...\",\n     *     \"tasks\": [...]\n     *   }\n     * }\n     *\n     * @since 2.1.0\n     */\n    orchestrateWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { request } = req.body;\n                // Validate input\n                if (!request || typeof request !== 'string') {\n                    return res.status(400).json({\n                        success: false,\n                        error: 'Request body must contain a \"request\" field with a string description of the desired workflow.'\n                    });\n                }\n                if (request.trim().length === 0) {\n                    return res.status(400).json({\n                        success: false,\n                        error: 'The request description cannot be empty.'\n                    });\n                }\n                if (request.length > 2000) {\n                    return res.status(400).json({\n                        success: false,\n                        error: 'The request description is too long. Please limit to 2000 characters.'\n                    });\n                }\n                // Check if orchestrator service is configured\n                if (!orchestratorService_1.default.isConfigured()) {\n                    return res.status(503).json({\n                        success: false,\n                        error: 'AI orchestration service is not properly configured. Please check the GEMINI_API_KEY environment variable.'\n                    });\n                }\n                // Generate workflow using orchestrator service\n                const result = yield orchestratorService_1.default.generateWorkflow(request.trim());\n                if (!result.success) {\n                    return res.status(422).json({\n                        success: false,\n                        error: result.error || 'Failed to generate workflow',\n                        validationErrors: result.validationErrors\n                    });\n                }\n                // Return the generated workflow\n                res.status(200).json({\n                    success: true,\n                    workflow: result.workflow\n                });\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n}\n/**\n * @exports {WorkflowController} workflowController\n * @description Singleton instance of the WorkflowController class, ready to be used in route definitions.\n * This exported instance provides all workflow-related HTTP request handlers.\n *\n * @since 0.5.1\n */\nexports.default = new WorkflowController();\n",
      "metadata": {
        "filename": "workflowController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/controllers/workflowExecutionController.js\n\n\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst workflowExecutionService_1 = __importDefault(require(\"../../services/workflowExecutionService\"));\nconst promptService_1 = __importDefault(require(\"../../services/promptService\"));\n// Conditionally import job service based on Redis availability\nlet JobService;\ntry {\n    // Try to import the real job service\n    JobService = require('../../services/jobService').default;\n}\ncatch (error) {\n    console.warn('Redis not available, using mock job service');\n    JobService = require('../../services/mockJobService').default;\n}\nclass WorkflowExecutionController {\n    runTask(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { task, dataStore } = req.body;\n                if (!task || !dataStore) {\n                    return res.status(400).json({ message: 'Task and dataStore are required' });\n                }\n                // Optimize: Only fetch the specific prompt if needed, instead of all prompts\n                let linkedPrompt;\n                if (task.promptId) {\n                    const foundPrompt = yield promptService_1.default.getPromptById(task.promptId);\n                    if (!foundPrompt) {\n                        return res.status(404).json({ message: `Prompt with ID ${task.promptId} not found` });\n                    }\n                    linkedPrompt = foundPrompt;\n                }\n                const result = yield workflowExecutionService_1.default.executeTask(task, dataStore, linkedPrompt);\n                res.status(200).json(result);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    executeWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { workflow, userInput } = req.body;\n                if (!workflow) {\n                    return res.status(400).json({ message: 'Workflow is required' });\n                }\n                if (!workflow.id) {\n                    return res.status(400).json({ message: 'Workflow must have an ID' });\n                }\n                // Add workflow to execution queue\n                const jobId = yield JobService.addWorkflowJob(workflow.id, workflow, userInput);\n                // Return immediately with job ID and pending status\n                res.status(202).json({\n                    jobId,\n                    status: 'pending',\n                    message: 'Workflow execution started. Use the job ID to check status.'\n                });\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    getJobStatus(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { jobId } = req.params;\n                if (!jobId) {\n                    return res.status(400).json({ message: 'Job ID is required' });\n                }\n                const jobStatus = yield JobService.getJobStatus(jobId);\n                if (!jobStatus) {\n                    return res.status(404).json({ message: 'Job not found' });\n                }\n                res.status(200).json(jobStatus);\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n    stopWorkflow(req, res, next) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { jobId } = req.params;\n                if (!jobId) {\n                    return res.status(400).json({ message: 'Job ID is required' });\n                }\n                const success = yield JobService.stopJob(jobId);\n                if (!success) {\n                    return res.status(404).json({ message: 'Job not found or already completed' });\n                }\n                res.status(200).json({\n                    message: 'Workflow stop requested successfully',\n                    jobId\n                });\n            }\n            catch (error) {\n                next(error);\n            }\n        });\n    }\n}\nexports.default = new WorkflowExecutionController();\n",
      "metadata": {
        "filename": "workflowExecutionController.js",
        "path": "/backend/dist/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/prompts.test.js\n\n\"use strict\";\n/**\n * @file prompts.test.ts\n * @description Integration tests for the /api/prompts endpoints.\n * Tests all CRUD operations for prompts with proper HTTP status codes and error handling.\n * Uses mocked database to isolate API logic testing.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst supertest_1 = __importDefault(require(\"supertest\"));\nconst app_1 = __importDefault(require(\"../app\"));\n// Mock the database pool\njest.mock('../config/database', () => ({\n    query: jest.fn(),\n    end: jest.fn(),\n    on: jest.fn(),\n}));\nconst database_1 = __importDefault(require(\"../config/database\"));\nconst mockQuery = database_1.default.query;\nconst mockEnd = database_1.default.end;\ndescribe('/api/prompts', () => {\n    const mockPromptId = 'test-prompt-id-123';\n    const validPromptData = {\n        title: 'Test Prompt',\n        promptText: 'This is a test prompt for testing purposes.',\n        sflField: {\n            topic: 'Testing',\n            taskType: 'Code Generation',\n            domainSpecifics: 'Unit tests',\n            keywords: 'test, jest, supertest'\n        },\n        sflTenor: {\n            aiPersona: 'Expert',\n            targetAudience: ['Software Developers'],\n            desiredTone: 'Technical',\n            interpersonalStance: 'Helpful'\n        },\n        sflMode: {\n            outputFormat: 'Code',\n            rhetoricalStructure: 'Step-by-step',\n            lengthConstraint: 'Detailed',\n            textualDirectives: 'Include comments'\n        },\n        notes: 'Test prompt for integration testing'\n    };\n    beforeEach(() => {\n        jest.clearAllMocks();\n    });\n    afterAll(() => __awaiter(void 0, void 0, void 0, function* () {\n        yield mockEnd();\n    }));\n    describe('POST /api/prompts', () => {\n        it('should create a prompt successfully with valid data', () => __awaiter(void 0, void 0, void 0, function* () {\n            const mockDbResponse = {\n                rows: [{\n                        id: mockPromptId,\n                        user_id: '00000000-0000-0000-0000-000000000001',\n                        title: validPromptData.title,\n                        body: validPromptData.promptText,\n                        metadata: {\n                            sflField: validPromptData.sflField,\n                            sflTenor: validPromptData.sflTenor,\n                            sflMode: validPromptData.sflMode,\n                            notes: validPromptData.notes\n                        },\n                        created_at: '2024-01-01T00:00:00Z',\n                        updated_at: '2024-01-01T00:00:00Z'\n                    }]\n            };\n            mockQuery.mockResolvedValueOnce(mockDbResponse);\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .post('/api/prompts')\n                .send(validPromptData)\n                .expect(201);\n            expect(response.body).toMatchObject({\n                id: mockPromptId,\n                title: validPromptData.title,\n                promptText: validPromptData.promptText,\n                sflField: validPromptData.sflField\n            });\n            expect(mockQuery).toHaveBeenCalledWith('INSERT INTO prompts (user_id, title, body, metadata) VALUES ($1, $2, $3, $4) RETURNING *', expect.any(Array));\n        }));\n        it('should return 400 when title is missing', () => __awaiter(void 0, void 0, void 0, function* () {\n            const invalidData = Object.assign(Object.assign({}, validPromptData), { title: '' });\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .post('/api/prompts')\n                .send(invalidData)\n                .expect(400);\n            expect(response.body.message).toContain('Title');\n            expect(mockQuery).not.toHaveBeenCalled();\n        }));\n        it('should return 400 when promptText is missing', () => __awaiter(void 0, void 0, void 0, function* () {\n            const invalidData = Object.assign(Object.assign({}, validPromptData), { promptText: '' });\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .post('/api/prompts')\n                .send(invalidData)\n                .expect(400);\n            expect(response.body.message).toContain('Prompt text');\n            expect(mockQuery).not.toHaveBeenCalled();\n        }));\n    });\n    describe('GET /api/prompts', () => {\n        it('should retrieve all prompts successfully', () => __awaiter(void 0, void 0, void 0, function* () {\n            const mockDbResponse = {\n                rows: [\n                    {\n                        id: mockPromptId,\n                        user_id: '00000000-0000-0000-0000-000000000001',\n                        title: 'Test Prompt',\n                        body: 'Test prompt text',\n                        metadata: {\n                            sflField: { topic: 'Test', taskType: 'Testing', domainSpecifics: '', keywords: '' },\n                            sflTenor: { aiPersona: 'Expert', targetAudience: [], desiredTone: 'Neutral', interpersonalStance: '' },\n                            sflMode: { outputFormat: 'Text', rhetoricalStructure: '', lengthConstraint: 'Short', textualDirectives: '' }\n                        },\n                        created_at: '2024-01-01T00:00:00Z',\n                        updated_at: '2024-01-01T00:00:00Z'\n                    }\n                ]\n            };\n            mockQuery.mockResolvedValueOnce(mockDbResponse);\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .get('/api/prompts')\n                .expect(200);\n            expect(Array.isArray(response.body)).toBe(true);\n            expect(response.body).toHaveLength(1);\n            expect(response.body[0]).toMatchObject({\n                id: mockPromptId,\n                title: 'Test Prompt'\n            });\n            expect(mockQuery).toHaveBeenCalledWith('SELECT * FROM prompts ORDER BY updated_at DESC');\n        }));\n    });\n    describe('GET /api/prompts/:id', () => {\n        it('should retrieve a single prompt successfully with valid ID', () => __awaiter(void 0, void 0, void 0, function* () {\n            const mockDbResponse = {\n                rows: [{\n                        id: mockPromptId,\n                        user_id: '00000000-0000-0000-0000-000000000001',\n                        title: 'Test Prompt',\n                        body: 'Test prompt text',\n                        metadata: {},\n                        created_at: '2024-01-01T00:00:00Z',\n                        updated_at: '2024-01-01T00:00:00Z'\n                    }]\n            };\n            mockQuery.mockResolvedValueOnce(mockDbResponse);\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .get(`/api/prompts/${mockPromptId}`)\n                .expect(200);\n            expect(response.body).toMatchObject({\n                id: mockPromptId,\n                title: 'Test Prompt'\n            });\n            expect(mockQuery).toHaveBeenCalledWith('SELECT * FROM prompts WHERE id = $1', [mockPromptId]);\n        }));\n        it('should return 404 for non-existent prompt ID', () => __awaiter(void 0, void 0, void 0, function* () {\n            const nonExistentId = '00000000-0000-0000-0000-000000000999';\n            mockQuery.mockResolvedValueOnce({ rows: [] });\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .get(`/api/prompts/${nonExistentId}`)\n                .expect(404);\n            expect(response.body.message).toBe('Prompt not found');\n        }));\n    });\n    describe('PUT /api/prompts/:id', () => {\n        it('should update a prompt successfully with valid data', () => __awaiter(void 0, void 0, void 0, function* () {\n            const existingPrompt = {\n                rows: [{\n                        id: mockPromptId,\n                        user_id: '00000000-0000-0000-0000-000000000001',\n                        title: 'Original Title',\n                        body: 'Original text',\n                        metadata: {},\n                        created_at: '2024-01-01T00:00:00Z',\n                        updated_at: '2024-01-01T00:00:00Z'\n                    }]\n            };\n            const updatedPrompt = {\n                rows: [Object.assign(Object.assign({}, existingPrompt.rows[0]), { title: 'Updated Title', body: 'Updated text', updated_at: '2024-01-01T01:00:00Z' })]\n            };\n            mockQuery\n                .mockResolvedValueOnce(existingPrompt) // SELECT existing\n                .mockResolvedValueOnce(updatedPrompt); // UPDATE\n            const updateData = { title: 'Updated Title', promptText: 'Updated text' };\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .put(`/api/prompts/${mockPromptId}`)\n                .send(updateData)\n                .expect(200);\n            expect(response.body).toMatchObject({\n                id: mockPromptId,\n                title: 'Updated Title',\n                promptText: 'Updated text'\n            });\n        }));\n        it('should return 404 for non-existent prompt ID', () => __awaiter(void 0, void 0, void 0, function* () {\n            const nonExistentId = '00000000-0000-0000-0000-000000000999';\n            mockQuery.mockResolvedValueOnce({ rows: [] });\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .put(`/api/prompts/${nonExistentId}`)\n                .send({ title: 'Updated Title' })\n                .expect(404);\n            expect(response.body.message).toBe('Prompt not found');\n        }));\n        it('should return 400 when trying to update title to empty string', () => __awaiter(void 0, void 0, void 0, function* () {\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .put(`/api/prompts/${mockPromptId}`)\n                .send({ title: '' })\n                .expect(400);\n            expect(response.body.message).toContain('Title');\n            expect(mockQuery).not.toHaveBeenCalled();\n        }));\n        it('should return 400 when trying to update promptText to empty string', () => __awaiter(void 0, void 0, void 0, function* () {\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .put(`/api/prompts/${mockPromptId}`)\n                .send({ promptText: '' })\n                .expect(400);\n            expect(response.body.message).toContain('Prompt text');\n            expect(mockQuery).not.toHaveBeenCalled();\n        }));\n    });\n    describe('DELETE /api/prompts/:id', () => {\n        it('should delete a prompt successfully with valid ID', () => __awaiter(void 0, void 0, void 0, function* () {\n            mockQuery.mockResolvedValueOnce({ rowCount: 1 });\n            yield (0, supertest_1.default)(app_1.default)\n                .delete(`/api/prompts/${mockPromptId}`)\n                .expect(204);\n            expect(mockQuery).toHaveBeenCalledWith('DELETE FROM prompts WHERE id = $1', [mockPromptId]);\n        }));\n        it('should return 404 for non-existent prompt ID', () => __awaiter(void 0, void 0, void 0, function* () {\n            const nonExistentId = '00000000-0000-0000-0000-000000000999';\n            mockQuery.mockResolvedValueOnce({ rowCount: 0 });\n            const response = yield (0, supertest_1.default)(app_1.default)\n                .delete(`/api/prompts/${nonExistentId}`)\n                .expect(404);\n            expect(response.body.message).toBe('Prompt not found');\n        }));\n    });\n});\n",
      "metadata": {
        "filename": "prompts.test.js",
        "path": "/backend/dist/api/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/api/routes.js\n\n\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst express_1 = require(\"express\");\nconst promptController_1 = __importDefault(require(\"./controllers/promptController\"));\nconst workflowController_1 = __importDefault(require(\"./controllers/workflowController\"));\nconst modelController_1 = __importDefault(require(\"./controllers/modelController\"));\nconst geminiController_1 = __importDefault(require(\"./controllers/geminiController\"));\nconst workflowExecutionController_1 = __importDefault(require(\"./controllers/workflowExecutionController\"));\nconst providerController_1 = __importDefault(require(\"./controllers/providerController\"));\n/**\n * @file defines the routes for the application's API\n * @author Your Name\n * @see {@link http://expressjs.com/en/guide/routing.html|Express Routing}\n */\nconst router = (0, express_1.Router)();\n// Prompt routes\nrouter.post('/prompts', promptController_1.default.createPrompt);\nrouter.get('/prompts', promptController_1.default.getPrompts);\nrouter.get('/prompts/:id', promptController_1.default.getPromptById);\nrouter.put('/prompts/:id', promptController_1.default.updatePrompt);\nrouter.delete('/prompts/:id', promptController_1.default.deletePrompt);\n// Workflow routes\nrouter.post('/workflows', workflowController_1.default.createWorkflow);\nrouter.get('/workflows', workflowController_1.default.getWorkflows);\nrouter.get('/workflows/:id', workflowController_1.default.getWorkflowById);\nrouter.put('/workflows/:id', workflowController_1.default.updateWorkflow);\nrouter.delete('/workflows/:id', workflowController_1.default.deleteWorkflow);\nrouter.post('/workflows/orchestrate', workflowController_1.default.orchestrateWorkflow);\nrouter.post('/workflows/run-task', workflowExecutionController_1.default.runTask);\nrouter.post('/workflows/execute', workflowExecutionController_1.default.executeWorkflow);\nrouter.get('/workflows/jobs/:jobId/status', workflowExecutionController_1.default.getJobStatus);\nrouter.post('/workflows/stop/:jobId', workflowExecutionController_1.default.stopWorkflow);\n// Model routes\nrouter.get('/models', modelController_1.default.getModels);\n// Gemini routes\nrouter.post('/gemini/test-prompt', geminiController_1.default.testPrompt);\nrouter.post('/gemini/generate-sfl', geminiController_1.default.generateSFLFromGoal);\nrouter.post('/gemini/regenerate-sfl', geminiController_1.default.regenerateSFLFromSuggestion);\nrouter.post('/gemini/generate-workflow', geminiController_1.default.generateWorkflowFromGoal);\n// Provider validation routes\nrouter.get('/providers/status', providerController_1.default.getProviderStatus);\nrouter.get('/providers/available', providerController_1.default.getAvailableProviders);\nrouter.get('/providers/health', providerController_1.default.checkProviderHealth);\nrouter.get('/providers/preferred', providerController_1.default.getPreferredProvider);\nrouter.post('/providers/validate', providerController_1.default.validateProvider);\nexports.default = router;\n",
      "metadata": {
        "filename": "routes.js",
        "path": "/backend/dist/api/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/app.js\n\n\"use strict\";\n/**\n * @file app.ts\n * @description Express application setup for the SFL-Prompt-Studio backend.\n * This file configures the Express app without starting the server,\n * making it suitable for testing and modular usage.\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst express_1 = __importDefault(require(\"express\"));\nconst errorHandler_1 = __importDefault(require(\"./middleware/errorHandler\"));\nconst tempAuth_1 = __importDefault(require(\"./middleware/tempAuth\"));\nconst routes_1 = __importDefault(require(\"./api/routes\"));\nconst app = (0, express_1.default)();\napp.use(express_1.default.json());\n// Temporary authentication middleware - replace with real auth\napp.use('/api', tempAuth_1.default);\napp.use('/api', routes_1.default);\napp.get('/', (req, res) => {\n    res.send('SFL Prompt Studio Backend is running!');\n});\napp.use(errorHandler_1.default);\nexports.default = app;\n",
      "metadata": {
        "filename": "app.js",
        "path": "/backend/dist/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/config/database.js\n\n\"use strict\";\n/**\n * @file database.ts\n * @description Manages the PostgreSQL database connection pool for the application.\n * Provides a configured pool instance that handles connection lifecycle management,\n * connection reuse, and automatic cleanup. This is the primary interface for all\n * database operations throughout the backend.\n *\n * @requires pg\n * @requires ./env\n * @since 0.5.1\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst pg_1 = require(\"pg\");\nconst env_1 = __importDefault(require(\"./env\"));\n/**\n * PostgreSQL connection pool instance.\n * Automatically manages database connections, handles connection pooling,\n * and provides efficient connection reuse across the application.\n *\n * The pool is configured using the database URL from environment configuration\n * and will automatically handle connection acquisition, release, and cleanup.\n *\n * @type {Pool}\n * @see {@link https://node-postgres.com/features/pooling|node-postgres pooling}\n *\n * @example\n * ```typescript\n * import pool from './config/database';\n *\n * // Execute a query\n * const result = await pool.query('SELECT * FROM prompts WHERE id = $1', [promptId]);\n *\n * // The connection is automatically returned to the pool\n * ```\n *\n * @since 0.5.1\n */\nconst pool = new pg_1.Pool({\n    connectionString: env_1.default.databaseUrl,\n});\n/**\n * Connection event handler.\n * Logs a confirmation message when a client successfully connects to the database.\n * This is useful for debugging connection issues and monitoring database connectivity.\n *\n * @event Pool#connect\n * @since 0.5.1\n */\npool.on('connect', () => {\n    console.log('Connected to the database');\n});\n/**\n * @exports {Pool} pool\n * @description The configured PostgreSQL connection pool instance.\n * This is the primary database interface used throughout the application\n * for executing queries and managing database connections.\n *\n * @since 0.5.1\n */\nexports.default = pool;\n",
      "metadata": {
        "filename": "database.js",
        "path": "/backend/dist/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/config/env.js\n\n\"use strict\";\n/**\n * @file env.ts\n * @description Environment configuration module that loads and exports environment variables\n * for the application. Uses dotenv to load variables from .env files and provides\n * a centralized configuration object with sensible defaults.\n *\n * This module should be imported by other configuration modules that need access\n * to environment-specific settings like database URLs, API keys, and runtime settings.\n *\n * @requires dotenv\n * @since 0.5.1\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst dotenv_1 = __importDefault(require(\"dotenv\"));\n// Load environment variables from .env file\ndotenv_1.default.config();\n/**\n * Application configuration object containing all environment variables.\n * Provides centralized access to environment-specific settings with fallback defaults\n * where appropriate. Some values may be undefined if not set in the environment.\n *\n * @type {Config}\n *\n * @example\n * ```typescript\n * import config from './config/env';\n *\n * console.log(`Starting server on port ${config.port}`);\n * console.log(`Environment: ${config.nodeEnv}`);\n *\n * if (!config.databaseUrl) {\n *   throw new Error('DATABASE_URL environment variable is required');\n * }\n * ```\n *\n * @since 0.5.1\n */\nexports.default = {\n    databaseUrl: process.env.DATABASE_URL,\n    redisUrl: process.env.REDIS_URL,\n    geminiApiKey: process.env.GEMINI_API_KEY,\n    openaiApiKey: process.env.OPENAI_API_KEY,\n    openrouterApiKey: process.env.OPENROUTER_API_KEY,\n    anthropicApiKey: process.env.ANTHROPIC_API_KEY,\n    defaultAiProvider: process.env.DEFAULT_AI_PROVIDER || 'google',\n    fallbackAiProvider: process.env.FALLBACK_AI_PROVIDER || 'openai',\n    openaiDefaultModel: process.env.OPENAI_DEFAULT_MODEL || 'gpt-4',\n    googleDefaultModel: process.env.GOOGLE_DEFAULT_MODEL || 'gemini-2.5-flash',\n    openrouterDefaultModel: process.env.OPENROUTER_DEFAULT_MODEL || 'openai/gpt-4',\n    openrouterBaseUrl: process.env.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1',\n    anthropicDefaultModel: process.env.ANTHROPIC_DEFAULT_MODEL || 'claude-3-sonnet',\n    enableGrounding: process.env.ENABLE_GROUNDING === 'true',\n    nodeEnv: process.env.NODE_ENV || 'development',\n    port: process.env.PORT || 4000,\n};\n",
      "metadata": {
        "filename": "env.js",
        "path": "/backend/dist/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/config/logger.js\n\n\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst winston_1 = __importDefault(require(\"winston\"));\n/**\n * @file Configures the application's logger using Winston.\n * @author Your Name\n */\n/**\n * @type {winston.Logger}\n * @description A Winston logger instance for logging application events.\n * In development, it logs to the console and to files. In production, it only logs to the console.\n * @see {@link https://github.com/winstonjs/winston|Winston documentation}\n */\nconst logger = winston_1.default.createLogger({\n    level: 'info',\n    format: winston_1.default.format.json(),\n    transports: [\n        new winston_1.default.transports.Console({\n            format: winston_1.default.format.simple(),\n        }),\n    ],\n});\n// If we're not in production then log to the `console` with the format:\n// `${info.level}: ${info.message} JSON.stringify({ ...rest }) `\nif (process.env.NODE_ENV !== 'production') {\n    logger.add(new winston_1.default.transports.File({ filename: 'error.log', level: 'error' }));\n    logger.add(new winston_1.default.transports.File({ filename: 'combined.log' }));\n}\nexports.default = logger;\n",
      "metadata": {
        "filename": "logger.js",
        "path": "/backend/dist/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/index.js\n\n\"use strict\";\n/**\n * @file index.ts\n * @description This is the main entry point for the SFL-Prompt-Studio backend server.\n * It imports the Express application, creates an HTTP server, and initializes WebSocket support.\n *\n * @requires ./app\n * @requires ./config/logger\n * @requires ./config/env\n * @requires ./services/webSocketService\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst http_1 = require(\"http\");\nconst app_1 = __importDefault(require(\"./app\"));\nconst logger_1 = __importDefault(require(\"./config/logger\"));\nconst env_1 = __importDefault(require(\"./config/env\"));\nconst webSocketService_1 = __importDefault(require(\"./services/webSocketService\"));\nconst port = env_1.default.port;\n// Create HTTP server\nconst server = (0, http_1.createServer)(app_1.default);\n// Initialize WebSocket service\nwebSocketService_1.default.initialize(server);\n// Start the server\nserver.listen(port, () => {\n    logger_1.default.info(`Server is running on http://localhost:${port}`);\n    logger_1.default.info(`WebSocket server is available at ws://localhost:${port}/ws`);\n});\n// Graceful shutdown\nprocess.on('SIGTERM', () => {\n    logger_1.default.info('SIGTERM received, shutting down gracefully');\n    webSocketService_1.default.shutdown();\n    server.close(() => {\n        logger_1.default.info('Server closed');\n        process.exit(0);\n    });\n});\nprocess.on('SIGINT', () => {\n    logger_1.default.info('SIGINT received, shutting down gracefully');\n    webSocketService_1.default.shutdown();\n    server.close(() => {\n        logger_1.default.info('Server closed');\n        process.exit(0);\n    });\n});\n",
      "metadata": {
        "filename": "index.js",
        "path": "/backend/dist/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/middleware/errorHandler.js\n\n\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst logger_1 = __importDefault(require(\"../config/logger\"));\n/**\n * @function errorHandler\n * @description Express middleware for centralized error handling.\n * It logs the error and sends a standardized JSON error response to the client.\n * For operational errors, it sends the specific error message. For other errors, it sends a generic message.\n *\n * @param {AppError} err - The error object. Can be a standard Error or a custom AppError.\n * @param {Request} req - The Express request object.\n * @param {Response} res - The Express response object.\n * @param {NextFunction} next - The Express next middleware function.\n */\nconst errorHandler = (err, req, res, next) => {\n    logger_1.default.error(err);\n    const statusCode = err.statusCode || 500;\n    const message = err.isOperational ? err.message : 'An unexpected error occurred.';\n    res.status(statusCode).json({\n        status: 'error',\n        statusCode,\n        message,\n    });\n};\nexports.default = errorHandler;\n",
      "metadata": {
        "filename": "errorHandler.js",
        "path": "/backend/dist/middleware/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/middleware/tempAuth.js\n\n\"use strict\";\n/**\n * @file tempAuth.ts\n * @description Temporary authentication middleware that sets a system user\n * This is a temporary solution until proper authentication is implemented\n *\n * WARNING: This middleware provides no real security and should be replaced\n * with proper authentication (JWT, OAuth, etc.) before production use\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.tempAuthMiddleware = void 0;\nrequire(\"../types/express\");\n/**\n * Temporary authentication middleware that sets a default system user\n * This allows the application to function while maintaining the security\n * improvements made in commit 215cd0c\n *\n * @param req Express request object\n * @param res Express response object\n * @param next Express next function\n */\nconst tempAuthMiddleware = (req, res, next) => {\n    // Set a temporary system user - replace with real authentication\n    req.user = {\n        id: '00000000-0000-0000-0000-000000000001', // System user ID from migration\n        username: 'system',\n        role: 'admin'\n    };\n    next();\n};\nexports.tempAuthMiddleware = tempAuthMiddleware;\nexports.default = exports.tempAuthMiddleware;\n",
      "metadata": {
        "filename": "tempAuth.js",
        "path": "/backend/dist/middleware/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/prompts/orchestratorPrompt.js\n\n\"use strict\";\n/**\n * @file orchestratorPrompt.ts\n * @description Contains the specialized system prompt for the AI Orchestrator that automatically\n * generates workflows from high-level user requests. This prompt is designed to instruct the LLM\n * to act as an expert project manager that decomposes complex tasks into structured workflows.\n *\n * @since 2.1.0\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ORCHESTRATOR_EXAMPLES = exports.ORCHESTRATOR_SYSTEM_PROMPT = void 0;\nexports.buildOrchestratorPrompt = buildOrchestratorPrompt;\n/**\n * @constant {string} ORCHESTRATOR_SYSTEM_PROMPT\n * @description The master system prompt for workflow orchestration. This prompt instructs the LLM\n * to decompose user requests into structured workflows with proper task dependencies, types, and data flow.\n */\nexports.ORCHESTRATOR_SYSTEM_PROMPT = `You are an expert AI workflow orchestrator and project manager. Your specialized role is to analyze complex, high-level user requests and automatically generate complete, executable workflows that break down these requests into logical, dependent tasks.\n\n## Core Responsibilities:\n1. **Task Decomposition**: Break complex requests into atomic, manageable tasks\n2. **Dependency Analysis**: Identify logical task dependencies and execution order\n3. **Resource Mapping**: Determine appropriate task types and data flow patterns\n4. **Workflow Optimization**: Create efficient, parallel execution paths where possible\n\n## Output Requirements:\nYou MUST respond with a single, valid JSON object that conforms exactly to the Workflow data structure. Do not include any explanatory text, comments, or formatting outside the JSON.\n\n## Workflow JSON Structure:\n{\n  \"name\": \"string - Concise, descriptive workflow name\",\n  \"description\": \"string - Brief overview of what the workflow accomplishes\", \n  \"tasks\": [\n    {\n      \"id\": \"string - Unique identifier (task-1, task-2, etc.)\",\n      \"name\": \"string - Short, descriptive task name\",\n      \"description\": \"string - One sentence explaining the task purpose\",\n      \"type\": \"TaskType - See available types below\",\n      \"dependencies\": [\"string[] - Array of task IDs this task depends on\"],\n      \"inputKeys\": [\"string[] - Data Store keys needed (use dot notation)\"],\n      \"outputKey\": \"string - Key where this task's result is stored\",\n      \"positionX\": \"number - X coordinate for UI layout (50-800 range)\",\n      \"positionY\": \"number - Y coordinate for UI layout (50-600 range)\"\n    }\n  ]\n}\n\n## Available Task Types:\n- **DATA_INPUT**: Captures user input or static values\n- **GEMINI_PROMPT**: Executes AI/LLM prompts for text generation\n- **IMAGE_ANALYSIS**: Analyzes visual content  \n- **TEXT_MANIPULATION**: Processes text with custom JavaScript functions\n- **SIMULATE_PROCESS**: Simulates processes for testing workflow logic\n- **DISPLAY_CHART**: Prepares data for visualization\n- **GEMINI_GROUNDED**: LLM prompts with real-time data grounding\n\n## Task-Specific Required Fields:\n\n**GEMINI_PROMPT/IMAGE_ANALYSIS/GEMINI_GROUNDED:**\n- Add: \"promptTemplate\": \"Your prompt text with {{placeholder}} variables\"\n\n**TEXT_MANIPULATION:**\n- Add: \"functionBody\": \"JavaScript function body as string, e.g. return \\`Result: \\${inputs.data}\\`\"\n\n**DATA_INPUT:**\n- Add: \"staticValue\": \"{{userInput.text}}\" or \"{{userInput.image}}\" or \"{{userInput.file}}\" or literal value\n\n**DISPLAY_CHART:**\n- Add: \"dataKey\": \"Key pointing to chartable data in Data Store\"\n\n## Data Flow Patterns:\n- Use \"userInput.text\", \"userInput.image\", \"userInput.file\" for initial user data\n- Reference task outputs via their outputKey in subsequent inputKeys\n- Use {{placeholder}} syntax in promptTemplate for dynamic content interpolation\n- Ensure proper dependency chains for data flow\n\n## Positioning Guidelines:\n- Arrange tasks logically from left to right (input → processing → output)\n- Space tasks 200-300 pixels apart horizontally\n- Use 100-150 pixel vertical spacing for parallel tasks\n- Keep initial tasks on the left (X: 50-150), final tasks on right (X: 600-800)\n\n## Quality Standards:\n- Create 3-8 tasks for typical workflows (more complex requests may need more)\n- Ensure every task has clear purpose and proper dependencies\n- Avoid circular dependencies\n- Include meaningful intermediate results that can be reused\n- Design for both sequential and parallel execution where logical`;\n/**\n * @constant {OrchestratorExample[]} ORCHESTRATOR_EXAMPLES\n * @description Few-shot learning examples that demonstrate proper workflow generation patterns\n */\nexports.ORCHESTRATOR_EXAMPLES = [\n    {\n        userRequest: \"Analyze customer feedback text for sentiment, extract key themes, and create a summary report\",\n        expectedWorkflow: {\n            name: \"Customer Feedback Analysis\",\n            description: \"Analyzes customer feedback for sentiment and themes, then generates a comprehensive summary report\",\n            tasks: [\n                {\n                    id: \"task-1\",\n                    name: \"Capture Feedback Text\",\n                    description: \"Receives the customer feedback text from user input\",\n                    type: \"DATA_INPUT\",\n                    dependencies: [],\n                    inputKeys: [],\n                    outputKey: \"feedbackText\",\n                    positionX: 50,\n                    positionY: 100,\n                    staticValue: \"{{userInput.text}}\"\n                },\n                {\n                    id: \"task-2\",\n                    name: \"Analyze Sentiment\",\n                    description: \"Determines the overall sentiment (positive, negative, neutral) of the feedback\",\n                    type: \"GEMINI_PROMPT\",\n                    dependencies: [\"task-1\"],\n                    inputKeys: [\"feedbackText\"],\n                    outputKey: \"sentimentAnalysis\",\n                    positionX: 300,\n                    positionY: 50,\n                    promptTemplate: \"Analyze the sentiment of this customer feedback and classify it as positive, negative, or neutral. Provide a confidence score and brief reasoning:\\\\n\\\\n{{feedbackText}}\"\n                },\n                {\n                    id: \"task-3\",\n                    name: \"Extract Key Themes\",\n                    description: \"Identifies the main topics and themes discussed in the feedback\",\n                    type: \"GEMINI_PROMPT\",\n                    dependencies: [\"task-1\"],\n                    inputKeys: [\"feedbackText\"],\n                    outputKey: \"keyThemes\",\n                    positionX: 300,\n                    positionY: 200,\n                    promptTemplate: \"Extract the key themes and topics from this customer feedback. List the main points discussed:\\\\n\\\\n{{feedbackText}}\"\n                },\n                {\n                    id: \"task-4\",\n                    name: \"Generate Summary Report\",\n                    description: \"Creates a comprehensive summary report combining sentiment and themes\",\n                    type: \"TEXT_MANIPULATION\",\n                    dependencies: [\"task-2\", \"task-3\"],\n                    inputKeys: [\"sentimentAnalysis\", \"keyThemes\"],\n                    outputKey: \"summaryReport\",\n                    positionX: 550,\n                    positionY: 125,\n                    functionBody: \"return `# Customer Feedback Analysis Report\\\\n\\\\n## Sentiment Analysis\\\\n${inputs.sentimentAnalysis}\\\\n\\\\n## Key Themes\\\\n${inputs.keyThemes}\\\\n\\\\n## Report Generated: ${new Date().toLocaleDateString()}`\"\n                }\n            ]\n        }\n    },\n    {\n        userRequest: \"Take a product image, analyze its features, generate a marketing description, and create product data for an e-commerce listing\",\n        expectedWorkflow: {\n            name: \"Product Image to E-commerce Listing\",\n            description: \"Processes product images to generate marketing content and structured e-commerce data\",\n            tasks: [\n                {\n                    id: \"task-1\",\n                    name: \"Load Product Image\",\n                    description: \"Captures the product image provided by the user\",\n                    type: \"DATA_INPUT\",\n                    dependencies: [],\n                    inputKeys: [],\n                    outputKey: \"productImage\",\n                    positionX: 50,\n                    positionY: 150,\n                    staticValue: \"{{userInput.image}}\"\n                },\n                {\n                    id: \"task-2\",\n                    name: \"Analyze Product Features\",\n                    description: \"Extracts visual features, colors, materials, and product characteristics from the image\",\n                    type: \"IMAGE_ANALYSIS\",\n                    dependencies: [\"task-1\"],\n                    inputKeys: [\"productImage\"],\n                    outputKey: \"productFeatures\",\n                    positionX: 250,\n                    positionY: 100,\n                    promptTemplate: \"Analyze this product image and describe: 1) Main features and functionality, 2) Materials and construction, 3) Colors and design elements, 4) Size/scale indicators, 5) Target audience/use cases\"\n                },\n                {\n                    id: \"task-3\",\n                    name: \"Generate Marketing Copy\",\n                    description: \"Creates compelling marketing description based on analyzed features\",\n                    type: \"GEMINI_PROMPT\",\n                    dependencies: [\"task-2\"],\n                    inputKeys: [\"productFeatures\"],\n                    outputKey: \"marketingDescription\",\n                    positionX: 450,\n                    positionY: 50,\n                    promptTemplate: \"Based on these product features, write compelling marketing copy for an e-commerce listing. Include benefits, key selling points, and emotional appeal:\\\\n\\\\n{{productFeatures}}\"\n                },\n                {\n                    id: \"task-4\",\n                    name: \"Structure Product Data\",\n                    description: \"Formats the analysis into structured e-commerce product data\",\n                    type: \"TEXT_MANIPULATION\",\n                    dependencies: [\"task-2\", \"task-3\"],\n                    inputKeys: [\"productFeatures\", \"marketingDescription\"],\n                    outputKey: \"productListing\",\n                    positionX: 650,\n                    positionY: 125,\n                    functionBody: \"const features = inputs.productFeatures; const marketing = inputs.marketingDescription; return JSON.stringify({ title: 'Generated from analysis', description: marketing, features: features, category: 'To be determined', tags: [] }, null, 2)\"\n                }\n            ]\n        }\n    }\n];\n/**\n * @function buildOrchestratorPrompt\n * @description Constructs the complete orchestrator prompt by combining the system instruction\n * with few-shot examples and the user's specific request\n *\n * @param {string} userRequest - The user's high-level request to be converted into a workflow\n * @returns {string} The complete prompt ready to be sent to the LLM\n */\nfunction buildOrchestratorPrompt(userRequest) {\n    const examplePrompts = exports.ORCHESTRATOR_EXAMPLES.map((example, index) => `### Example ${index + 1}:\n**User Request**: \"${example.userRequest}\"\n\n**Generated Workflow**:\n\\`\\`\\`json\n${JSON.stringify(example.expectedWorkflow, null, 2)}\n\\`\\`\\``).join('\\n\\n');\n    return `${exports.ORCHESTRATOR_SYSTEM_PROMPT}\n\n## Few-Shot Examples:\n${examplePrompts}\n\n## Your Task:\nGenerate a complete workflow JSON for the following user request. Remember to output ONLY the JSON object, no additional text or explanations.\n\n**User Request**: \"${userRequest}\"`;\n}\n",
      "metadata": {
        "filename": "orchestratorPrompt.js",
        "path": "/backend/dist/prompts/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/ai/AIProviderFactory.js\n\n\"use strict\";\n/**\n * @file AIProviderFactory.ts\n * @description Factory for creating AI service instances dynamically based on provider type.\n * This factory enables runtime provider switching and manages service instantiation\n * with proper configuration and error handling.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.aiProviderFactory = exports.AIProviderFactory = void 0;\nexports.createAIService = createAIService;\nexports.testAIProviderConnection = testAIProviderConnection;\nconst OpenAIService_1 = require(\"./OpenAIService\");\nconst AnthropicService_1 = require(\"./AnthropicService\");\nconst GeminiService_1 = require(\"./GeminiService\");\n/**\n * Service factory registry\n */\nconst SERVICE_FACTORIES = {\n    openai: OpenAIService_1.createOpenAIService,\n    anthropic: AnthropicService_1.createAnthropicService,\n    google: GeminiService_1.createGeminiService,\n    openrouter: (config) => {\n        throw new Error('OpenRouter service not yet implemented');\n    }\n};\n/**\n * Service instance cache for reusing configured services\n */\nclass ServiceCache {\n    constructor() {\n        this.cache = new Map();\n        this.maxCacheSize = 10;\n    }\n    /**\n     * Generate cache key for a service configuration\n     */\n    getCacheKey(provider, apiKey, baseUrl) {\n        // Use first 8 characters of API key hash for cache key (security)\n        const keyHash = Buffer.from(apiKey).toString('base64').substring(0, 8);\n        return `${provider}:${keyHash}:${baseUrl || 'default'}`;\n    }\n    /**\n     * Get cached service instance\n     */\n    get(provider, config) {\n        const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n        return this.cache.get(key);\n    }\n    /**\n     * Cache service instance\n     */\n    set(provider, config, service) {\n        const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n        // Implement LRU cache behavior\n        if (this.cache.size >= this.maxCacheSize) {\n            const firstKey = this.cache.keys().next().value;\n            if (firstKey) {\n                this.cache.delete(firstKey);\n            }\n        }\n        this.cache.set(key, service);\n    }\n    /**\n     * Clear cache (useful for testing or when configurations change)\n     */\n    clear() {\n        this.cache.clear();\n    }\n    /**\n     * Remove specific service from cache\n     */\n    remove(provider, config) {\n        const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n        this.cache.delete(key);\n    }\n    /**\n     * Get cache statistics\n     */\n    getStats() {\n        return {\n            size: this.cache.size,\n            maxSize: this.maxCacheSize,\n            keys: Array.from(this.cache.keys())\n        };\n    }\n}\n/**\n * AI Provider Factory class\n */\nclass AIProviderFactory {\n    constructor() {\n        this.serviceCache = new ServiceCache();\n    }\n    /**\n     * Get singleton instance of the factory\n     */\n    static getInstance() {\n        if (!AIProviderFactory.instance) {\n            AIProviderFactory.instance = new AIProviderFactory();\n        }\n        return AIProviderFactory.instance;\n    }\n    /**\n     * Create or retrieve AI service instance\n     * @param provider - The AI provider to create service for\n     * @param config - Configuration for the service\n     * @param useCache - Whether to use cached instances (default: true)\n     */\n    createService(provider, config, useCache = true) {\n        // Validate provider\n        if (!this.isProviderSupported(provider)) {\n            throw new Error(`Unsupported AI provider: ${provider}`);\n        }\n        // Validate configuration\n        this.validateConfig(config);\n        // Check cache first if enabled\n        if (useCache) {\n            const cachedService = this.serviceCache.get(provider, config);\n            if (cachedService) {\n                return cachedService;\n            }\n        }\n        try {\n            // Create new service instance\n            const factory = SERVICE_FACTORIES[provider];\n            const service = factory(config);\n            // Cache the service if enabled\n            if (useCache) {\n                this.serviceCache.set(provider, config, service);\n            }\n            return service;\n        }\n        catch (error) {\n            throw new Error(`Failed to create ${provider} service: ${error instanceof Error ? error.message : 'Unknown error'}`);\n        }\n    }\n    /**\n     * Test if a provider is supported\n     */\n    isProviderSupported(provider) {\n        return provider in SERVICE_FACTORIES;\n    }\n    /**\n     * Get list of supported providers\n     */\n    getSupportedProviders() {\n        return Object.keys(SERVICE_FACTORIES);\n    }\n    /**\n     * Get list of implemented providers (excluding placeholder implementations)\n     */\n    getImplementedProviders() {\n        const implemented = [];\n        for (const provider of Object.keys(SERVICE_FACTORIES)) {\n            try {\n                // Try to create a dummy service to check if implemented\n                const dummyConfig = { apiKey: 'test' };\n                SERVICE_FACTORIES[provider](dummyConfig);\n                implemented.push(provider);\n            }\n            catch (error) {\n                // Provider not yet implemented\n                if (error instanceof Error && error.message.includes('not yet implemented')) {\n                    continue;\n                }\n                // Other errors mean the provider is implemented but configuration failed\n                implemented.push(provider);\n            }\n        }\n        return implemented;\n    }\n    /**\n     * Test connection for a provider\n     * @param provider - The provider to test\n     * @param config - Configuration for the test\n     */\n    testProviderConnection(provider, config) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const service = this.createService(provider, config, false); // Don't cache test instances\n                return yield service.testConnection();\n            }\n            catch (error) {\n                console.error(`Failed to test ${provider} connection:`, error);\n                return false;\n            }\n        });\n    }\n    /**\n     * Get service capabilities for a provider\n     * @param provider - The provider to query\n     * @param config - Configuration for the service\n     */\n    getProviderCapabilities(provider, config) {\n        const service = this.createService(provider, config);\n        return service.getCapabilities();\n    }\n    /**\n     * Clear service cache\n     */\n    clearCache() {\n        this.serviceCache.clear();\n    }\n    /**\n     * Remove specific service from cache\n     */\n    removeCachedService(provider, config) {\n        this.serviceCache.remove(provider, config);\n    }\n    /**\n     * Get cache statistics\n     */\n    getCacheStats() {\n        return this.serviceCache.getStats();\n    }\n    /**\n     * Validate service configuration\n     */\n    validateConfig(config) {\n        if (!config.apiKey || config.apiKey.trim() === '') {\n            throw new Error('API key is required');\n        }\n        if (config.timeout && config.timeout < 1000) {\n            throw new Error('Timeout must be at least 1000ms');\n        }\n        if (config.baseUrl && !this.isValidUrl(config.baseUrl)) {\n            throw new Error('Invalid base URL format');\n        }\n    }\n    /**\n     * Validate URL format\n     */\n    isValidUrl(url) {\n        try {\n            new URL(url);\n            return true;\n        }\n        catch (_a) {\n            return false;\n        }\n    }\n}\nexports.AIProviderFactory = AIProviderFactory;\n/**\n * Convenience function to get factory instance\n */\nexports.aiProviderFactory = AIProviderFactory.getInstance();\n/**\n * Convenience function to create AI service\n */\nfunction createAIService(provider, config) {\n    return exports.aiProviderFactory.createService(provider, config);\n}\n/**\n * Convenience function to test provider connection\n */\nfunction testAIProviderConnection(provider, config) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return exports.aiProviderFactory.testProviderConnection(provider, config);\n    });\n}\n",
      "metadata": {
        "filename": "AIProviderFactory.js",
        "path": "/backend/dist/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/ai/AnthropicService.js\n\n\"use strict\";\n/**\n * @file AnthropicService.ts\n * @description Anthropic Claude AI service implementation.\n * Provides integration with Anthropic's Claude models including Claude 3.5 Sonnet and Claude 3 Haiku.\n * Handles Anthropic-specific parameter mapping, authentication, and response parsing.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AnthropicService = void 0;\nexports.createAnthropicService = createAnthropicService;\nconst axios_1 = __importDefault(require(\"axios\"));\nconst BaseAIService_1 = require(\"./BaseAIService\");\n/**\n * Anthropic service implementation\n */\nclass AnthropicService extends BaseAIService_1.BaseAIService {\n    constructor(config) {\n        const capabilities = {\n            supportedParameters: [\n                'temperature',\n                'maxTokens',\n                'top_p',\n                'top_k',\n                'system',\n                'stop_sequences'\n            ],\n            maxContextLength: 200000, // Claude 3.5 context length\n            supportsStreaming: true,\n            supportsFunctionCalling: false,\n            supportsImages: true\n        };\n        super('anthropic', config, capabilities);\n        this.baseUrl = config.baseUrl || 'https://api.anthropic.com';\n        this.client = axios_1.default.create({\n            baseURL: this.baseUrl,\n            timeout: config.timeout || 30000,\n            headers: this.getRequestHeaders()\n        });\n    }\n    /**\n     * Test connection to Anthropic API\n     */\n    testConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // Anthropic doesn't have a models endpoint, so we test with a minimal request\n                const testRequest = {\n                    model: 'claude-3-haiku-20240307',\n                    max_tokens: 1,\n                    messages: [{\n                            role: 'user',\n                            content: 'Hi'\n                        }]\n                };\n                const response = yield this.client.post('/v1/messages', testRequest);\n                return response.status === 200;\n            }\n            catch (error) {\n                console.error('Anthropic connection test failed:', error);\n                return false;\n            }\n        });\n    }\n    /**\n     * List available Anthropic models\n     */\n    listModels() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // Anthropic doesn't provide a models endpoint, so we return known models\n            return [\n                'claude-3-5-sonnet-20241022',\n                'claude-3-haiku-20240307',\n                'claude-3-sonnet-20240229',\n                'claude-3-opus-20240229'\n            ];\n        });\n    }\n    /**\n     * Generate completion using Anthropic API\n     */\n    generateCompletion(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const startTime = Date.now();\n            try {\n                const payload = this.buildRequestPayload(request);\n                this.logRequest(payload);\n                const response = yield this.client.post('/v1/messages', payload);\n                const aiResponse = this.parseResponse(response.data, startTime);\n                this.logResponse(aiResponse);\n                return aiResponse;\n            }\n            catch (error) {\n                console.error('Anthropic completion failed:', error);\n                throw this.handleError(error);\n            }\n        });\n    }\n    /**\n     * Generate streaming completion (placeholder implementation)\n     */\n    generateStreamingCompletion(request, onChunk) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // For now, implement as non-streaming\n            // TODO: Implement actual streaming support\n            const response = yield this.generateCompletion(request);\n            onChunk(response.text);\n            return response;\n        });\n    }\n    /**\n     * Validate Anthropic parameters\n     */\n    validateParameters(model, parameters) {\n        const errors = [];\n        const params = parameters;\n        // Validate temperature\n        if (params.temperature !== undefined) {\n            if (params.temperature < 0 || params.temperature > 1) {\n                errors.push('temperature must be between 0 and 1');\n            }\n        }\n        // Validate maxTokens\n        if (params.maxTokens !== undefined) {\n            if (params.maxTokens < 1 || params.maxTokens > 8192) {\n                errors.push('maxTokens must be between 1 and 8192');\n            }\n        }\n        // Validate top_p\n        if (params.top_p !== undefined) {\n            if (params.top_p < 0 || params.top_p > 1) {\n                errors.push('top_p must be between 0 and 1');\n            }\n        }\n        // Validate top_k\n        if (params.top_k !== undefined) {\n            if (params.top_k < 0 || params.top_k > 200) {\n                errors.push('top_k must be between 0 and 200');\n            }\n        }\n        // Validate stop_sequences\n        if (params.stop_sequences !== undefined) {\n            if (!Array.isArray(params.stop_sequences)) {\n                errors.push('stop_sequences must be an array');\n            }\n            else if (params.stop_sequences.length > 4) {\n                errors.push('stop_sequences can have at most 4 sequences');\n            }\n        }\n        return {\n            valid: errors.length === 0,\n            errors\n        };\n    }\n    /**\n     * Normalize parameters to Anthropic format\n     */\n    normalizeParameters(parameters) {\n        const params = parameters;\n        const normalized = {};\n        // Map standard parameters\n        if (params.temperature !== undefined)\n            normalized.temperature = params.temperature;\n        if (params.maxTokens !== undefined)\n            normalized.max_tokens = params.maxTokens;\n        if (params.top_p !== undefined)\n            normalized.top_p = params.top_p;\n        if (params.top_k !== undefined)\n            normalized.top_k = params.top_k;\n        if (params.system !== undefined)\n            normalized.system = params.system;\n        if (params.stop_sequences !== undefined)\n            normalized.stop_sequences = params.stop_sequences;\n        return this.sanitizeParameters(normalized);\n    }\n    /**\n     * Build Anthropic API request payload\n     */\n    buildRequestPayload(request) {\n        const parameters = this.normalizeParameters(request.parameters);\n        const params = request.parameters;\n        // Build messages array (Anthropic requires alternating user/assistant messages)\n        const messages = [];\n        // Add conversation history if provided\n        if (request.conversationHistory) {\n            request.conversationHistory.forEach(msg => {\n                if (msg.role !== 'system') { // System messages are handled separately\n                    messages.push({\n                        role: msg.role,\n                        content: msg.content\n                    });\n                }\n            });\n        }\n        // Add current prompt\n        messages.push({\n            role: 'user',\n            content: request.prompt\n        });\n        // Ensure max_tokens is set (required by Anthropic)\n        const maxTokens = parameters.max_tokens || 1024;\n        delete parameters.max_tokens;\n        // Extract system message\n        const systemMessage = params.system || request.systemMessage;\n        delete parameters.system;\n        const payload = Object.assign({ model: request.model, max_tokens: maxTokens, messages }, parameters);\n        if (systemMessage) {\n            payload.system = systemMessage;\n        }\n        return payload;\n    }\n    /**\n     * Parse Anthropic response to standard format\n     */\n    parseResponse(response, startTime) {\n        const content = response.content[0];\n        if (!content || content.type !== 'text') {\n            throw new Error('No text content returned from Anthropic API');\n        }\n        return {\n            text: content.text,\n            usage: {\n                promptTokens: response.usage.input_tokens,\n                completionTokens: response.usage.output_tokens,\n                totalTokens: response.usage.input_tokens + response.usage.output_tokens\n            },\n            metadata: {\n                id: response.id,\n                stopReason: response.stop_reason,\n                stopSequence: response.stop_sequence\n            },\n            model: response.model,\n            processingTime: this.calculateProcessingTime(startTime)\n        };\n    }\n    /**\n     * Add Anthropic-specific authentication headers\n     */\n    addAuthHeaders(headers) {\n        headers['x-api-key'] = this.config.apiKey;\n        headers['anthropic-version'] = '2023-06-01';\n    }\n}\nexports.AnthropicService = AnthropicService;\n/**\n * Factory function for creating Anthropic service instances\n */\nfunction createAnthropicService(config) {\n    return new AnthropicService(config);\n}\n",
      "metadata": {
        "filename": "AnthropicService.js",
        "path": "/backend/dist/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/ai/BaseAIService.js\n\n\"use strict\";\n/**\n * @file BaseAIService.ts\n * @description Abstract base class for AI service implementations.\n * Defines the common interface and shared functionality for all AI providers.\n * This architecture allows for dynamic provider switching while maintaining\n * consistent behavior across different AI services.\n *\n * @requires ../../types/aiProvider\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.BaseAIService = void 0;\n/**\n * Abstract base class for AI service implementations.\n * All AI provider services must extend this class and implement the required methods.\n */\nclass BaseAIService {\n    /**\n     * Constructor for base AI service\n     * @param provider - The AI provider identifier\n     * @param config - Service configuration\n     * @param capabilities - Service capabilities\n     */\n    constructor(provider, config, capabilities) {\n        this.provider = provider;\n        this.config = config;\n        this.capabilities = capabilities;\n        this.validateConfig();\n    }\n    /**\n     * Get the provider identifier\n     */\n    getProvider() {\n        return this.provider;\n    }\n    /**\n     * Get service capabilities\n     */\n    getCapabilities() {\n        return Object.assign({}, this.capabilities);\n    }\n    /**\n     * Handle provider-specific errors and convert them to standard format\n     * @param error - The error from the provider\n     */\n    handleError(error) {\n        var _a;\n        if (error.response) {\n            // HTTP error response\n            const status = error.response.status;\n            const message = ((_a = error.response.data) === null || _a === void 0 ? void 0 : _a.message) || error.response.statusText || 'Unknown error';\n            switch (status) {\n                case 401:\n                    return new Error(`Authentication failed: ${message}`);\n                case 403:\n                    return new Error(`Access forbidden: ${message}`);\n                case 404:\n                    return new Error(`Resource not found: ${message}`);\n                case 429:\n                    return new Error(`Rate limit exceeded: ${message}`);\n                case 500:\n                    return new Error(`Server error: ${message}`);\n                default:\n                    return new Error(`API error (${status}): ${message}`);\n            }\n        }\n        else if (error.request) {\n            // Network error\n            return new Error('Network error: Unable to reach the AI service');\n        }\n        else {\n            // Other error\n            return new Error(error.message || 'Unknown error occurred');\n        }\n    }\n    /**\n     * Validate the service configuration\n     */\n    validateConfig() {\n        if (!this.config.apiKey) {\n            throw new Error(`API key is required for ${this.provider} service`);\n        }\n        if (this.config.timeout && this.config.timeout < 1000) {\n            throw new Error('Timeout must be at least 1000ms');\n        }\n    }\n    /**\n     * Get request headers with authentication\n     */\n    getRequestHeaders() {\n        const headers = Object.assign({ 'Content-Type': 'application/json', 'User-Agent': 'SFL-Prompt-Studio/1.0' }, this.config.headers);\n        // Add provider-specific authentication headers\n        this.addAuthHeaders(headers);\n        return headers;\n    }\n    /**\n     * Calculate processing time\n     * @param startTime - Request start time\n     */\n    calculateProcessingTime(startTime) {\n        return Date.now() - startTime;\n    }\n    /**\n     * Sanitize parameters to remove undefined/null values\n     * @param params - Parameters to sanitize\n     */\n    sanitizeParameters(params) {\n        const sanitized = {};\n        Object.entries(params).forEach(([key, value]) => {\n            if (value !== undefined && value !== null) {\n                sanitized[key] = value;\n            }\n        });\n        return sanitized;\n    }\n    /**\n     * Log request for debugging (with sensitive data removed)\n     * @param request - The request to log\n     */\n    logRequest(request) {\n        var _a, _b;\n        if (process.env.NODE_ENV === 'development') {\n            const safeRequest = Object.assign({}, request);\n            // Remove sensitive data\n            if ((_a = safeRequest.headers) === null || _a === void 0 ? void 0 : _a.Authorization) {\n                safeRequest.headers.Authorization = '[REDACTED]';\n            }\n            if ((_b = safeRequest.headers) === null || _b === void 0 ? void 0 : _b['x-api-key']) {\n                safeRequest.headers['x-api-key'] = '[REDACTED]';\n            }\n            console.log(`[${this.provider.toUpperCase()}] Request:`, JSON.stringify(safeRequest, null, 2));\n        }\n    }\n    /**\n     * Log response for debugging\n     * @param response - The response to log\n     */\n    logResponse(response) {\n        if (process.env.NODE_ENV === 'development') {\n            console.log(`[${this.provider.toUpperCase()}] Response:`, {\n                textLength: response.text.length,\n                usage: response.usage,\n                processingTime: response.processingTime,\n                model: response.model\n            });\n        }\n    }\n}\nexports.BaseAIService = BaseAIService;\n",
      "metadata": {
        "filename": "BaseAIService.js",
        "path": "/backend/dist/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/ai/GeminiService.js\n\n\"use strict\";\n/**\n * @file GeminiService.ts\n * @description Google Gemini AI service implementation.\n * Provides integration with Google's Gemini models including Gemini Pro and Gemini Flash.\n * Handles Gemini-specific parameter mapping, authentication, and response parsing.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.GeminiService = void 0;\nexports.createGeminiService = createGeminiService;\nconst axios_1 = __importDefault(require(\"axios\"));\nconst BaseAIService_1 = require(\"./BaseAIService\");\n/**\n * Gemini service implementation\n */\nclass GeminiService extends BaseAIService_1.BaseAIService {\n    constructor(config) {\n        const capabilities = {\n            supportedParameters: [\n                'temperature',\n                'maxTokens',\n                'topK',\n                'topP',\n                'systemInstruction',\n                'safetySettings'\n            ],\n            maxContextLength: 1048576, // Gemini Pro context length\n            supportsStreaming: true,\n            supportsFunctionCalling: true,\n            supportsImages: true\n        };\n        super('google', config, capabilities);\n        this.baseUrl = config.baseUrl || 'https://generativelanguage.googleapis.com/v1beta';\n        this.client = axios_1.default.create({\n            baseURL: this.baseUrl,\n            timeout: config.timeout || 60000,\n            headers: this.getRequestHeaders()\n        });\n    }\n    /**\n     * Test connection to Gemini API\n     */\n    testConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // Test with a simple model listing request\n                const response = yield this.client.get(`/models?key=${this.config.apiKey}`);\n                return response.status === 200;\n            }\n            catch (error) {\n                console.error('Gemini connection test failed:', error);\n                return false;\n            }\n        });\n    }\n    /**\n     * List available Gemini models\n     */\n    listModels() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const response = yield this.client.get(`/models?key=${this.config.apiKey}`);\n                if (response.data && response.data.models) {\n                    return response.data.models\n                        .filter((model) => model.name.includes('gemini'))\n                        .map((model) => model.name.replace('models/', ''))\n                        .sort();\n                }\n                // Return default models if API call fails\n                return [\n                    'gemini-2.5-flash',\n                    'gemini-1.5-flash',\n                    'gemini-1.5-pro',\n                    'gemini-pro',\n                    'gemini-pro-vision'\n                ];\n            }\n            catch (error) {\n                console.error('Failed to list Gemini models:', error);\n                // Return default models on error\n                return [\n                    'gemini-2.5-flash',\n                    'gemini-1.5-flash',\n                    'gemini-1.5-pro',\n                    'gemini-pro',\n                    'gemini-pro-vision'\n                ];\n            }\n        });\n    }\n    /**\n     * Generate completion using Gemini API\n     */\n    generateCompletion(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const startTime = Date.now();\n            try {\n                const payload = this.buildRequestPayload(request);\n                this.logRequest(payload);\n                const modelName = this.normalizeModelName(request.model);\n                const url = `/models/${modelName}:generateContent?key=${this.config.apiKey}`;\n                const response = yield this.client.post(url, payload);\n                const aiResponse = this.parseResponse(response.data, startTime);\n                this.logResponse(aiResponse);\n                return aiResponse;\n            }\n            catch (error) {\n                console.error('Gemini completion failed:', error);\n                throw this.handleError(error);\n            }\n        });\n    }\n    /**\n     * Generate streaming completion (placeholder implementation)\n     */\n    generateStreamingCompletion(request, onChunk) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // For now, implement as non-streaming\n            // TODO: Implement actual streaming support using streamGenerateContent\n            const response = yield this.generateCompletion(request);\n            onChunk(response.text);\n            return response;\n        });\n    }\n    /**\n     * Validate Gemini parameters\n     */\n    validateParameters(model, parameters) {\n        const errors = [];\n        const params = parameters;\n        // Validate temperature\n        if (params.temperature !== undefined) {\n            if (params.temperature < 0 || params.temperature > 2) {\n                errors.push('temperature must be between 0 and 2');\n            }\n        }\n        // Validate maxTokens\n        if (params.maxTokens !== undefined) {\n            if (params.maxTokens < 1 || params.maxTokens > 8192) {\n                errors.push('maxTokens must be between 1 and 8192');\n            }\n        }\n        // Validate topK\n        if (params.topK !== undefined) {\n            if (params.topK < 1 || params.topK > 40) {\n                errors.push('topK must be between 1 and 40');\n            }\n        }\n        // Validate topP\n        if (params.topP !== undefined) {\n            if (params.topP < 0 || params.topP > 1) {\n                errors.push('topP must be between 0 and 1');\n            }\n        }\n        return {\n            valid: errors.length === 0,\n            errors\n        };\n    }\n    /**\n     * Normalize parameters to Gemini format\n     */\n    normalizeParameters(parameters) {\n        const params = parameters;\n        const normalized = {};\n        // Map to Gemini generationConfig format\n        const generationConfig = {};\n        if (params.temperature !== undefined)\n            generationConfig.temperature = params.temperature;\n        if (params.maxTokens !== undefined)\n            generationConfig.maxOutputTokens = params.maxTokens;\n        if (params.topK !== undefined)\n            generationConfig.topK = params.topK;\n        if (params.topP !== undefined)\n            generationConfig.topP = params.topP;\n        if (Object.keys(generationConfig).length > 0) {\n            normalized.generationConfig = generationConfig;\n        }\n        // Handle safety settings\n        if (params.safetySettings) {\n            normalized.safetySettings = params.safetySettings;\n        }\n        return this.sanitizeParameters(normalized);\n    }\n    /**\n     * Build Gemini API request payload\n     */\n    buildRequestPayload(request) {\n        const parameters = this.normalizeParameters(request.parameters);\n        const params = request.parameters;\n        // Build contents array\n        const contents = [];\n        // Add conversation history if provided\n        if (request.conversationHistory) {\n            request.conversationHistory.forEach(msg => {\n                contents.push({\n                    parts: [{ text: msg.content }],\n                    role: msg.role === 'assistant' ? 'model' : 'user'\n                });\n            });\n        }\n        // Add current prompt\n        contents.push({\n            parts: [{ text: request.prompt }],\n            role: 'user'\n        });\n        const payload = Object.assign({ contents }, parameters);\n        // Add system instruction if provided\n        const systemMessage = params.systemInstruction || request.systemMessage;\n        if (systemMessage) {\n            payload.systemInstruction = {\n                parts: [{ text: systemMessage }],\n                role: 'system'\n            };\n        }\n        return payload;\n    }\n    /**\n     * Parse Gemini response to standard format\n     */\n    parseResponse(response, startTime) {\n        var _a, _b, _c, _d;\n        const candidate = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0];\n        if (!candidate) {\n            throw new Error('No candidates returned from Gemini API');\n        }\n        const text = ((_d = (_c = (_b = candidate.content) === null || _b === void 0 ? void 0 : _b.parts) === null || _c === void 0 ? void 0 : _c[0]) === null || _d === void 0 ? void 0 : _d.text) || '';\n        return {\n            text,\n            usage: response.usageMetadata ? {\n                promptTokens: response.usageMetadata.promptTokenCount,\n                completionTokens: response.usageMetadata.candidatesTokenCount,\n                totalTokens: response.usageMetadata.totalTokenCount\n            } : undefined,\n            metadata: {\n                finishReason: candidate.finishReason,\n                safetyRatings: candidate.safetyRatings,\n                promptFeedback: response.promptFeedback\n            },\n            model: 'gemini', // Gemini doesn't return model in response\n            processingTime: this.calculateProcessingTime(startTime)\n        };\n    }\n    /**\n     * Add Gemini-specific authentication headers\n     */\n    addAuthHeaders(headers) {\n        // Gemini uses API key in query params, not headers\n        // But we include it here for completeness\n        headers['x-goog-api-key'] = this.config.apiKey;\n    }\n    /**\n     * Normalize model name for Gemini API\n     */\n    normalizeModelName(model) {\n        // Remove 'models/' prefix if present\n        if (model.startsWith('models/')) {\n            return model.substring(7);\n        }\n        return model;\n    }\n}\nexports.GeminiService = GeminiService;\n/**\n * Factory function for creating Gemini service instances\n */\nfunction createGeminiService(config) {\n    return new GeminiService(config);\n}\n",
      "metadata": {
        "filename": "GeminiService.js",
        "path": "/backend/dist/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/ai/OpenAIService.js\n\n\"use strict\";\n/**\n * @file OpenAIService.ts\n * @description OpenAI AI service implementation.\n * Provides integration with OpenAI's GPT models including GPT-4, GPT-4 Turbo, and GPT-3.5.\n * Handles OpenAI-specific parameter mapping, authentication, and response parsing.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OpenAIService = void 0;\nexports.createOpenAIService = createOpenAIService;\nconst axios_1 = __importDefault(require(\"axios\"));\nconst BaseAIService_1 = require(\"./BaseAIService\");\n/**\n * OpenAI service implementation\n */\nclass OpenAIService extends BaseAIService_1.BaseAIService {\n    constructor(config) {\n        const capabilities = {\n            supportedParameters: [\n                'temperature',\n                'maxTokens',\n                'top_p',\n                'presence_penalty',\n                'frequency_penalty',\n                'systemMessage',\n                'n',\n                'stop'\n            ],\n            maxContextLength: 128000, // GPT-4 context length\n            supportsStreaming: true,\n            supportsFunctionCalling: true,\n            supportsImages: true\n        };\n        super('openai', config, capabilities);\n        this.baseUrl = config.baseUrl || 'https://api.openai.com/v1';\n        this.client = axios_1.default.create({\n            baseURL: this.baseUrl,\n            timeout: config.timeout || 30000,\n            headers: this.getRequestHeaders()\n        });\n    }\n    /**\n     * Test connection to OpenAI API\n     */\n    testConnection() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const response = yield this.client.get('/models');\n                return response.status === 200;\n            }\n            catch (error) {\n                console.error('OpenAI connection test failed:', error);\n                return false;\n            }\n        });\n    }\n    /**\n     * List available OpenAI models\n     */\n    listModels() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const response = yield this.client.get('/models');\n                // Filter to only include GPT models that are relevant for text generation\n                const gptModels = response.data.data\n                    .filter((model) => model.id.includes('gpt') &&\n                    !model.id.includes('instruct') &&\n                    !model.id.includes('edit') &&\n                    !model.id.includes('whisper') &&\n                    !model.id.includes('tts') &&\n                    !model.id.includes('dall-e'))\n                    .map((model) => model.id)\n                    .sort();\n                return gptModels;\n            }\n            catch (error) {\n                console.error('Failed to list OpenAI models:', error);\n                throw this.handleError(error);\n            }\n        });\n    }\n    /**\n     * Generate completion using OpenAI API\n     */\n    generateCompletion(request) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const startTime = Date.now();\n            try {\n                const payload = this.buildRequestPayload(request);\n                this.logRequest(payload);\n                const response = yield this.client.post('/chat/completions', payload);\n                const aiResponse = this.parseResponse(response.data, startTime);\n                this.logResponse(aiResponse);\n                return aiResponse;\n            }\n            catch (error) {\n                console.error('OpenAI completion failed:', error);\n                throw this.handleError(error);\n            }\n        });\n    }\n    /**\n     * Generate streaming completion (placeholder implementation)\n     */\n    generateStreamingCompletion(request, onChunk) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // For now, implement as non-streaming\n            // TODO: Implement actual streaming support\n            const response = yield this.generateCompletion(request);\n            onChunk(response.text);\n            return response;\n        });\n    }\n    /**\n     * Validate OpenAI parameters\n     */\n    validateParameters(model, parameters) {\n        const errors = [];\n        const params = parameters;\n        // Validate temperature\n        if (params.temperature !== undefined) {\n            if (params.temperature < 0 || params.temperature > 2) {\n                errors.push('temperature must be between 0 and 2');\n            }\n        }\n        // Validate maxTokens\n        if (params.maxTokens !== undefined) {\n            if (params.maxTokens < 1 || params.maxTokens > 4096) {\n                errors.push('maxTokens must be between 1 and 4096');\n            }\n        }\n        // Validate top_p\n        if (params.top_p !== undefined) {\n            if (params.top_p < 0 || params.top_p > 1) {\n                errors.push('top_p must be between 0 and 1');\n            }\n        }\n        // Validate presence_penalty\n        if (params.presence_penalty !== undefined) {\n            if (params.presence_penalty < -2 || params.presence_penalty > 2) {\n                errors.push('presence_penalty must be between -2 and 2');\n            }\n        }\n        // Validate frequency_penalty\n        if (params.frequency_penalty !== undefined) {\n            if (params.frequency_penalty < -2 || params.frequency_penalty > 2) {\n                errors.push('frequency_penalty must be between -2 and 2');\n            }\n        }\n        // Validate n\n        if (params.n !== undefined) {\n            if (params.n < 1 || params.n > 4) {\n                errors.push('n must be between 1 and 4');\n            }\n        }\n        return {\n            valid: errors.length === 0,\n            errors\n        };\n    }\n    /**\n     * Normalize parameters to OpenAI format\n     */\n    normalizeParameters(parameters) {\n        const params = parameters;\n        const normalized = {};\n        // Map standard parameters\n        if (params.temperature !== undefined)\n            normalized.temperature = params.temperature;\n        if (params.maxTokens !== undefined)\n            normalized.max_tokens = params.maxTokens;\n        if (params.top_p !== undefined)\n            normalized.top_p = params.top_p;\n        if (params.presence_penalty !== undefined)\n            normalized.presence_penalty = params.presence_penalty;\n        if (params.frequency_penalty !== undefined)\n            normalized.frequency_penalty = params.frequency_penalty;\n        if (params.n !== undefined)\n            normalized.n = params.n;\n        if (params.stop !== undefined)\n            normalized.stop = params.stop;\n        return this.sanitizeParameters(normalized);\n    }\n    /**\n     * Build OpenAI API request payload\n     */\n    buildRequestPayload(request) {\n        const parameters = this.normalizeParameters(request.parameters);\n        const params = request.parameters;\n        // Build messages array\n        const messages = [];\n        // Add system message if provided\n        const systemMessage = params.systemMessage || request.systemMessage;\n        if (systemMessage) {\n            messages.push({\n                role: 'system',\n                content: systemMessage\n            });\n        }\n        // Add conversation history if provided\n        if (request.conversationHistory) {\n            request.conversationHistory.forEach(msg => {\n                messages.push({\n                    role: msg.role,\n                    content: msg.content\n                });\n            });\n        }\n        // Add current prompt\n        messages.push({\n            role: 'user',\n            content: request.prompt\n        });\n        return Object.assign({ model: request.model, messages }, parameters);\n    }\n    /**\n     * Parse OpenAI response to standard format\n     */\n    parseResponse(response, startTime) {\n        const choice = response.choices[0];\n        if (!choice) {\n            throw new Error('No choices returned from OpenAI API');\n        }\n        return {\n            text: choice.message.content || '',\n            usage: response.usage ? {\n                promptTokens: response.usage.prompt_tokens,\n                completionTokens: response.usage.completion_tokens,\n                totalTokens: response.usage.total_tokens\n            } : undefined,\n            metadata: {\n                id: response.id,\n                created: response.created,\n                finishReason: choice.finish_reason\n            },\n            model: response.model,\n            processingTime: this.calculateProcessingTime(startTime)\n        };\n    }\n    /**\n     * Add OpenAI-specific authentication headers\n     */\n    addAuthHeaders(headers) {\n        headers['Authorization'] = `Bearer ${this.config.apiKey}`;\n    }\n}\nexports.OpenAIService = OpenAIService;\n/**\n * Factory function for creating OpenAI service instances\n */\nfunction createOpenAIService(config) {\n    return new OpenAIService(config);\n}\n",
      "metadata": {
        "filename": "OpenAIService.js",
        "path": "/backend/dist/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/geminiService.js\n\n\"use strict\";\n/**\n * @file geminiService.ts\n * @description Service module for interacting with Google's Gemini AI API.\n * Provides functionality for prompt testing, SFL prompt generation, and workflow creation\n * using the Gemini language model. This service handles API communication, response parsing,\n * and error handling for all Gemini-related operations.\n *\n * @requires @google/genai\n * @requires ../types\n * @since 0.5.1\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst genai_1 = require(\"@google/genai\");\n/**\n * @constant {string|undefined} API_KEY\n * @description The API key for accessing Google's Gemini API, retrieved from environment variables.\n * @private\n */\nconst API_KEY = process.env.GEMINI_API_KEY;\nif (!API_KEY) {\n    console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\n/**\n * @constant {GoogleGenAI} ai\n * @description Initialized GoogleGenAI client instance for API communication.\n * @private\n */\nconst ai = new genai_1.GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\n/**\n * Parses JSON content from AI-generated text using multiple extraction strategies.\n * This utility function handles various formats that the AI might return, including\n * code blocks, plain JSON, and text with prefixes.\n *\n * @param {string} text - The raw text response from the AI that contains JSON data.\n * @returns {any} The parsed JSON object.\n * @throws {Error} Throws an error if all parsing strategies fail.\n *\n * @example\n * ```typescript\n * const aiResponse = \"```json\\n{\\\"key\\\": \\\"value\\\"}\\n```\";\n * const parsed = parseJsonFromText(aiResponse);\n * console.log(parsed); // { key: \"value\" }\n * ```\n *\n * @since 0.5.1\n * @private\n */\nconst parseJsonFromText = (text) => {\n    console.log(\"Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n    // Try multiple extraction strategies\n    const strategies = [\n        // Strategy 1: Extract code block content (original)\n        () => {\n            const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n            const match = text.match(fenceRegex);\n            return match && match[1] ? match[1].trim() : null;\n        },\n        // Strategy 2: Extract content between first { and last }\n        () => {\n            const firstBrace = text.indexOf('{');\n            const lastBrace = text.lastIndexOf('}');\n            if (firstBrace !== -1 && lastBrace > firstBrace) {\n                return text.substring(firstBrace, lastBrace + 1);\n            }\n            return null;\n        },\n        // Strategy 3: Try the text as-is if it starts with {\n        () => {\n            const trimmed = text.trim();\n            return trimmed.startsWith('{') ? trimmed : null;\n        },\n        // Strategy 4: Remove common prefixes and try again\n        () => {\n            const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n            const firstBrace = cleaned.indexOf('{');\n            const lastBrace = cleaned.lastIndexOf('}');\n            if (firstBrace !== -1 && lastBrace > firstBrace) {\n                return cleaned.substring(firstBrace, lastBrace + 1);\n            }\n            return null;\n        }\n    ];\n    // Try each strategy\n    for (let i = 0; i < strategies.length; i++) {\n        const jsonStr = strategies[i]();\n        if (jsonStr) {\n            try {\n                console.log(`Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n                const parsed = JSON.parse(jsonStr);\n                console.log(\"Successfully parsed JSON with strategy\", i + 1);\n                return parsed;\n            }\n            catch (e) {\n                console.log(`Strategy ${i + 1} failed to parse:`, e);\n                continue;\n            }\n        }\n    }\n    // If all strategies fail, log detailed error info\n    console.error(\"All JSON parsing strategies failed\");\n    console.error(\"Raw text length:\", text.length);\n    console.error(\"Raw text preview:\", text.substring(0, 500));\n    console.error(\"Text ends with:\", text.substring(Math.max(0, text.length - 100)));\n    throw new Error(\"The AI returned a response that could not be parsed as JSON using any available strategy.\");\n};\n/**\n * @class GeminiService\n * @description Service class for interacting with Google's Gemini AI API.\n * Provides methods for testing prompts, generating SFL-structured prompts from goals,\n * regenerating prompts based on suggestions, and creating workflows.\n *\n * @since 0.5.1\n */\nclass GeminiService {\n    /**\n     * Tests a prompt by sending it to the Gemini API and returning the response.\n     * This method is used for validating prompt effectiveness and getting sample responses.\n     *\n     * @param {string} promptText - The prompt text to test with the Gemini model.\n     * @returns {Promise<string>} A promise that resolves to the AI-generated response text.\n     * @throws {Error} Throws an error if the API key is not configured or if the API call fails.\n     *\n     * @example\n     * ```typescript\n     * const service = new GeminiService();\n     * try {\n     *   const response = await service.testPrompt(\"Explain quantum computing briefly.\");\n     *   console.log(\"AI Response:\", response);\n     * } catch (error) {\n     *   console.error(\"Test failed:\", error.message);\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    testPrompt(promptText) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b, _c, _d, _e;\n            if (!API_KEY) {\n                throw new Error(\"Gemini API Key is not configured.\");\n            }\n            try {\n                const response = yield ai.models.generateContent({\n                    model: 'gemini-2.5-flash',\n                    contents: [{ role: \"user\", parts: [{ text: promptText }] }],\n                });\n                return ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"\";\n            }\n            catch (error) {\n                console.error(\"Error calling Gemini API:\", error);\n                if (error instanceof Error) {\n                    throw new Error(`Gemini API Error: ${error.message}`);\n                }\n                throw new Error(\"An unknown error occurred while contacting the Gemini API.\");\n            }\n        });\n    }\n    /**\n     * Generates a complete SFL (Systemic Functional Linguistics) prompt structure from a high-level goal.\n     * This method uses AI to analyze the goal and create structured prompt components including\n     * Field (what), Tenor (who), and Mode (how) aspects. Optionally incorporates style from a source document.\n     *\n     * @param {string} goal - A natural language description of what the user wants to achieve.\n     * @param {string} [sourceDocContent] - Optional content from a source document to provide stylistic reference.\n     * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise resolving to the generated SFL prompt structure.\n     * @throws {Error} Throws an error if the API key is not configured or if the generation fails.\n     *\n     * @example\n     * ```typescript\n     * const service = new GeminiService();\n     * const goal = \"Create a formal business proposal for a new software project\";\n     * const sourceDoc = \"Sample business document text for style reference...\";\n     * try {\n     *   const sflPrompt = await service.generateSFLFromGoal(goal, sourceDoc);\n     *   console.log(\"Generated SFL prompt:\", sflPrompt.title);\n     * } catch (error) {\n     *   console.error(\"Generation failed:\", error.message);\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    generateSFLFromGoal(goal, sourceDocContent) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b, _c, _d, _e;\n            if (!API_KEY) {\n                throw new Error(\"Gemini API Key is not configured.\");\n            }\n            const systemInstruction = `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to analyze a user's goal and structure it into a detailed SFL-based prompt.\\n    If a source document is provided for stylistic reference, you MUST analyze its style (e.g., tone, complexity, vocabulary, sentence structure) and incorporate those stylistic qualities into the SFL fields and the final promptText. For example, update the 'desiredTone', 'aiPersona', and 'textualDirectives' to match the source. The generated 'promptText' should be a complete, standalone prompt that implicitly carries the desired style.\\n    The output MUST be a single, valid JSON object. Do not include any text, notes, or explanations outside of the JSON object.\\n    The JSON object should have the following structure: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string }.\\n    \\n    - title: Create a concise, descriptive title based on the user's goal.\\n    - promptText: Synthesize all the SFL elements into a complete, well-formed prompt that can be sent directly to an AI.\\n    - sflField (What is happening?): Analyze the subject matter.\\n    - sflTenor (Who is taking part?): Define the roles and relationships. The \"targetAudience\" field must be an array of strings, even if only one audience is identified.\\n    - sflMode (How is it being communicated?): Specify the format and structure of the output.\\n    - exampleOutput: Provide a brief but illustrative example of the expected output.\\n    - notes: Add any relevant notes or suggestions for the user.\\n    - All fields in the JSON must be filled with meaningful content.`;\n            const userContent = sourceDocContent\n                ? `Source document for style reference:\\n\\n---\\n\\n${sourceDocContent}\\n\\n----\\n\\nUser's goal: \"${goal}\"`\n                : `Here is the user's goal: \"${goal}\"`;\n            try {\n                const response = yield ai.models.generateContent({\n                    model: 'gemini-2.5-flash',\n                    contents: [{ role: \"user\", parts: [{ text: userContent }] }],\n                    config: {\n                        responseMimeType: \"application/json\",\n                        systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n                    },\n                });\n                const text = ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"{}\";\n                const jsonData = parseJsonFromText(text);\n                if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n                    jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n                }\n                if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n                    jsonData.sflTenor.targetAudience = [];\n                }\n                return jsonData;\n            }\n            catch (error) {\n                console.error(\"Error calling Gemini API for SFL generation:\", error);\n                if (error instanceof Error) {\n                    throw new Error(`Gemini API Error: ${error.message}`);\n                }\n                throw new Error(\"An unknown error occurred while generating the SFL prompt.\");\n            }\n        });\n    }\n    /**\n     * Regenerates an existing SFL prompt based on a user's suggestion for improvement.\n     * This method takes an existing prompt and a natural language suggestion, then uses AI\n     * to intelligently modify the prompt structure while maintaining SFL principles.\n     *\n     * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>} currentPrompt - The existing prompt to be modified.\n     * @param {string} suggestion - A natural language suggestion for how to improve or change the prompt.\n     * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise resolving to the regenerated SFL prompt structure.\n     * @throws {Error} Throws an error if the API key is not configured or if the regeneration fails.\n     *\n     * @example\n     * ```typescript\n     * const service = new GeminiService();\n     * const existingPrompt = { // ... existing SFL prompt structure };\n     * const suggestion = \"Make the tone more casual and add examples\";\n     * try {\n     *   const improvedPrompt = await service.regenerateSFLFromSuggestion(existingPrompt, suggestion);\n     *   console.log(\"Improved prompt:\", improvedPrompt.title);\n     * } catch (error) {\n     *   console.error(\"Regeneration failed:\", error.message);\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    regenerateSFLFromSuggestion(currentPrompt, suggestion) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b, _c, _d, _e;\n            if (!API_KEY) {\n                throw new Error(\"Gemini API Key is not configured.\");\n            }\n            const systemInstruction = `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to revise an existing SFL prompt based on a user's suggestion.\\n    The user will provide a JSON object representing the current prompt and a text string with their requested change.\\n    If a source document is provided (as part of the prompt object or separately), its style should be analyzed and take precedence, influencing the revision.\\n    You MUST return a single, valid JSON object that represents the *revised* prompt. Do not include any text, notes, or explanations outside of the JSON object.\\n    The output JSON object must have the exact same structure as the input, containing all the original fields, but with values updated according to the suggestion and stylistic source.\\n    The structure is: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string, \"sourceDocument\": { \"name\": string, \"content\": string } | undefined }.\\n    \\n    - Critically analyze the user's suggestion and apply it to all relevant fields in the prompt.\\n    - If a 'sourceDocument' is present, ensure its style is reflected in the revised SFL fields and 'promptText'.\\n    - The 'promptText' field is the most important; it must be re-written to reflect the change.\\n    - Other SFL fields (Field, Tenor, Mode) should be updated logically to align with the new 'promptText' and the user's suggestion.\\n    - Even update the 'title', 'exampleOutput', and 'notes' if the suggestion implies it.\\n    - Ensure 'targetAudience' remains an array of strings.\\n    - Preserve the 'sourceDocument' field in the output if it existed in the input.`;\n            // eslint-disable-next-line @typescript-eslint/no-unused-vars\n            const { sourceDocument } = currentPrompt, promptForPayload = __rest(currentPrompt, [\"sourceDocument\"]);\n            const userContent = `\n    Here is the current prompt JSON:\n    ${JSON.stringify(promptForPayload)}\n    \n    ${sourceDocument ? `This prompt is associated with the following source document for stylistic reference:\\n---\\n${sourceDocument.content}\\n---\\n` : ''}\n\n    Here is my suggestion for how to change it:\n    \"${suggestion}\"\n\n    Now, provide the complete, revised JSON object.\n    `;\n            try {\n                const response = yield ai.models.generateContent({\n                    model: 'gemini-2.5-flash',\n                    contents: [{ role: \"user\", parts: [{ text: userContent }] }],\n                    config: {\n                        responseMimeType: \"application/json\",\n                        systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n                    },\n                });\n                const text = ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"{}\";\n                const jsonData = parseJsonFromText(text);\n                if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n                    jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n                }\n                if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n                    jsonData.sflTenor.targetAudience = [];\n                }\n                // Preserve the source document from the original prompt\n                jsonData.sourceDocument = sourceDocument;\n                return jsonData;\n            }\n            catch (error) {\n                console.error(\"Error calling Gemini API for SFL regeneration:\", error);\n                if (error instanceof Error) {\n                    throw new Error(`Gemini API Error: ${error.message}`);\n                }\n                throw new Error(\"An unknown error occurred while regenerating the SFL prompt.\");\n            }\n        });\n    }\n    /**\n     * Generates a complete workflow structure from a high-level goal description.\n     * This method uses AI to analyze a user's goal and create a multi-task workflow\n     * with appropriate task types, dependencies, and data flow connections.\n     *\n     * @param {string} goal - A natural language description of the multi-step process to automate.\n     * @returns {Promise<Workflow>} A promise resolving to the generated workflow structure with tasks.\n     * @throws {Error} Throws an error if the API key is not configured or if the workflow generation fails.\n     *\n     * @example\n     * ```typescript\n     * const service = new GeminiService();\n     * const goal = \"Analyze customer feedback sentiment and generate a summary report\";\n     * try {\n     *   const workflow = await service.generateWorkflowFromGoal(goal);\n     *   console.log(`Generated workflow \"${workflow.name}\" with ${workflow.tasks.length} tasks`);\n     * } catch (error) {\n     *   console.error(\"Workflow generation failed:\", error.message);\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    generateWorkflowFromGoal(goal) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b, _c, _d, _e;\n            if (!API_KEY) {\n                throw new Error(\"Gemini API Key is not configured.\");\n            }\n            const systemInstruction = `You are an expert AI workflow orchestrator. Your task is to analyze a user's goal and generate a complete, multi-task workflow as a valid JSON object.\\n    \\nThe user goal will be provided. Based on this, create a workflow with a series of tasks. The output MUST be a single, valid JSON object representing the workflow. Do not include any text or explanations outside the JSON.\\n\\nThe root JSON object must have 'name', 'description', and 'tasks' fields. Each task in the 'tasks' array must have the following fields:\\n- id: A unique string identifier for the task (e.g., \"task-1\").\\n- name: A short, descriptive name for the task.\\n- description: A one-sentence explanation of what the task does.\\n- type: One of \"DATA_INPUT\", \"GEMINI_PROMPT\", \"IMAGE_ANALYSIS\", \"TEXT_MANIPULATION\", \"DISPLAY_CHART\", \"GEMINI_GROUNDED\".\\n- dependencies: An array of task IDs that this task depends on. Empty for initial tasks.\\n- inputKeys: An array of strings representing keys from the Data Store needed for this task. Use dot notation for nested keys (e.g., \"userInput.text\").\\n- outputKey: A string for the key where the task's result will be stored in the Data Store.\\n\\nRules for specific task types:\\n- GEMINI_PROMPT/IMAGE_ANALYSIS: Must include a 'promptTemplate' field. Use {{key}} for placeholders.\\n- TEXT_MANIPULATION: Must include a 'functionBody' field containing a JavaScript function body as a string. E.g., \"return \\`Report: \\${inputs.summary}\\`\".\\n- DATA_INPUT: Must include a 'staticValue' field. Use \"{{userInput.text}}\", \"{{userInput.image}}\", or \"{{userInput.file}}\" to get data from the user input area.\\n- DISPLAY_CHART: Must include a 'dataKey' field pointing to data in the Data Store suitable for charting.\\n- GEMINI_GROUNDED: For tasks requiring up-to-date information. Should have a 'promptTemplate'.\\n\\nExample Goal: \"Analyze a user-provided text for sentiment and then summarize it.\"\\nExample Output:\\n{\\n  \"name\": \"Sentiment Analysis and Summary\",\\n  \"description\": \"A workflow that first determines the sentiment of a text and then provides a concise summary.\",\\n  \"tasks\": [\\n    { \"id\": \"task-1\", \"name\": \"Get User Text\", \"description\": \"Receives the text to be analyzed from the user.\", \"type\": \"DATA_INPUT\", \"dependencies\": [], \"inputKeys\": [], \"outputKey\": \"inputText\", \"staticValue\": \"{{userInput.text}}\" },\\n    { \"id\": \"task-2\", \"name\": \"Analyze Sentiment\", \"description\": \"Determines if the text is positive, negative, or neutral.\", \"type\": \"GEMINI_PROMPT\", \"dependencies\": [\"task-1\"], \"inputKeys\": [\"inputText\"], \"outputKey\": \"sentiment\", \"promptTemplate\": \"Analyze the sentiment of the following text and return only 'positive', 'negative', or 'neutral':\\\\n\\\\n{{inputText}}\" },\\n    { \"id\": \"task-3\", \"name\": \"Summarize Text\", \"description\": \"Creates a one-sentence summary of the text.\", \"type\": \"GEMINI_PROMPT\", \"dependencies\": [\"task-1\"], \"inputKeys\": [\"inputText\"], \"outputKey\": \"summary\", \"promptTemplate\": \"Summarize the following text in a single sentence:\\\\n\\\\n{{inputText}}\" },\\n    { \"id\": \"task-4\", \"name\": \"Format Report\", \"description\": \"Combines the sentiment and summary into a final report.\", \"type\": \"TEXT_MANIPULATION\", \"dependencies\": [\"task-2\", \"task-3\"], \"inputKeys\": [\"sentiment\", \"summary\"], \"outputKey\": \"finalReport\", \"functionBody\": \"return \\`Sentiment: \\${inputs.sentiment.toUpperCase()}\\nSummary: \\${inputs.summary}\\`\" }\\n  ]\\n}`;\n            try {\n                const response = yield ai.models.generateContent({\n                    model: 'gemini-2.5-flash',\n                    contents: [{ role: \"user\", parts: [{ text: `User's goal: \"${goal}\"` }] }],\n                    config: {\n                        responseMimeType: \"application/json\",\n                        systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n                    },\n                });\n                const text = ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"{}\";\n                const jsonData = parseJsonFromText(text);\n                if (!jsonData.name || !jsonData.description || !Array.isArray(jsonData.tasks)) {\n                    throw new Error(\"Generated workflow is missing required fields (name, description, tasks).\");\n                }\n                jsonData.id = `wf-custom-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n                return jsonData;\n            }\n            catch (error) {\n                console.error(\"Error calling Gemini API for Workflow generation:\", error);\n                if (error instanceof Error) {\n                    throw new Error(`Gemini API Error: ${error.message}`);\n                }\n                throw new Error(\"An unknown error occurred while generating the workflow.\");\n            }\n        });\n    }\n}\n/**\n * @exports {GeminiService} geminiService\n * @description Singleton instance of the GeminiService class, ready to be used across the application.\n * This exported instance provides all Gemini AI functionality including prompt testing,\n * SFL generation, and workflow creation.\n *\n * @since 0.5.1\n */\nexports.default = new GeminiService();\n",
      "metadata": {
        "filename": "geminiService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/jobService.js\n\n\"use strict\";\n/**\n * @file jobService.ts\n * @description Job service that manages background workflow execution using BullMQ.\n * Provides functionality to add workflow execution jobs to a queue and process them\n * asynchronously. Integrates with the existing workflowExecutionService for actual execution.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst bullmq_1 = require(\"bullmq\");\nconst ioredis_1 = __importDefault(require(\"ioredis\"));\nconst env_1 = __importDefault(require(\"../config/env\"));\nconst workflowExecutionService_1 = __importDefault(require(\"./workflowExecutionService\"));\nconst promptService_1 = __importDefault(require(\"./promptService\"));\nconst webSocketService_1 = __importDefault(require(\"./webSocketService\"));\n/**\n * Service class for managing workflow execution jobs using BullMQ\n */\nclass JobService {\n    constructor() {\n        if (!env_1.default.redisUrl) {\n            console.warn('REDIS_URL environment variable not set, job service will be disabled');\n            return;\n        }\n        try {\n            // Initialize Redis connection with BullMQ-compatible settings\n            this.redis = new ioredis_1.default(env_1.default.redisUrl, {\n                maxRetriesPerRequest: null, // Required for BullMQ\n                lazyConnect: true, // Don't connect immediately\n            });\n            // Initialize BullMQ queue\n            this.queue = new bullmq_1.Queue('workflow-execution', {\n                connection: this.redis,\n                defaultJobOptions: {\n                    removeOnComplete: 10, // Keep last 10 completed jobs\n                    removeOnFail: 50, // Keep last 50 failed jobs\n                    attempts: 3, // Retry failed jobs up to 3 times\n                    backoff: {\n                        type: 'exponential',\n                        delay: 2000,\n                    },\n                },\n            });\n            // Initialize BullMQ worker\n            this.worker = new bullmq_1.Worker('workflow-execution', this.processWorkflowJob.bind(this), {\n                connection: this.redis,\n                concurrency: 5, // Process up to 5 jobs concurrently\n            });\n            // Set up worker event listeners\n            this.setupWorkerEvents();\n        }\n        catch (error) {\n            console.error('Failed to initialize job service:', error);\n            throw error;\n        }\n    }\n    /**\n     * Adds a workflow execution job to the queue\n     * @param workflowId - Unique identifier for the workflow\n     * @param workflow - The workflow object to execute\n     * @param userInput - Optional user input data\n     * @returns Promise resolving to the job ID\n     */\n    addWorkflowJob(workflowId, workflow, userInput) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.queue) {\n                throw new Error('Job service not initialized - Redis connection not available');\n            }\n            const jobData = {\n                workflowId,\n                workflow,\n                userInput,\n            };\n            const job = yield this.queue.add('execute-workflow', jobData, {\n                jobId: `workflow-${workflowId}-${Date.now()}`,\n            });\n            return job.id;\n        });\n    }\n    /**\n     * Gets the status of a specific job\n     * @param jobId - The job ID to check\n     * @returns Promise resolving to job status information\n     */\n    getJobStatus(jobId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.queue) {\n                throw new Error('Job service not initialized - Redis connection not available');\n            }\n            const job = yield this.queue.getJob(jobId);\n            if (!job) {\n                return null;\n            }\n            return {\n                id: job.id,\n                status: yield job.getState(),\n                progress: job.progress,\n                returnValue: job.returnvalue,\n                failedReason: job.failedReason,\n                processedOn: job.processedOn,\n                finishedOn: job.finishedOn,\n            };\n        });\n    }\n    /**\n     * Stops a specific job\n     * @param jobId - The job ID to stop\n     * @returns Promise resolving to success status\n     */\n    stopJob(jobId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!this.queue) {\n                throw new Error('Job service not initialized - Redis connection not available');\n            }\n            const job = yield this.queue.getJob(jobId);\n            if (!job) {\n                return false;\n            }\n            const jobState = yield job.getState();\n            // Can only stop jobs that are waiting, active, or delayed\n            if (['waiting', 'active', 'delayed'].includes(jobState)) {\n                try {\n                    // Remove the job from the queue\n                    yield job.remove();\n                    // Broadcast stop message to WebSocket clients\n                    webSocketService_1.default.broadcastToJob(jobId, {\n                        type: 'workflow_stopped',\n                        workflowId: job.data.workflowId,\n                        status: 'stopped',\n                        reason: 'user_cancelled',\n                    });\n                    return true;\n                }\n                catch (error) {\n                    console.error(`Failed to stop job ${jobId}:`, error);\n                    return false;\n                }\n            }\n            return false; // Job is already completed or failed\n        });\n    }\n    /**\n     * Processes a workflow execution job\n     * @param job - The BullMQ job to process\n     * @returns Promise resolving to the workflow execution result\n     */\n    processWorkflowJob(job) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b;\n            const { workflowId, workflow, userInput } = job.data;\n            try {\n                // Update job progress\n                yield job.updateProgress({ status: 'started', workflowId });\n                // Get prompts needed for the workflow\n                const promptIds = (workflow.tasks || [])\n                    .filter(task => task.promptId)\n                    .map(task => task.promptId);\n                const prompts = [];\n                for (const promptId of promptIds) {\n                    const prompt = yield promptService_1.default.getPromptById(promptId);\n                    if (prompt) {\n                        prompts.push(prompt);\n                    }\n                }\n                // Execute workflow tasks in order\n                const results = {};\n                const dataStore = { userInput: userInput || {} };\n                // Simple sequential execution for now (will be enhanced with topological sort later)\n                const tasks = workflow.tasks || [];\n                for (let i = 0; i < tasks.length; i++) {\n                    const task = tasks[i];\n                    try {\n                        // Check if job has been cancelled before processing each task\n                        const currentJob = yield ((_a = this.queue) === null || _a === void 0 ? void 0 : _a.getJob(job.id));\n                        if (!currentJob) {\n                            // Job was removed (cancelled)\n                            throw new Error('Workflow execution was cancelled');\n                        }\n                        // Update progress for current task\n                        yield job.updateProgress({\n                            status: 'active',\n                            taskId: task.id,\n                            taskName: task.name,\n                            currentTask: i + 1,\n                            totalTasks: tasks.length,\n                        });\n                        // Find the prompt for this task if it has one\n                        const linkedPrompt = task.promptId\n                            ? prompts.find(p => p.id === task.promptId)\n                            : undefined;\n                        // Execute the task\n                        const result = yield workflowExecutionService_1.default.executeTask(task, dataStore, linkedPrompt);\n                        // Check again for cancellation after task execution\n                        const jobAfterExecution = yield ((_b = this.queue) === null || _b === void 0 ? void 0 : _b.getJob(job.id));\n                        if (!jobAfterExecution) {\n                            // Job was removed (cancelled) during execution\n                            throw new Error('Workflow execution was cancelled');\n                        }\n                        // Store result in dataStore for next tasks\n                        dataStore[task.outputKey] = result;\n                        results[task.id] = result;\n                        // Update progress for completed task\n                        yield job.updateProgress({\n                            status: 'completed',\n                            taskId: task.id,\n                            taskName: task.name,\n                            result,\n                        });\n                    }\n                    catch (error) {\n                        // Check if this is a cancellation error\n                        if (error instanceof Error && error.message === 'Workflow execution was cancelled') {\n                            // Don't update progress for cancelled tasks, just throw\n                            throw error;\n                        }\n                        // Update progress for failed task\n                        yield job.updateProgress({\n                            status: 'failed',\n                            taskId: task.id,\n                            taskName: task.name,\n                            error: error instanceof Error ? error.message : 'Unknown error',\n                        });\n                        throw error; // Re-throw to fail the entire job\n                    }\n                }\n                return {\n                    workflowId,\n                    status: 'completed',\n                    results,\n                    dataStore,\n                };\n            }\n            catch (error) {\n                console.error(`Workflow execution failed for ${workflowId}:`, error);\n                throw error;\n            }\n        });\n    }\n    /**\n     * Sets up event listeners for the worker\n     */\n    setupWorkerEvents() {\n        if (!this.worker) {\n            console.warn('Worker not initialized, skipping event setup');\n            return;\n        }\n        this.worker.on('completed', (job) => {\n            console.log(`Job ${job.id} completed successfully`);\n            // Broadcast completion to WebSocket clients\n            webSocketService_1.default.broadcastToJob(job.id, {\n                type: 'workflow_complete',\n                workflowId: job.data.workflowId,\n                status: 'completed',\n                result: job.returnvalue,\n            });\n        });\n        this.worker.on('failed', (job, error) => {\n            console.error(`Job ${job === null || job === void 0 ? void 0 : job.id} failed:`, error.message);\n            if (job === null || job === void 0 ? void 0 : job.id) {\n                // Broadcast failure to WebSocket clients\n                webSocketService_1.default.broadcastToJob(job.id, {\n                    type: 'workflow_failed',\n                    workflowId: job.data.workflowId,\n                    status: 'failed',\n                    error: error.message,\n                });\n            }\n        });\n        this.worker.on('active', (job) => {\n            console.log(`Job ${job.id} started processing`);\n            // Broadcast start to WebSocket clients\n            webSocketService_1.default.broadcastToJob(job.id, {\n                type: 'workflow_progress',\n                workflowId: job.data.workflowId,\n                status: 'running',\n            });\n        });\n        this.worker.on('progress', (job, progress) => {\n            // Type guard to ensure progress is a WorkflowJobProgress object\n            if (typeof progress === 'object' && progress !== null &&\n                'taskId' in progress && 'taskName' in progress && 'status' in progress) {\n                const workflowProgress = progress;\n                // Broadcast task progress to WebSocket clients\n                webSocketService_1.default.broadcastToJob(job.id, {\n                    type: 'task_status',\n                    workflowId: job.data.workflowId,\n                    taskId: workflowProgress.taskId,\n                    taskName: workflowProgress.taskName,\n                    status: workflowProgress.status,\n                    result: workflowProgress.result,\n                    error: workflowProgress.error,\n                });\n            }\n        });\n        this.worker.on('stalled', (jobId) => {\n            console.warn(`Job ${jobId} stalled`);\n        });\n    }\n    /**\n     * Gracefully shuts down the job service\n     */\n    shutdown() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.worker) {\n                yield this.worker.close();\n            }\n            if (this.queue) {\n                yield this.queue.close();\n            }\n            if (this.redis) {\n                yield this.redis.quit();\n            }\n        });\n    }\n}\nexports.default = new JobService();\n",
      "metadata": {
        "filename": "jobService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/mockJobService.js\n\n\"use strict\";\n/**\n * Mock job service for development when Redis is not available.\n * Provides the same interface as the real JobService but doesn't require Redis.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass MockJobService {\n    addWorkflowJob(workflowId, workflow, userInput) {\n        return __awaiter(this, void 0, void 0, function* () {\n            console.log('Mock JobService: Would add workflow job', { workflowId, workflow: workflow.name });\n            // Return a mock job ID\n            return `mock-job-${Date.now()}`;\n        });\n    }\n    getJobStatus(jobId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            console.log('Mock JobService: Would get job status for', jobId);\n            // Return mock status\n            return {\n                id: jobId,\n                status: 'mock-completed',\n                data: { workflowId: 'mock-workflow' },\n                result: { message: 'Mock job completed - Redis not available' },\n            };\n        });\n    }\n    stopJob(jobId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            console.log('Mock JobService: Would stop job', jobId);\n            // Always return true for mock (job stopped successfully)\n            return true;\n        });\n    }\n    // Add other methods as needed to match the real JobService interface\n    shutdown() {\n        console.log('Mock JobService: Shutdown called');\n    }\n}\nexports.default = new MockJobService();\n",
      "metadata": {
        "filename": "mockJobService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/modelService.js\n\n\"use strict\";\n/**\n * @file modelService.ts\n * @description This service handles database operations related to AI models.\n * It provides methods to retrieve information about the available models that can be used\n * for workflow tasks and prompt testing. Models are stored in the database with metadata\n * about their capabilities and availability.\n *\n * @requires ../config/database\n * @since 0.5.1\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst database_1 = __importDefault(require(\"../config/database\"));\n/**\n * @class ModelService\n * @description A class to encapsulate all database logic for AI models.\n * Provides methods to retrieve model information for use in workflow configuration\n * and prompt testing interfaces.\n *\n * @since 0.5.1\n */\nclass ModelService {\n    /**\n     * Retrieves all active models from the database.\n     * Returns only models that are currently available for use, ordered alphabetically by name.\n     *\n     * @returns {Promise<Model[]>} A promise that resolves to an array of active models.\n     *\n     * @example\n     * ```typescript\n     * const availableModels = await modelService.getModels();\n     * console.log('Available models:');\n     * availableModels.forEach(model => {\n     *   console.log(`- ${model.name}: ${model.description || 'No description'}`);\n     * });\n     * ```\n     *\n     * @since 0.5.1\n     */\n    getModels() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('SELECT * FROM models WHERE is_active = true ORDER BY name');\n            return result.rows;\n        });\n    }\n}\n/**\n * @exports {ModelService} modelService\n * @description Singleton instance of the ModelService class, ready to be used across the application.\n * This exported instance provides all model-related database operations.\n *\n * @since 0.5.1\n */\nexports.default = new ModelService();\n",
      "metadata": {
        "filename": "modelService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/orchestratorService.js\n\n\"use strict\";\n/**\n * @file orchestratorService.ts\n * @description Service for AI-powered workflow orchestration. This service takes high-level user requests\n * and uses LLM-powered decomposition to generate complete, executable workflows automatically.\n *\n * @requires @google/genai\n * @requires ../types\n * @requires ../prompts/orchestratorPrompt\n * @since 2.1.0\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst genai_1 = require(\"@google/genai\");\nconst orchestratorPrompt_1 = require(\"../prompts/orchestratorPrompt\");\n/**\n * @constant {string|undefined} API_KEY\n * @description The API key for accessing Google's Gemini API, retrieved from environment variables.\n * @private\n */\nconst API_KEY = process.env.GEMINI_API_KEY;\nif (!API_KEY) {\n    console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\n/**\n * @constant {GoogleGenAI} ai\n * @description Initialized GoogleGenAI client instance for API communication.\n * @private\n */\nconst ai = new genai_1.GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\n/**\n * Parses JSON content from AI-generated text using multiple extraction strategies.\n * Enhanced version of the parser from geminiService with better error handling.\n *\n * @param {string} text - The raw text response from the AI that contains JSON data.\n * @returns {any} The parsed JSON object.\n * @throws {Error} Throws an error if all parsing strategies fail.\n * @private\n */\nconst parseJsonFromText = (text) => {\n    console.log(\"Orchestrator: Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n    const strategies = [\n        // Strategy 1: Extract code block content\n        () => {\n            const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n            const match = text.match(fenceRegex);\n            return match && match[1] ? match[1].trim() : null;\n        },\n        // Strategy 2: Extract content between first { and last }\n        () => {\n            const firstBrace = text.indexOf('{');\n            const lastBrace = text.lastIndexOf('}');\n            if (firstBrace !== -1 && lastBrace > firstBrace) {\n                return text.substring(firstBrace, lastBrace + 1);\n            }\n            return null;\n        },\n        // Strategy 3: Try the text as-is if it starts with {\n        () => {\n            const trimmed = text.trim();\n            return trimmed.startsWith('{') ? trimmed : null;\n        },\n        // Strategy 4: Remove common prefixes and try again\n        () => {\n            const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n            const firstBrace = cleaned.indexOf('{');\n            const lastBrace = cleaned.lastIndexOf('}');\n            if (firstBrace !== -1 && lastBrace > firstBrace) {\n                return cleaned.substring(firstBrace, lastBrace + 1);\n            }\n            return null;\n        }\n    ];\n    for (let i = 0; i < strategies.length; i++) {\n        const jsonStr = strategies[i]();\n        if (jsonStr) {\n            try {\n                console.log(`Orchestrator: Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n                const parsed = JSON.parse(jsonStr);\n                console.log(\"Orchestrator: Successfully parsed JSON with strategy\", i + 1);\n                return parsed;\n            }\n            catch (e) {\n                console.log(`Orchestrator: Strategy ${i + 1} failed to parse:`, e);\n                continue;\n            }\n        }\n    }\n    console.error(\"Orchestrator: All JSON parsing strategies failed\");\n    throw new Error(\"The AI orchestrator returned a response that could not be parsed as JSON.\");\n};\n/**\n * Validates that a workflow object conforms to the expected structure and business rules.\n *\n * @param {any} workflow - The workflow object to validate\n * @returns {string[]} Array of validation error messages, empty if valid\n * @private\n */\nconst validateWorkflow = (workflow) => {\n    const errors = [];\n    // Check required top-level fields\n    if (!workflow.name || typeof workflow.name !== 'string') {\n        errors.push(\"Workflow must have a 'name' field of type string\");\n    }\n    if (!workflow.description || typeof workflow.description !== 'string') {\n        errors.push(\"Workflow must have a 'description' field of type string\");\n    }\n    if (!Array.isArray(workflow.tasks)) {\n        errors.push(\"Workflow must have a 'tasks' field that is an array\");\n        return errors; // Can't validate tasks if it's not an array\n    }\n    if (workflow.tasks.length === 0) {\n        errors.push(\"Workflow must contain at least one task\");\n    }\n    // Validate each task\n    const taskIds = new Set();\n    workflow.tasks.forEach((task, index) => {\n        const taskPrefix = `Task ${index + 1} (${task.id || 'unknown'})`;\n        // Required fields\n        if (!task.id || typeof task.id !== 'string') {\n            errors.push(`${taskPrefix}: must have a unique 'id' field of type string`);\n        }\n        else if (taskIds.has(task.id)) {\n            errors.push(`${taskPrefix}: duplicate task ID '${task.id}'`);\n        }\n        else {\n            taskIds.add(task.id);\n        }\n        if (!task.name || typeof task.name !== 'string') {\n            errors.push(`${taskPrefix}: must have a 'name' field of type string`);\n        }\n        if (!task.description || typeof task.description !== 'string') {\n            errors.push(`${taskPrefix}: must have a 'description' field of type string`);\n        }\n        if (!task.type || typeof task.type !== 'string') {\n            errors.push(`${taskPrefix}: must have a 'type' field of type string`);\n        }\n        if (!Array.isArray(task.dependencies)) {\n            errors.push(`${taskPrefix}: must have a 'dependencies' field that is an array`);\n        }\n        if (!Array.isArray(task.inputKeys)) {\n            errors.push(`${taskPrefix}: must have an 'inputKeys' field that is an array`);\n        }\n        if (!task.outputKey || typeof task.outputKey !== 'string') {\n            errors.push(`${taskPrefix}: must have an 'outputKey' field of type string`);\n        }\n        // Validate dependencies reference existing tasks\n        if (Array.isArray(task.dependencies)) {\n            task.dependencies.forEach((depId) => {\n                if (typeof depId !== 'string') {\n                    errors.push(`${taskPrefix}: dependency must be a string, got ${typeof depId}`);\n                }\n                // Note: We can't validate if the dependency exists yet since we're processing tasks in order\n            });\n        }\n        // Type-specific validations\n        if (task.type) {\n            switch (task.type) {\n                case 'GEMINI_PROMPT':\n                case 'IMAGE_ANALYSIS':\n                case 'GEMINI_GROUNDED':\n                    if (!task.promptTemplate || typeof task.promptTemplate !== 'string') {\n                        errors.push(`${taskPrefix}: type '${task.type}' requires a 'promptTemplate' field of type string`);\n                    }\n                    break;\n                case 'TEXT_MANIPULATION':\n                    if (!task.functionBody || typeof task.functionBody !== 'string') {\n                        errors.push(`${taskPrefix}: type 'TEXT_MANIPULATION' requires a 'functionBody' field of type string`);\n                    }\n                    break;\n                case 'DATA_INPUT':\n                    if (task.staticValue === undefined) {\n                        errors.push(`${taskPrefix}: type 'DATA_INPUT' requires a 'staticValue' field`);\n                    }\n                    break;\n                case 'DISPLAY_CHART':\n                    if (!task.dataKey || typeof task.dataKey !== 'string') {\n                        errors.push(`${taskPrefix}: type 'DISPLAY_CHART' requires a 'dataKey' field of type string`);\n                    }\n                    break;\n            }\n        }\n    });\n    // Validate that all dependency references exist\n    workflow.tasks.forEach((task) => {\n        if (Array.isArray(task.dependencies)) {\n            task.dependencies.forEach((depId) => {\n                if (!taskIds.has(depId)) {\n                    errors.push(`Task '${task.id}': references non-existent dependency '${depId}'`);\n                }\n            });\n        }\n    });\n    return errors;\n};\n/**\n * Detects circular dependencies in a workflow task graph.\n *\n * @param {Task[]} tasks - Array of workflow tasks to check\n * @returns {boolean} True if circular dependencies are detected\n * @private\n */\nconst hasCircularDependencies = (tasks) => {\n    const visited = new Set();\n    const recursionStack = new Set();\n    const taskMap = new Map();\n    tasks.forEach(task => taskMap.set(task.id, task));\n    const dfsVisit = (taskId) => {\n        if (recursionStack.has(taskId)) {\n            return true; // Circular dependency detected\n        }\n        if (visited.has(taskId)) {\n            return false; // Already processed\n        }\n        visited.add(taskId);\n        recursionStack.add(taskId);\n        const task = taskMap.get(taskId);\n        if (task) {\n            for (const depId of task.dependencies) {\n                if (dfsVisit(depId)) {\n                    return true;\n                }\n            }\n        }\n        recursionStack.delete(taskId);\n        return false;\n    };\n    // Check each task\n    for (const task of tasks) {\n        if (!visited.has(task.id)) {\n            if (dfsVisit(task.id)) {\n                return true;\n            }\n        }\n    }\n    return false;\n};\n/**\n * @class OrchestratorService\n * @description Service class for AI-powered workflow orchestration.\n * Provides methods for generating complete workflows from high-level user requests.\n *\n * @since 2.1.0\n */\nclass OrchestratorService {\n    /**\n     * Generates a complete workflow from a high-level user request using AI orchestration.\n     * This method uses advanced prompting techniques to decompose complex requests into\n     * structured, executable workflows with proper task dependencies and data flow.\n     *\n     * @param {string} userRequest - The high-level request describing what the user wants to accomplish\n     * @returns {Promise<OrchestratorResponse>} A promise that resolves to the orchestration result\n     *\n     * @example\n     * ```typescript\n     * const orchestrator = new OrchestratorService();\n     * const result = await orchestrator.generateWorkflow(\n     *   \"Analyze customer feedback for sentiment and generate a report\"\n     * );\n     * if (result.success) {\n     *   console.log(`Generated workflow: ${result.workflow.name}`);\n     *   console.log(`Tasks: ${result.workflow.tasks.length}`);\n     * }\n     * ```\n     *\n     * @since 2.1.0\n     */\n    generateWorkflow(userRequest) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b, _c, _d, _e;\n            if (!API_KEY) {\n                return {\n                    success: false,\n                    error: \"Gemini API Key is not configured. Cannot generate workflow.\"\n                };\n            }\n            if (!(userRequest === null || userRequest === void 0 ? void 0 : userRequest.trim())) {\n                return {\n                    success: false,\n                    error: \"User request cannot be empty.\"\n                };\n            }\n            try {\n                console.log(\"Orchestrator: Generating workflow for request:\", userRequest);\n                const orchestratorPrompt = (0, orchestratorPrompt_1.buildOrchestratorPrompt)(userRequest);\n                console.log(\"Orchestrator: Sending request to Gemini API\");\n                const response = yield ai.models.generateContent({\n                    model: 'gemini-2.5-flash',\n                    contents: [{ role: \"user\", parts: [{ text: orchestratorPrompt }] }],\n                    config: {\n                        responseMimeType: \"application/json\",\n                        temperature: 0.3, // Lower temperature for more consistent structure\n                        topK: 40,\n                        topP: 0.8\n                    },\n                });\n                const text = ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"{}\";\n                console.log(\"Orchestrator: Received response from API, parsing...\");\n                let workflowData;\n                try {\n                    workflowData = parseJsonFromText(text);\n                }\n                catch (parseError) {\n                    console.error(\"Orchestrator: Failed to parse JSON:\", parseError);\n                    return {\n                        success: false,\n                        error: \"Failed to parse workflow structure from AI response.\",\n                    };\n                }\n                // Validate the workflow structure\n                const validationErrors = validateWorkflow(workflowData);\n                if (validationErrors.length > 0) {\n                    console.error(\"Orchestrator: Validation errors:\", validationErrors);\n                    return {\n                        success: false,\n                        error: \"Generated workflow failed validation.\",\n                        validationErrors\n                    };\n                }\n                // Check for circular dependencies\n                if (hasCircularDependencies(workflowData.tasks)) {\n                    return {\n                        success: false,\n                        error: \"Generated workflow contains circular dependencies.\"\n                    };\n                }\n                // Generate a unique ID for the workflow\n                workflowData.id = `orchestrated-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n                console.log(`Orchestrator: Successfully generated workflow \"${workflowData.name}\" with ${workflowData.tasks.length} tasks`);\n                return {\n                    success: true,\n                    workflow: workflowData\n                };\n            }\n            catch (error) {\n                console.error(\"Orchestrator: Error during workflow generation:\", error);\n                if (error instanceof Error) {\n                    return {\n                        success: false,\n                        error: `Workflow generation failed: ${error.message}`\n                    };\n                }\n                return {\n                    success: false,\n                    error: \"An unknown error occurred during workflow generation.\"\n                };\n            }\n        });\n    }\n    /**\n     * Validates an existing workflow structure for completeness and correctness.\n     * Can be used to validate workflows before execution or after modifications.\n     *\n     * @param {Workflow} workflow - The workflow to validate\n     * @returns {string[]} Array of validation error messages, empty if valid\n     *\n     * @example\n     * ```typescript\n     * const orchestrator = new OrchestratorService();\n     * const errors = orchestrator.validateWorkflowStructure(myWorkflow);\n     * if (errors.length === 0) {\n     *   console.log(\"Workflow is valid\");\n     * } else {\n     *   console.error(\"Validation errors:\", errors);\n     * }\n     * ```\n     *\n     * @since 2.1.0\n     */\n    validateWorkflowStructure(workflow) {\n        const errors = validateWorkflow(workflow);\n        if (errors.length === 0 && workflow.tasks && hasCircularDependencies(workflow.tasks)) {\n            errors.push(\"Workflow contains circular dependencies\");\n        }\n        return errors;\n    }\n    /**\n     * Checks if the orchestrator service is properly configured and ready to use.\n     *\n     * @returns {boolean} True if the service is ready, false otherwise\n     *\n     * @since 2.1.0\n     */\n    isConfigured() {\n        return !!API_KEY;\n    }\n}\n/**\n * @exports {OrchestratorService} orchestratorService\n * @description Singleton instance of the OrchestratorService class, ready to be used across the application.\n * This exported instance provides AI-powered workflow generation functionality.\n *\n * @since 2.1.0\n */\nexports.default = new OrchestratorService();\n",
      "metadata": {
        "filename": "orchestratorService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/promptService.js\n\n\"use strict\";\n/**\n * @file promptService.ts\n * @description This service handles all business logic and database operations related to prompts.\n * It includes functions for creating, retrieving, updating, and deleting prompts,\n * as well as mapping between the SFL prompt format used in the frontend and the database schema.\n *\n * @requires ../config/database\n * @requires ../types\n * @since 0.5.1\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst database_1 = __importDefault(require(\"../config/database\"));\nrequire(\"../types/express\");\n/**\n * @class PromptService\n * @description A class to encapsulate all business logic for prompts.\n * Provides methods for CRUD operations on prompts and handles data transformation\n * between the SFL frontend format and the database schema.\n *\n * @since 0.5.1\n */\nclass PromptService {\n    /**\n     * Maps the detailed `PromptSFL` format to the database `Prompt` format.\n     * Transforms the rich SFL structure into a flattened database record where SFL metadata\n     * is stored as JSON in the metadata column.\n     *\n     * @param {PromptSFL | Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} sflData - The SFL prompt data.\n     * @param {string} userId - The ID of the authenticated user creating/updating the prompt.\n     * @returns {Omit<Prompt, 'id' | 'created_at' | 'updated_at'>} The prompt data formatted for the database.\n     * @private\n     * @since 0.5.1\n     */\n    mapSFLToPrompt(sflData, userId) {\n        const metadata = {\n            sflField: sflData.sflField,\n            sflTenor: sflData.sflTenor,\n            sflMode: sflData.sflMode,\n            exampleOutput: sflData.exampleOutput,\n            notes: sflData.notes,\n            sourceDocument: sflData.sourceDocument,\n        };\n        return {\n            user_id: userId,\n            title: sflData.title || 'Untitled Prompt',\n            body: sflData.promptText || '',\n            metadata,\n        };\n    }\n    /**\n     * Maps a database `Prompt` record to the `PromptSFL` format.\n     * Reconstructs the full SFL structure from the flattened database record,\n     * providing default values for missing SFL components.\n     *\n     * @param {Prompt} dbPrompt - The prompt record from the database.\n     * @returns {PromptSFL} The prompt data in the SFL format.\n     * @private\n     * @since 0.5.1\n     */\n    mapPromptToSFL(dbPrompt) {\n        const metadata = dbPrompt.metadata || {};\n        return {\n            id: dbPrompt.id,\n            title: dbPrompt.title,\n            promptText: dbPrompt.body,\n            createdAt: dbPrompt.created_at,\n            updatedAt: dbPrompt.updated_at,\n            sflField: metadata.sflField || { topic: '', taskType: '', domainSpecifics: '', keywords: '' },\n            sflTenor: metadata.sflTenor || { aiPersona: '', targetAudience: [], desiredTone: '', interpersonalStance: '' },\n            sflMode: metadata.sflMode || { outputFormat: '', rhetoricalStructure: '', lengthConstraint: '', textualDirectives: '' },\n            exampleOutput: metadata.exampleOutput,\n            notes: metadata.notes,\n            sourceDocument: metadata.sourceDocument,\n        };\n    }\n    /**\n     * Creates a new prompt in the database.\n     * Validates required fields and transforms the SFL data before insertion.\n     *\n     * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} promptData - The SFL data for the new prompt.\n     * @param {string} userId - The ID of the authenticated user creating the prompt.\n     * @returns {Promise<PromptSFL>} A promise that resolves to the newly created prompt.\n     * @throws {Error} If the title or prompt text is empty.\n     *\n     * @example\n     * ```typescript\n     * const newPromptData = {\n     *   title: \"My New Prompt\",\n     *   promptText: \"Generate a summary of the following text: {{input}}\",\n     *   sflField: { topic: \"Text Summarization\", taskType: \"Summarization\", ... },\n     *   // ... other SFL components\n     * };\n     * const createdPrompt = await promptService.createPrompt(newPromptData, userId);\n     * ```\n     *\n     * @since 0.5.1\n     */\n    createPrompt(promptData, userId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b;\n            if (!((_a = promptData.title) === null || _a === void 0 ? void 0 : _a.trim())) {\n                throw new Error('Title is required');\n            }\n            if (!((_b = promptData.promptText) === null || _b === void 0 ? void 0 : _b.trim())) {\n                throw new Error('Prompt text is required');\n            }\n            if (!(userId === null || userId === void 0 ? void 0 : userId.trim())) {\n                throw new Error('User ID is required');\n            }\n            const mappedData = this.mapSFLToPrompt(promptData, userId);\n            const result = yield database_1.default.query('INSERT INTO prompts (user_id, title, body, metadata) VALUES ($1, $2, $3, $4) RETURNING *', [mappedData.user_id, mappedData.title, mappedData.body, mappedData.metadata]);\n            return this.mapPromptToSFL(result.rows[0]);\n        });\n    }\n    /**\n     * Retrieves all prompts from the database.\n     * Returns prompts ordered by most recently updated first.\n     *\n     * @param {any} filters - An object containing filter criteria (currently unused, reserved for future filtering functionality).\n     * @returns {Promise<PromptSFL[]>} A promise that resolves to an array of prompts in SFL format.\n     *\n     * @example\n     * ```typescript\n     * const allPrompts = await promptService.getPrompts({});\n     * console.log(`Found ${allPrompts.length} prompts`);\n     * ```\n     *\n     * @since 0.5.1\n     */\n    getPrompts(filters) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('SELECT * FROM prompts ORDER BY updated_at DESC');\n            return result.rows.map(row => this.mapPromptToSFL(row));\n        });\n    }\n    /**\n     * Retrieves a single prompt by its ID.\n     *\n     * @param {string} id - The UUID of the prompt to retrieve.\n     * @returns {Promise<PromptSFL | null>} A promise that resolves to the prompt in SFL format, or null if not found.\n     *\n     * @example\n     * ```typescript\n     * const prompt = await promptService.getPromptById('123e4567-e89b-12d3-a456-426614174000');\n     * if (prompt) {\n     *   console.log(`Found prompt: ${prompt.title}`);\n     * } else {\n     *   console.log('Prompt not found');\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    getPromptById(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('SELECT * FROM prompts WHERE id = $1', [id]);\n            if (!result.rows[0])\n                return null;\n            return this.mapPromptToSFL(result.rows[0]);\n        });\n    }\n    /**\n     * Updates an existing prompt in the database.\n     * Performs partial updates by merging the provided data with the existing prompt.\n     * Validates that title and promptText remain non-empty if they are being updated.\n     *\n     * @param {string} id - The UUID of the prompt to update.\n     * @param {Partial<PromptSFL>} promptData - An object containing the fields to update.\n     * @param {string} userId - The ID of the authenticated user updating the prompt.\n     * @returns {Promise<PromptSFL | null>} A promise that resolves to the updated prompt, or null if not found.\n     * @throws {Error} If the title or prompt text is being updated to an empty value.\n     *\n     * @example\n     * ```typescript\n     * const updates = {\n     *   title: \"Updated Prompt Title\",\n     *   sflField: { ...existingField, topic: \"New Topic\" }\n     * };\n     * const updatedPrompt = await promptService.updatePrompt(promptId, updates, userId);\n     * ```\n     *\n     * @since 0.5.1\n     */\n    updatePrompt(id, promptData, userId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b;\n            if (promptData.title !== undefined && !((_a = promptData.title) === null || _a === void 0 ? void 0 : _a.trim())) {\n                throw new Error('Title cannot be empty');\n            }\n            if (promptData.promptText !== undefined && !((_b = promptData.promptText) === null || _b === void 0 ? void 0 : _b.trim())) {\n                throw new Error('Prompt text cannot be empty');\n            }\n            if (!(userId === null || userId === void 0 ? void 0 : userId.trim())) {\n                throw new Error('User ID is required');\n            }\n            const existing = yield database_1.default.query('SELECT * FROM prompts WHERE id = $1', [id]);\n            if (!existing.rows[0])\n                return null;\n            const existingSFL = this.mapPromptToSFL(existing.rows[0]);\n            const updatedSFL = Object.assign(Object.assign({}, existingSFL), promptData);\n            const mappedData = this.mapSFLToPrompt(updatedSFL, userId);\n            const result = yield database_1.default.query('UPDATE prompts SET user_id = $1, title = $2, body = $3, metadata = $4, updated_at = now() WHERE id = $5 RETURNING *', [mappedData.user_id, mappedData.title, mappedData.body, mappedData.metadata, id]);\n            return result.rows[0] ? this.mapPromptToSFL(result.rows[0]) : null;\n        });\n    }\n    /**\n     * Deletes a prompt from the database.\n     *\n     * @param {string} id - The UUID of the prompt to delete.\n     * @returns {Promise<boolean>} A promise that resolves to true if the deletion was successful, false if the prompt was not found.\n     *\n     * @example\n     * ```typescript\n     * const deleted = await promptService.deletePrompt('123e4567-e89b-12d3-a456-426614174000');\n     * if (deleted) {\n     *   console.log('Prompt successfully deleted');\n     * } else {\n     *   console.log('Prompt not found or could not be deleted');\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    deletePrompt(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('DELETE FROM prompts WHERE id = $1', [id]);\n            return !!result.rowCount;\n        });\n    }\n}\n/**\n * @exports {PromptService} promptService\n * @description Singleton instance of the PromptService class, ready to be used across the application.\n * This exported instance provides all prompt-related database operations and data transformations.\n *\n * @since 0.5.1\n */\nexports.default = new PromptService();\n",
      "metadata": {
        "filename": "promptService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/providerValidationService.js\n\n\"use strict\";\n/**\n * @file providerValidationService.ts\n * @description Service for validating AI provider API keys and detecting available providers from environment variables\n * @since 0.6.0\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.detectAvailableProviders = detectAvailableProviders;\nexports.getProviderConfig = getProviderConfig;\nexports.validateProviderApiKey = validateProviderApiKey;\nexports.validateAllProviders = validateAllProviders;\nexports.hasValidProvider = hasValidProvider;\nexports.getPreferredProvider = getPreferredProvider;\nconst env_1 = __importDefault(require(\"../config/env\"));\n/**\n * Detects which AI providers are configured via environment variables\n * @returns Array of provider availability information\n */\nfunction detectAvailableProviders() {\n    const providers = [\n        {\n            provider: 'google',\n            hasApiKey: !!env_1.default.geminiApiKey,\n            isConfigured: !!(env_1.default.geminiApiKey && env_1.default.googleDefaultModel),\n        },\n        {\n            provider: 'openai',\n            hasApiKey: !!env_1.default.openaiApiKey,\n            isConfigured: !!(env_1.default.openaiApiKey && env_1.default.openaiDefaultModel),\n        },\n        {\n            provider: 'openrouter',\n            hasApiKey: !!env_1.default.openrouterApiKey,\n            isConfigured: !!(env_1.default.openrouterApiKey && env_1.default.openrouterDefaultModel && env_1.default.openrouterBaseUrl),\n        },\n        {\n            provider: 'anthropic',\n            hasApiKey: !!env_1.default.anthropicApiKey,\n            isConfigured: !!(env_1.default.anthropicApiKey && env_1.default.anthropicDefaultModel),\n        },\n    ];\n    return providers;\n}\n/**\n * Gets the configured provider settings\n * @param provider The AI provider\n * @returns Provider configuration or null if not configured\n */\nfunction getProviderConfig(provider) {\n    switch (provider) {\n        case 'google':\n            if (!env_1.default.geminiApiKey)\n                return null;\n            return {\n                apiKey: env_1.default.geminiApiKey,\n                defaultModel: env_1.default.googleDefaultModel,\n            };\n        case 'openai':\n            if (!env_1.default.openaiApiKey)\n                return null;\n            return {\n                apiKey: env_1.default.openaiApiKey,\n                defaultModel: env_1.default.openaiDefaultModel,\n            };\n        case 'openrouter':\n            if (!env_1.default.openrouterApiKey)\n                return null;\n            return {\n                apiKey: env_1.default.openrouterApiKey,\n                defaultModel: env_1.default.openrouterDefaultModel,\n                baseUrl: env_1.default.openrouterBaseUrl,\n            };\n        case 'anthropic':\n            if (!env_1.default.anthropicApiKey)\n                return null;\n            return {\n                apiKey: env_1.default.anthropicApiKey,\n                defaultModel: env_1.default.anthropicDefaultModel,\n            };\n        default:\n            return null;\n    }\n}\n/**\n * Validates an API key by making a request to the provider's API\n * @param provider The AI provider\n * @param apiKey The API key to validate\n * @param baseUrl Optional base URL for OpenRouter/custom providers\n * @returns Promise resolving to validation result\n */\nfunction validateProviderApiKey(provider, apiKey, baseUrl) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (!apiKey || apiKey.trim().length === 0) {\n            return { success: false, error: 'API key cannot be empty' };\n        }\n        try {\n            switch (provider) {\n                case 'google': {\n                    const response = yield fetch('https://generativelanguage.googleapis.com/v1beta/models', {\n                        method: 'GET',\n                        headers: {\n                            'x-goog-api-key': apiKey,\n                            'Content-Type': 'application/json',\n                        },\n                    });\n                    if (!response.ok) {\n                        if (response.status === 401) {\n                            return { success: false, error: 'Invalid Google API key' };\n                        }\n                        else if (response.status === 403) {\n                            return { success: false, error: 'Google API key does not have permission to access Generative AI models' };\n                        }\n                        else if (response.status === 429) {\n                            return { success: false, error: 'Rate limit exceeded for Google API' };\n                        }\n                        else {\n                            return { success: false, error: `Google API error: ${response.status} ${response.statusText}` };\n                        }\n                    }\n                    return { success: true };\n                }\n                case 'openai': {\n                    const url = baseUrl || 'https://api.openai.com';\n                    const response = yield fetch(`${url}/v1/models`, {\n                        method: 'GET',\n                        headers: {\n                            'Authorization': `Bearer ${apiKey}`,\n                            'Content-Type': 'application/json',\n                        },\n                    });\n                    if (!response.ok) {\n                        if (response.status === 401) {\n                            return { success: false, error: 'Invalid OpenAI API key' };\n                        }\n                        else if (response.status === 403) {\n                            return { success: false, error: 'OpenAI API key does not have permission to access models' };\n                        }\n                        else if (response.status === 429) {\n                            return { success: false, error: 'Rate limit exceeded for OpenAI API' };\n                        }\n                        else {\n                            return { success: false, error: `OpenAI API error: ${response.status} ${response.statusText}` };\n                        }\n                    }\n                    return { success: true };\n                }\n                case 'openrouter': {\n                    const url = baseUrl || env_1.default.openrouterBaseUrl;\n                    const response = yield fetch(`${url}/models`, {\n                        method: 'GET',\n                        headers: {\n                            'Authorization': `Bearer ${apiKey}`,\n                            'Content-Type': 'application/json',\n                        },\n                    });\n                    if (!response.ok) {\n                        if (response.status === 401) {\n                            return { success: false, error: 'Invalid OpenRouter API key' };\n                        }\n                        else if (response.status === 403) {\n                            return { success: false, error: 'OpenRouter API key does not have permission to access models' };\n                        }\n                        else if (response.status === 429) {\n                            return { success: false, error: 'Rate limit exceeded for OpenRouter API' };\n                        }\n                        else {\n                            return { success: false, error: `OpenRouter API error: ${response.status} ${response.statusText}` };\n                        }\n                    }\n                    return { success: true };\n                }\n                case 'anthropic': {\n                    // Note: Anthropic doesn't have a simple models endpoint like others\n                    // We'll do a minimal completion request to validate the key\n                    const response = yield fetch('https://api.anthropic.com/v1/messages', {\n                        method: 'POST',\n                        headers: {\n                            'Authorization': `Bearer ${apiKey}`,\n                            'Content-Type': 'application/json',\n                            'anthropic-version': '2023-06-01',\n                        },\n                        body: JSON.stringify({\n                            model: 'claude-3-haiku-20240307',\n                            max_tokens: 1,\n                            messages: [{ role: 'user', content: 'test' }],\n                        }),\n                    });\n                    if (!response.ok) {\n                        if (response.status === 401) {\n                            return { success: false, error: 'Invalid Anthropic API key' };\n                        }\n                        else if (response.status === 403) {\n                            return { success: false, error: 'Anthropic API key does not have permission to access Claude' };\n                        }\n                        else if (response.status === 429) {\n                            return { success: false, error: 'Rate limit exceeded for Anthropic API' };\n                        }\n                        else {\n                            return { success: false, error: `Anthropic API error: ${response.status} ${response.statusText}` };\n                        }\n                    }\n                    return { success: true };\n                }\n                default:\n                    return { success: false, error: `Unsupported provider: ${provider}` };\n            }\n        }\n        catch (error) {\n            return {\n                success: false,\n                error: `Network error validating ${provider} API key: ${error instanceof Error ? error.message : String(error)}`,\n            };\n        }\n    });\n}\n/**\n * Validates all configured providers\n * @returns Promise resolving to array of provider availability with validation results\n */\nfunction validateAllProviders() {\n    return __awaiter(this, void 0, void 0, function* () {\n        const providers = detectAvailableProviders();\n        const validationPromises = providers.map((provider) => __awaiter(this, void 0, void 0, function* () {\n            if (!provider.hasApiKey) {\n                return Object.assign(Object.assign({}, provider), { validationResult: { success: false, error: 'No API key configured' } });\n            }\n            const config = getProviderConfig(provider.provider);\n            if (!config) {\n                return Object.assign(Object.assign({}, provider), { validationResult: { success: false, error: 'Provider not configured' } });\n            }\n            const validationResult = yield validateProviderApiKey(provider.provider, config.apiKey, config.baseUrl);\n            return Object.assign(Object.assign({}, provider), { validationResult });\n        }));\n        return yield Promise.all(validationPromises);\n    });\n}\n/**\n * Checks if at least one provider is valid and configured\n * @returns Promise resolving to boolean indicating if any provider is available\n */\nfunction hasValidProvider() {\n    return __awaiter(this, void 0, void 0, function* () {\n        const results = yield validateAllProviders();\n        return results.some(result => { var _a; return ((_a = result.validationResult) === null || _a === void 0 ? void 0 : _a.success) === true; });\n    });\n}\n/**\n * Gets the preferred provider based on configuration and availability\n * @returns Promise resolving to the preferred provider or null if none available\n */\nfunction getPreferredProvider() {\n    return __awaiter(this, void 0, void 0, function* () {\n        var _a, _b;\n        const results = yield validateAllProviders();\n        // First try the default provider\n        const defaultProvider = results.find(r => r.provider === env_1.default.defaultAiProvider);\n        if ((_a = defaultProvider === null || defaultProvider === void 0 ? void 0 : defaultProvider.validationResult) === null || _a === void 0 ? void 0 : _a.success) {\n            return defaultProvider.provider;\n        }\n        // Then try the fallback provider\n        const fallbackProvider = results.find(r => r.provider === env_1.default.fallbackAiProvider);\n        if ((_b = fallbackProvider === null || fallbackProvider === void 0 ? void 0 : fallbackProvider.validationResult) === null || _b === void 0 ? void 0 : _b.success) {\n            return fallbackProvider.provider;\n        }\n        // Finally, return the first valid provider\n        const validProvider = results.find(r => { var _a; return (_a = r.validationResult) === null || _a === void 0 ? void 0 : _a.success; });\n        return (validProvider === null || validProvider === void 0 ? void 0 : validProvider.provider) || null;\n    });\n}\n",
      "metadata": {
        "filename": "providerValidationService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/unifiedAIService.js\n\n\"use strict\";\n/**\n * @file unifiedAIService.ts\n * @description Unified AI service that provides dynamic provider switching while maintaining\n * compatibility with existing SFL prompt generation and workflow creation functionality.\n * Acts as a bridge between the legacy GeminiService interface and the new multi-provider architecture.\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.UnifiedAIService = void 0;\nconst AIProviderFactory_1 = require(\"./ai/AIProviderFactory\");\nconst geminiService_1 = __importDefault(require(\"./geminiService\"));\n/**\n * Unified AI service that supports multiple providers while maintaining backward compatibility\n */\nclass UnifiedAIService {\n    constructor() {\n        // Set default provider configuration (fallback to Gemini for backward compatibility)\n        this.defaultProvider = {\n            provider: 'google',\n            model: 'gemini-2.5-flash',\n            parameters: {\n                temperature: 0.7,\n                maxTokens: 4096\n            }\n        };\n    }\n    /**\n     * Get singleton instance\n     */\n    static getInstance() {\n        if (!UnifiedAIService.instance) {\n            UnifiedAIService.instance = new UnifiedAIService();\n        }\n        return UnifiedAIService.instance;\n    }\n    /**\n     * Test a prompt with specified or default provider\n     */\n    testPrompt(promptText, providerConfig) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!(providerConfig === null || providerConfig === void 0 ? void 0 : providerConfig.provider) || providerConfig.provider === 'google') {\n                // Use legacy Gemini service for backward compatibility\n                return yield geminiService_1.default.testPrompt(promptText);\n            }\n            // Use new provider system\n            const aiService = this.createAIService(providerConfig);\n            const request = {\n                provider: providerConfig.provider,\n                model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n                parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n                prompt: promptText\n            };\n            const response = yield aiService.generateCompletion(request);\n            return response.text;\n        });\n    }\n    /**\n     * Generate SFL prompt from goal with specified or default provider\n     */\n    generateSFLFromGoal(goal, sourceDocContent, providerConfig) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!(providerConfig === null || providerConfig === void 0 ? void 0 : providerConfig.provider) || providerConfig.provider === 'google') {\n                // Use legacy Gemini service for backward compatibility\n                return yield geminiService_1.default.generateSFLFromGoal(goal, sourceDocContent);\n            }\n            // For non-Gemini providers, we need to adapt the prompt structure\n            const aiService = this.createAIService(providerConfig);\n            const systemInstruction = this.getSFLSystemInstruction();\n            const userContent = sourceDocContent\n                ? `Source document for style reference:\\n\\n---\\n\\n${sourceDocContent}\\n\\n----\\n\\nUser's goal: \"${goal}\"`\n                : `Here is the user's goal: \"${goal}\"`;\n            const request = {\n                provider: providerConfig.provider,\n                model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n                parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n                prompt: userContent,\n                systemMessage: systemInstruction\n            };\n            const response = yield aiService.generateCompletion(request);\n            const jsonData = this.parseJsonFromText(response.text);\n            // Ensure targetAudience is an array\n            if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n                jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n            }\n            if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n                jsonData.sflTenor.targetAudience = [];\n            }\n            return jsonData;\n        });\n    }\n    /**\n     * Regenerate SFL prompt from suggestion with specified or default provider\n     */\n    regenerateSFLFromSuggestion(currentPrompt, suggestion, providerConfig) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!(providerConfig === null || providerConfig === void 0 ? void 0 : providerConfig.provider) || providerConfig.provider === 'google') {\n                // Use legacy Gemini service for backward compatibility\n                return yield geminiService_1.default.regenerateSFLFromSuggestion(currentPrompt, suggestion);\n            }\n            // For non-Gemini providers, we need to adapt the prompt structure\n            const aiService = this.createAIService(providerConfig);\n            const systemInstruction = this.getSFLRegenerationSystemInstruction();\n            const { sourceDocument } = currentPrompt, promptForPayload = __rest(currentPrompt, [\"sourceDocument\"]);\n            const userContent = `\n    Here is the current prompt JSON:\n    ${JSON.stringify(promptForPayload)}\n    \n    ${sourceDocument ? `This prompt is associated with the following source document for stylistic reference:\\n---\\n${sourceDocument.content}\\n---\\n` : ''}\n\n    Here is my suggestion for how to change it:\n    \"${suggestion}\"\n\n    Now, provide the complete, revised JSON object.\n    `;\n            const request = {\n                provider: providerConfig.provider,\n                model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n                parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n                prompt: userContent,\n                systemMessage: systemInstruction\n            };\n            const response = yield aiService.generateCompletion(request);\n            const jsonData = this.parseJsonFromText(response.text);\n            // Ensure targetAudience is an array\n            if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n                jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n            }\n            if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n                jsonData.sflTenor.targetAudience = [];\n            }\n            // Preserve the source document from the original prompt\n            jsonData.sourceDocument = sourceDocument;\n            return jsonData;\n        });\n    }\n    /**\n     * Generate workflow from goal with specified or default provider\n     */\n    generateWorkflowFromGoal(goal, providerConfig) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (!(providerConfig === null || providerConfig === void 0 ? void 0 : providerConfig.provider) || providerConfig.provider === 'google') {\n                // Use legacy Gemini service for backward compatibility\n                return yield geminiService_1.default.generateWorkflowFromGoal(goal);\n            }\n            // For non-Gemini providers, we need to adapt the prompt structure\n            const aiService = this.createAIService(providerConfig);\n            const systemInstruction = this.getWorkflowSystemInstruction();\n            const request = {\n                provider: providerConfig.provider,\n                model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n                parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n                prompt: `User's goal: \"${goal}\"`,\n                systemMessage: systemInstruction\n            };\n            const response = yield aiService.generateCompletion(request);\n            const jsonData = this.parseJsonFromText(response.text);\n            if (!jsonData.name || !jsonData.description || !Array.isArray(jsonData.tasks)) {\n                throw new Error(\"Generated workflow is missing required fields (name, description, tasks).\");\n            }\n            jsonData.id = `wf-custom-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n            return jsonData;\n        });\n    }\n    /**\n     * Create AI service instance for the specified provider\n     */\n    createAIService(config) {\n        if (!config.provider) {\n            throw new Error('Provider is required');\n        }\n        if (!config.apiKey) {\n            // Try to get API key from environment variables\n            config.apiKey = this.getApiKeyFromEnv(config.provider);\n        }\n        const serviceConfig = {\n            apiKey: config.apiKey,\n            baseUrl: config.baseUrl,\n            timeout: 30000\n        };\n        return AIProviderFactory_1.aiProviderFactory.createService(config.provider, serviceConfig);\n    }\n    /**\n     * Get API key from environment variables\n     */\n    getApiKeyFromEnv(provider) {\n        switch (provider) {\n            case 'openai':\n                return process.env.OPENAI_API_KEY || '';\n            case 'anthropic':\n                return process.env.ANTHROPIC_API_KEY || '';\n            case 'google':\n                return process.env.GEMINI_API_KEY || '';\n            case 'openrouter':\n                return process.env.OPENROUTER_API_KEY || '';\n            default:\n                throw new Error(`No API key found for provider: ${provider}`);\n        }\n    }\n    /**\n     * Get default model for provider\n     */\n    getDefaultModelForProvider(provider) {\n        switch (provider) {\n            case 'openai':\n                return 'gpt-4';\n            case 'anthropic':\n                return 'claude-3-5-sonnet-20241022';\n            case 'google':\n                return 'gemini-2.5-flash';\n            case 'openrouter':\n                return 'openai/gpt-4';\n            default:\n                throw new Error(`No default model configured for provider: ${provider}`);\n        }\n    }\n    /**\n     * Get default parameters for provider\n     */\n    getDefaultParametersForProvider(provider) {\n        const baseParams = {\n            temperature: 0.7,\n            maxTokens: 4096\n        };\n        switch (provider) {\n            case 'openai':\n                return Object.assign(Object.assign({}, baseParams), { top_p: 1.0, presence_penalty: 0, frequency_penalty: 0 });\n            case 'anthropic':\n                return Object.assign(Object.assign({}, baseParams), { top_p: 1.0, top_k: 0 });\n            case 'google':\n                return Object.assign(Object.assign({}, baseParams), { topP: 1.0, topK: 40 });\n            case 'openrouter':\n                return Object.assign(Object.assign({}, baseParams), { top_p: 1.0, presence_penalty: 0, frequency_penalty: 0 });\n            default:\n                return baseParams;\n        }\n    }\n    /**\n     * Get system instruction for SFL generation\n     */\n    getSFLSystemInstruction() {\n        return `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to analyze a user's goal and structure it into a detailed SFL-based prompt.\n    If a source document is provided for stylistic reference, you MUST analyze its style (e.g., tone, complexity, vocabulary, sentence structure) and incorporate those stylistic qualities into the SFL fields and the final promptText. For example, update the 'desiredTone', 'aiPersona', and 'textualDirectives' to match the source. The generated 'promptText' should be a complete, standalone prompt that implicitly carries the desired style.\n    The output MUST be a single, valid JSON object. Do not include any text, notes, or explanations outside of the JSON object.\n    The JSON object should have the following structure: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string }.\n    \n    - title: Create a concise, descriptive title based on the user's goal.\n    - promptText: Synthesize all the SFL elements into a complete, well-formed prompt that can be sent directly to an AI.\n    - sflField (What is happening?): Analyze the subject matter.\n    - sflTenor (Who is taking part?): Define the roles and relationships. The \"targetAudience\" field must be an array of strings, even if only one audience is identified.\n    - sflMode (How is it being communicated?): Specify the format and structure of the output.\n    - exampleOutput: Provide a brief but illustrative example of the expected output.\n    - notes: Add any relevant notes or suggestions for the user.\n    - All fields in the JSON must be filled with meaningful content.`;\n    }\n    /**\n     * Get system instruction for SFL regeneration\n     */\n    getSFLRegenerationSystemInstruction() {\n        return `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to revise an existing SFL prompt based on a user's suggestion.\n    The user will provide a JSON object representing the current prompt and a text string with their requested change.\n    If a source document is provided (as part of the prompt object or separately), its style should be analyzed and take precedence, influencing the revision.\n    You MUST return a single, valid JSON object that represents the *revised* prompt. Do not include any text, notes, or explanations outside of the JSON object.\n    The output JSON object must have the exact same structure as the input, containing all the original fields, but with values updated according to the suggestion and stylistic source.\n    The structure is: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string, \"sourceDocument\": { \"name\": string, \"content\": string } | undefined }.\n    \n    - Critically analyze the user's suggestion and apply it to all relevant fields in the prompt.\n    - If a 'sourceDocument' is present, ensure its style is reflected in the revised SFL fields and 'promptText'.\n    - The 'promptText' field is the most important; it must be re-written to reflect the change.\n    - Other SFL fields (Field, Tenor, Mode) should be updated logically to align with the new 'promptText' and the user's suggestion.\n    - Even update the 'title', 'exampleOutput', and 'notes' if the suggestion implies it.\n    - Ensure 'targetAudience' remains an array of strings.\n    - Preserve the 'sourceDocument' field in the output if it existed in the input.`;\n    }\n    /**\n     * Get system instruction for workflow generation\n     */\n    getWorkflowSystemInstruction() {\n        return `You are an expert AI workflow orchestrator. Your task is to analyze a user's goal and generate a complete, multi-task workflow as a valid JSON object.\n    \nThe user goal will be provided. Based on this, create a workflow with a series of tasks. The output MUST be a single, valid JSON object representing the workflow. Do not include any text or explanations outside the JSON.\n\nThe root JSON object must have 'name', 'description', and 'tasks' fields. Each task in the 'tasks' array must have the following fields:\n- id: A unique string identifier for the task (e.g., \"task-1\").\n- name: A short, descriptive name for the task.\n- description: A one-sentence explanation of what the task does.\n- type: One of \"DATA_INPUT\", \"GEMINI_PROMPT\", \"IMAGE_ANALYSIS\", \"TEXT_MANIPULATION\", \"DISPLAY_CHART\", \"GEMINI_GROUNDED\".\n- dependencies: An array of task IDs that this task depends on. Empty for initial tasks.\n- inputKeys: An array of strings representing keys from the Data Store needed for this task. Use dot notation for nested keys (e.g., \"userInput.text\").\n- outputKey: A string for the key where the task's result will be stored in the Data Store.\n\nRules for specific task types:\n- GEMINI_PROMPT/IMAGE_ANALYSIS: Must include a 'promptTemplate' field. Use {{key}} for placeholders.\n- TEXT_MANIPULATION: Must include a 'functionBody' field containing a JavaScript function body as a string. E.g., \"return \\`Report: \\${inputs.summary}\\`\".\n- DATA_INPUT: Must include a 'staticValue' field. Use \"{{userInput.text}}\", \"{{userInput.image}}\", or \"{{userInput.file}}\" to get data from the user input area.\n- DISPLAY_CHART: Must include a 'dataKey' field pointing to data in the Data Store suitable for charting.\n- GEMINI_GROUNDED: For tasks requiring up-to-date information. Should have a 'promptTemplate'.`;\n    }\n    /**\n     * Parse JSON content from AI-generated text (adapted from geminiService)\n     */\n    parseJsonFromText(text) {\n        console.log(\"Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n        // Try multiple extraction strategies\n        const strategies = [\n            // Strategy 1: Extract code block content\n            () => {\n                const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n                const match = text.match(fenceRegex);\n                return match && match[1] ? match[1].trim() : null;\n            },\n            // Strategy 2: Extract content between first { and last }\n            () => {\n                const firstBrace = text.indexOf('{');\n                const lastBrace = text.lastIndexOf('}');\n                if (firstBrace !== -1 && lastBrace > firstBrace) {\n                    return text.substring(firstBrace, lastBrace + 1);\n                }\n                return null;\n            },\n            // Strategy 3: Try the text as-is if it starts with {\n            () => {\n                const trimmed = text.trim();\n                return trimmed.startsWith('{') ? trimmed : null;\n            },\n            // Strategy 4: Remove common prefixes and try again\n            () => {\n                const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n                const firstBrace = cleaned.indexOf('{');\n                const lastBrace = cleaned.lastIndexOf('}');\n                if (firstBrace !== -1 && lastBrace > firstBrace) {\n                    return cleaned.substring(firstBrace, lastBrace + 1);\n                }\n                return null;\n            }\n        ];\n        // Try each strategy\n        for (let i = 0; i < strategies.length; i++) {\n            const jsonStr = strategies[i]();\n            if (jsonStr) {\n                try {\n                    console.log(`Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n                    const parsed = JSON.parse(jsonStr);\n                    console.log(\"Successfully parsed JSON with strategy\", i + 1);\n                    return parsed;\n                }\n                catch (e) {\n                    console.log(`Strategy ${i + 1} failed to parse:`, e);\n                    continue;\n                }\n            }\n        }\n        // If all strategies fail, log detailed error info\n        console.error(\"All JSON parsing strategies failed\");\n        console.error(\"Raw text length:\", text.length);\n        console.error(\"Raw text preview:\", text.substring(0, 500));\n        console.error(\"Text ends with:\", text.substring(Math.max(0, text.length - 100)));\n        throw new Error(\"The AI returned a response that could not be parsed as JSON using any available strategy.\");\n    }\n}\nexports.UnifiedAIService = UnifiedAIService;\n// Export singleton instance\nexports.default = UnifiedAIService.getInstance();\n",
      "metadata": {
        "filename": "unifiedAIService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/webSocketService.js\n\n\"use strict\";\n/**\n * @file webSocketService.ts\n * @description WebSocket service for real-time communication with clients.\n * Manages WebSocket connections and broadcasts workflow execution updates.\n */\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst ws_1 = require(\"ws\");\nconst logger_1 = __importDefault(require(\"../config/logger\"));\n/**\n * Service class for managing WebSocket connections and real-time updates\n */\nclass WebSocketService {\n    constructor() {\n        this.wss = null;\n        this.clients = new Map();\n    }\n    /**\n     * Initializes the WebSocket server\n     * @param server - HTTP server to attach WebSocket server to\n     */\n    initialize(server) {\n        this.wss = new ws_1.WebSocketServer({\n            server,\n            path: '/ws',\n        });\n        this.wss.on('connection', this.handleConnection.bind(this));\n        logger_1.default.info('WebSocket server initialized');\n    }\n    /**\n     * Handles new WebSocket connections\n     * @param ws - The WebSocket connection\n     */\n    handleConnection(ws) {\n        const clientId = this.generateClientId();\n        const client = {\n            ws,\n            subscriptions: new Set(),\n            id: clientId,\n        };\n        this.clients.set(clientId, client);\n        logger_1.default.info(`New WebSocket client connected: ${clientId}`);\n        // Send welcome message\n        this.sendToClient(clientId, {\n            type: 'workflow_progress',\n            jobId: 'system',\n            status: 'connected',\n            timestamp: new Date().toISOString(),\n        });\n        // Handle incoming messages\n        ws.on('message', (data) => {\n            try {\n                const message = JSON.parse(data.toString());\n                this.handleClientMessage(clientId, message);\n            }\n            catch (error) {\n                logger_1.default.error(`Failed to parse WebSocket message from ${clientId}:`, error);\n            }\n        });\n        // Handle connection close\n        ws.on('close', () => {\n            this.clients.delete(clientId);\n            logger_1.default.info(`WebSocket client disconnected: ${clientId}`);\n        });\n        // Handle errors\n        ws.on('error', (error) => {\n            logger_1.default.error(`WebSocket error for client ${clientId}:`, error);\n            this.clients.delete(clientId);\n        });\n    }\n    /**\n     * Handles messages from clients\n     * @param clientId - The client ID\n     * @param message - The message from the client\n     */\n    handleClientMessage(clientId, message) {\n        const client = this.clients.get(clientId);\n        if (!client)\n            return;\n        switch (message.type) {\n            case 'subscribe':\n                if (message.jobId) {\n                    client.subscriptions.add(message.jobId);\n                    logger_1.default.info(`Client ${clientId} subscribed to job ${message.jobId}`);\n                }\n                break;\n            case 'unsubscribe':\n                if (message.jobId) {\n                    client.subscriptions.delete(message.jobId);\n                    logger_1.default.info(`Client ${clientId} unsubscribed from job ${message.jobId}`);\n                }\n                break;\n            default:\n                logger_1.default.warn(`Unknown message type from client ${clientId}:`, message.type);\n        }\n    }\n    /**\n     * Sends a message to a specific client\n     * @param clientId - The client ID\n     * @param message - The message to send\n     */\n    sendToClient(clientId, message) {\n        const client = this.clients.get(clientId);\n        if (!client || client.ws.readyState !== ws_1.WebSocket.OPEN) {\n            return;\n        }\n        try {\n            client.ws.send(JSON.stringify(message));\n        }\n        catch (error) {\n            logger_1.default.error(`Failed to send message to client ${clientId}:`, error);\n            this.clients.delete(clientId);\n        }\n    }\n    /**\n     * Broadcasts a message to all clients subscribed to a specific job\n     * @param jobId - The job ID\n     * @param message - The message to broadcast\n     */\n    broadcastToJob(jobId, message) {\n        const fullMessage = Object.assign(Object.assign({}, message), { jobId, timestamp: new Date().toISOString() });\n        let sentCount = 0;\n        for (const [clientId, client] of this.clients) {\n            if (client.subscriptions.has(jobId)) {\n                this.sendToClient(clientId, fullMessage);\n                sentCount++;\n            }\n        }\n        logger_1.default.debug(`Broadcasted message to ${sentCount} clients for job ${jobId}`);\n    }\n    /**\n     * Broadcasts a message to all connected clients\n     * @param message - The message to broadcast\n     */\n    broadcastToAll(message) {\n        const fullMessage = Object.assign(Object.assign({}, message), { timestamp: new Date().toISOString() });\n        let sentCount = 0;\n        for (const [clientId] of this.clients) {\n            this.sendToClient(clientId, fullMessage);\n            sentCount++;\n        }\n        logger_1.default.debug(`Broadcasted message to ${sentCount} clients`);\n    }\n    /**\n     * Gets the number of connected clients\n     * @returns The number of connected clients\n     */\n    getClientCount() {\n        return this.clients.size;\n    }\n    /**\n     * Gets the number of clients subscribed to a specific job\n     * @param jobId - The job ID\n     * @returns The number of subscribed clients\n     */\n    getSubscribedClientCount(jobId) {\n        let count = 0;\n        for (const client of this.clients.values()) {\n            if (client.subscriptions.has(jobId)) {\n                count++;\n            }\n        }\n        return count;\n    }\n    /**\n     * Generates a unique client ID\n     * @returns A unique client ID\n     */\n    generateClientId() {\n        return `client_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n    }\n    /**\n     * Shuts down the WebSocket service\n     */\n    shutdown() {\n        if (this.wss) {\n            this.wss.close(() => {\n                logger_1.default.info('WebSocket server closed');\n            });\n        }\n        for (const [clientId, client] of this.clients) {\n            client.ws.close();\n        }\n        this.clients.clear();\n    }\n}\nexports.default = new WebSocketService();\n",
      "metadata": {
        "filename": "webSocketService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/workflowExecutionService.js\n\n\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst genai_1 = require(\"@google/genai\");\nconst API_KEY = process.env.GEMINI_API_KEY;\nif (!API_KEY) {\n    console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\nconst ai = new genai_1.GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\nconst getNested = (obj, path) => {\n    return path.split('.').reduce((acc, part) => acc && acc[part], obj);\n};\nconst templateString = (template, dataStore) => {\n    const singleVarMatch = template.trim().match(/^\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}$/);\n    if (singleVarMatch) {\n        const key = singleVarMatch[1];\n        const value = getNested(dataStore, key);\n        return value !== undefined ? value : template;\n    }\n    return template.replace(/\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}/g, (match, key) => {\n        const value = getNested(dataStore, key);\n        if (value === undefined || value === null) {\n            console.warn(`Template key \"${key}\" not found in data store.`);\n            return match;\n        }\n        if (typeof value === 'object') {\n            return JSON.stringify(value, null, 2);\n        }\n        return String(value);\n    });\n};\nconst executeGeminiPrompt = (prompt, agentConfig) => __awaiter(void 0, void 0, void 0, function* () {\n    var _a, _b, _c, _d, _e;\n    const model = (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.model) || 'gemini-2.5-flash';\n    const response = yield ai.models.generateContent({\n        model: model,\n        contents: [{ role: \"user\", parts: [{ text: prompt }] }],\n        config: {\n            temperature: agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.temperature,\n            topK: agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.topK,\n            topP: agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.topP,\n            systemInstruction: (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.systemInstruction) ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n        },\n    });\n    return ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"\";\n});\nconst executeImageAnalysis = (prompt, imagePart, agentConfig) => __awaiter(void 0, void 0, void 0, function* () {\n    var _a, _b, _c, _d, _e;\n    const model = (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.model) || 'gemini-2.5-flash';\n    const textPart = { text: prompt };\n    const response = yield ai.models.generateContent({\n        model,\n        contents: [{ role: \"user\", parts: [textPart, imagePart] }],\n        config: {\n            temperature: agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.temperature,\n            systemInstruction: (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.systemInstruction) ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n        },\n    });\n    return ((_e = (_d = (_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.content) === null || _c === void 0 ? void 0 : _c.parts) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.text) || \"\";\n});\nconst executeGroundedGeneration = (prompt, agentConfig) => __awaiter(void 0, void 0, void 0, function* () {\n    var _a, _b, _c, _d, _e, _f, _g, _h;\n    const model = (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.model) || 'gemini-2.5-flash';\n    const response = yield ai.models.generateContent({\n        model,\n        contents: [{ role: \"user\", parts: [{ text: prompt }] }],\n        config: {\n            tools: [{ googleSearch: {} }],\n            systemInstruction: (agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.systemInstruction) ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n            temperature: agentConfig === null || agentConfig === void 0 ? void 0 : agentConfig.temperature,\n        }\n    });\n    const groundingChunks = ((_c = (_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0]) === null || _b === void 0 ? void 0 : _b.groundingMetadata) === null || _c === void 0 ? void 0 : _c.groundingChunks) || [];\n    const sources = groundingChunks\n        .map((chunk) => chunk.web)\n        .filter((web) => web && web.uri);\n    return {\n        text: ((_h = (_g = (_f = (_e = (_d = response.candidates) === null || _d === void 0 ? void 0 : _d[0]) === null || _e === void 0 ? void 0 : _e.content) === null || _f === void 0 ? void 0 : _f.parts) === null || _g === void 0 ? void 0 : _g[0]) === null || _h === void 0 ? void 0 : _h.text) || \"\",\n        sources: sources,\n    };\n});\nconst executeTextManipulation = (funcBody, inputs) => {\n    try {\n        const func = new Function('inputs', funcBody);\n        return func(inputs);\n    }\n    catch (e) {\n        throw new Error(`Error in custom function: ${e.message}`);\n    }\n};\n/**\n * Performs topological sort on workflow tasks using Kahn's algorithm\n * @param tasks Array of tasks to sort\n * @returns Object containing sorted tasks and any error feedback\n */\nconst topologicalSort = (tasks) => {\n    const feedback = [];\n    // Create adjacency list and in-degree count\n    const adjList = new Map();\n    const inDegree = new Map();\n    const taskMap = new Map();\n    // Initialize all tasks\n    for (const task of tasks) {\n        taskMap.set(task.id, task);\n        adjList.set(task.id, []);\n        inDegree.set(task.id, 0);\n    }\n    // Build dependency graph\n    for (const task of tasks) {\n        for (const depId of task.dependencies) {\n            if (!taskMap.has(depId)) {\n                feedback.push(`Task \"${task.name}\" depends on non-existent task ID: ${depId}`);\n                continue;\n            }\n            // Add edge from dependency to current task\n            adjList.get(depId).push(task.id);\n            inDegree.set(task.id, inDegree.get(task.id) + 1);\n        }\n    }\n    // Kahn's algorithm\n    const queue = [];\n    const result = [];\n    // Find all nodes with no incoming edges\n    for (const [taskId, degree] of inDegree) {\n        if (degree === 0) {\n            queue.push(taskId);\n        }\n    }\n    while (queue.length > 0) {\n        const currentId = queue.shift();\n        const currentTask = taskMap.get(currentId);\n        result.push(currentTask);\n        // Remove this node from the graph\n        for (const neighborId of adjList.get(currentId)) {\n            inDegree.set(neighborId, inDegree.get(neighborId) - 1);\n            if (inDegree.get(neighborId) === 0) {\n                queue.push(neighborId);\n            }\n        }\n    }\n    // Check for cycles\n    if (result.length !== tasks.length) {\n        feedback.push('Cycle detected in task dependencies - workflow cannot be executed');\n        return { sortedTasks: [], feedback };\n    }\n    return { sortedTasks: result, feedback };\n};\n/**\n * Resolves input dependencies and interpolates prompt templates\n * @param task The task to process\n * @param dataStore The current data store\n * @returns The interpolated prompt template and resolved inputs\n */\nconst resolveTaskInputs = (task, dataStore) => {\n    const resolvedInputs = {};\n    // Resolve inputs from data store using inputKeys\n    for (const key of task.inputKeys) {\n        const value = getNested(dataStore, key);\n        if (value === undefined) {\n            throw new Error(`Missing required input key \"${key}\" in data store for task \"${task.name}\"`);\n        }\n        // Use simple key for the resolved inputs (remove dot notation)\n        const simpleKey = key.split('.').pop() || key;\n        resolvedInputs[simpleKey] = value;\n    }\n    // If task has input mappings, resolve those as well\n    if (task.inputs) {\n        for (const [inputName, mapping] of Object.entries(task.inputs)) {\n            const { nodeId, outputName } = mapping;\n            // Look for the output in the data store\n            const outputValue = dataStore[nodeId];\n            if (outputValue === undefined) {\n                throw new Error(`Task \"${task.name}\" depends on output from task \"${nodeId}\" which has not been executed`);\n            }\n            // If outputName is specified, get that specific property\n            let resolvedValue = outputValue;\n            if (outputName && outputName !== nodeId) {\n                if (typeof outputValue === 'object' && outputValue !== null) {\n                    resolvedValue = outputValue[outputName];\n                    if (resolvedValue === undefined) {\n                        throw new Error(`Task \"${task.name}\" expects output \"${outputName}\" from task \"${nodeId}\" but it was not found`);\n                    }\n                }\n            }\n            resolvedInputs[inputName] = resolvedValue;\n        }\n    }\n    // Interpolate prompt template if present\n    let interpolatedPrompt;\n    if (task.promptTemplate) {\n        interpolatedPrompt = templateString(task.promptTemplate, Object.assign(Object.assign({}, dataStore), resolvedInputs));\n    }\n    return { resolvedInputs, interpolatedPrompt };\n};\nclass WorkflowExecutionService {\n    executeTask(task, dataStore, prompt) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a;\n            // Resolve task inputs and interpolate templates\n            const { resolvedInputs, interpolatedPrompt } = resolveTaskInputs(task, dataStore);\n            switch (task.type) {\n                case 'DATA_INPUT':\n                    if (task.staticValue && typeof task.staticValue === 'string') {\n                        return templateString(task.staticValue, dataStore);\n                    }\n                    return task.staticValue;\n                case 'GEMINI_PROMPT': {\n                    if (task.promptId) {\n                        if (!prompt) {\n                            throw new Error(`Task \"${task.name}\" requires prompt ID \"${task.promptId}\" but no prompt was provided.`);\n                        }\n                        const linkedPrompt = prompt;\n                        const { sflTenor, sflMode } = linkedPrompt;\n                        const instructionParts = [];\n                        if (sflTenor.aiPersona)\n                            instructionParts.push(`You will act as a ${sflTenor.aiPersona}.`);\n                        if (sflTenor.desiredTone)\n                            instructionParts.push(`Your tone should be ${sflTenor.desiredTone}.`);\n                        if ((_a = sflTenor.targetAudience) === null || _a === void 0 ? void 0 : _a.length)\n                            instructionParts.push(`You are writing for ${sflTenor.targetAudience.join(', ')}.`);\n                        if (sflMode.textualDirectives)\n                            instructionParts.push(`Follow these directives: ${sflMode.textualDirectives}.`);\n                        const systemInstruction = instructionParts.join(' ');\n                        // Use enhanced interpolation with resolved inputs\n                        const finalPromptText = templateString(linkedPrompt.promptText, Object.assign(Object.assign({}, dataStore), resolvedInputs));\n                        const finalAgentConfig = Object.assign(Object.assign({}, task.agentConfig), { systemInstruction });\n                        return executeGeminiPrompt(finalPromptText, finalAgentConfig);\n                    }\n                    else {\n                        if (!interpolatedPrompt)\n                            throw new Error(\"Prompt template is missing for non-linked prompt task.\");\n                        return executeGeminiPrompt(interpolatedPrompt, task.agentConfig);\n                    }\n                }\n                case 'GEMINI_GROUNDED':\n                    if (!interpolatedPrompt)\n                        throw new Error(\"Prompt template is missing.\");\n                    return executeGroundedGeneration(interpolatedPrompt, task.agentConfig);\n                case 'IMAGE_ANALYSIS': {\n                    if (!interpolatedPrompt)\n                        throw new Error(\"Prompt template is missing.\");\n                    const imageInputKey = task.inputKeys[0];\n                    if (!imageInputKey) {\n                        throw new Error(\"IMAGE_ANALYSIS task must have at least one input key pointing to the image data.\");\n                    }\n                    const imageData = resolvedInputs[imageInputKey.split('.').pop() || imageInputKey];\n                    if (!imageData || typeof imageData.base64 !== 'string' || typeof imageData.type !== 'string') {\n                        throw new Error(`Image data from key \"${imageInputKey}\" is missing, malformed, or not found in inputs.`);\n                    }\n                    const imagePart = {\n                        inlineData: {\n                            data: imageData.base64,\n                            mimeType: imageData.type,\n                        },\n                    };\n                    return executeImageAnalysis(interpolatedPrompt, imagePart, task.agentConfig);\n                }\n                case 'TEXT_MANIPULATION':\n                    if (!task.functionBody)\n                        throw new Error(\"Function body is missing.\");\n                    return executeTextManipulation(task.functionBody, resolvedInputs);\n                default:\n                    throw new Error(`Unsupported task type: ${task.type}`);\n            }\n        });\n    }\n    /**\n     * Executes a complete workflow with proper dependency resolution\n     * @param workflow The workflow to execute\n     * @param userInput Initial user input\n     * @param prompts Array of available prompts\n     * @returns Execution results with data store and task results\n     */\n    executeWorkflow(workflow_1) {\n        return __awaiter(this, arguments, void 0, function* (workflow, userInput = {}, prompts = []) {\n            // Perform topological sort to determine execution order\n            const { sortedTasks, feedback } = topologicalSort(workflow.tasks || []);\n            if (sortedTasks.length === 0) {\n                throw new Error('Cannot execute workflow: ' + feedback.join(', '));\n            }\n            // Initialize data store with user input\n            const dataStore = { userInput };\n            const results = {};\n            // Execute tasks in topologically sorted order\n            for (const task of sortedTasks) {\n                try {\n                    // Find linked prompt if task has one\n                    const linkedPrompt = task.promptId\n                        ? prompts.find(p => p.id === task.promptId)\n                        : undefined;\n                    // Execute the task\n                    const result = yield this.executeTask(task, dataStore, linkedPrompt);\n                    // Store result in data store for subsequent tasks\n                    dataStore[task.outputKey] = result;\n                    results[task.id] = result;\n                }\n                catch (error) {\n                    const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n                    throw new Error(`Task \"${task.name}\" failed: ${errorMessage}`);\n                }\n            }\n            return { dataStore, results, feedback };\n        });\n    }\n}\nexports.default = new WorkflowExecutionService();\n",
      "metadata": {
        "filename": "workflowExecutionService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/services/workflowService.js\n\n\"use strict\";\n/**\n * @file workflowService.ts\n * @description This service handles all business logic and database operations related to workflows.\n * It provides methods for creating, retrieving, updating, and deleting workflows.\n * Workflows contain task definitions and their execution logic stored as JSON in the graph_data column.\n *\n * @requires ../config/database\n * @requires ../types\n * @since 0.5.1\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst database_1 = __importDefault(require(\"../config/database\"));\n/**\n * @class WorkflowService\n * @description A class to encapsulate all business logic for workflows.\n * Provides CRUD operations for workflows and handles the complex graph_data structure\n * that defines the workflow's tasks and their relationships.\n *\n * @since 0.5.1\n */\nclass WorkflowService {\n    /**\n     * Creates a new workflow in the database.\n     * Stores the workflow definition including its task graph structure.\n     *\n     * @param {Omit<Workflow, 'id' | 'created_at' | 'updated_at'>} workflowData - The data for the new workflow.\n     * @returns {Promise<Workflow>} A promise that resolves to the newly created workflow.\n     * @throws {Error} If required fields are missing or database operation fails.\n     *\n     * @example\n     * ```typescript\n     * const newWorkflow = {\n     *   user_id: '123e4567-e89b-12d3-a456-426614174000',\n     *   name: 'Document Analysis Workflow',\n     *   graph_data: {\n     *     tasks: [...],\n     *     connections: [...]\n     *   }\n     * };\n     * const created = await workflowService.createWorkflow(newWorkflow);\n     * ```\n     *\n     * @since 0.5.1\n     */\n    createWorkflow(workflowData) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const { user_id, name, graph_data } = workflowData;\n            const result = yield database_1.default.query('INSERT INTO workflows (user_id, name, graph_data) VALUES ($1, $2, $3) RETURNING *', [user_id, name, graph_data]);\n            return result.rows[0];\n        });\n    }\n    /**\n     * Retrieves all workflows from the database.\n     * Returns workflows ordered by most recently updated first.\n     *\n     * @returns {Promise<Workflow[]>} A promise that resolves to an array of workflows.\n     *\n     * @example\n     * ```typescript\n     * const allWorkflows = await workflowService.getWorkflows();\n     * console.log(`Found ${allWorkflows.length} workflows`);\n     * allWorkflows.forEach(wf => console.log(`- ${wf.name}`));\n     * ```\n     *\n     * @since 0.5.1\n     */\n    getWorkflows() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('SELECT * FROM workflows ORDER BY updated_at DESC');\n            return result.rows;\n        });\n    }\n    /**\n     * Retrieves a single workflow by its ID.\n     *\n     * @param {string} id - The UUID of the workflow to retrieve.\n     * @returns {Promise<Workflow | null>} A promise that resolves to the workflow, or null if not found.\n     *\n     * @example\n     * ```typescript\n     * const workflow = await workflowService.getWorkflowById('123e4567-e89b-12d3-a456-426614174000');\n     * if (workflow) {\n     *   console.log(`Found workflow: ${workflow.name}`);\n     *   console.log(`Tasks: ${workflow.graph_data.tasks?.length || 0}`);\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    getWorkflowById(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('SELECT * FROM workflows WHERE id = $1', [id]);\n            return result.rows[0] || null;\n        });\n    }\n    /**\n     * Updates an existing workflow in the database.\n     * Performs partial updates by merging the provided data with existing workflow.\n     * Preserves existing data for fields not specified in the update.\n     *\n     * @param {string} id - The UUID of the workflow to update.\n     * @param {Partial<Workflow>} workflowData - An object containing the fields to update.\n     * @returns {Promise<Workflow | null>} A promise that resolves to the updated workflow, or null if not found.\n     *\n     * @example\n     * ```typescript\n     * const updates = {\n     *   name: 'Updated Workflow Name',\n     *   graph_data: {\n     *     ...existingGraphData,\n     *     tasks: [...modifiedTasks]\n     *   }\n     * };\n     * const updated = await workflowService.updateWorkflow(workflowId, updates);\n     * ```\n     *\n     * @since 0.5.1\n     */\n    updateWorkflow(id, workflowData) {\n        return __awaiter(this, void 0, void 0, function* () {\n            var _a, _b;\n            // First, fetch the existing workflow from the database\n            const existing = yield database_1.default.query('SELECT * FROM workflows WHERE id = $1', [id]);\n            if (!existing.rows[0])\n                return null;\n            // Create a merged object by combining existing data with new data\n            const name = (_a = workflowData.name) !== null && _a !== void 0 ? _a : existing.rows[0].name;\n            const graph_data = (_b = workflowData.graph_data) !== null && _b !== void 0 ? _b : existing.rows[0].graph_data;\n            // Update with the merged values to ensure partial updates don't overwrite existing data\n            const result = yield database_1.default.query('UPDATE workflows SET name = $1, graph_data = $2, updated_at = now() WHERE id = $3 RETURNING *', [name, graph_data, id]);\n            return result.rows[0] || null;\n        });\n    }\n    /**\n     * Deletes a workflow from the database.\n     *\n     * @param {string} id - The UUID of the workflow to delete.\n     * @returns {Promise<boolean>} A promise that resolves to true if the deletion was successful, false if the workflow was not found.\n     *\n     * @example\n     * ```typescript\n     * const deleted = await workflowService.deleteWorkflow('123e4567-e89b-12d3-a456-426614174000');\n     * if (deleted) {\n     *   console.log('Workflow successfully deleted');\n     * } else {\n     *   console.log('Workflow not found');\n     * }\n     * ```\n     *\n     * @since 0.5.1\n     */\n    deleteWorkflow(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const result = yield database_1.default.query('DELETE FROM workflows WHERE id = $1', [id]);\n            return !!result.rowCount;\n        });\n    }\n}\n/**\n * @exports {WorkflowService} workflowService\n * @description Singleton instance of the WorkflowService class, ready to be used across the application.\n * This exported instance provides all workflow-related database operations.\n *\n * @since 0.5.1\n */\nexports.default = new WorkflowService();\n",
      "metadata": {
        "filename": "workflowService.js",
        "path": "/backend/dist/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/setupTests.js\n\n\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Global test setup\nconst globals_1 = require(\"@jest/globals\");\n// Increase test timeout for integration tests\nglobals_1.jest.setTimeout(30000);\n",
      "metadata": {
        "filename": "setupTests.js",
        "path": "/backend/dist/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/types/aiProvider.js\n\n\"use strict\";\n/**\n * @file aiProvider.ts\n * @description Backend type definitions for AI provider management and parameter configuration.\n * These types mirror the frontend types to ensure consistency across the application.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n",
      "metadata": {
        "filename": "aiProvider.js",
        "path": "/backend/dist/types/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/types/express.js\n\n\"use strict\";\n/**\n * @file express.ts\n * @description Express.js type extensions for authentication middleware integration\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n",
      "metadata": {
        "filename": "express.js",
        "path": "/backend/dist/types/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/dist/types.js\n\n\"use strict\";\n/**\n * @file types.ts\n * @description This file contains TypeScript type definitions and interfaces for the backend.\n * It defines the data structures for database entities like Prompts and Workflows,\n * as well as the detailed SFL-structured prompt types that align with the frontend.\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.TaskType = void 0;\n/**\n * @enum {string} TaskType\n * @description Enumerates the different types of tasks that can be part of a workflow.\n */\nvar TaskType;\n(function (TaskType) {\n    TaskType[\"DATA_INPUT\"] = \"DATA_INPUT\";\n    TaskType[\"GEMINI_PROMPT\"] = \"GEMINI_PROMPT\";\n    TaskType[\"IMAGE_ANALYSIS\"] = \"IMAGE_ANALYSIS\";\n    TaskType[\"TEXT_MANIPULATION\"] = \"TEXT_MANIPULATION\";\n    TaskType[\"SIMULATE_PROCESS\"] = \"SIMULATE_PROCESS\";\n    TaskType[\"DISPLAY_CHART\"] = \"DISPLAY_CHART\";\n    TaskType[\"GEMINI_GROUNDED\"] = \"GEMINI_GROUNDED\";\n})(TaskType || (exports.TaskType = TaskType = {}));\n",
      "metadata": {
        "filename": "types.js",
        "path": "/backend/dist/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/jest.config.js\n\nmodule.exports = {\n  preset: 'ts-jest',\n  testEnvironment: 'node',\n  roots: ['<rootDir>/src'],\n  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],\n  transform: {\n    '^.+\\\\.ts$': 'ts-jest',\n  },\n  collectCoverageFrom: [\n    'src/**/*.ts',\n    '!src/**/*.d.ts',\n  ],\n  setupFilesAfterEnv: ['<rootDir>/src/setupTests.ts'],\n};\n",
      "metadata": {
        "filename": "jest.config.js",
        "path": "/backend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/geminiController.ts\n\nimport { Request, Response, NextFunction } from 'express';\nimport GeminiService from '../../services/geminiService';\nimport UnifiedAIService, { ProviderAwareRequest } from '../../services/unifiedAIService';\nimport { aiProviderFactory } from '../../services/ai/AIProviderFactory';\nimport { AIProvider, ModelParameters } from '../../types/aiProvider';\n\nclass GeminiController {\n  async testPrompt(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { promptText, provider, model, parameters, apiKey, baseUrl } = req.body;\n      if (!promptText) {\n        return res.status(400).json({ message: 'promptText is required' });\n      }\n\n      // Create provider configuration from request\n      const providerConfig: ProviderAwareRequest = {\n        provider: provider as AIProvider,\n        model,\n        parameters,\n        apiKey,\n        baseUrl\n      };\n\n      const result = await UnifiedAIService.testPrompt(promptText, providerConfig);\n      res.status(200).json({ text: result });\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  async generateSFLFromGoal(req: Request, res: Response, next: NextFunction) {\n    try {\n      console.log('POST /api/gemini/generate-sfl received');\n      console.log('Request body:', JSON.stringify(req.body, null, 2));\n      \n      const { goal, sourceDocContent, provider, model, parameters, apiKey, baseUrl } = req.body;\n      if (!goal) {\n        console.log('Error: Goal is required but not provided');\n        return res.status(400).json({ message: 'Goal is required' });\n      }\n\n      // Create provider configuration from request\n      const providerConfig: ProviderAwareRequest = {\n        provider: provider as AIProvider,\n        model,\n        parameters,\n        apiKey,\n        baseUrl\n      };\n      \n      console.log('Calling UnifiedAIService.generateSFLFromGoal...');\n      const result = await UnifiedAIService.generateSFLFromGoal(goal, sourceDocContent, providerConfig);\n      console.log('Generated SFL result:', JSON.stringify(result, null, 2));\n      \n      res.status(200).json(result);\n    } catch (error) {\n      console.error('Error in generateSFLFromGoal controller:', error);\n      next(error);\n    }\n  }\n\n  async regenerateSFLFromSuggestion(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { currentPrompt, suggestion, provider, model, parameters, apiKey, baseUrl } = req.body;\n      if (!currentPrompt || !suggestion) {\n        return res.status(400).json({ message: 'Current prompt and suggestion are required' });\n      }\n\n      // Create provider configuration from request\n      const providerConfig: ProviderAwareRequest = {\n        provider: provider as AIProvider,\n        model,\n        parameters,\n        apiKey,\n        baseUrl\n      };\n\n      const result = await UnifiedAIService.regenerateSFLFromSuggestion(currentPrompt, suggestion, providerConfig);\n      res.status(200).json(result);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  async generateWorkflowFromGoal(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { goal, provider, model, parameters, apiKey, baseUrl } = req.body;\n      if (!goal) {\n        return res.status(400).json({ message: 'Goal is required' });\n      }\n\n      // Create provider configuration from request\n      const providerConfig: ProviderAwareRequest = {\n        provider: provider as AIProvider,\n        model,\n        parameters,\n        apiKey,\n        baseUrl\n      };\n\n      const result = await UnifiedAIService.generateWorkflowFromGoal(goal, providerConfig);\n      res.status(200).json(result);\n    } catch (error) {\n      next(error);\n    }\n  }\n}\n\nexport default new GeminiController();\n",
      "metadata": {
        "filename": "geminiController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/modelController.ts\n\nimport { Request, Response, NextFunction } from 'express';\nimport ModelService from '../../services/modelService';\n\n/**\n * @class ModelController\n * @description Controller for handling model-related requests.\n */\nclass ModelController {\n  /**\n   * @method getModels\n   * @description Retrieves a list of all available models.\n   * @param {Request} req - The Express request object.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async getModels(req: Request, res: Response, next: NextFunction) {\n    try {\n      const models = await ModelService.getModels();\n      res.status(200).json(models);\n    } catch (error) {\n      next(error);\n    }\n  }\n}\n\nexport default new ModelController();\n",
      "metadata": {
        "filename": "modelController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/promptController.ts\n\nimport { Request, Response, NextFunction } from 'express';\nimport PromptService from '../../services/promptService';\nimport '../../types/express';\n\n/**\n * @class PromptController\n * @description Controller for handling prompt-related requests.\n */\nclass PromptController {\n  /**\n   * @method createPrompt\n   * @description Creates a new prompt.\n   * @param {Request} req - The Express request object, containing the prompt data in the body and user info.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async createPrompt(req: Request, res: Response, next: NextFunction) {\n    try {\n      if (!req.user?.id) {\n        return res.status(401).json({ message: 'Authentication required' });\n      }\n\n      const prompt = await PromptService.createPrompt(req.body, req.user.id);\n      res.status(201).json(prompt);\n    } catch (error) {\n      console.error('Create prompt error:', error);\n      if (error instanceof Error) {\n        res.status(400).json({ message: error.message });\n      } else {\n        next(error);\n      }\n    }\n  }\n\n  /**\n   * @method getPrompts\n   * @description Retrieves a list of prompts, with optional filtering.\n   * @param {Request} req - The Express request object, containing query parameters for filtering.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async getPrompts(req: Request, res: Response, next: NextFunction) {\n    try {\n      const prompts = await PromptService.getPrompts(req.query);\n      res.status(200).json(prompts);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * @method getPromptById\n   * @description Retrieves a single prompt by its ID.\n   * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async getPromptById(req: Request, res: Response, next: NextFunction) {\n    try {\n      const prompt = await PromptService.getPromptById(req.params.id);\n      if (!prompt) {\n        return res.status(404).json({ message: 'Prompt not found' });\n      }\n      res.status(200).json(prompt);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * @method updatePrompt\n   * @description Updates an existing prompt.\n   * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter, update data in the body, and user info.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async updatePrompt(req: Request, res: Response, next: NextFunction) {\n    try {\n      if (!req.user?.id) {\n        return res.status(401).json({ message: 'Authentication required' });\n      }\n\n      const prompt = await PromptService.updatePrompt(req.params.id, req.body, req.user.id);\n      if (!prompt) {\n        return res.status(404).json({ message: 'Prompt not found' });\n      }\n      res.status(200).json(prompt);\n    } catch (error) {\n      console.error('Update prompt error:', error);\n      if (error instanceof Error) {\n        res.status(400).json({ message: error.message });\n      } else {\n        next(error);\n      }\n    }\n  }\n\n  /**\n   * @method deletePrompt\n   * @description Deletes a prompt by its ID.\n   * @param {Request} req - The Express request object, containing the prompt ID as a URL parameter.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function.\n   * @returns {Promise<void>} - A promise that resolves when the response is sent.\n   */\n  async deletePrompt(req: Request, res: Response, next: NextFunction) {\n    try {\n      const success = await PromptService.deletePrompt(req.params.id);\n      if (!success) {\n        return res.status(404).json({ message: 'Prompt not found' });\n      }\n      res.status(204).send();\n    } catch (error) {\n      next(error);\n    }\n  }\n}\n\nexport default new PromptController();\n",
      "metadata": {
        "filename": "promptController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/providerController.ts\n\n/**\n * @file providerController.ts\n * @description Controller for AI provider validation and status endpoints\n * @since 0.6.0\n */\n\nimport { Request, Response } from 'express';\nimport {\n  detectAvailableProviders,\n  validateAllProviders,\n  hasValidProvider,\n  getPreferredProvider,\n  validateProviderApiKey,\n  type AIProvider,\n} from '../../services/providerValidationService';\n\n/**\n * Controller class for managing AI provider validation and configuration\n */\nclass ProviderController {\n  /**\n   * Get the status of all available providers\n   * @route GET /api/providers/status\n   */\n  static async getProviderStatus(req: Request, res: Response): Promise<void> {\n    try {\n      const providers = await validateAllProviders();\n      const hasAnyValid = providers.some(p => p.validationResult?.success === true);\n      const preferredProvider = await getPreferredProvider();\n\n      res.json({\n        success: true,\n        data: {\n          providers,\n          hasValidProvider: hasAnyValid,\n          preferredProvider,\n        },\n      });\n    } catch (error) {\n      console.error('Error checking provider status:', error);\n      res.status(500).json({\n        success: false,\n        error: 'Failed to check provider status',\n        details: error instanceof Error ? error.message : String(error),\n      });\n    }\n  }\n\n  /**\n   * Get available providers without validation (faster)\n   * @route GET /api/providers/available\n   */\n  static async getAvailableProviders(req: Request, res: Response): Promise<void> {\n    try {\n      const providers = detectAvailableProviders();\n\n      res.json({\n        success: true,\n        data: {\n          providers,\n        },\n      });\n    } catch (error) {\n      console.error('Error getting available providers:', error);\n      res.status(500).json({\n        success: false,\n        error: 'Failed to get available providers',\n        details: error instanceof Error ? error.message : String(error),\n      });\n    }\n  }\n\n  /**\n   * Check if at least one provider is valid and ready\n   * @route GET /api/providers/health\n   */\n  static async checkProviderHealth(req: Request, res: Response): Promise<void> {\n    try {\n      const isHealthy = await hasValidProvider();\n      const preferredProvider = await getPreferredProvider();\n\n      res.json({\n        success: true,\n        data: {\n          healthy: isHealthy,\n          preferredProvider,\n          requiresSetup: !isHealthy,\n        },\n      });\n    } catch (error) {\n      console.error('Error checking provider health:', error);\n      res.status(500).json({\n        success: false,\n        error: 'Failed to check provider health',\n        details: error instanceof Error ? error.message : String(error),\n      });\n    }\n  }\n\n  /**\n   * Validate a specific provider's API key\n   * @route POST /api/providers/validate\n   * @body { provider: string, apiKey: string, baseUrl?: string }\n   */\n  static async validateProvider(req: Request, res: Response): Promise<void> {\n    try {\n      const { provider, apiKey, baseUrl } = req.body;\n\n      if (!provider || !apiKey) {\n        res.status(400).json({\n          success: false,\n          error: 'Provider and API key are required',\n        });\n        return;\n      }\n\n      // Validate provider type\n      const validProviders: AIProvider[] = ['google', 'openai', 'openrouter', 'anthropic'];\n      if (!validProviders.includes(provider)) {\n        res.status(400).json({\n          success: false,\n          error: `Invalid provider. Must be one of: ${validProviders.join(', ')}`,\n        });\n        return;\n      }\n\n      const result = await validateProviderApiKey(provider, apiKey, baseUrl);\n\n      res.json({\n        success: true,\n        data: {\n          provider,\n          validation: result,\n        },\n      });\n    } catch (error) {\n      console.error('Error validating provider:', error);\n      res.status(500).json({\n        success: false,\n        error: 'Failed to validate provider',\n        details: error instanceof Error ? error.message : String(error),\n      });\n    }\n  }\n\n  /**\n   * Get the preferred provider based on configuration\n   * @route GET /api/providers/preferred\n   */\n  static async getPreferredProvider(req: Request, res: Response): Promise<void> {\n    try {\n      const preferredProvider = await getPreferredProvider();\n\n      if (!preferredProvider) {\n        res.status(404).json({\n          success: false,\n          error: 'No valid provider available',\n          data: {\n            preferredProvider: null,\n            requiresSetup: true,\n          },\n        });\n        return;\n      }\n\n      res.json({\n        success: true,\n        data: {\n          preferredProvider,\n          requiresSetup: false,\n        },\n      });\n    } catch (error) {\n      console.error('Error getting preferred provider:', error);\n      res.status(500).json({\n        success: false,\n        error: 'Failed to get preferred provider',\n        details: error instanceof Error ? error.message : String(error),\n      });\n    }\n  }\n}\n\nexport default ProviderController;\n",
      "metadata": {
        "filename": "providerController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/workflowController.ts\n\n/**\n * @file workflowController.ts\n * @description Controller for handling HTTP requests related to workflows.\n * Provides REST API endpoints for CRUD operations on workflow entities.\n * All methods follow Express.js controller patterns and include proper error handling.\n * \n * @requires express\n * @requires ../../services/workflowService\n * @since 0.5.1\n */\n\nimport { Request, Response, NextFunction } from 'express';\nimport WorkflowService from '../../services/workflowService';\nimport OrchestratorService from '../../services/orchestratorService';\n\n/**\n * @class WorkflowController\n * @description Controller for handling workflow-related HTTP requests.\n * Provides REST API endpoints for creating, reading, updating, and deleting workflows.\n * Each method handles request validation, service calls, and appropriate HTTP responses.\n * \n * @since 0.5.1\n */\nclass WorkflowController {\n  /**\n   * Creates a new workflow from the request body.\n   * Expects workflow data including name, user_id, and graph_data in the request body.\n   * \n   * @param {Request} req - The Express request object, containing the workflow data in the body.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes validation or database errors to the error handler middleware.\n   * \n   * @example\n   * POST /api/workflows\n   * Content-Type: application/json\n   * {\n   *   \"user_id\": \"123e4567-e89b-12d3-a456-426614174000\",\n   *   \"name\": \"Document Processing Workflow\",\n   *   \"graph_data\": { \"tasks\": [...], \"connections\": [...] }\n   * }\n   * \n   * @since 0.5.1\n   */\n  async createWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const workflow = await WorkflowService.createWorkflow(req.body);\n      res.status(201).json(workflow);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * Retrieves all workflows from the database.\n   * Returns workflows ordered by most recently updated first.\n   * \n   * @param {Request} req - The Express request object.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes database errors to the error handler middleware.\n   * \n   * @example\n   * GET /api/workflows\n   * Response: 200 OK\n   * [\n   *   {\n   *     \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n   *     \"name\": \"Workflow 1\",\n   *     \"graph_data\": {...},\n   *     \"created_at\": \"2024-01-01T00:00:00Z\",\n   *     \"updated_at\": \"2024-01-01T00:00:00Z\"\n   *   }\n   * ]\n   * \n   * @since 0.5.1\n   */\n  async getWorkflows(req: Request, res: Response, next: NextFunction) {\n    try {\n      const workflows = await WorkflowService.getWorkflows();\n      res.status(200).json(workflows);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * Retrieves a single workflow by its UUID.\n   * Returns 404 if the workflow is not found.\n   * \n   * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes database errors to the error handler middleware.\n   * \n   * @example\n   * GET /api/workflows/123e4567-e89b-12d3-a456-426614174000\n   * Response: 200 OK\n   * {\n   *   \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n   *   \"name\": \"My Workflow\",\n   *   \"graph_data\": {...}\n   * }\n   * \n   * @since 0.5.1\n   */\n  async getWorkflowById(req: Request, res: Response, next: NextFunction) {\n    try {\n      const workflow = await WorkflowService.getWorkflowById(req.params.id);\n      if (!workflow) {\n        return res.status(404).json({ message: 'Workflow not found' });\n      }\n      res.status(200).json(workflow);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * Updates an existing workflow with partial data.\n   * Performs a partial update, merging the request body with existing workflow data.\n   * Returns 404 if the workflow is not found.\n   * \n   * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter and the update data in the body.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes validation or database errors to the error handler middleware.\n   * \n   * @example\n   * PUT /api/workflows/123e4567-e89b-12d3-a456-426614174000\n   * Content-Type: application/json\n   * {\n   *   \"name\": \"Updated Workflow Name\",\n   *   \"graph_data\": { \"tasks\": [...] }\n   * }\n   * \n   * @since 0.5.1\n   */\n  async updateWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const workflow = await WorkflowService.updateWorkflow(req.params.id, req.body);\n      if (!workflow) {\n        return res.status(404).json({ message: 'Workflow not found' });\n      }\n      res.status(200).json(workflow);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * Deletes a workflow by its UUID.\n   * Returns 404 if the workflow is not found, otherwise returns 204 No Content.\n   * \n   * @param {Request} req - The Express request object, containing the workflow ID as a URL parameter.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes database errors to the error handler middleware.\n   * \n   * @example\n   * DELETE /api/workflows/123e4567-e89b-12d3-a456-426614174000\n   * Response: 204 No Content (if successful)\n   * Response: 404 Not Found (if workflow doesn't exist)\n   * \n   * @since 0.5.1\n   */\n  async deleteWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const success = await WorkflowService.deleteWorkflow(req.params.id);\n      if (!success) {\n        return res.status(404).json({ message: 'Workflow not found' });\n      }\n      res.status(204).send();\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  /**\n   * Orchestrates a new workflow from a high-level user request using AI.\n   * Takes a natural language description and automatically generates a complete,\n   * executable workflow with proper task dependencies and data flow.\n   * \n   * @param {Request} req - The Express request object, containing the user request in the body.\n   * @param {Response} res - The Express response object.\n   * @param {NextFunction} next - The Express next middleware function for error handling.\n   * @returns {Promise<void>} A promise that resolves when the response is sent.\n   * \n   * @throws {Error} Passes orchestration or validation errors to the error handler middleware.\n   * \n   * @example\n   * POST /api/workflows/orchestrate\n   * Content-Type: application/json\n   * {\n   *   \"request\": \"Analyze customer feedback for sentiment and generate a summary report\"\n   * }\n   * \n   * Response: 200 OK\n   * {\n   *   \"success\": true,\n   *   \"workflow\": {\n   *     \"id\": \"orchestrated-1234567890-abcdef\",\n   *     \"name\": \"Customer Feedback Analysis\",\n   *     \"description\": \"Analyzes customer feedback for sentiment...\",\n   *     \"tasks\": [...]\n   *   }\n   * }\n   * \n   * @since 2.1.0\n   */\n  async orchestrateWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { request } = req.body;\n\n      // Validate input\n      if (!request || typeof request !== 'string') {\n        return res.status(400).json({\n          success: false,\n          error: 'Request body must contain a \"request\" field with a string description of the desired workflow.'\n        });\n      }\n\n      if (request.trim().length === 0) {\n        return res.status(400).json({\n          success: false,\n          error: 'The request description cannot be empty.'\n        });\n      }\n\n      if (request.length > 2000) {\n        return res.status(400).json({\n          success: false,\n          error: 'The request description is too long. Please limit to 2000 characters.'\n        });\n      }\n\n      // Check if orchestrator service is configured\n      if (!OrchestratorService.isConfigured()) {\n        return res.status(503).json({\n          success: false,\n          error: 'AI orchestration service is not properly configured. Please check the GEMINI_API_KEY environment variable.'\n        });\n      }\n\n      // Generate workflow using orchestrator service\n      const result = await OrchestratorService.generateWorkflow(request.trim());\n\n      if (!result.success) {\n        return res.status(422).json({\n          success: false,\n          error: result.error || 'Failed to generate workflow',\n          validationErrors: result.validationErrors\n        });\n      }\n\n      // Return the generated workflow\n      res.status(200).json({\n        success: true,\n        workflow: result.workflow\n      });\n\n    } catch (error) {\n      next(error);\n    }\n  }\n}\n\n/**\n * @exports {WorkflowController} workflowController\n * @description Singleton instance of the WorkflowController class, ready to be used in route definitions.\n * This exported instance provides all workflow-related HTTP request handlers.\n * \n * @since 0.5.1\n */\nexport default new WorkflowController();\n",
      "metadata": {
        "filename": "workflowController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/controllers/workflowExecutionController.ts\n\nimport { Request, Response, NextFunction } from 'express';\nimport WorkflowExecutionService from '../../services/workflowExecutionService';\nimport PromptService from '../../services/promptService';\nimport config from '../../config/env';\nimport { PromptSFL, Workflow } from '../../types';\n\n// Conditionally import job service based on Redis availability\nlet JobService: any;\ntry {\n  // Try to import the real job service\n  JobService = require('../../services/jobService').default;\n} catch (error) {\n  console.warn('Redis not available, using mock job service');\n  JobService = require('../../services/mockJobService').default;\n}\n\nclass WorkflowExecutionController {\n  async runTask(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { task, dataStore } = req.body;\n      if (!task || !dataStore) {\n        return res.status(400).json({ message: 'Task and dataStore are required' });\n      }\n      \n      // Optimize: Only fetch the specific prompt if needed, instead of all prompts\n      let linkedPrompt: PromptSFL | undefined;\n      if (task.promptId) {\n        const foundPrompt = await PromptService.getPromptById(task.promptId);\n        if (!foundPrompt) {\n          return res.status(404).json({ message: `Prompt with ID ${task.promptId} not found` });\n        }\n        linkedPrompt = foundPrompt;\n      }\n      \n      const result = await WorkflowExecutionService.executeTask(task, dataStore, linkedPrompt);\n      res.status(200).json(result);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  async executeWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { workflow, userInput } = req.body;\n      \n      if (!workflow) {\n        return res.status(400).json({ message: 'Workflow is required' });\n      }\n\n      if (!workflow.id) {\n        return res.status(400).json({ message: 'Workflow must have an ID' });\n      }\n\n      // Add workflow to execution queue\n      const jobId = await JobService.addWorkflowJob(\n        workflow.id,\n        workflow as Workflow,\n        userInput\n      );\n\n      // Return immediately with job ID and pending status\n      res.status(202).json({\n        jobId,\n        status: 'pending',\n        message: 'Workflow execution started. Use the job ID to check status.'\n      });\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  async getJobStatus(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { jobId } = req.params;\n      \n      if (!jobId) {\n        return res.status(400).json({ message: 'Job ID is required' });\n      }\n\n      const jobStatus = await JobService.getJobStatus(jobId);\n      \n      if (!jobStatus) {\n        return res.status(404).json({ message: 'Job not found' });\n      }\n\n      res.status(200).json(jobStatus);\n    } catch (error) {\n      next(error);\n    }\n  }\n\n  async stopWorkflow(req: Request, res: Response, next: NextFunction) {\n    try {\n      const { jobId } = req.params;\n      \n      if (!jobId) {\n        return res.status(400).json({ message: 'Job ID is required' });\n      }\n\n      const success = await JobService.stopJob(jobId);\n      \n      if (!success) {\n        return res.status(404).json({ message: 'Job not found or already completed' });\n      }\n\n      res.status(200).json({\n        message: 'Workflow stop requested successfully',\n        jobId\n      });\n    } catch (error) {\n      next(error);\n    }\n  }\n}\n\nexport default new WorkflowExecutionController();\n",
      "metadata": {
        "filename": "workflowExecutionController.ts",
        "path": "/backend/src/api/controllers/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/prompts.test.ts\n\n/**\n * @file prompts.test.ts\n * @description Integration tests for the /api/prompts endpoints.\n * Tests all CRUD operations for prompts with proper HTTP status codes and error handling.\n * Uses mocked database to isolate API logic testing.\n */\n\nimport request from 'supertest';\nimport app from '../app';\nimport { PromptSFL } from '../types';\n\n// Mock the database pool\njest.mock('../config/database', () => ({\n  query: jest.fn(),\n  end: jest.fn(),\n  on: jest.fn(),\n}));\n\nimport pool from '../config/database';\n\nconst mockQuery = pool.query as jest.MockedFunction<any>;\nconst mockEnd = pool.end as jest.MockedFunction<any>;\n\ndescribe('/api/prompts', () => {\n  const mockPromptId = 'test-prompt-id-123';\n  const validPromptData = {\n    title: 'Test Prompt',\n    promptText: 'This is a test prompt for testing purposes.',\n    sflField: {\n      topic: 'Testing',\n      taskType: 'Code Generation',\n      domainSpecifics: 'Unit tests',\n      keywords: 'test, jest, supertest'\n    },\n    sflTenor: {\n      aiPersona: 'Expert',\n      targetAudience: ['Software Developers'],\n      desiredTone: 'Technical',\n      interpersonalStance: 'Helpful'\n    },\n    sflMode: {\n      outputFormat: 'Code',\n      rhetoricalStructure: 'Step-by-step',\n      lengthConstraint: 'Detailed',\n      textualDirectives: 'Include comments'\n    },\n    notes: 'Test prompt for integration testing'\n  };\n\n  beforeEach(() => {\n    jest.clearAllMocks();\n  });\n\n  afterAll(async () => {\n    await mockEnd();\n  });\n\n  describe('POST /api/prompts', () => {\n    it('should create a prompt successfully with valid data', async () => {\n      const mockDbResponse = {\n        rows: [{\n          id: mockPromptId,\n          user_id: '00000000-0000-0000-0000-000000000001',\n          title: validPromptData.title,\n          body: validPromptData.promptText,\n          metadata: {\n            sflField: validPromptData.sflField,\n            sflTenor: validPromptData.sflTenor,\n            sflMode: validPromptData.sflMode,\n            notes: validPromptData.notes\n          },\n          created_at: '2024-01-01T00:00:00Z',\n          updated_at: '2024-01-01T00:00:00Z'\n        }]\n      };\n\n      mockQuery.mockResolvedValueOnce(mockDbResponse);\n\n      const response = await request(app)\n        .post('/api/prompts')\n        .send(validPromptData)\n        .expect(201);\n\n      expect(response.body).toMatchObject({\n        id: mockPromptId,\n        title: validPromptData.title,\n        promptText: validPromptData.promptText,\n        sflField: validPromptData.sflField\n      });\n\n      expect(mockQuery).toHaveBeenCalledWith(\n        'INSERT INTO prompts (user_id, title, body, metadata) VALUES ($1, $2, $3, $4) RETURNING *',\n        expect.any(Array)\n      );\n    });\n\n    it('should return 400 when title is missing', async () => {\n      const invalidData = { ...validPromptData, title: '' };\n\n      const response = await request(app)\n        .post('/api/prompts')\n        .send(invalidData)\n        .expect(400);\n\n      expect(response.body.message).toContain('Title');\n      expect(mockQuery).not.toHaveBeenCalled();\n    });\n\n    it('should return 400 when promptText is missing', async () => {\n      const invalidData = { ...validPromptData, promptText: '' };\n\n      const response = await request(app)\n        .post('/api/prompts')\n        .send(invalidData)\n        .expect(400);\n\n      expect(response.body.message).toContain('Prompt text');\n      expect(mockQuery).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('GET /api/prompts', () => {\n    it('should retrieve all prompts successfully', async () => {\n      const mockDbResponse = {\n        rows: [\n          {\n            id: mockPromptId,\n            user_id: '00000000-0000-0000-0000-000000000001',\n            title: 'Test Prompt',\n            body: 'Test prompt text',\n            metadata: {\n              sflField: { topic: 'Test', taskType: 'Testing', domainSpecifics: '', keywords: '' },\n              sflTenor: { aiPersona: 'Expert', targetAudience: [], desiredTone: 'Neutral', interpersonalStance: '' },\n              sflMode: { outputFormat: 'Text', rhetoricalStructure: '', lengthConstraint: 'Short', textualDirectives: '' }\n            },\n            created_at: '2024-01-01T00:00:00Z',\n            updated_at: '2024-01-01T00:00:00Z'\n          }\n        ]\n      };\n\n      mockQuery.mockResolvedValueOnce(mockDbResponse);\n\n      const response = await request(app)\n        .get('/api/prompts')\n        .expect(200);\n\n      expect(Array.isArray(response.body)).toBe(true);\n      expect(response.body).toHaveLength(1);\n      expect(response.body[0]).toMatchObject({\n        id: mockPromptId,\n        title: 'Test Prompt'\n      });\n\n      expect(mockQuery).toHaveBeenCalledWith('SELECT * FROM prompts ORDER BY updated_at DESC');\n    });\n  });\n\n  describe('GET /api/prompts/:id', () => {\n    it('should retrieve a single prompt successfully with valid ID', async () => {\n      const mockDbResponse = {\n        rows: [{\n          id: mockPromptId,\n          user_id: '00000000-0000-0000-0000-000000000001',\n          title: 'Test Prompt',\n          body: 'Test prompt text',\n          metadata: {},\n          created_at: '2024-01-01T00:00:00Z',\n          updated_at: '2024-01-01T00:00:00Z'\n        }]\n      };\n\n      mockQuery.mockResolvedValueOnce(mockDbResponse);\n\n      const response = await request(app)\n        .get(`/api/prompts/${mockPromptId}`)\n        .expect(200);\n\n      expect(response.body).toMatchObject({\n        id: mockPromptId,\n        title: 'Test Prompt'\n      });\n\n      expect(mockQuery).toHaveBeenCalledWith('SELECT * FROM prompts WHERE id = $1', [mockPromptId]);\n    });\n\n    it('should return 404 for non-existent prompt ID', async () => {\n      const nonExistentId = '00000000-0000-0000-0000-000000000999';\n      \n      mockQuery.mockResolvedValueOnce({ rows: [] });\n\n      const response = await request(app)\n        .get(`/api/prompts/${nonExistentId}`)\n        .expect(404);\n\n      expect(response.body.message).toBe('Prompt not found');\n    });\n  });\n\n  describe('PUT /api/prompts/:id', () => {\n    it('should update a prompt successfully with valid data', async () => {\n      const existingPrompt = {\n        rows: [{\n          id: mockPromptId,\n          user_id: '00000000-0000-0000-0000-000000000001',\n          title: 'Original Title',\n          body: 'Original text',\n          metadata: {},\n          created_at: '2024-01-01T00:00:00Z',\n          updated_at: '2024-01-01T00:00:00Z'\n        }]\n      };\n\n      const updatedPrompt = {\n        rows: [{\n          ...existingPrompt.rows[0],\n          title: 'Updated Title',\n          body: 'Updated text',\n          updated_at: '2024-01-01T01:00:00Z'\n        }]\n      };\n\n      mockQuery\n        .mockResolvedValueOnce(existingPrompt)  // SELECT existing\n        .mockResolvedValueOnce(updatedPrompt);  // UPDATE\n\n      const updateData = { title: 'Updated Title', promptText: 'Updated text' };\n\n      const response = await request(app)\n        .put(`/api/prompts/${mockPromptId}`)\n        .send(updateData)\n        .expect(200);\n\n      expect(response.body).toMatchObject({\n        id: mockPromptId,\n        title: 'Updated Title',\n        promptText: 'Updated text'\n      });\n    });\n\n    it('should return 404 for non-existent prompt ID', async () => {\n      const nonExistentId = '00000000-0000-0000-0000-000000000999';\n      \n      mockQuery.mockResolvedValueOnce({ rows: [] });\n\n      const response = await request(app)\n        .put(`/api/prompts/${nonExistentId}`)\n        .send({ title: 'Updated Title' })\n        .expect(404);\n\n      expect(response.body.message).toBe('Prompt not found');\n    });\n\n    it('should return 400 when trying to update title to empty string', async () => {\n      const response = await request(app)\n        .put(`/api/prompts/${mockPromptId}`)\n        .send({ title: '' })\n        .expect(400);\n\n      expect(response.body.message).toContain('Title');\n      expect(mockQuery).not.toHaveBeenCalled();\n    });\n\n    it('should return 400 when trying to update promptText to empty string', async () => {\n      const response = await request(app)\n        .put(`/api/prompts/${mockPromptId}`)\n        .send({ promptText: '' })\n        .expect(400);\n\n      expect(response.body.message).toContain('Prompt text');\n      expect(mockQuery).not.toHaveBeenCalled();\n    });\n  });\n\n  describe('DELETE /api/prompts/:id', () => {\n    it('should delete a prompt successfully with valid ID', async () => {\n      mockQuery.mockResolvedValueOnce({ rowCount: 1 });\n\n      await request(app)\n        .delete(`/api/prompts/${mockPromptId}`)\n        .expect(204);\n\n      expect(mockQuery).toHaveBeenCalledWith('DELETE FROM prompts WHERE id = $1', [mockPromptId]);\n    });\n\n    it('should return 404 for non-existent prompt ID', async () => {\n      const nonExistentId = '00000000-0000-0000-0000-000000000999';\n      \n      mockQuery.mockResolvedValueOnce({ rowCount: 0 });\n\n      const response = await request(app)\n        .delete(`/api/prompts/${nonExistentId}`)\n        .expect(404);\n\n      expect(response.body.message).toBe('Prompt not found');\n    });\n  });\n});\n",
      "metadata": {
        "filename": "prompts.test.ts",
        "path": "/backend/src/api/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/api/routes.ts\n\nimport { Router } from 'express';\nimport PromptController from './controllers/promptController';\nimport WorkflowController from './controllers/workflowController';\nimport ModelController from './controllers/modelController';\nimport GeminiController from './controllers/geminiController';\nimport WorkflowExecutionController from './controllers/workflowExecutionController';\nimport ProviderController from './controllers/providerController';\n\n/**\n * @file defines the routes for the application's API\n * @author Your Name\n * @see {@link http://expressjs.com/en/guide/routing.html|Express Routing}\n */\n\nconst router = Router();\n\n// Prompt routes\nrouter.post('/prompts', PromptController.createPrompt);\nrouter.get('/prompts', PromptController.getPrompts);\nrouter.get('/prompts/:id', PromptController.getPromptById);\nrouter.put('/prompts/:id', PromptController.updatePrompt);\nrouter.delete('/prompts/:id', PromptController.deletePrompt);\n\n// Workflow routes\nrouter.post('/workflows', WorkflowController.createWorkflow);\nrouter.get('/workflows', WorkflowController.getWorkflows);\nrouter.get('/workflows/:id', WorkflowController.getWorkflowById);\nrouter.put('/workflows/:id', WorkflowController.updateWorkflow);\nrouter.delete('/workflows/:id', WorkflowController.deleteWorkflow);\nrouter.post('/workflows/orchestrate', WorkflowController.orchestrateWorkflow);\nrouter.post('/workflows/run-task', WorkflowExecutionController.runTask);\nrouter.post('/workflows/execute', WorkflowExecutionController.executeWorkflow);\nrouter.get('/workflows/jobs/:jobId/status', WorkflowExecutionController.getJobStatus);\nrouter.post('/workflows/stop/:jobId', WorkflowExecutionController.stopWorkflow);\n\n// Model routes\nrouter.get('/models', ModelController.getModels);\n\n// Gemini routes\nrouter.post('/gemini/test-prompt', GeminiController.testPrompt);\nrouter.post('/gemini/generate-sfl', GeminiController.generateSFLFromGoal);\nrouter.post('/gemini/regenerate-sfl', GeminiController.regenerateSFLFromSuggestion);\nrouter.post('/gemini/generate-workflow', GeminiController.generateWorkflowFromGoal);\n\n// Provider validation routes\nrouter.get('/providers/status', ProviderController.getProviderStatus);\nrouter.get('/providers/available', ProviderController.getAvailableProviders);\nrouter.get('/providers/health', ProviderController.checkProviderHealth);\nrouter.get('/providers/preferred', ProviderController.getPreferredProvider);\nrouter.post('/providers/validate', ProviderController.validateProvider);\n\nexport default router;\n",
      "metadata": {
        "filename": "routes.ts",
        "path": "/backend/src/api/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/app.ts\n\n/**\n * @file app.ts\n * @description Express application setup for the SFL-Prompt-Studio backend.\n * This file configures the Express app without starting the server,\n * making it suitable for testing and modular usage.\n */\n\nimport express, { Request, Response } from 'express';\nimport errorHandler from './middleware/errorHandler';\nimport tempAuthMiddleware from './middleware/tempAuth';\nimport apiRoutes from './api/routes';\n\nconst app = express();\n\napp.use(express.json());\n// Temporary authentication middleware - replace with real auth\napp.use('/api', tempAuthMiddleware);\napp.use('/api', apiRoutes);\n\napp.get('/', (req: Request, res: Response) => {\n  res.send('SFL Prompt Studio Backend is running!');\n});\n\napp.use(errorHandler);\n\nexport default app;\n",
      "metadata": {
        "filename": "app.ts",
        "path": "/backend/src/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/config/database.ts\n\n/**\n * @file database.ts\n * @description Manages the PostgreSQL database connection pool for the application.\n * Provides a configured pool instance that handles connection lifecycle management,\n * connection reuse, and automatic cleanup. This is the primary interface for all\n * database operations throughout the backend.\n * \n * @requires pg\n * @requires ./env\n * @since 0.5.1\n */\n\nimport { Pool } from 'pg';\nimport config from './env';\n\n/**\n * PostgreSQL connection pool instance.\n * Automatically manages database connections, handles connection pooling,\n * and provides efficient connection reuse across the application.\n * \n * The pool is configured using the database URL from environment configuration\n * and will automatically handle connection acquisition, release, and cleanup.\n * \n * @type {Pool}\n * @see {@link https://node-postgres.com/features/pooling|node-postgres pooling}\n * \n * @example\n * ```typescript\n * import pool from './config/database';\n * \n * // Execute a query\n * const result = await pool.query('SELECT * FROM prompts WHERE id = $1', [promptId]);\n * \n * // The connection is automatically returned to the pool\n * ```\n * \n * @since 0.5.1\n */\nconst pool: Pool = new Pool({\n  connectionString: config.databaseUrl,\n});\n\n/**\n * Connection event handler.\n * Logs a confirmation message when a client successfully connects to the database.\n * This is useful for debugging connection issues and monitoring database connectivity.\n * \n * @event Pool#connect\n * @since 0.5.1\n */\npool.on('connect', () => {\n  console.log('Connected to the database');\n});\n\n/**\n * @exports {Pool} pool\n * @description The configured PostgreSQL connection pool instance.\n * This is the primary database interface used throughout the application\n * for executing queries and managing database connections.\n * \n * @since 0.5.1\n */\nexport default pool;\n",
      "metadata": {
        "filename": "database.ts",
        "path": "/backend/src/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/config/env.ts\n\n/**\n * @file env.ts\n * @description Environment configuration module that loads and exports environment variables\n * for the application. Uses dotenv to load variables from .env files and provides\n * a centralized configuration object with sensible defaults.\n * \n * This module should be imported by other configuration modules that need access\n * to environment-specific settings like database URLs, API keys, and runtime settings.\n * \n * @requires dotenv\n * @since 0.5.1\n */\n\nimport dotenv from 'dotenv';\n\n// Load environment variables from .env file\ndotenv.config();\n\n/**\n * @interface Config\n * @description Type definition for the application configuration object.\n */\ninterface Config {\n  /** The connection URL for the PostgreSQL database */\n  databaseUrl: string | undefined;\n  /** The connection URL for the Redis server */\n  redisUrl: string | undefined;\n  /** The API key for accessing Google's Gemini service */\n  geminiApiKey: string | undefined;\n  /** The API key for accessing OpenAI's service */\n  openaiApiKey: string | undefined;\n  /** The API key for accessing OpenRouter's service */\n  openrouterApiKey: string | undefined;\n  /** The API key for accessing Anthropic's Claude service */\n  anthropicApiKey: string | undefined;\n  /** The default AI provider to use */\n  defaultAiProvider: string;\n  /** The fallback AI provider if default fails */\n  fallbackAiProvider: string;\n  /** OpenAI default model */\n  openaiDefaultModel: string;\n  /** Google default model */\n  googleDefaultModel: string;\n  /** OpenRouter default model */\n  openrouterDefaultModel: string;\n  /** OpenRouter base URL */\n  openrouterBaseUrl: string;\n  /** Anthropic default model */\n  anthropicDefaultModel: string;\n  /** Whether grounding is enabled */\n  enableGrounding: boolean;\n  /** The current environment (development, production, test) */\n  nodeEnv: string;\n  /** The port number for the application server */\n  port: string | number;\n}\n\n/**\n * Application configuration object containing all environment variables.\n * Provides centralized access to environment-specific settings with fallback defaults\n * where appropriate. Some values may be undefined if not set in the environment.\n * \n * @type {Config}\n * \n * @example\n * ```typescript\n * import config from './config/env';\n * \n * console.log(`Starting server on port ${config.port}`);\n * console.log(`Environment: ${config.nodeEnv}`);\n * \n * if (!config.databaseUrl) {\n *   throw new Error('DATABASE_URL environment variable is required');\n * }\n * ```\n * \n * @since 0.5.1\n */\nexport default {\n  databaseUrl: process.env.DATABASE_URL,\n  redisUrl: process.env.REDIS_URL,\n  geminiApiKey: process.env.GEMINI_API_KEY,\n  openaiApiKey: process.env.OPENAI_API_KEY,\n  openrouterApiKey: process.env.OPENROUTER_API_KEY,\n  anthropicApiKey: process.env.ANTHROPIC_API_KEY,\n  defaultAiProvider: process.env.DEFAULT_AI_PROVIDER || 'google',\n  fallbackAiProvider: process.env.FALLBACK_AI_PROVIDER || 'openai',\n  openaiDefaultModel: process.env.OPENAI_DEFAULT_MODEL || 'gpt-4',\n  googleDefaultModel: process.env.GOOGLE_DEFAULT_MODEL || 'gemini-2.5-flash',\n  openrouterDefaultModel: process.env.OPENROUTER_DEFAULT_MODEL || 'openai/gpt-4',\n  openrouterBaseUrl: process.env.OPENROUTER_BASE_URL || 'https://openrouter.ai/api/v1',\n  anthropicDefaultModel: process.env.ANTHROPIC_DEFAULT_MODEL || 'claude-3-sonnet',\n  enableGrounding: process.env.ENABLE_GROUNDING === 'true',\n  nodeEnv: process.env.NODE_ENV || 'development',\n  port: process.env.PORT || 4000,\n};\n",
      "metadata": {
        "filename": "env.ts",
        "path": "/backend/src/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/config/logger.ts\n\nimport winston from 'winston';\n\n/**\n * @file Configures the application's logger using Winston.\n * @author Your Name\n */\n\n/**\n * @type {winston.Logger}\n * @description A Winston logger instance for logging application events.\n * In development, it logs to the console and to files. In production, it only logs to the console.\n * @see {@link https://github.com/winstonjs/winston|Winston documentation}\n */\nconst logger = winston.createLogger({\n  level: 'info',\n  format: winston.format.json(),\n  transports: [\n    new winston.transports.Console({\n      format: winston.format.simple(),\n    }),\n  ],\n});\n\n// If we're not in production then log to the `console` with the format:\n// `${info.level}: ${info.message} JSON.stringify({ ...rest }) `\nif (process.env.NODE_ENV !== 'production') {\n  logger.add(new winston.transports.File({ filename: 'error.log', level: 'error' }));\n  logger.add(new winston.transports.File({ filename: 'combined.log' }));\n}\n\nexport default logger;\n",
      "metadata": {
        "filename": "logger.ts",
        "path": "/backend/src/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/index.ts\n\n/**\n * @file index.ts\n * @description This is the main entry point for the SFL-Prompt-Studio backend server.\n * It imports the Express application, creates an HTTP server, and initializes WebSocket support.\n *\n * @requires ./app\n * @requires ./config/logger\n * @requires ./config/env\n * @requires ./services/webSocketService\n */\n\nimport { createServer } from 'http';\nimport app from './app';\nimport logger from './config/logger';\nimport config from './config/env';\nimport webSocketService from './services/webSocketService';\n\nconst port = config.port;\n\n// Create HTTP server\nconst server = createServer(app);\n\n// Initialize WebSocket service\nwebSocketService.initialize(server);\n\n// Start the server\nserver.listen(port, () => {\n  logger.info(`Server is running on http://localhost:${port}`);\n  logger.info(`WebSocket server is available at ws://localhost:${port}/ws`);\n});\n\n// Graceful shutdown\nprocess.on('SIGTERM', () => {\n  logger.info('SIGTERM received, shutting down gracefully');\n  webSocketService.shutdown();\n  server.close(() => {\n    logger.info('Server closed');\n    process.exit(0);\n  });\n});\n\nprocess.on('SIGINT', () => {\n  logger.info('SIGINT received, shutting down gracefully');\n  webSocketService.shutdown();\n  server.close(() => {\n    logger.info('Server closed');\n    process.exit(0);\n  });\n});\n",
      "metadata": {
        "filename": "index.ts",
        "path": "/backend/src/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/middleware/errorHandler.ts\n\nimport { Request, Response, NextFunction } from 'express';\nimport logger from '../config/logger';\n\n/**\n * @interface AppError\n * @extends Error\n * @description Custom error interface to include an optional statusCode and isOperational flag.\n * @property {number} [statusCode] - The HTTP status code to be sent in the response.\n * @property {boolean} [isOperational] - A flag to indicate if the error is operational (i.e., a known, handled error).\n */\ninterface AppError extends Error {\n  statusCode?: number;\n  isOperational?: boolean;\n}\n\n/**\n * @function errorHandler\n * @description Express middleware for centralized error handling.\n * It logs the error and sends a standardized JSON error response to the client.\n * For operational errors, it sends the specific error message. For other errors, it sends a generic message.\n *\n * @param {AppError} err - The error object. Can be a standard Error or a custom AppError.\n * @param {Request} req - The Express request object.\n * @param {Response} res - The Express response object.\n * @param {NextFunction} next - The Express next middleware function.\n */\nconst errorHandler = (err: AppError, req: Request, res: Response, next: NextFunction) => {\n  logger.error(err);\n\n  const statusCode = err.statusCode || 500;\n  const message = err.isOperational ? err.message : 'An unexpected error occurred.';\n\n  res.status(statusCode).json({\n    status: 'error',\n    statusCode,\n    message,\n  });\n};\n\nexport default errorHandler;\n",
      "metadata": {
        "filename": "errorHandler.ts",
        "path": "/backend/src/middleware/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/middleware/tempAuth.ts\n\n/**\n * @file tempAuth.ts\n * @description Temporary authentication middleware that sets a system user\n * This is a temporary solution until proper authentication is implemented\n * \n * WARNING: This middleware provides no real security and should be replaced\n * with proper authentication (JWT, OAuth, etc.) before production use\n */\n\nimport { Request, Response, NextFunction } from 'express';\nimport '../types/express';\n\n/**\n * Temporary authentication middleware that sets a default system user\n * This allows the application to function while maintaining the security\n * improvements made in commit 215cd0c\n * \n * @param req Express request object\n * @param res Express response object  \n * @param next Express next function\n */\nexport const tempAuthMiddleware = (req: Request, res: Response, next: NextFunction) => {\n  // Set a temporary system user - replace with real authentication\n  req.user = {\n    id: '00000000-0000-0000-0000-000000000001', // System user ID from migration\n    username: 'system',\n    role: 'admin'\n  };\n  \n  next();\n};\n\nexport default tempAuthMiddleware;\n",
      "metadata": {
        "filename": "tempAuth.ts",
        "path": "/backend/src/middleware/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/prompts/orchestratorPrompt.ts\n\n/**\n * @file orchestratorPrompt.ts\n * @description Contains the specialized system prompt for the AI Orchestrator that automatically\n * generates workflows from high-level user requests. This prompt is designed to instruct the LLM\n * to act as an expert project manager that decomposes complex tasks into structured workflows.\n * \n * @since 2.1.0\n */\n\n/**\n * @constant {string} ORCHESTRATOR_SYSTEM_PROMPT\n * @description The master system prompt for workflow orchestration. This prompt instructs the LLM\n * to decompose user requests into structured workflows with proper task dependencies, types, and data flow.\n */\nexport const ORCHESTRATOR_SYSTEM_PROMPT = `You are an expert AI workflow orchestrator and project manager. Your specialized role is to analyze complex, high-level user requests and automatically generate complete, executable workflows that break down these requests into logical, dependent tasks.\n\n## Core Responsibilities:\n1. **Task Decomposition**: Break complex requests into atomic, manageable tasks\n2. **Dependency Analysis**: Identify logical task dependencies and execution order\n3. **Resource Mapping**: Determine appropriate task types and data flow patterns\n4. **Workflow Optimization**: Create efficient, parallel execution paths where possible\n\n## Output Requirements:\nYou MUST respond with a single, valid JSON object that conforms exactly to the Workflow data structure. Do not include any explanatory text, comments, or formatting outside the JSON.\n\n## Workflow JSON Structure:\n{\n  \"name\": \"string - Concise, descriptive workflow name\",\n  \"description\": \"string - Brief overview of what the workflow accomplishes\", \n  \"tasks\": [\n    {\n      \"id\": \"string - Unique identifier (task-1, task-2, etc.)\",\n      \"name\": \"string - Short, descriptive task name\",\n      \"description\": \"string - One sentence explaining the task purpose\",\n      \"type\": \"TaskType - See available types below\",\n      \"dependencies\": [\"string[] - Array of task IDs this task depends on\"],\n      \"inputKeys\": [\"string[] - Data Store keys needed (use dot notation)\"],\n      \"outputKey\": \"string - Key where this task's result is stored\",\n      \"positionX\": \"number - X coordinate for UI layout (50-800 range)\",\n      \"positionY\": \"number - Y coordinate for UI layout (50-600 range)\"\n    }\n  ]\n}\n\n## Available Task Types:\n- **DATA_INPUT**: Captures user input or static values\n- **GEMINI_PROMPT**: Executes AI/LLM prompts for text generation\n- **IMAGE_ANALYSIS**: Analyzes visual content  \n- **TEXT_MANIPULATION**: Processes text with custom JavaScript functions\n- **SIMULATE_PROCESS**: Simulates processes for testing workflow logic\n- **DISPLAY_CHART**: Prepares data for visualization\n- **GEMINI_GROUNDED**: LLM prompts with real-time data grounding\n\n## Task-Specific Required Fields:\n\n**GEMINI_PROMPT/IMAGE_ANALYSIS/GEMINI_GROUNDED:**\n- Add: \"promptTemplate\": \"Your prompt text with {{placeholder}} variables\"\n\n**TEXT_MANIPULATION:**\n- Add: \"functionBody\": \"JavaScript function body as string, e.g. return \\`Result: \\${inputs.data}\\`\"\n\n**DATA_INPUT:**\n- Add: \"staticValue\": \"{{userInput.text}}\" or \"{{userInput.image}}\" or \"{{userInput.file}}\" or literal value\n\n**DISPLAY_CHART:**\n- Add: \"dataKey\": \"Key pointing to chartable data in Data Store\"\n\n## Data Flow Patterns:\n- Use \"userInput.text\", \"userInput.image\", \"userInput.file\" for initial user data\n- Reference task outputs via their outputKey in subsequent inputKeys\n- Use {{placeholder}} syntax in promptTemplate for dynamic content interpolation\n- Ensure proper dependency chains for data flow\n\n## Positioning Guidelines:\n- Arrange tasks logically from left to right (input → processing → output)\n- Space tasks 200-300 pixels apart horizontally\n- Use 100-150 pixel vertical spacing for parallel tasks\n- Keep initial tasks on the left (X: 50-150), final tasks on right (X: 600-800)\n\n## Quality Standards:\n- Create 3-8 tasks for typical workflows (more complex requests may need more)\n- Ensure every task has clear purpose and proper dependencies\n- Avoid circular dependencies\n- Include meaningful intermediate results that can be reused\n- Design for both sequential and parallel execution where logical`;\n\n/**\n * @interface OrchestratorExample\n * @description Structure for few-shot learning examples that demonstrate proper workflow generation\n */\ninterface OrchestratorExample {\n  userRequest: string;\n  expectedWorkflow: {\n    name: string;\n    description: string;\n    tasks: Array<{\n      id: string;\n      name: string;\n      description: string;\n      type: string;\n      dependencies: string[];\n      inputKeys: string[];\n      outputKey: string;\n      positionX: number;\n      positionY: number;\n      [key: string]: any; // For task-specific fields\n    }>;\n  };\n}\n\n/**\n * @constant {OrchestratorExample[]} ORCHESTRATOR_EXAMPLES\n * @description Few-shot learning examples that demonstrate proper workflow generation patterns\n */\nexport const ORCHESTRATOR_EXAMPLES: OrchestratorExample[] = [\n  {\n    userRequest: \"Analyze customer feedback text for sentiment, extract key themes, and create a summary report\",\n    expectedWorkflow: {\n      name: \"Customer Feedback Analysis\",\n      description: \"Analyzes customer feedback for sentiment and themes, then generates a comprehensive summary report\",\n      tasks: [\n        {\n          id: \"task-1\",\n          name: \"Capture Feedback Text\",\n          description: \"Receives the customer feedback text from user input\",\n          type: \"DATA_INPUT\",\n          dependencies: [],\n          inputKeys: [],\n          outputKey: \"feedbackText\",\n          positionX: 50,\n          positionY: 100,\n          staticValue: \"{{userInput.text}}\"\n        },\n        {\n          id: \"task-2\", \n          name: \"Analyze Sentiment\",\n          description: \"Determines the overall sentiment (positive, negative, neutral) of the feedback\",\n          type: \"GEMINI_PROMPT\",\n          dependencies: [\"task-1\"],\n          inputKeys: [\"feedbackText\"],\n          outputKey: \"sentimentAnalysis\",\n          positionX: 300,\n          positionY: 50,\n          promptTemplate: \"Analyze the sentiment of this customer feedback and classify it as positive, negative, or neutral. Provide a confidence score and brief reasoning:\\\\n\\\\n{{feedbackText}}\"\n        },\n        {\n          id: \"task-3\",\n          name: \"Extract Key Themes\", \n          description: \"Identifies the main topics and themes discussed in the feedback\",\n          type: \"GEMINI_PROMPT\",\n          dependencies: [\"task-1\"],\n          inputKeys: [\"feedbackText\"],\n          outputKey: \"keyThemes\",\n          positionX: 300,\n          positionY: 200,\n          promptTemplate: \"Extract the key themes and topics from this customer feedback. List the main points discussed:\\\\n\\\\n{{feedbackText}}\"\n        },\n        {\n          id: \"task-4\",\n          name: \"Generate Summary Report\",\n          description: \"Creates a comprehensive summary report combining sentiment and themes\",\n          type: \"TEXT_MANIPULATION\",\n          dependencies: [\"task-2\", \"task-3\"],\n          inputKeys: [\"sentimentAnalysis\", \"keyThemes\"],\n          outputKey: \"summaryReport\",\n          positionX: 550,\n          positionY: 125,\n          functionBody: \"return `# Customer Feedback Analysis Report\\\\n\\\\n## Sentiment Analysis\\\\n${inputs.sentimentAnalysis}\\\\n\\\\n## Key Themes\\\\n${inputs.keyThemes}\\\\n\\\\n## Report Generated: ${new Date().toLocaleDateString()}`\"\n        }\n      ]\n    }\n  },\n  {\n    userRequest: \"Take a product image, analyze its features, generate a marketing description, and create product data for an e-commerce listing\",\n    expectedWorkflow: {\n      name: \"Product Image to E-commerce Listing\",\n      description: \"Processes product images to generate marketing content and structured e-commerce data\",\n      tasks: [\n        {\n          id: \"task-1\",\n          name: \"Load Product Image\",\n          description: \"Captures the product image provided by the user\",\n          type: \"DATA_INPUT\", \n          dependencies: [],\n          inputKeys: [],\n          outputKey: \"productImage\",\n          positionX: 50,\n          positionY: 150,\n          staticValue: \"{{userInput.image}}\"\n        },\n        {\n          id: \"task-2\",\n          name: \"Analyze Product Features\",\n          description: \"Extracts visual features, colors, materials, and product characteristics from the image\",\n          type: \"IMAGE_ANALYSIS\",\n          dependencies: [\"task-1\"],\n          inputKeys: [\"productImage\"],\n          outputKey: \"productFeatures\",\n          positionX: 250,\n          positionY: 100,\n          promptTemplate: \"Analyze this product image and describe: 1) Main features and functionality, 2) Materials and construction, 3) Colors and design elements, 4) Size/scale indicators, 5) Target audience/use cases\"\n        },\n        {\n          id: \"task-3\",\n          name: \"Generate Marketing Copy\",\n          description: \"Creates compelling marketing description based on analyzed features\",\n          type: \"GEMINI_PROMPT\",\n          dependencies: [\"task-2\"],\n          inputKeys: [\"productFeatures\"],\n          outputKey: \"marketingDescription\",\n          positionX: 450,\n          positionY: 50,\n          promptTemplate: \"Based on these product features, write compelling marketing copy for an e-commerce listing. Include benefits, key selling points, and emotional appeal:\\\\n\\\\n{{productFeatures}}\"\n        },\n        {\n          id: \"task-4\",\n          name: \"Structure Product Data\",\n          description: \"Formats the analysis into structured e-commerce product data\",\n          type: \"TEXT_MANIPULATION\",\n          dependencies: [\"task-2\", \"task-3\"],\n          inputKeys: [\"productFeatures\", \"marketingDescription\"],\n          outputKey: \"productListing\",\n          positionX: 650,\n          positionY: 125,\n          functionBody: \"const features = inputs.productFeatures; const marketing = inputs.marketingDescription; return JSON.stringify({ title: 'Generated from analysis', description: marketing, features: features, category: 'To be determined', tags: [] }, null, 2)\"\n        }\n      ]\n    }\n  }\n];\n\n/**\n * @function buildOrchestratorPrompt\n * @description Constructs the complete orchestrator prompt by combining the system instruction\n * with few-shot examples and the user's specific request\n * \n * @param {string} userRequest - The user's high-level request to be converted into a workflow\n * @returns {string} The complete prompt ready to be sent to the LLM\n */\nexport function buildOrchestratorPrompt(userRequest: string): string {\n  const examplePrompts = ORCHESTRATOR_EXAMPLES.map((example, index) => \n    `### Example ${index + 1}:\n**User Request**: \"${example.userRequest}\"\n\n**Generated Workflow**:\n\\`\\`\\`json\n${JSON.stringify(example.expectedWorkflow, null, 2)}\n\\`\\`\\``\n  ).join('\\n\\n');\n\n  return `${ORCHESTRATOR_SYSTEM_PROMPT}\n\n## Few-Shot Examples:\n${examplePrompts}\n\n## Your Task:\nGenerate a complete workflow JSON for the following user request. Remember to output ONLY the JSON object, no additional text or explanations.\n\n**User Request**: \"${userRequest}\"`;\n}\n",
      "metadata": {
        "filename": "orchestratorPrompt.ts",
        "path": "/backend/src/prompts/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/ai/AIProviderFactory.ts\n\n/**\n * @file AIProviderFactory.ts\n * @description Factory for creating AI service instances dynamically based on provider type.\n * This factory enables runtime provider switching and manages service instantiation\n * with proper configuration and error handling.\n */\n\nimport { BaseAIService, AIServiceConfig } from './BaseAIService';\nimport { AIProvider } from '../../types/aiProvider';\nimport { createOpenAIService } from './OpenAIService';\nimport { createAnthropicService } from './AnthropicService';\nimport { createGeminiService } from './GeminiService';\n// TODO: Import other services when implemented\n// import { createOpenRouterService } from './OpenRouterService';\n\n/**\n * Registry of available AI service factories\n */\ntype ServiceFactoryMap = {\n  [K in AIProvider]: (config: AIServiceConfig) => BaseAIService;\n};\n\n/**\n * Service factory registry\n */\nconst SERVICE_FACTORIES: ServiceFactoryMap = {\n  openai: createOpenAIService,\n  anthropic: createAnthropicService,\n  google: createGeminiService,\n  openrouter: (config: AIServiceConfig) => {\n    throw new Error('OpenRouter service not yet implemented');\n  }\n};\n\n/**\n * Service instance cache for reusing configured services\n */\nclass ServiceCache {\n  private cache = new Map<string, BaseAIService>();\n  private readonly maxCacheSize = 10;\n\n  /**\n   * Generate cache key for a service configuration\n   */\n  private getCacheKey(provider: AIProvider, apiKey: string, baseUrl?: string): string {\n    // Use first 8 characters of API key hash for cache key (security)\n    const keyHash = Buffer.from(apiKey).toString('base64').substring(0, 8);\n    return `${provider}:${keyHash}:${baseUrl || 'default'}`;\n  }\n\n  /**\n   * Get cached service instance\n   */\n  get(provider: AIProvider, config: AIServiceConfig): BaseAIService | undefined {\n    const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n    return this.cache.get(key);\n  }\n\n  /**\n   * Cache service instance\n   */\n  set(provider: AIProvider, config: AIServiceConfig, service: BaseAIService): void {\n    const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n    \n    // Implement LRU cache behavior\n    if (this.cache.size >= this.maxCacheSize) {\n      const firstKey = this.cache.keys().next().value;\n      if (firstKey) {\n        this.cache.delete(firstKey);\n      }\n    }\n    \n    this.cache.set(key, service);\n  }\n\n  /**\n   * Clear cache (useful for testing or when configurations change)\n   */\n  clear(): void {\n    this.cache.clear();\n  }\n\n  /**\n   * Remove specific service from cache\n   */\n  remove(provider: AIProvider, config: AIServiceConfig): void {\n    const key = this.getCacheKey(provider, config.apiKey, config.baseUrl);\n    this.cache.delete(key);\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): { size: number; maxSize: number; keys: string[] } {\n    return {\n      size: this.cache.size,\n      maxSize: this.maxCacheSize,\n      keys: Array.from(this.cache.keys())\n    };\n  }\n}\n\n/**\n * AI Provider Factory class\n */\nexport class AIProviderFactory {\n  private static instance: AIProviderFactory;\n  private serviceCache: ServiceCache;\n\n  private constructor() {\n    this.serviceCache = new ServiceCache();\n  }\n\n  /**\n   * Get singleton instance of the factory\n   */\n  static getInstance(): AIProviderFactory {\n    if (!AIProviderFactory.instance) {\n      AIProviderFactory.instance = new AIProviderFactory();\n    }\n    return AIProviderFactory.instance;\n  }\n\n  /**\n   * Create or retrieve AI service instance\n   * @param provider - The AI provider to create service for\n   * @param config - Configuration for the service\n   * @param useCache - Whether to use cached instances (default: true)\n   */\n  createService(provider: AIProvider, config: AIServiceConfig, useCache: boolean = true): BaseAIService {\n    // Validate provider\n    if (!this.isProviderSupported(provider)) {\n      throw new Error(`Unsupported AI provider: ${provider}`);\n    }\n\n    // Validate configuration\n    this.validateConfig(config);\n\n    // Check cache first if enabled\n    if (useCache) {\n      const cachedService = this.serviceCache.get(provider, config);\n      if (cachedService) {\n        return cachedService;\n      }\n    }\n\n    try {\n      // Create new service instance\n      const factory = SERVICE_FACTORIES[provider];\n      const service = factory(config);\n\n      // Cache the service if enabled\n      if (useCache) {\n        this.serviceCache.set(provider, config, service);\n      }\n\n      return service;\n    } catch (error) {\n      throw new Error(`Failed to create ${provider} service: ${error instanceof Error ? error.message : 'Unknown error'}`);\n    }\n  }\n\n  /**\n   * Test if a provider is supported\n   */\n  isProviderSupported(provider: AIProvider): boolean {\n    return provider in SERVICE_FACTORIES;\n  }\n\n  /**\n   * Get list of supported providers\n   */\n  getSupportedProviders(): AIProvider[] {\n    return Object.keys(SERVICE_FACTORIES) as AIProvider[];\n  }\n\n  /**\n   * Get list of implemented providers (excluding placeholder implementations)\n   */\n  getImplementedProviders(): AIProvider[] {\n    const implemented: AIProvider[] = [];\n    \n    for (const provider of Object.keys(SERVICE_FACTORIES) as AIProvider[]) {\n      try {\n        // Try to create a dummy service to check if implemented\n        const dummyConfig: AIServiceConfig = { apiKey: 'test' };\n        SERVICE_FACTORIES[provider](dummyConfig);\n        implemented.push(provider);\n      } catch (error) {\n        // Provider not yet implemented\n        if (error instanceof Error && error.message.includes('not yet implemented')) {\n          continue;\n        }\n        // Other errors mean the provider is implemented but configuration failed\n        implemented.push(provider);\n      }\n    }\n    \n    return implemented;\n  }\n\n  /**\n   * Test connection for a provider\n   * @param provider - The provider to test\n   * @param config - Configuration for the test\n   */\n  async testProviderConnection(provider: AIProvider, config: AIServiceConfig): Promise<boolean> {\n    try {\n      const service = this.createService(provider, config, false); // Don't cache test instances\n      return await service.testConnection();\n    } catch (error) {\n      console.error(`Failed to test ${provider} connection:`, error);\n      return false;\n    }\n  }\n\n  /**\n   * Get service capabilities for a provider\n   * @param provider - The provider to query\n   * @param config - Configuration for the service\n   */\n  getProviderCapabilities(provider: AIProvider, config: AIServiceConfig) {\n    const service = this.createService(provider, config);\n    return service.getCapabilities();\n  }\n\n  /**\n   * Clear service cache\n   */\n  clearCache(): void {\n    this.serviceCache.clear();\n  }\n\n  /**\n   * Remove specific service from cache\n   */\n  removeCachedService(provider: AIProvider, config: AIServiceConfig): void {\n    this.serviceCache.remove(provider, config);\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getCacheStats() {\n    return this.serviceCache.getStats();\n  }\n\n  /**\n   * Validate service configuration\n   */\n  private validateConfig(config: AIServiceConfig): void {\n    if (!config.apiKey || config.apiKey.trim() === '') {\n      throw new Error('API key is required');\n    }\n\n    if (config.timeout && config.timeout < 1000) {\n      throw new Error('Timeout must be at least 1000ms');\n    }\n\n    if (config.baseUrl && !this.isValidUrl(config.baseUrl)) {\n      throw new Error('Invalid base URL format');\n    }\n  }\n\n  /**\n   * Validate URL format\n   */\n  private isValidUrl(url: string): boolean {\n    try {\n      new URL(url);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n}\n\n/**\n * Convenience function to get factory instance\n */\nexport const aiProviderFactory = AIProviderFactory.getInstance();\n\n/**\n * Convenience function to create AI service\n */\nexport function createAIService(provider: AIProvider, config: AIServiceConfig): BaseAIService {\n  return aiProviderFactory.createService(provider, config);\n}\n\n/**\n * Convenience function to test provider connection\n */\nexport async function testAIProviderConnection(provider: AIProvider, config: AIServiceConfig): Promise<boolean> {\n  return aiProviderFactory.testProviderConnection(provider, config);\n}\n",
      "metadata": {
        "filename": "AIProviderFactory.ts",
        "path": "/backend/src/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/ai/AnthropicService.ts\n\n/**\n * @file AnthropicService.ts\n * @description Anthropic Claude AI service implementation.\n * Provides integration with Anthropic's Claude models including Claude 3.5 Sonnet and Claude 3 Haiku.\n * Handles Anthropic-specific parameter mapping, authentication, and response parsing.\n */\n\nimport axios, { AxiosInstance, AxiosResponse } from 'axios';\nimport { BaseAIService, AIResponse, AIServiceConfig, AIServiceCapabilities } from './BaseAIService';\nimport { AIRequest, ModelParameters, AnthropicParameters } from '../../types/aiProvider';\n\n/**\n * Anthropic API request interfaces\n */\ninterface AnthropicMessage {\n  role: 'user' | 'assistant';\n  content: string;\n}\n\ninterface AnthropicRequest {\n  model: string;\n  max_tokens: number;\n  messages: AnthropicMessage[];\n  system?: string;\n  temperature?: number;\n  top_p?: number;\n  top_k?: number;\n  stop_sequences?: string[];\n}\n\n/**\n * Anthropic API response interfaces\n */\ninterface AnthropicContent {\n  type: 'text';\n  text: string;\n}\n\ninterface AnthropicUsage {\n  input_tokens: number;\n  output_tokens: number;\n}\n\ninterface AnthropicResponse {\n  id: string;\n  type: 'message';\n  role: 'assistant';\n  content: AnthropicContent[];\n  model: string;\n  stop_reason: string;\n  stop_sequence?: string;\n  usage: AnthropicUsage;\n}\n\n/**\n * Anthropic service implementation\n */\nexport class AnthropicService extends BaseAIService {\n  private client: AxiosInstance;\n  private readonly baseUrl: string;\n\n  constructor(config: AIServiceConfig) {\n    const capabilities: AIServiceCapabilities = {\n      supportedParameters: [\n        'temperature',\n        'maxTokens',\n        'top_p',\n        'top_k',\n        'system',\n        'stop_sequences'\n      ],\n      maxContextLength: 200000, // Claude 3.5 context length\n      supportsStreaming: true,\n      supportsFunctionCalling: false,\n      supportsImages: true\n    };\n\n    super('anthropic', config, capabilities);\n    \n    this.baseUrl = config.baseUrl || 'https://api.anthropic.com';\n    this.client = axios.create({\n      baseURL: this.baseUrl,\n      timeout: config.timeout || 30000,\n      headers: this.getRequestHeaders()\n    });\n  }\n\n  /**\n   * Test connection to Anthropic API\n   */\n  async testConnection(): Promise<boolean> {\n    try {\n      // Anthropic doesn't have a models endpoint, so we test with a minimal request\n      const testRequest: AnthropicRequest = {\n        model: 'claude-3-haiku-20240307',\n        max_tokens: 1,\n        messages: [{\n          role: 'user',\n          content: 'Hi'\n        }]\n      };\n      \n      const response = await this.client.post('/v1/messages', testRequest);\n      return response.status === 200;\n    } catch (error) {\n      console.error('Anthropic connection test failed:', error);\n      return false;\n    }\n  }\n\n  /**\n   * List available Anthropic models\n   */\n  async listModels(): Promise<string[]> {\n    // Anthropic doesn't provide a models endpoint, so we return known models\n    return [\n      'claude-3-5-sonnet-20241022',\n      'claude-3-haiku-20240307',\n      'claude-3-sonnet-20240229',\n      'claude-3-opus-20240229'\n    ];\n  }\n\n  /**\n   * Generate completion using Anthropic API\n   */\n  async generateCompletion(request: AIRequest): Promise<AIResponse> {\n    const startTime = Date.now();\n    \n    try {\n      const payload = this.buildRequestPayload(request);\n      this.logRequest(payload);\n      \n      const response: AxiosResponse<AnthropicResponse> = await this.client.post('/v1/messages', payload);\n      \n      const aiResponse = this.parseResponse(response.data, startTime);\n      this.logResponse(aiResponse);\n      \n      return aiResponse;\n    } catch (error) {\n      console.error('Anthropic completion failed:', error);\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Generate streaming completion (placeholder implementation)\n   */\n  async generateStreamingCompletion(\n    request: AIRequest,\n    onChunk: (chunk: string) => void\n  ): Promise<AIResponse> {\n    // For now, implement as non-streaming\n    // TODO: Implement actual streaming support\n    const response = await this.generateCompletion(request);\n    onChunk(response.text);\n    return response;\n  }\n\n  /**\n   * Validate Anthropic parameters\n   */\n  validateParameters(model: string, parameters: ModelParameters): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n    const params = parameters as AnthropicParameters;\n\n    // Validate temperature\n    if (params.temperature !== undefined) {\n      if (params.temperature < 0 || params.temperature > 1) {\n        errors.push('temperature must be between 0 and 1');\n      }\n    }\n\n    // Validate maxTokens\n    if (params.maxTokens !== undefined) {\n      if (params.maxTokens < 1 || params.maxTokens > 8192) {\n        errors.push('maxTokens must be between 1 and 8192');\n      }\n    }\n\n    // Validate top_p\n    if (params.top_p !== undefined) {\n      if (params.top_p < 0 || params.top_p > 1) {\n        errors.push('top_p must be between 0 and 1');\n      }\n    }\n\n    // Validate top_k\n    if (params.top_k !== undefined) {\n      if (params.top_k < 0 || params.top_k > 200) {\n        errors.push('top_k must be between 0 and 200');\n      }\n    }\n\n    // Validate stop_sequences\n    if (params.stop_sequences !== undefined) {\n      if (!Array.isArray(params.stop_sequences)) {\n        errors.push('stop_sequences must be an array');\n      } else if (params.stop_sequences.length > 4) {\n        errors.push('stop_sequences can have at most 4 sequences');\n      }\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors\n    };\n  }\n\n  /**\n   * Normalize parameters to Anthropic format\n   */\n  protected normalizeParameters(parameters: ModelParameters): Record<string, any> {\n    const params = parameters as AnthropicParameters;\n    const normalized: Record<string, any> = {};\n\n    // Map standard parameters\n    if (params.temperature !== undefined) normalized.temperature = params.temperature;\n    if (params.maxTokens !== undefined) normalized.max_tokens = params.maxTokens;\n    if (params.top_p !== undefined) normalized.top_p = params.top_p;\n    if (params.top_k !== undefined) normalized.top_k = params.top_k;\n    if (params.system !== undefined) normalized.system = params.system;\n    if (params.stop_sequences !== undefined) normalized.stop_sequences = params.stop_sequences;\n\n    return this.sanitizeParameters(normalized);\n  }\n\n  /**\n   * Build Anthropic API request payload\n   */\n  protected buildRequestPayload(request: AIRequest): AnthropicRequest {\n    const parameters = this.normalizeParameters(request.parameters);\n    const params = request.parameters as AnthropicParameters;\n    \n    // Build messages array (Anthropic requires alternating user/assistant messages)\n    const messages: AnthropicMessage[] = [];\n    \n    // Add conversation history if provided\n    if (request.conversationHistory) {\n      request.conversationHistory.forEach(msg => {\n        if (msg.role !== 'system') { // System messages are handled separately\n          messages.push({\n            role: msg.role as 'user' | 'assistant',\n            content: msg.content\n          });\n        }\n      });\n    }\n    \n    // Add current prompt\n    messages.push({\n      role: 'user',\n      content: request.prompt\n    });\n    \n    // Ensure max_tokens is set (required by Anthropic)\n    const maxTokens = parameters.max_tokens || 1024;\n    delete parameters.max_tokens;\n    \n    // Extract system message\n    const systemMessage = params.system || request.systemMessage;\n    delete parameters.system;\n    \n    const payload: AnthropicRequest = {\n      model: request.model,\n      max_tokens: maxTokens,\n      messages,\n      ...parameters\n    };\n    \n    if (systemMessage) {\n      payload.system = systemMessage;\n    }\n    \n    return payload;\n  }\n\n  /**\n   * Parse Anthropic response to standard format\n   */\n  protected parseResponse(response: AnthropicResponse, startTime: number): AIResponse {\n    const content = response.content[0];\n    if (!content || content.type !== 'text') {\n      throw new Error('No text content returned from Anthropic API');\n    }\n\n    return {\n      text: content.text,\n      usage: {\n        promptTokens: response.usage.input_tokens,\n        completionTokens: response.usage.output_tokens,\n        totalTokens: response.usage.input_tokens + response.usage.output_tokens\n      },\n      metadata: {\n        id: response.id,\n        stopReason: response.stop_reason,\n        stopSequence: response.stop_sequence\n      },\n      model: response.model,\n      processingTime: this.calculateProcessingTime(startTime)\n    };\n  }\n\n  /**\n   * Add Anthropic-specific authentication headers\n   */\n  protected addAuthHeaders(headers: Record<string, string>): void {\n    headers['x-api-key'] = this.config.apiKey;\n    headers['anthropic-version'] = '2023-06-01';\n  }\n}\n\n/**\n * Factory function for creating Anthropic service instances\n */\nexport function createAnthropicService(config: AIServiceConfig): AnthropicService {\n  return new AnthropicService(config);\n}\n",
      "metadata": {
        "filename": "AnthropicService.ts",
        "path": "/backend/src/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/ai/BaseAIService.ts\n\n/**\n * @file BaseAIService.ts\n * @description Abstract base class for AI service implementations.\n * Defines the common interface and shared functionality for all AI providers.\n * This architecture allows for dynamic provider switching while maintaining\n * consistent behavior across different AI services.\n *\n * @requires ../../types/aiProvider\n */\n\nimport { AIProvider, ModelParameters, AIRequest } from '../../types/aiProvider';\n\n/**\n * Standard AI response interface\n */\nexport interface AIResponse {\n  /** The generated text response */\n  text: string;\n  /** Token usage information */\n  usage?: {\n    promptTokens: number;\n    completionTokens: number;\n    totalTokens: number;\n  };\n  /** Additional metadata from the provider */\n  metadata?: Record<string, any>;\n  /** The model used for generation */\n  model: string;\n  /** Processing time in milliseconds */\n  processingTime?: number;\n}\n\n/**\n * AI service capabilities\n */\nexport interface AIServiceCapabilities {\n  /** Supported parameter types */\n  supportedParameters: string[];\n  /** Maximum context length */\n  maxContextLength: number;\n  /** Whether the service supports streaming */\n  supportsStreaming: boolean;\n  /** Whether the service supports function calling */\n  supportsFunctionCalling: boolean;\n  /** Whether the service supports image inputs */\n  supportsImages: boolean;\n}\n\n/**\n * Configuration options for AI service initialization\n */\nexport interface AIServiceConfig {\n  /** API key for the service */\n  apiKey: string;\n  /** Optional base URL override */\n  baseUrl?: string;\n  /** Timeout in milliseconds */\n  timeout?: number;\n  /** Additional headers */\n  headers?: Record<string, string>;\n}\n\n/**\n * Abstract base class for AI service implementations.\n * All AI provider services must extend this class and implement the required methods.\n */\nexport abstract class BaseAIService {\n  protected readonly provider: AIProvider;\n  protected readonly config: AIServiceConfig;\n  protected readonly capabilities: AIServiceCapabilities;\n\n  /**\n   * Constructor for base AI service\n   * @param provider - The AI provider identifier\n   * @param config - Service configuration\n   * @param capabilities - Service capabilities\n   */\n  constructor(provider: AIProvider, config: AIServiceConfig, capabilities: AIServiceCapabilities) {\n    this.provider = provider;\n    this.config = config;\n    this.capabilities = capabilities;\n    \n    this.validateConfig();\n  }\n\n  /**\n   * Get the provider identifier\n   */\n  getProvider(): AIProvider {\n    return this.provider;\n  }\n\n  /**\n   * Get service capabilities\n   */\n  getCapabilities(): AIServiceCapabilities {\n    return { ...this.capabilities };\n  }\n\n  /**\n   * Test the service connection and API key validity\n   */\n  abstract testConnection(): Promise<boolean>;\n\n  /**\n   * List available models for this provider\n   */\n  abstract listModels(): Promise<string[]>;\n\n  /**\n   * Generate text completion using the AI service\n   * @param request - The AI request configuration\n   */\n  abstract generateCompletion(request: AIRequest): Promise<AIResponse>;\n\n  /**\n   * Generate streaming text completion (if supported)\n   * @param request - The AI request configuration\n   * @param onChunk - Callback for each streaming chunk\n   */\n  abstract generateStreamingCompletion(\n    request: AIRequest,\n    onChunk: (chunk: string) => void\n  ): Promise<AIResponse>;\n\n  /**\n   * Validate model parameters against provider constraints\n   * @param model - The model identifier\n   * @param parameters - The parameters to validate\n   */\n  abstract validateParameters(model: string, parameters: ModelParameters): {\n    valid: boolean;\n    errors: string[];\n  };\n\n  /**\n   * Normalize parameters from the frontend format to provider-specific format\n   * @param parameters - Frontend parameters\n   */\n  protected abstract normalizeParameters(parameters: ModelParameters): Record<string, any>;\n\n  /**\n   * Build the request payload for the provider's API\n   * @param request - The standardized AI request\n   */\n  protected abstract buildRequestPayload(request: AIRequest): Record<string, any>;\n\n  /**\n   * Parse the provider's response into the standard format\n   * @param response - Raw provider response\n   * @param startTime - Request start time for calculating processing time\n   */\n  protected abstract parseResponse(response: any, startTime: number): AIResponse;\n\n  /**\n   * Handle provider-specific errors and convert them to standard format\n   * @param error - The error from the provider\n   */\n  protected handleError(error: any): Error {\n    if (error.response) {\n      // HTTP error response\n      const status = error.response.status;\n      const message = error.response.data?.message || error.response.statusText || 'Unknown error';\n      \n      switch (status) {\n        case 401:\n          return new Error(`Authentication failed: ${message}`);\n        case 403:\n          return new Error(`Access forbidden: ${message}`);\n        case 404:\n          return new Error(`Resource not found: ${message}`);\n        case 429:\n          return new Error(`Rate limit exceeded: ${message}`);\n        case 500:\n          return new Error(`Server error: ${message}`);\n        default:\n          return new Error(`API error (${status}): ${message}`);\n      }\n    } else if (error.request) {\n      // Network error\n      return new Error('Network error: Unable to reach the AI service');\n    } else {\n      // Other error\n      return new Error(error.message || 'Unknown error occurred');\n    }\n  }\n\n  /**\n   * Validate the service configuration\n   */\n  private validateConfig(): void {\n    if (!this.config.apiKey) {\n      throw new Error(`API key is required for ${this.provider} service`);\n    }\n    \n    if (this.config.timeout && this.config.timeout < 1000) {\n      throw new Error('Timeout must be at least 1000ms');\n    }\n  }\n\n  /**\n   * Get request headers with authentication\n   */\n  protected getRequestHeaders(): Record<string, string> {\n    const headers: Record<string, string> = {\n      'Content-Type': 'application/json',\n      'User-Agent': 'SFL-Prompt-Studio/1.0',\n      ...this.config.headers\n    };\n    \n    // Add provider-specific authentication headers\n    this.addAuthHeaders(headers);\n    \n    return headers;\n  }\n\n  /**\n   * Add provider-specific authentication headers\n   * @param headers - Headers object to modify\n   */\n  protected abstract addAuthHeaders(headers: Record<string, string>): void;\n\n  /**\n   * Calculate processing time\n   * @param startTime - Request start time\n   */\n  protected calculateProcessingTime(startTime: number): number {\n    return Date.now() - startTime;\n  }\n\n  /**\n   * Sanitize parameters to remove undefined/null values\n   * @param params - Parameters to sanitize\n   */\n  protected sanitizeParameters(params: Record<string, any>): Record<string, any> {\n    const sanitized: Record<string, any> = {};\n    \n    Object.entries(params).forEach(([key, value]) => {\n      if (value !== undefined && value !== null) {\n        sanitized[key] = value;\n      }\n    });\n    \n    return sanitized;\n  }\n\n  /**\n   * Log request for debugging (with sensitive data removed)\n   * @param request - The request to log\n   */\n  protected logRequest(request: any): void {\n    if (process.env.NODE_ENV === 'development') {\n      const safeRequest = { ...request };\n      // Remove sensitive data\n      if (safeRequest.headers?.Authorization) {\n        safeRequest.headers.Authorization = '[REDACTED]';\n      }\n      if (safeRequest.headers?.['x-api-key']) {\n        safeRequest.headers['x-api-key'] = '[REDACTED]';\n      }\n      \n      console.log(`[${this.provider.toUpperCase()}] Request:`, JSON.stringify(safeRequest, null, 2));\n    }\n  }\n\n  /**\n   * Log response for debugging\n   * @param response - The response to log\n   */\n  protected logResponse(response: AIResponse): void {\n    if (process.env.NODE_ENV === 'development') {\n      console.log(`[${this.provider.toUpperCase()}] Response:`, {\n        textLength: response.text.length,\n        usage: response.usage,\n        processingTime: response.processingTime,\n        model: response.model\n      });\n    }\n  }\n}\n\n/**\n * Factory function type for creating AI service instances\n */\nexport type AIServiceFactory = (config: AIServiceConfig) => BaseAIService;\n",
      "metadata": {
        "filename": "BaseAIService.ts",
        "path": "/backend/src/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/ai/GeminiService.ts\n\n/**\n * @file GeminiService.ts\n * @description Google Gemini AI service implementation.\n * Provides integration with Google's Gemini models including Gemini Pro and Gemini Flash.\n * Handles Gemini-specific parameter mapping, authentication, and response parsing.\n */\n\nimport axios, { AxiosInstance, AxiosResponse } from 'axios';\nimport { BaseAIService, AIResponse, AIServiceConfig, AIServiceCapabilities } from './BaseAIService';\nimport { AIRequest, ModelParameters, GeminiParameters } from '../../types/aiProvider';\n\n/**\n * Gemini API interfaces\n */\ninterface GeminiContent {\n  parts: Array<{\n    text: string;\n  }>;\n  role?: 'user' | 'model';\n}\n\ninterface GeminiCandidate {\n  content: GeminiContent;\n  finishReason: string;\n  index: number;\n  safetyRatings?: Array<{\n    category: string;\n    probability: string;\n  }>;\n}\n\ninterface GeminiUsage {\n  promptTokenCount: number;\n  candidatesTokenCount: number;\n  totalTokenCount: number;\n}\n\ninterface GeminiResponse {\n  candidates: GeminiCandidate[];\n  usageMetadata?: GeminiUsage;\n  promptFeedback?: {\n    safetyRatings: Array<{\n      category: string;\n      probability: string;\n    }>;\n  };\n}\n\ninterface GeminiGenerateContentRequest {\n  contents: GeminiContent[];\n  generationConfig?: {\n    temperature?: number;\n    topK?: number;\n    topP?: number;\n    maxOutputTokens?: number;\n    candidateCount?: number;\n    stopSequences?: string[];\n  };\n  safetySettings?: Array<{\n    category: string;\n    threshold: string;\n  }>;\n  systemInstruction?: {\n    parts: Array<{\n      text: string;\n    }>;\n    role: 'system';\n  };\n}\n\n/**\n * Gemini service implementation\n */\nexport class GeminiService extends BaseAIService {\n  private client: AxiosInstance;\n  private readonly baseUrl: string;\n\n  constructor(config: AIServiceConfig) {\n    const capabilities: AIServiceCapabilities = {\n      supportedParameters: [\n        'temperature', \n        'maxTokens', \n        'topK', \n        'topP',\n        'systemInstruction',\n        'safetySettings'\n      ],\n      maxContextLength: 1048576, // Gemini Pro context length\n      supportsStreaming: true,\n      supportsFunctionCalling: true,\n      supportsImages: true\n    };\n\n    super('google', config, capabilities);\n    \n    this.baseUrl = config.baseUrl || 'https://generativelanguage.googleapis.com/v1beta';\n    this.client = axios.create({\n      baseURL: this.baseUrl,\n      timeout: config.timeout || 60000,\n      headers: this.getRequestHeaders()\n    });\n  }\n\n  /**\n   * Test connection to Gemini API\n   */\n  async testConnection(): Promise<boolean> {\n    try {\n      // Test with a simple model listing request\n      const response = await this.client.get(`/models?key=${this.config.apiKey}`);\n      return response.status === 200;\n    } catch (error) {\n      console.error('Gemini connection test failed:', error);\n      return false;\n    }\n  }\n\n  /**\n   * List available Gemini models\n   */\n  async listModels(): Promise<string[]> {\n    try {\n      const response = await this.client.get(`/models?key=${this.config.apiKey}`);\n      \n      if (response.data && response.data.models) {\n        return response.data.models\n          .filter((model: any) => model.name.includes('gemini'))\n          .map((model: any) => model.name.replace('models/', ''))\n          .sort();\n      }\n      \n      // Return default models if API call fails\n      return [\n        'gemini-2.5-flash',\n        'gemini-1.5-flash',\n        'gemini-1.5-pro',\n        'gemini-pro',\n        'gemini-pro-vision'\n      ];\n    } catch (error) {\n      console.error('Failed to list Gemini models:', error);\n      // Return default models on error\n      return [\n        'gemini-2.5-flash',\n        'gemini-1.5-flash', \n        'gemini-1.5-pro',\n        'gemini-pro',\n        'gemini-pro-vision'\n      ];\n    }\n  }\n\n  /**\n   * Generate completion using Gemini API\n   */\n  async generateCompletion(request: AIRequest): Promise<AIResponse> {\n    const startTime = Date.now();\n    \n    try {\n      const payload = this.buildRequestPayload(request);\n      this.logRequest(payload);\n      \n      const modelName = this.normalizeModelName(request.model);\n      const url = `/models/${modelName}:generateContent?key=${this.config.apiKey}`;\n      \n      const response: AxiosResponse<GeminiResponse> = await this.client.post(url, payload);\n      \n      const aiResponse = this.parseResponse(response.data, startTime);\n      this.logResponse(aiResponse);\n      \n      return aiResponse;\n    } catch (error) {\n      console.error('Gemini completion failed:', error);\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Generate streaming completion (placeholder implementation)\n   */\n  async generateStreamingCompletion(\n    request: AIRequest,\n    onChunk: (chunk: string) => void\n  ): Promise<AIResponse> {\n    // For now, implement as non-streaming\n    // TODO: Implement actual streaming support using streamGenerateContent\n    const response = await this.generateCompletion(request);\n    onChunk(response.text);\n    return response;\n  }\n\n  /**\n   * Validate Gemini parameters\n   */\n  validateParameters(model: string, parameters: ModelParameters): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n    const params = parameters as GeminiParameters;\n\n    // Validate temperature\n    if (params.temperature !== undefined) {\n      if (params.temperature < 0 || params.temperature > 2) {\n        errors.push('temperature must be between 0 and 2');\n      }\n    }\n\n    // Validate maxTokens\n    if (params.maxTokens !== undefined) {\n      if (params.maxTokens < 1 || params.maxTokens > 8192) {\n        errors.push('maxTokens must be between 1 and 8192');\n      }\n    }\n\n    // Validate topK\n    if (params.topK !== undefined) {\n      if (params.topK < 1 || params.topK > 40) {\n        errors.push('topK must be between 1 and 40');\n      }\n    }\n\n    // Validate topP\n    if (params.topP !== undefined) {\n      if (params.topP < 0 || params.topP > 1) {\n        errors.push('topP must be between 0 and 1');\n      }\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors\n    };\n  }\n\n  /**\n   * Normalize parameters to Gemini format\n   */\n  protected normalizeParameters(parameters: ModelParameters): Record<string, any> {\n    const params = parameters as GeminiParameters;\n    const normalized: Record<string, any> = {};\n\n    // Map to Gemini generationConfig format\n    const generationConfig: Record<string, any> = {};\n    \n    if (params.temperature !== undefined) generationConfig.temperature = params.temperature;\n    if (params.maxTokens !== undefined) generationConfig.maxOutputTokens = params.maxTokens;\n    if (params.topK !== undefined) generationConfig.topK = params.topK;\n    if (params.topP !== undefined) generationConfig.topP = params.topP;\n\n    if (Object.keys(generationConfig).length > 0) {\n      normalized.generationConfig = generationConfig;\n    }\n\n    // Handle safety settings\n    if (params.safetySettings) {\n      normalized.safetySettings = params.safetySettings;\n    }\n\n    return this.sanitizeParameters(normalized);\n  }\n\n  /**\n   * Build Gemini API request payload\n   */\n  protected buildRequestPayload(request: AIRequest): GeminiGenerateContentRequest {\n    const parameters = this.normalizeParameters(request.parameters);\n    const params = request.parameters as GeminiParameters;\n    \n    // Build contents array\n    const contents: GeminiContent[] = [];\n    \n    // Add conversation history if provided\n    if (request.conversationHistory) {\n      request.conversationHistory.forEach(msg => {\n        contents.push({\n          parts: [{ text: msg.content }],\n          role: msg.role === 'assistant' ? 'model' : 'user'\n        });\n      });\n    }\n    \n    // Add current prompt\n    contents.push({\n      parts: [{ text: request.prompt }],\n      role: 'user'\n    });\n\n    const payload: GeminiGenerateContentRequest = {\n      contents,\n      ...parameters\n    };\n\n    // Add system instruction if provided\n    const systemMessage = params.systemInstruction || request.systemMessage;\n    if (systemMessage) {\n      payload.systemInstruction = {\n        parts: [{ text: systemMessage }],\n        role: 'system'\n      };\n    }\n\n    return payload;\n  }\n\n  /**\n   * Parse Gemini response to standard format\n   */\n  protected parseResponse(response: GeminiResponse, startTime: number): AIResponse {\n    const candidate = response.candidates?.[0];\n    if (!candidate) {\n      throw new Error('No candidates returned from Gemini API');\n    }\n\n    const text = candidate.content?.parts?.[0]?.text || '';\n\n    return {\n      text,\n      usage: response.usageMetadata ? {\n        promptTokens: response.usageMetadata.promptTokenCount,\n        completionTokens: response.usageMetadata.candidatesTokenCount,\n        totalTokens: response.usageMetadata.totalTokenCount\n      } : undefined,\n      metadata: {\n        finishReason: candidate.finishReason,\n        safetyRatings: candidate.safetyRatings,\n        promptFeedback: response.promptFeedback\n      },\n      model: 'gemini', // Gemini doesn't return model in response\n      processingTime: this.calculateProcessingTime(startTime)\n    };\n  }\n\n  /**\n   * Add Gemini-specific authentication headers\n   */\n  protected addAuthHeaders(headers: Record<string, string>): void {\n    // Gemini uses API key in query params, not headers\n    // But we include it here for completeness\n    headers['x-goog-api-key'] = this.config.apiKey;\n  }\n\n  /**\n   * Normalize model name for Gemini API\n   */\n  private normalizeModelName(model: string): string {\n    // Remove 'models/' prefix if present\n    if (model.startsWith('models/')) {\n      return model.substring(7);\n    }\n    return model;\n  }\n}\n\n/**\n * Factory function for creating Gemini service instances\n */\nexport function createGeminiService(config: AIServiceConfig): GeminiService {\n  return new GeminiService(config);\n}\n",
      "metadata": {
        "filename": "GeminiService.ts",
        "path": "/backend/src/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/ai/OpenAIService.ts\n\n/**\n * @file OpenAIService.ts\n * @description OpenAI AI service implementation.\n * Provides integration with OpenAI's GPT models including GPT-4, GPT-4 Turbo, and GPT-3.5.\n * Handles OpenAI-specific parameter mapping, authentication, and response parsing.\n */\n\nimport axios, { AxiosInstance, AxiosResponse } from 'axios';\nimport { BaseAIService, AIResponse, AIServiceConfig, AIServiceCapabilities } from './BaseAIService';\nimport { AIRequest, ModelParameters, OpenAIParameters } from '../../types/aiProvider';\n\n/**\n * OpenAI API response interfaces\n */\ninterface OpenAIMessage {\n  role: 'system' | 'user' | 'assistant';\n  content: string;\n}\n\ninterface OpenAIChoice {\n  index: number;\n  message: OpenAIMessage;\n  finish_reason: string;\n}\n\ninterface OpenAIUsage {\n  prompt_tokens: number;\n  completion_tokens: number;\n  total_tokens: number;\n}\n\ninterface OpenAIResponse {\n  id: string;\n  object: string;\n  created: number;\n  model: string;\n  choices: OpenAIChoice[];\n  usage: OpenAIUsage;\n}\n\ninterface OpenAIModel {\n  id: string;\n  object: string;\n  created: number;\n  owned_by: string;\n}\n\ninterface OpenAIModelsResponse {\n  object: string;\n  data: OpenAIModel[];\n}\n\n/**\n * OpenAI service implementation\n */\nexport class OpenAIService extends BaseAIService {\n  private client: AxiosInstance;\n  private readonly baseUrl: string;\n\n  constructor(config: AIServiceConfig) {\n    const capabilities: AIServiceCapabilities = {\n      supportedParameters: [\n        'temperature', \n        'maxTokens', \n        'top_p', \n        'presence_penalty', \n        'frequency_penalty',\n        'systemMessage',\n        'n',\n        'stop'\n      ],\n      maxContextLength: 128000, // GPT-4 context length\n      supportsStreaming: true,\n      supportsFunctionCalling: true,\n      supportsImages: true\n    };\n\n    super('openai', config, capabilities);\n    \n    this.baseUrl = config.baseUrl || 'https://api.openai.com/v1';\n    this.client = axios.create({\n      baseURL: this.baseUrl,\n      timeout: config.timeout || 30000,\n      headers: this.getRequestHeaders()\n    });\n  }\n\n  /**\n   * Test connection to OpenAI API\n   */\n  async testConnection(): Promise<boolean> {\n    try {\n      const response = await this.client.get('/models');\n      return response.status === 200;\n    } catch (error) {\n      console.error('OpenAI connection test failed:', error);\n      return false;\n    }\n  }\n\n  /**\n   * List available OpenAI models\n   */\n  async listModels(): Promise<string[]> {\n    try {\n      const response: AxiosResponse<OpenAIModelsResponse> = await this.client.get('/models');\n      \n      // Filter to only include GPT models that are relevant for text generation\n      const gptModels = response.data.data\n        .filter((model: OpenAIModel) => \n          model.id.includes('gpt') && \n          !model.id.includes('instruct') &&\n          !model.id.includes('edit') &&\n          !model.id.includes('whisper') &&\n          !model.id.includes('tts') &&\n          !model.id.includes('dall-e')\n        )\n        .map((model: OpenAIModel) => model.id)\n        .sort();\n      \n      return gptModels;\n    } catch (error) {\n      console.error('Failed to list OpenAI models:', error);\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Generate completion using OpenAI API\n   */\n  async generateCompletion(request: AIRequest): Promise<AIResponse> {\n    const startTime = Date.now();\n    \n    try {\n      const payload = this.buildRequestPayload(request);\n      this.logRequest(payload);\n      \n      const response: AxiosResponse<OpenAIResponse> = await this.client.post('/chat/completions', payload);\n      \n      const aiResponse = this.parseResponse(response.data, startTime);\n      this.logResponse(aiResponse);\n      \n      return aiResponse;\n    } catch (error) {\n      console.error('OpenAI completion failed:', error);\n      throw this.handleError(error);\n    }\n  }\n\n  /**\n   * Generate streaming completion (placeholder implementation)\n   */\n  async generateStreamingCompletion(\n    request: AIRequest,\n    onChunk: (chunk: string) => void\n  ): Promise<AIResponse> {\n    // For now, implement as non-streaming\n    // TODO: Implement actual streaming support\n    const response = await this.generateCompletion(request);\n    onChunk(response.text);\n    return response;\n  }\n\n  /**\n   * Validate OpenAI parameters\n   */\n  validateParameters(model: string, parameters: ModelParameters): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n    const params = parameters as OpenAIParameters;\n\n    // Validate temperature\n    if (params.temperature !== undefined) {\n      if (params.temperature < 0 || params.temperature > 2) {\n        errors.push('temperature must be between 0 and 2');\n      }\n    }\n\n    // Validate maxTokens\n    if (params.maxTokens !== undefined) {\n      if (params.maxTokens < 1 || params.maxTokens > 4096) {\n        errors.push('maxTokens must be between 1 and 4096');\n      }\n    }\n\n    // Validate top_p\n    if (params.top_p !== undefined) {\n      if (params.top_p < 0 || params.top_p > 1) {\n        errors.push('top_p must be between 0 and 1');\n      }\n    }\n\n    // Validate presence_penalty\n    if (params.presence_penalty !== undefined) {\n      if (params.presence_penalty < -2 || params.presence_penalty > 2) {\n        errors.push('presence_penalty must be between -2 and 2');\n      }\n    }\n\n    // Validate frequency_penalty\n    if (params.frequency_penalty !== undefined) {\n      if (params.frequency_penalty < -2 || params.frequency_penalty > 2) {\n        errors.push('frequency_penalty must be between -2 and 2');\n      }\n    }\n\n    // Validate n\n    if (params.n !== undefined) {\n      if (params.n < 1 || params.n > 4) {\n        errors.push('n must be between 1 and 4');\n      }\n    }\n\n    return {\n      valid: errors.length === 0,\n      errors\n    };\n  }\n\n  /**\n   * Normalize parameters to OpenAI format\n   */\n  protected normalizeParameters(parameters: ModelParameters): Record<string, any> {\n    const params = parameters as OpenAIParameters;\n    const normalized: Record<string, any> = {};\n\n    // Map standard parameters\n    if (params.temperature !== undefined) normalized.temperature = params.temperature;\n    if (params.maxTokens !== undefined) normalized.max_tokens = params.maxTokens;\n    if (params.top_p !== undefined) normalized.top_p = params.top_p;\n    if (params.presence_penalty !== undefined) normalized.presence_penalty = params.presence_penalty;\n    if (params.frequency_penalty !== undefined) normalized.frequency_penalty = params.frequency_penalty;\n    if (params.n !== undefined) normalized.n = params.n;\n    if (params.stop !== undefined) normalized.stop = params.stop;\n\n    return this.sanitizeParameters(normalized);\n  }\n\n  /**\n   * Build OpenAI API request payload\n   */\n  protected buildRequestPayload(request: AIRequest): Record<string, any> {\n    const parameters = this.normalizeParameters(request.parameters);\n    const params = request.parameters as OpenAIParameters;\n    \n    // Build messages array\n    const messages: OpenAIMessage[] = [];\n    \n    // Add system message if provided\n    const systemMessage = params.systemMessage || request.systemMessage;\n    if (systemMessage) {\n      messages.push({\n        role: 'system',\n        content: systemMessage\n      });\n    }\n    \n    // Add conversation history if provided\n    if (request.conversationHistory) {\n      request.conversationHistory.forEach(msg => {\n        messages.push({\n          role: msg.role,\n          content: msg.content\n        });\n      });\n    }\n    \n    // Add current prompt\n    messages.push({\n      role: 'user',\n      content: request.prompt\n    });\n    \n    return {\n      model: request.model,\n      messages,\n      ...parameters\n    };\n  }\n\n  /**\n   * Parse OpenAI response to standard format\n   */\n  protected parseResponse(response: OpenAIResponse, startTime: number): AIResponse {\n    const choice = response.choices[0];\n    if (!choice) {\n      throw new Error('No choices returned from OpenAI API');\n    }\n\n    return {\n      text: choice.message.content || '',\n      usage: response.usage ? {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens,\n        totalTokens: response.usage.total_tokens\n      } : undefined,\n      metadata: {\n        id: response.id,\n        created: response.created,\n        finishReason: choice.finish_reason\n      },\n      model: response.model,\n      processingTime: this.calculateProcessingTime(startTime)\n    };\n  }\n\n  /**\n   * Add OpenAI-specific authentication headers\n   */\n  protected addAuthHeaders(headers: Record<string, string>): void {\n    headers['Authorization'] = `Bearer ${this.config.apiKey}`;\n  }\n}\n\n/**\n * Factory function for creating OpenAI service instances\n */\nexport function createOpenAIService(config: AIServiceConfig): OpenAIService {\n  return new OpenAIService(config);\n}\n",
      "metadata": {
        "filename": "OpenAIService.ts",
        "path": "/backend/src/services/ai/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/geminiService.ts\n\n/**\n * @file geminiService.ts\n * @description Service module for interacting with Google's Gemini AI API.\n * Provides functionality for prompt testing, SFL prompt generation, and workflow creation\n * using the Gemini language model. This service handles API communication, response parsing,\n * and error handling for all Gemini-related operations.\n * \n * @requires @google/genai\n * @requires ../types\n * @since 0.5.1\n */\n\nimport { GoogleGenAI, GenerateContentResponse } from \"@google/genai\";\nimport { PromptSFL, Workflow } from '../types';\n\n/**\n * @constant {string|undefined} API_KEY\n * @description The API key for accessing Google's Gemini API, retrieved from environment variables.\n * @private\n */\nconst API_KEY = process.env.GEMINI_API_KEY;\n\nif (!API_KEY) {\n  console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\n\n/**\n * @constant {GoogleGenAI} ai\n * @description Initialized GoogleGenAI client instance for API communication.\n * @private\n */\nconst ai = new GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\n\n/**\n * Parses JSON content from AI-generated text using multiple extraction strategies.\n * This utility function handles various formats that the AI might return, including\n * code blocks, plain JSON, and text with prefixes.\n * \n * @param {string} text - The raw text response from the AI that contains JSON data.\n * @returns {any} The parsed JSON object.\n * @throws {Error} Throws an error if all parsing strategies fail.\n * \n * @example\n * ```typescript\n * const aiResponse = \"```json\\n{\\\"key\\\": \\\"value\\\"}\\n```\";\n * const parsed = parseJsonFromText(aiResponse);\n * console.log(parsed); // { key: \"value\" }\n * ```\n * \n * @since 0.5.1\n * @private\n */\nconst parseJsonFromText = (text: string): any => {\n  console.log(\"Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n  \n  // Try multiple extraction strategies\n  const strategies = [\n    // Strategy 1: Extract code block content (original)\n    () => {\n      const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n      const match = text.match(fenceRegex);\n      return match && match[1] ? match[1].trim() : null;\n    },\n    \n    // Strategy 2: Extract content between first { and last }\n    () => {\n      const firstBrace = text.indexOf('{');\n      const lastBrace = text.lastIndexOf('}');\n      if (firstBrace !== -1 && lastBrace > firstBrace) {\n        return text.substring(firstBrace, lastBrace + 1);\n      }\n      return null;\n    },\n    \n    // Strategy 3: Try the text as-is if it starts with {\n    () => {\n      const trimmed = text.trim();\n      return trimmed.startsWith('{') ? trimmed : null;\n    },\n    \n    // Strategy 4: Remove common prefixes and try again\n    () => {\n      const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n      const firstBrace = cleaned.indexOf('{');\n      const lastBrace = cleaned.lastIndexOf('}');\n      if (firstBrace !== -1 && lastBrace > firstBrace) {\n        return cleaned.substring(firstBrace, lastBrace + 1);\n      }\n      return null;\n    }\n  ];\n\n  // Try each strategy\n  for (let i = 0; i < strategies.length; i++) {\n    const jsonStr = strategies[i]();\n    if (jsonStr) {\n      try {\n        console.log(`Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n        const parsed = JSON.parse(jsonStr);\n        console.log(\"Successfully parsed JSON with strategy\", i + 1);\n        return parsed;\n      } catch (e) {\n        console.log(`Strategy ${i + 1} failed to parse:`, e);\n        continue;\n      }\n    }\n  }\n\n  // If all strategies fail, log detailed error info\n  console.error(\"All JSON parsing strategies failed\");\n  console.error(\"Raw text length:\", text.length);\n  console.error(\"Raw text preview:\", text.substring(0, 500));\n  console.error(\"Text ends with:\", text.substring(Math.max(0, text.length - 100)));\n  \n  throw new Error(\"The AI returned a response that could not be parsed as JSON using any available strategy.\");\n};\n\n/**\n * @class GeminiService\n * @description Service class for interacting with Google's Gemini AI API.\n * Provides methods for testing prompts, generating SFL-structured prompts from goals,\n * regenerating prompts based on suggestions, and creating workflows.\n * \n * @since 0.5.1\n */\nclass GeminiService {\n  /**\n   * Tests a prompt by sending it to the Gemini API and returning the response.\n   * This method is used for validating prompt effectiveness and getting sample responses.\n   * \n   * @param {string} promptText - The prompt text to test with the Gemini model.\n   * @returns {Promise<string>} A promise that resolves to the AI-generated response text.\n   * @throws {Error} Throws an error if the API key is not configured or if the API call fails.\n   * \n   * @example\n   * ```typescript\n   * const service = new GeminiService();\n   * try {\n   *   const response = await service.testPrompt(\"Explain quantum computing briefly.\");\n   *   console.log(\"AI Response:\", response);\n   * } catch (error) {\n   *   console.error(\"Test failed:\", error.message);\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async testPrompt(promptText: string): Promise<string> {\n    if (!API_KEY) {\n      throw new Error(\"Gemini API Key is not configured.\");\n    }\n    try {\n      const response: GenerateContentResponse = await ai.models.generateContent({\n        model: 'gemini-2.5-flash',\n        contents: [{ role: \"user\", parts: [{ text: promptText }] }],\n      });\n      \n      return response.candidates?.[0]?.content?.parts?.[0]?.text || \"\";\n\n    } catch (error: unknown) {\n      console.error(\"Error calling Gemini API:\", error);\n      if (error instanceof Error) {\n        throw new Error(`Gemini API Error: ${error.message}`);\n      }\n      throw new Error(\"An unknown error occurred while contacting the Gemini API.\");\n    }\n  }\n\n  /**\n   * Generates a complete SFL (Systemic Functional Linguistics) prompt structure from a high-level goal.\n   * This method uses AI to analyze the goal and create structured prompt components including\n   * Field (what), Tenor (who), and Mode (how) aspects. Optionally incorporates style from a source document.\n   * \n   * @param {string} goal - A natural language description of what the user wants to achieve.\n   * @param {string} [sourceDocContent] - Optional content from a source document to provide stylistic reference.\n   * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise resolving to the generated SFL prompt structure.\n   * @throws {Error} Throws an error if the API key is not configured or if the generation fails.\n   * \n   * @example\n   * ```typescript\n   * const service = new GeminiService();\n   * const goal = \"Create a formal business proposal for a new software project\";\n   * const sourceDoc = \"Sample business document text for style reference...\";\n   * try {\n   *   const sflPrompt = await service.generateSFLFromGoal(goal, sourceDoc);\n   *   console.log(\"Generated SFL prompt:\", sflPrompt.title);\n   * } catch (error) {\n   *   console.error(\"Generation failed:\", error.message);\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async generateSFLFromGoal(goal: string, sourceDocContent?: string): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> {\n    if (!API_KEY) {\n        throw new Error(\"Gemini API Key is not configured.\");\n    }\n    \n    const systemInstruction = `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to analyze a user's goal and structure it into a detailed SFL-based prompt.\\n    If a source document is provided for stylistic reference, you MUST analyze its style (e.g., tone, complexity, vocabulary, sentence structure) and incorporate those stylistic qualities into the SFL fields and the final promptText. For example, update the 'desiredTone', 'aiPersona', and 'textualDirectives' to match the source. The generated 'promptText' should be a complete, standalone prompt that implicitly carries the desired style.\\n    The output MUST be a single, valid JSON object. Do not include any text, notes, or explanations outside of the JSON object.\\n    The JSON object should have the following structure: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string }.\\n    \\n    - title: Create a concise, descriptive title based on the user's goal.\\n    - promptText: Synthesize all the SFL elements into a complete, well-formed prompt that can be sent directly to an AI.\\n    - sflField (What is happening?): Analyze the subject matter.\\n    - sflTenor (Who is taking part?): Define the roles and relationships. The \"targetAudience\" field must be an array of strings, even if only one audience is identified.\\n    - sflMode (How is it being communicated?): Specify the format and structure of the output.\\n    - exampleOutput: Provide a brief but illustrative example of the expected output.\\n    - notes: Add any relevant notes or suggestions for the user.\\n    - All fields in the JSON must be filled with meaningful content.`;\n    \n    const userContent = sourceDocContent\n      ? `Source document for style reference:\\n\\n---\\n\\n${sourceDocContent}\\n\\n----\\n\\nUser's goal: \"${goal}\"`\n      : `Here is the user's goal: \"${goal}\"`;\n\n    try {\n        const response: GenerateContentResponse = await ai.models.generateContent({\n            model: 'gemini-2.5-flash',\n            contents: [{ role: \"user\", parts: [{ text: userContent }] }],\n            config: {\n                responseMimeType: \"application/json\",\n                systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n            },\n        });\n\n        const text = response.candidates?.[0]?.content?.parts?.[0]?.text || \"{}\";\n        const jsonData = parseJsonFromText(text);\n        \n        if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n            jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n        }\n        if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n            jsonData.sflTenor.targetAudience = [];\n        }\n\n        return jsonData as Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>;\n\n    } catch (error: unknown) {\n        console.error(\"Error calling Gemini API for SFL generation:\", error);\n        if (error instanceof Error) {\n            throw new Error(`Gemini API Error: ${error.message}`);\n        }\n        throw new Error(\"An unknown error occurred while generating the SFL prompt.\");\n    }\n  }\n\n  /**\n   * Regenerates an existing SFL prompt based on a user's suggestion for improvement.\n   * This method takes an existing prompt and a natural language suggestion, then uses AI\n   * to intelligently modify the prompt structure while maintaining SFL principles.\n   * \n   * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>} currentPrompt - The existing prompt to be modified.\n   * @param {string} suggestion - A natural language suggestion for how to improve or change the prompt.\n   * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise resolving to the regenerated SFL prompt structure.\n   * @throws {Error} Throws an error if the API key is not configured or if the regeneration fails.\n   * \n   * @example\n   * ```typescript\n   * const service = new GeminiService();\n   * const existingPrompt = { // ... existing SFL prompt structure };\n   * const suggestion = \"Make the tone more casual and add examples\";\n   * try {\n   *   const improvedPrompt = await service.regenerateSFLFromSuggestion(existingPrompt, suggestion);\n   *   console.log(\"Improved prompt:\", improvedPrompt.title);\n   * } catch (error) {\n   *   console.error(\"Regeneration failed:\", error.message);\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async regenerateSFLFromSuggestion(\n    currentPrompt: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>,\n    suggestion: string\n  ): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> {\n    if (!API_KEY) {\n        throw new Error(\"Gemini API Key is not configured.\");\n    }\n    \n    const systemInstruction = `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to revise an existing SFL prompt based on a user's suggestion.\\n    The user will provide a JSON object representing the current prompt and a text string with their requested change.\\n    If a source document is provided (as part of the prompt object or separately), its style should be analyzed and take precedence, influencing the revision.\\n    You MUST return a single, valid JSON object that represents the *revised* prompt. Do not include any text, notes, or explanations outside of the JSON object.\\n    The output JSON object must have the exact same structure as the input, containing all the original fields, but with values updated according to the suggestion and stylistic source.\\n    The structure is: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string, \"sourceDocument\": { \"name\": string, \"content\": string } | undefined }.\\n    \\n    - Critically analyze the user's suggestion and apply it to all relevant fields in the prompt.\\n    - If a 'sourceDocument' is present, ensure its style is reflected in the revised SFL fields and 'promptText'.\\n    - The 'promptText' field is the most important; it must be re-written to reflect the change.\\n    - Other SFL fields (Field, Tenor, Mode) should be updated logically to align with the new 'promptText' and the user's suggestion.\\n    - Even update the 'title', 'exampleOutput', and 'notes' if the suggestion implies it.\\n    - Ensure 'targetAudience' remains an array of strings.\\n    - Preserve the 'sourceDocument' field in the output if it existed in the input.`;\n    \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    const { sourceDocument, ...promptForPayload } = currentPrompt;\n\n    const userContent = `\n    Here is the current prompt JSON:\n    ${JSON.stringify(promptForPayload)}\n    \n    ${sourceDocument ? `This prompt is associated with the following source document for stylistic reference:\\n---\\n${sourceDocument.content}\\n---\\n` : ''}\n\n    Here is my suggestion for how to change it:\n    \"${suggestion}\"\n\n    Now, provide the complete, revised JSON object.\n    `;\n\n    try {\n        const response: GenerateContentResponse = await ai.models.generateContent({\n            model: 'gemini-2.5-flash',\n            contents: [{ role: \"user\", parts: [{ text: userContent }] }],\n            config: {\n                responseMimeType: \"application/json\",\n                systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n            },\n        });\n\n        const text = response.candidates?.[0]?.content?.parts?.[0]?.text || \"{}\";\n        const jsonData = parseJsonFromText(text);\n        \n        if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n            jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n        }\n        if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n            jsonData.sflTenor.targetAudience = [];\n        }\n        \n        // Preserve the source document from the original prompt\n        jsonData.sourceDocument = sourceDocument;\n\n        return jsonData as Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>;\n\n    } catch (error: unknown) {\n        console.error(\"Error calling Gemini API for SFL regeneration:\", error);\n        if (error instanceof Error) {\n            throw new Error(`Gemini API Error: ${error.message}`);\n        }\n        throw new Error(\"An unknown error occurred while regenerating the SFL prompt.\");\n    }\n  }\n\n  /**\n   * Generates a complete workflow structure from a high-level goal description.\n   * This method uses AI to analyze a user's goal and create a multi-task workflow\n   * with appropriate task types, dependencies, and data flow connections.\n   * \n   * @param {string} goal - A natural language description of the multi-step process to automate.\n   * @returns {Promise<Workflow>} A promise resolving to the generated workflow structure with tasks.\n   * @throws {Error} Throws an error if the API key is not configured or if the workflow generation fails.\n   * \n   * @example\n   * ```typescript\n   * const service = new GeminiService();\n   * const goal = \"Analyze customer feedback sentiment and generate a summary report\";\n   * try {\n   *   const workflow = await service.generateWorkflowFromGoal(goal);\n   *   console.log(`Generated workflow \"${workflow.name}\" with ${workflow.tasks.length} tasks`);\n   * } catch (error) {\n   *   console.error(\"Workflow generation failed:\", error.message);\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async generateWorkflowFromGoal(goal: string): Promise<Workflow> {\n    if (!API_KEY) {\n        throw new Error(\"Gemini API Key is not configured.\");\n    }\n\n    const systemInstruction = `You are an expert AI workflow orchestrator. Your task is to analyze a user's goal and generate a complete, multi-task workflow as a valid JSON object.\\n    \\nThe user goal will be provided. Based on this, create a workflow with a series of tasks. The output MUST be a single, valid JSON object representing the workflow. Do not include any text or explanations outside the JSON.\\n\\nThe root JSON object must have 'name', 'description', and 'tasks' fields. Each task in the 'tasks' array must have the following fields:\\n- id: A unique string identifier for the task (e.g., \"task-1\").\\n- name: A short, descriptive name for the task.\\n- description: A one-sentence explanation of what the task does.\\n- type: One of \"DATA_INPUT\", \"GEMINI_PROMPT\", \"IMAGE_ANALYSIS\", \"TEXT_MANIPULATION\", \"DISPLAY_CHART\", \"GEMINI_GROUNDED\".\\n- dependencies: An array of task IDs that this task depends on. Empty for initial tasks.\\n- inputKeys: An array of strings representing keys from the Data Store needed for this task. Use dot notation for nested keys (e.g., \"userInput.text\").\\n- outputKey: A string for the key where the task's result will be stored in the Data Store.\\n\\nRules for specific task types:\\n- GEMINI_PROMPT/IMAGE_ANALYSIS: Must include a 'promptTemplate' field. Use {{key}} for placeholders.\\n- TEXT_MANIPULATION: Must include a 'functionBody' field containing a JavaScript function body as a string. E.g., \"return \\`Report: \\${inputs.summary}\\`\".\\n- DATA_INPUT: Must include a 'staticValue' field. Use \"{{userInput.text}}\", \"{{userInput.image}}\", or \"{{userInput.file}}\" to get data from the user input area.\\n- DISPLAY_CHART: Must include a 'dataKey' field pointing to data in the Data Store suitable for charting.\\n- GEMINI_GROUNDED: For tasks requiring up-to-date information. Should have a 'promptTemplate'.\\n\\nExample Goal: \"Analyze a user-provided text for sentiment and then summarize it.\"\\nExample Output:\\n{\\n  \"name\": \"Sentiment Analysis and Summary\",\\n  \"description\": \"A workflow that first determines the sentiment of a text and then provides a concise summary.\",\\n  \"tasks\": [\\n    { \"id\": \"task-1\", \"name\": \"Get User Text\", \"description\": \"Receives the text to be analyzed from the user.\", \"type\": \"DATA_INPUT\", \"dependencies\": [], \"inputKeys\": [], \"outputKey\": \"inputText\", \"staticValue\": \"{{userInput.text}}\" },\\n    { \"id\": \"task-2\", \"name\": \"Analyze Sentiment\", \"description\": \"Determines if the text is positive, negative, or neutral.\", \"type\": \"GEMINI_PROMPT\", \"dependencies\": [\"task-1\"], \"inputKeys\": [\"inputText\"], \"outputKey\": \"sentiment\", \"promptTemplate\": \"Analyze the sentiment of the following text and return only 'positive', 'negative', or 'neutral':\\\\n\\\\n{{inputText}}\" },\\n    { \"id\": \"task-3\", \"name\": \"Summarize Text\", \"description\": \"Creates a one-sentence summary of the text.\", \"type\": \"GEMINI_PROMPT\", \"dependencies\": [\"task-1\"], \"inputKeys\": [\"inputText\"], \"outputKey\": \"summary\", \"promptTemplate\": \"Summarize the following text in a single sentence:\\\\n\\\\n{{inputText}}\" },\\n    { \"id\": \"task-4\", \"name\": \"Format Report\", \"description\": \"Combines the sentiment and summary into a final report.\", \"type\": \"TEXT_MANIPULATION\", \"dependencies\": [\"task-2\", \"task-3\"], \"inputKeys\": [\"sentiment\", \"summary\"], \"outputKey\": \"finalReport\", \"functionBody\": \"return \\`Sentiment: \\${inputs.sentiment.toUpperCase()}\\nSummary: \\${inputs.summary}\\`\" }\\n  ]\\n}`;\n\n    try {\n        const response: GenerateContentResponse = await ai.models.generateContent({\n            model: 'gemini-2.5-flash',\n            contents: [{ role: \"user\", parts: [{ text: `User's goal: \"${goal}\"` }] }],\n            config: {\n                responseMimeType: \"application/json\",\n                systemInstruction: { role: \"system\", parts: [{ text: systemInstruction }] },\n            },\n        });\n\n        const text = response.candidates?.[0]?.content?.parts?.[0]?.text || \"{}\";\n        const jsonData = parseJsonFromText(text);\n        \n        if (!jsonData.name || !jsonData.description || !Array.isArray(jsonData.tasks)) {\n            throw new Error(\"Generated workflow is missing required fields (name, description, tasks).\");\n        }\n        \n        jsonData.id = `wf-custom-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n\n        return jsonData as Workflow;\n\n    } catch (error: unknown) {\n        console.error(\"Error calling Gemini API for Workflow generation:\", error);\n        if (error instanceof Error) {\n            throw new Error(`Gemini API Error: ${error.message}`);\n        }\n        throw new Error(\"An unknown error occurred while generating the workflow.\");\n    }\n  }\n}\n\n/**\n * @exports {GeminiService} geminiService\n * @description Singleton instance of the GeminiService class, ready to be used across the application.\n * This exported instance provides all Gemini AI functionality including prompt testing,\n * SFL generation, and workflow creation.\n * \n * @since 0.5.1\n */\nexport default new GeminiService();\n",
      "metadata": {
        "filename": "geminiService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/jobService.ts\n\n/**\n * @file jobService.ts\n * @description Job service that manages background workflow execution using BullMQ.\n * Provides functionality to add workflow execution jobs to a queue and process them\n * asynchronously. Integrates with the existing workflowExecutionService for actual execution.\n */\n\nimport { Queue, Worker, Job, JobProgress } from 'bullmq';\nimport Redis from 'ioredis';\nimport config from '../config/env';\nimport workflowExecutionService from './workflowExecutionService';\nimport promptService from './promptService';\nimport webSocketService from './webSocketService';\nimport { Workflow, Task, PromptSFL } from '../types';\n\n/**\n * @interface WorkflowJobData\n * @description Structure of data passed to workflow execution jobs\n */\ninterface WorkflowJobData {\n  workflowId: string;\n  workflow: Workflow;\n  userInput?: Record<string, any>;\n}\n\n/**\n * @interface WorkflowJobProgress\n * @description Structure for job progress updates\n */\ninterface WorkflowJobProgress {\n  taskId: string;\n  taskName: string;\n  status: 'active' | 'completed' | 'failed';\n  result?: any;\n  error?: string;\n}\n\n/**\n * Service class for managing workflow execution jobs using BullMQ\n */\nclass JobService {\n  private queue?: Queue;\n  private worker?: Worker;\n  private redis?: Redis;\n\n  constructor() {\n    if (!config.redisUrl) {\n      console.warn('REDIS_URL environment variable not set, job service will be disabled');\n      return;\n    }\n\n    try {\n      // Initialize Redis connection with BullMQ-compatible settings\n      this.redis = new Redis(config.redisUrl, {\n        maxRetriesPerRequest: null, // Required for BullMQ\n        lazyConnect: true, // Don't connect immediately\n      });\n\n      // Initialize BullMQ queue\n      this.queue = new Queue('workflow-execution', {\n        connection: this.redis,\n        defaultJobOptions: {\n          removeOnComplete: 10, // Keep last 10 completed jobs\n          removeOnFail: 50,     // Keep last 50 failed jobs\n          attempts: 3,          // Retry failed jobs up to 3 times\n          backoff: {\n            type: 'exponential',\n            delay: 2000,\n          },\n        },\n      });\n\n      // Initialize BullMQ worker\n      this.worker = new Worker('workflow-execution', this.processWorkflowJob.bind(this), {\n        connection: this.redis,\n        concurrency: 5, // Process up to 5 jobs concurrently\n      });\n\n      // Set up worker event listeners\n      this.setupWorkerEvents();\n    } catch (error) {\n      console.error('Failed to initialize job service:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Adds a workflow execution job to the queue\n   * @param workflowId - Unique identifier for the workflow\n   * @param workflow - The workflow object to execute\n   * @param userInput - Optional user input data\n   * @returns Promise resolving to the job ID\n   */\n  async addWorkflowJob(\n    workflowId: string, \n    workflow: Workflow, \n    userInput?: Record<string, any>\n  ): Promise<string> {\n    if (!this.queue) {\n      throw new Error('Job service not initialized - Redis connection not available');\n    }\n\n    const jobData: WorkflowJobData = {\n      workflowId,\n      workflow,\n      userInput,\n    };\n\n    const job = await this.queue.add('execute-workflow', jobData, {\n      jobId: `workflow-${workflowId}-${Date.now()}`,\n    });\n\n    return job.id!;\n  }\n\n  /**\n   * Gets the status of a specific job\n   * @param jobId - The job ID to check\n   * @returns Promise resolving to job status information\n   */\n  async getJobStatus(jobId: string) {\n    if (!this.queue) {\n      throw new Error('Job service not initialized - Redis connection not available');\n    }\n\n    const job = await this.queue.getJob(jobId);\n    if (!job) {\n      return null;\n    }\n\n    return {\n      id: job.id,\n      status: await job.getState(),\n      progress: job.progress,\n      returnValue: job.returnvalue,\n      failedReason: job.failedReason,\n      processedOn: job.processedOn,\n      finishedOn: job.finishedOn,\n    };\n  }\n\n  /**\n   * Stops a specific job\n   * @param jobId - The job ID to stop\n   * @returns Promise resolving to success status\n   */\n  async stopJob(jobId: string): Promise<boolean> {\n    if (!this.queue) {\n      throw new Error('Job service not initialized - Redis connection not available');\n    }\n\n    const job = await this.queue.getJob(jobId);\n    if (!job) {\n      return false;\n    }\n\n    const jobState = await job.getState();\n    \n    // Can only stop jobs that are waiting, active, or delayed\n    if (['waiting', 'active', 'delayed'].includes(jobState)) {\n      try {\n        // Remove the job from the queue\n        await job.remove();\n        \n        // Broadcast stop message to WebSocket clients\n        webSocketService.broadcastToJob(jobId, {\n          type: 'workflow_stopped',\n          workflowId: job.data.workflowId,\n          status: 'stopped',\n          reason: 'user_cancelled',\n        });\n        \n        return true;\n      } catch (error) {\n        console.error(`Failed to stop job ${jobId}:`, error);\n        return false;\n      }\n    }\n    \n    return false; // Job is already completed or failed\n  }\n\n  /**\n   * Processes a workflow execution job\n   * @param job - The BullMQ job to process\n   * @returns Promise resolving to the workflow execution result\n   */\n  private async processWorkflowJob(job: Job<WorkflowJobData>): Promise<any> {\n    const { workflowId, workflow, userInput } = job.data;\n\n    try {\n      // Update job progress\n      await job.updateProgress({ status: 'started', workflowId });\n\n      // Get prompts needed for the workflow\n      const promptIds = (workflow.tasks || [])\n        .filter(task => task.promptId)\n        .map(task => task.promptId!);\n      \n      const prompts: PromptSFL[] = [];\n      for (const promptId of promptIds) {\n        const prompt = await promptService.getPromptById(promptId);\n        if (prompt) {\n          prompts.push(prompt);\n        }\n      }\n\n      // Execute workflow tasks in order\n      const results: Record<string, any> = {};\n      const dataStore: Record<string, any> = { userInput: userInput || {} };\n\n      // Simple sequential execution for now (will be enhanced with topological sort later)\n      const tasks = workflow.tasks || [];\n      for (let i = 0; i < tasks.length; i++) {\n        const task = tasks[i];\n        \n        try {\n          // Check if job has been cancelled before processing each task\n          const currentJob = await this.queue?.getJob(job.id!);\n          if (!currentJob) {\n            // Job was removed (cancelled)\n            throw new Error('Workflow execution was cancelled');\n          }\n\n          // Update progress for current task\n          await job.updateProgress({\n            status: 'active',\n            taskId: task.id,\n            taskName: task.name,\n            currentTask: i + 1,\n            totalTasks: tasks.length,\n          } as WorkflowJobProgress);\n\n          // Find the prompt for this task if it has one\n          const linkedPrompt = task.promptId \n            ? prompts.find(p => p.id === task.promptId)\n            : undefined;\n\n          // Execute the task\n          const result = await workflowExecutionService.executeTask(task, dataStore, linkedPrompt);\n          \n          // Check again for cancellation after task execution\n          const jobAfterExecution = await this.queue?.getJob(job.id!);\n          if (!jobAfterExecution) {\n            // Job was removed (cancelled) during execution\n            throw new Error('Workflow execution was cancelled');\n          }\n          \n          // Store result in dataStore for next tasks\n          dataStore[task.outputKey] = result;\n          results[task.id] = result;\n\n          // Update progress for completed task\n          await job.updateProgress({\n            status: 'completed',\n            taskId: task.id,\n            taskName: task.name,\n            result,\n          } as WorkflowJobProgress);\n\n        } catch (error) {\n          // Check if this is a cancellation error\n          if (error instanceof Error && error.message === 'Workflow execution was cancelled') {\n            // Don't update progress for cancelled tasks, just throw\n            throw error;\n          }\n\n          // Update progress for failed task\n          await job.updateProgress({\n            status: 'failed',\n            taskId: task.id,\n            taskName: task.name,\n            error: error instanceof Error ? error.message : 'Unknown error',\n          } as WorkflowJobProgress);\n\n          throw error; // Re-throw to fail the entire job\n        }\n      }\n\n      return {\n        workflowId,\n        status: 'completed',\n        results,\n        dataStore,\n      };\n\n    } catch (error) {\n      console.error(`Workflow execution failed for ${workflowId}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Sets up event listeners for the worker\n   */\n  private setupWorkerEvents(): void {\n    if (!this.worker) {\n      console.warn('Worker not initialized, skipping event setup');\n      return;\n    }\n\n    this.worker.on('completed', (job: Job) => {\n      console.log(`Job ${job.id} completed successfully`);\n      \n      // Broadcast completion to WebSocket clients\n      webSocketService.broadcastToJob(job.id!, {\n        type: 'workflow_complete',\n        workflowId: job.data.workflowId,\n        status: 'completed',\n        result: job.returnvalue,\n      });\n    });\n\n    this.worker.on('failed', (job: Job | undefined, error: Error) => {\n      console.error(`Job ${job?.id} failed:`, error.message);\n      \n      if (job?.id) {\n        // Broadcast failure to WebSocket clients\n        webSocketService.broadcastToJob(job.id, {\n          type: 'workflow_failed',\n          workflowId: job.data.workflowId,\n          status: 'failed',\n          error: error.message,\n        });\n      }\n    });\n\n    this.worker.on('active', (job: Job) => {\n      console.log(`Job ${job.id} started processing`);\n      \n      // Broadcast start to WebSocket clients\n      webSocketService.broadcastToJob(job.id!, {\n        type: 'workflow_progress',\n        workflowId: job.data.workflowId,\n        status: 'running',\n      });\n    });\n\n    this.worker.on('progress', (job: Job, progress: JobProgress) => {\n      // Type guard to ensure progress is a WorkflowJobProgress object\n      if (typeof progress === 'object' && progress !== null && \n          'taskId' in progress && 'taskName' in progress && 'status' in progress) {\n        const workflowProgress = progress as WorkflowJobProgress;\n        \n        // Broadcast task progress to WebSocket clients\n        webSocketService.broadcastToJob(job.id!, {\n          type: 'task_status',\n          workflowId: job.data.workflowId,\n          taskId: workflowProgress.taskId,\n          taskName: workflowProgress.taskName,\n          status: workflowProgress.status,\n          result: workflowProgress.result,\n          error: workflowProgress.error,\n        });\n      }\n    });\n\n    this.worker.on('stalled', (jobId: string) => {\n      console.warn(`Job ${jobId} stalled`);\n    });\n  }\n\n  /**\n   * Gracefully shuts down the job service\n   */\n  async shutdown(): Promise<void> {\n    if (this.worker) {\n      await this.worker.close();\n    }\n    if (this.queue) {\n      await this.queue.close();\n    }\n    if (this.redis) {\n      await this.redis.quit();\n    }\n  }\n}\n\nexport default new JobService();\n",
      "metadata": {
        "filename": "jobService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/mockJobService.ts\n\n/**\n * Mock job service for development when Redis is not available.\n * Provides the same interface as the real JobService but doesn't require Redis.\n */\n\nimport { Workflow } from '../types';\n\ninterface WorkflowJobData {\n  workflowId: string;\n  workflow: Workflow;\n  userInput?: Record<string, any>;\n}\n\nclass MockJobService {\n  async addWorkflowJob(workflowId: string, workflow: Workflow, userInput?: Record<string, any>): Promise<string> {\n    console.log('Mock JobService: Would add workflow job', { workflowId, workflow: workflow.name });\n    // Return a mock job ID\n    return `mock-job-${Date.now()}`;\n  }\n\n  async getJobStatus(jobId: string): Promise<any> {\n    console.log('Mock JobService: Would get job status for', jobId);\n    // Return mock status\n    return {\n      id: jobId,\n      status: 'mock-completed',\n      data: { workflowId: 'mock-workflow' },\n      result: { message: 'Mock job completed - Redis not available' },\n    };\n  }\n\n  async stopJob(jobId: string): Promise<boolean> {\n    console.log('Mock JobService: Would stop job', jobId);\n    // Always return true for mock (job stopped successfully)\n    return true;\n  }\n\n  // Add other methods as needed to match the real JobService interface\n  shutdown(): void {\n    console.log('Mock JobService: Shutdown called');\n  }\n}\n\nexport default new MockJobService();\n",
      "metadata": {
        "filename": "mockJobService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/modelService.ts\n\n/**\n * @file modelService.ts\n * @description This service handles database operations related to AI models.\n * It provides methods to retrieve information about the available models that can be used\n * for workflow tasks and prompt testing. Models are stored in the database with metadata\n * about their capabilities and availability.\n *\n * @requires ../config/database\n * @since 0.5.1\n */\n\nimport pool from '../config/database';\n\n/**\n * @interface Model\n * @description Represents the structure of a model record in the database.\n * Contains metadata about an AI model including its name, description, and active status.\n * \n * @property {string} id - The unique identifier for the model.\n * @property {string} name - The display name of the model (e.g., 'gemini-1.5-flash').\n * @property {string|null} description - Optional description of the model's capabilities.\n * @property {boolean} is_active - Whether the model is currently available for use.\n * \n * @since 0.5.1\n */\ninterface Model {\n  id: string;\n  name: string;\n  description: string | null;\n  is_active: boolean;\n}\n\n/**\n * @class ModelService\n * @description A class to encapsulate all database logic for AI models.\n * Provides methods to retrieve model information for use in workflow configuration\n * and prompt testing interfaces.\n * \n * @since 0.5.1\n */\nclass ModelService {\n  /**\n   * Retrieves all active models from the database.\n   * Returns only models that are currently available for use, ordered alphabetically by name.\n   * \n   * @returns {Promise<Model[]>} A promise that resolves to an array of active models.\n   * \n   * @example\n   * ```typescript\n   * const availableModels = await modelService.getModels();\n   * console.log('Available models:');\n   * availableModels.forEach(model => {\n   *   console.log(`- ${model.name}: ${model.description || 'No description'}`);\n   * });\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async getModels(): Promise<Model[]> {\n    const result = await pool.query('SELECT * FROM models WHERE is_active = true ORDER BY name');\n    return result.rows;\n  }\n}\n\n/**\n * @exports {ModelService} modelService\n * @description Singleton instance of the ModelService class, ready to be used across the application.\n * This exported instance provides all model-related database operations.\n * \n * @since 0.5.1\n */\nexport default new ModelService();\n",
      "metadata": {
        "filename": "modelService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/orchestratorService.ts\n\n/**\n * @file orchestratorService.ts\n * @description Service for AI-powered workflow orchestration. This service takes high-level user requests\n * and uses LLM-powered decomposition to generate complete, executable workflows automatically.\n * \n * @requires @google/genai\n * @requires ../types\n * @requires ../prompts/orchestratorPrompt\n * @since 2.1.0\n */\n\nimport { GoogleGenAI, GenerateContentResponse } from \"@google/genai\";\nimport { Workflow, Task } from '../types';\nimport { buildOrchestratorPrompt } from '../prompts/orchestratorPrompt';\n\n/**\n * @constant {string|undefined} API_KEY\n * @description The API key for accessing Google's Gemini API, retrieved from environment variables.\n * @private\n */\nconst API_KEY = process.env.GEMINI_API_KEY;\n\nif (!API_KEY) {\n  console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\n\n/**\n * @constant {GoogleGenAI} ai\n * @description Initialized GoogleGenAI client instance for API communication.\n * @private\n */\nconst ai = new GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\n\n/**\n * @interface OrchestratorResponse\n * @description Represents the response from the orchestrator service\n */\ninterface OrchestratorResponse {\n  success: boolean;\n  workflow?: Workflow;\n  error?: string;\n  validationErrors?: string[];\n}\n\n/**\n * Parses JSON content from AI-generated text using multiple extraction strategies.\n * Enhanced version of the parser from geminiService with better error handling.\n * \n * @param {string} text - The raw text response from the AI that contains JSON data.\n * @returns {any} The parsed JSON object.\n * @throws {Error} Throws an error if all parsing strategies fail.\n * @private\n */\nconst parseJsonFromText = (text: string): any => {\n  console.log(\"Orchestrator: Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n  \n  const strategies = [\n    // Strategy 1: Extract code block content\n    () => {\n      const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n      const match = text.match(fenceRegex);\n      return match && match[1] ? match[1].trim() : null;\n    },\n    \n    // Strategy 2: Extract content between first { and last }\n    () => {\n      const firstBrace = text.indexOf('{');\n      const lastBrace = text.lastIndexOf('}');\n      if (firstBrace !== -1 && lastBrace > firstBrace) {\n        return text.substring(firstBrace, lastBrace + 1);\n      }\n      return null;\n    },\n    \n    // Strategy 3: Try the text as-is if it starts with {\n    () => {\n      const trimmed = text.trim();\n      return trimmed.startsWith('{') ? trimmed : null;\n    },\n    \n    // Strategy 4: Remove common prefixes and try again\n    () => {\n      const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n      const firstBrace = cleaned.indexOf('{');\n      const lastBrace = cleaned.lastIndexOf('}');\n      if (firstBrace !== -1 && lastBrace > firstBrace) {\n        return cleaned.substring(firstBrace, lastBrace + 1);\n      }\n      return null;\n    }\n  ];\n\n  for (let i = 0; i < strategies.length; i++) {\n    const jsonStr = strategies[i]();\n    if (jsonStr) {\n      try {\n        console.log(`Orchestrator: Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n        const parsed = JSON.parse(jsonStr);\n        console.log(\"Orchestrator: Successfully parsed JSON with strategy\", i + 1);\n        return parsed;\n      } catch (e) {\n        console.log(`Orchestrator: Strategy ${i + 1} failed to parse:`, e);\n        continue;\n      }\n    }\n  }\n\n  console.error(\"Orchestrator: All JSON parsing strategies failed\");\n  throw new Error(\"The AI orchestrator returned a response that could not be parsed as JSON.\");\n};\n\n/**\n * Validates that a workflow object conforms to the expected structure and business rules.\n * \n * @param {any} workflow - The workflow object to validate\n * @returns {string[]} Array of validation error messages, empty if valid\n * @private\n */\nconst validateWorkflow = (workflow: any): string[] => {\n  const errors: string[] = [];\n\n  // Check required top-level fields\n  if (!workflow.name || typeof workflow.name !== 'string') {\n    errors.push(\"Workflow must have a 'name' field of type string\");\n  }\n  \n  if (!workflow.description || typeof workflow.description !== 'string') {\n    errors.push(\"Workflow must have a 'description' field of type string\");\n  }\n  \n  if (!Array.isArray(workflow.tasks)) {\n    errors.push(\"Workflow must have a 'tasks' field that is an array\");\n    return errors; // Can't validate tasks if it's not an array\n  }\n\n  if (workflow.tasks.length === 0) {\n    errors.push(\"Workflow must contain at least one task\");\n  }\n\n  // Validate each task\n  const taskIds = new Set<string>();\n  workflow.tasks.forEach((task: any, index: number) => {\n    const taskPrefix = `Task ${index + 1} (${task.id || 'unknown'})`;\n\n    // Required fields\n    if (!task.id || typeof task.id !== 'string') {\n      errors.push(`${taskPrefix}: must have a unique 'id' field of type string`);\n    } else if (taskIds.has(task.id)) {\n      errors.push(`${taskPrefix}: duplicate task ID '${task.id}'`);\n    } else {\n      taskIds.add(task.id);\n    }\n\n    if (!task.name || typeof task.name !== 'string') {\n      errors.push(`${taskPrefix}: must have a 'name' field of type string`);\n    }\n\n    if (!task.description || typeof task.description !== 'string') {\n      errors.push(`${taskPrefix}: must have a 'description' field of type string`);\n    }\n\n    if (!task.type || typeof task.type !== 'string') {\n      errors.push(`${taskPrefix}: must have a 'type' field of type string`);\n    }\n\n    if (!Array.isArray(task.dependencies)) {\n      errors.push(`${taskPrefix}: must have a 'dependencies' field that is an array`);\n    }\n\n    if (!Array.isArray(task.inputKeys)) {\n      errors.push(`${taskPrefix}: must have an 'inputKeys' field that is an array`);\n    }\n\n    if (!task.outputKey || typeof task.outputKey !== 'string') {\n      errors.push(`${taskPrefix}: must have an 'outputKey' field of type string`);\n    }\n\n    // Validate dependencies reference existing tasks\n    if (Array.isArray(task.dependencies)) {\n      task.dependencies.forEach((depId: string) => {\n        if (typeof depId !== 'string') {\n          errors.push(`${taskPrefix}: dependency must be a string, got ${typeof depId}`);\n        }\n        // Note: We can't validate if the dependency exists yet since we're processing tasks in order\n      });\n    }\n\n    // Type-specific validations\n    if (task.type) {\n      switch (task.type) {\n        case 'GEMINI_PROMPT':\n        case 'IMAGE_ANALYSIS':\n        case 'GEMINI_GROUNDED':\n          if (!task.promptTemplate || typeof task.promptTemplate !== 'string') {\n            errors.push(`${taskPrefix}: type '${task.type}' requires a 'promptTemplate' field of type string`);\n          }\n          break;\n        \n        case 'TEXT_MANIPULATION':\n          if (!task.functionBody || typeof task.functionBody !== 'string') {\n            errors.push(`${taskPrefix}: type 'TEXT_MANIPULATION' requires a 'functionBody' field of type string`);\n          }\n          break;\n        \n        case 'DATA_INPUT':\n          if (task.staticValue === undefined) {\n            errors.push(`${taskPrefix}: type 'DATA_INPUT' requires a 'staticValue' field`);\n          }\n          break;\n        \n        case 'DISPLAY_CHART':\n          if (!task.dataKey || typeof task.dataKey !== 'string') {\n            errors.push(`${taskPrefix}: type 'DISPLAY_CHART' requires a 'dataKey' field of type string`);\n          }\n          break;\n      }\n    }\n  });\n\n  // Validate that all dependency references exist\n  workflow.tasks.forEach((task: any) => {\n    if (Array.isArray(task.dependencies)) {\n      task.dependencies.forEach((depId: string) => {\n        if (!taskIds.has(depId)) {\n          errors.push(`Task '${task.id}': references non-existent dependency '${depId}'`);\n        }\n      });\n    }\n  });\n\n  return errors;\n};\n\n/**\n * Detects circular dependencies in a workflow task graph.\n * \n * @param {Task[]} tasks - Array of workflow tasks to check\n * @returns {boolean} True if circular dependencies are detected\n * @private\n */\nconst hasCircularDependencies = (tasks: Task[]): boolean => {\n  const visited = new Set<string>();\n  const recursionStack = new Set<string>();\n  \n  const taskMap = new Map<string, Task>();\n  tasks.forEach(task => taskMap.set(task.id, task));\n\n  const dfsVisit = (taskId: string): boolean => {\n    if (recursionStack.has(taskId)) {\n      return true; // Circular dependency detected\n    }\n    \n    if (visited.has(taskId)) {\n      return false; // Already processed\n    }\n\n    visited.add(taskId);\n    recursionStack.add(taskId);\n\n    const task = taskMap.get(taskId);\n    if (task) {\n      for (const depId of task.dependencies) {\n        if (dfsVisit(depId)) {\n          return true;\n        }\n      }\n    }\n\n    recursionStack.delete(taskId);\n    return false;\n  };\n\n  // Check each task\n  for (const task of tasks) {\n    if (!visited.has(task.id)) {\n      if (dfsVisit(task.id)) {\n        return true;\n      }\n    }\n  }\n\n  return false;\n};\n\n/**\n * @class OrchestratorService\n * @description Service class for AI-powered workflow orchestration.\n * Provides methods for generating complete workflows from high-level user requests.\n * \n * @since 2.1.0\n */\nclass OrchestratorService {\n  /**\n   * Generates a complete workflow from a high-level user request using AI orchestration.\n   * This method uses advanced prompting techniques to decompose complex requests into\n   * structured, executable workflows with proper task dependencies and data flow.\n   * \n   * @param {string} userRequest - The high-level request describing what the user wants to accomplish\n   * @returns {Promise<OrchestratorResponse>} A promise that resolves to the orchestration result\n   * \n   * @example\n   * ```typescript\n   * const orchestrator = new OrchestratorService();\n   * const result = await orchestrator.generateWorkflow(\n   *   \"Analyze customer feedback for sentiment and generate a report\"\n   * );\n   * if (result.success) {\n   *   console.log(`Generated workflow: ${result.workflow.name}`);\n   *   console.log(`Tasks: ${result.workflow.tasks.length}`);\n   * }\n   * ```\n   * \n   * @since 2.1.0\n   */\n  async generateWorkflow(userRequest: string): Promise<OrchestratorResponse> {\n    if (!API_KEY) {\n      return {\n        success: false,\n        error: \"Gemini API Key is not configured. Cannot generate workflow.\"\n      };\n    }\n\n    if (!userRequest?.trim()) {\n      return {\n        success: false,\n        error: \"User request cannot be empty.\"\n      };\n    }\n\n    try {\n      console.log(\"Orchestrator: Generating workflow for request:\", userRequest);\n\n      const orchestratorPrompt = buildOrchestratorPrompt(userRequest);\n      \n      console.log(\"Orchestrator: Sending request to Gemini API\");\n      const response: GenerateContentResponse = await ai.models.generateContent({\n        model: 'gemini-2.5-flash',\n        contents: [{ role: \"user\", parts: [{ text: orchestratorPrompt }] }],\n        config: {\n          responseMimeType: \"application/json\",\n          temperature: 0.3, // Lower temperature for more consistent structure\n          topK: 40,\n          topP: 0.8\n        },\n      });\n\n      const text = response.candidates?.[0]?.content?.parts?.[0]?.text || \"{}\";\n      console.log(\"Orchestrator: Received response from API, parsing...\");\n\n      let workflowData: any;\n      try {\n        workflowData = parseJsonFromText(text);\n      } catch (parseError) {\n        console.error(\"Orchestrator: Failed to parse JSON:\", parseError);\n        return {\n          success: false,\n          error: \"Failed to parse workflow structure from AI response.\",\n        };\n      }\n\n      // Validate the workflow structure\n      const validationErrors = validateWorkflow(workflowData);\n      if (validationErrors.length > 0) {\n        console.error(\"Orchestrator: Validation errors:\", validationErrors);\n        return {\n          success: false,\n          error: \"Generated workflow failed validation.\",\n          validationErrors\n        };\n      }\n\n      // Check for circular dependencies\n      if (hasCircularDependencies(workflowData.tasks)) {\n        return {\n          success: false,\n          error: \"Generated workflow contains circular dependencies.\"\n        };\n      }\n\n      // Generate a unique ID for the workflow\n      workflowData.id = `orchestrated-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n\n      console.log(`Orchestrator: Successfully generated workflow \"${workflowData.name}\" with ${workflowData.tasks.length} tasks`);\n\n      return {\n        success: true,\n        workflow: workflowData as Workflow\n      };\n\n    } catch (error: unknown) {\n      console.error(\"Orchestrator: Error during workflow generation:\", error);\n      \n      if (error instanceof Error) {\n        return {\n          success: false,\n          error: `Workflow generation failed: ${error.message}`\n        };\n      }\n      \n      return {\n        success: false,\n        error: \"An unknown error occurred during workflow generation.\"\n      };\n    }\n  }\n\n  /**\n   * Validates an existing workflow structure for completeness and correctness.\n   * Can be used to validate workflows before execution or after modifications.\n   * \n   * @param {Workflow} workflow - The workflow to validate\n   * @returns {string[]} Array of validation error messages, empty if valid\n   * \n   * @example\n   * ```typescript\n   * const orchestrator = new OrchestratorService();\n   * const errors = orchestrator.validateWorkflowStructure(myWorkflow);\n   * if (errors.length === 0) {\n   *   console.log(\"Workflow is valid\");\n   * } else {\n   *   console.error(\"Validation errors:\", errors);\n   * }\n   * ```\n   * \n   * @since 2.1.0\n   */\n  validateWorkflowStructure(workflow: Workflow): string[] {\n    const errors = validateWorkflow(workflow);\n    \n    if (errors.length === 0 && workflow.tasks && hasCircularDependencies(workflow.tasks)) {\n      errors.push(\"Workflow contains circular dependencies\");\n    }\n\n    return errors;\n  }\n\n  /**\n   * Checks if the orchestrator service is properly configured and ready to use.\n   * \n   * @returns {boolean} True if the service is ready, false otherwise\n   * \n   * @since 2.1.0\n   */\n  isConfigured(): boolean {\n    return !!API_KEY;\n  }\n}\n\n/**\n * @exports {OrchestratorService} orchestratorService\n * @description Singleton instance of the OrchestratorService class, ready to be used across the application.\n * This exported instance provides AI-powered workflow generation functionality.\n * \n * @since 2.1.0\n */\nexport default new OrchestratorService();\n",
      "metadata": {
        "filename": "orchestratorService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/promptService.ts\n\n/**\n * @file promptService.ts\n * @description This service handles all business logic and database operations related to prompts.\n * It includes functions for creating, retrieving, updating, and deleting prompts,\n * as well as mapping between the SFL prompt format used in the frontend and the database schema.\n *\n * @requires ../config/database\n * @requires ../types\n * @since 0.5.1\n */\n\nimport pool from '../config/database';\nimport { Prompt, PromptSFL } from '../types';\nimport '../types/express';\n\n/**\n * @class PromptService\n * @description A class to encapsulate all business logic for prompts.\n * Provides methods for CRUD operations on prompts and handles data transformation\n * between the SFL frontend format and the database schema.\n * \n * @since 0.5.1\n */\nclass PromptService {\n  /**\n   * Maps the detailed `PromptSFL` format to the database `Prompt` format.\n   * Transforms the rich SFL structure into a flattened database record where SFL metadata\n   * is stored as JSON in the metadata column.\n   * \n   * @param {PromptSFL | Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} sflData - The SFL prompt data.\n   * @param {string} userId - The ID of the authenticated user creating/updating the prompt.\n   * @returns {Omit<Prompt, 'id' | 'created_at' | 'updated_at'>} The prompt data formatted for the database.\n   * @private\n   * @since 0.5.1\n   */\n  private mapSFLToPrompt(sflData: PromptSFL | Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>, userId: string): Omit<Prompt, 'id' | 'created_at' | 'updated_at'> {\n    const metadata = {\n      sflField: sflData.sflField,\n      sflTenor: sflData.sflTenor,\n      sflMode: sflData.sflMode,\n      exampleOutput: sflData.exampleOutput,\n      notes: sflData.notes,\n      sourceDocument: sflData.sourceDocument,\n    };\n\n    return {\n      user_id: userId,\n      title: sflData.title || 'Untitled Prompt',\n      body: sflData.promptText || '',\n      metadata,\n    };\n  }\n\n  /**\n   * Maps a database `Prompt` record to the `PromptSFL` format.\n   * Reconstructs the full SFL structure from the flattened database record,\n   * providing default values for missing SFL components.\n   * \n   * @param {Prompt} dbPrompt - The prompt record from the database.\n   * @returns {PromptSFL} The prompt data in the SFL format.\n   * @private\n   * @since 0.5.1\n   */\n  private mapPromptToSFL(dbPrompt: Prompt): PromptSFL {\n    const metadata = dbPrompt.metadata || {};\n    \n    return {\n      id: dbPrompt.id,\n      title: dbPrompt.title,\n      promptText: dbPrompt.body,\n      createdAt: dbPrompt.created_at,\n      updatedAt: dbPrompt.updated_at,\n      sflField: metadata.sflField || { topic: '', taskType: '', domainSpecifics: '', keywords: '' },\n      sflTenor: metadata.sflTenor || { aiPersona: '', targetAudience: [], desiredTone: '', interpersonalStance: '' },\n      sflMode: metadata.sflMode || { outputFormat: '', rhetoricalStructure: '', lengthConstraint: '', textualDirectives: '' },\n      exampleOutput: metadata.exampleOutput,\n      notes: metadata.notes,\n      sourceDocument: metadata.sourceDocument,\n    };\n  }\n\n  /**\n   * Creates a new prompt in the database.\n   * Validates required fields and transforms the SFL data before insertion.\n   * \n   * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} promptData - The SFL data for the new prompt.\n   * @param {string} userId - The ID of the authenticated user creating the prompt.\n   * @returns {Promise<PromptSFL>} A promise that resolves to the newly created prompt.\n   * @throws {Error} If the title or prompt text is empty.\n   * \n   * @example\n   * ```typescript\n   * const newPromptData = {\n   *   title: \"My New Prompt\",\n   *   promptText: \"Generate a summary of the following text: {{input}}\",\n   *   sflField: { topic: \"Text Summarization\", taskType: \"Summarization\", ... },\n   *   // ... other SFL components\n   * };\n   * const createdPrompt = await promptService.createPrompt(newPromptData, userId);\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async createPrompt(promptData: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>, userId: string): Promise<PromptSFL> {\n    if (!promptData.title?.trim()) {\n      throw new Error('Title is required');\n    }\n    if (!promptData.promptText?.trim()) {\n      throw new Error('Prompt text is required');\n    }\n    if (!userId?.trim()) {\n      throw new Error('User ID is required');\n    }\n\n    const mappedData = this.mapSFLToPrompt(promptData, userId);\n    const result = await pool.query(\n      'INSERT INTO prompts (user_id, title, body, metadata) VALUES ($1, $2, $3, $4) RETURNING *',\n      [mappedData.user_id, mappedData.title, mappedData.body, mappedData.metadata]\n    );\n    \n    return this.mapPromptToSFL(result.rows[0]);\n  }\n\n  /**\n   * Retrieves all prompts from the database.\n   * Returns prompts ordered by most recently updated first.\n   * \n   * @param {any} filters - An object containing filter criteria (currently unused, reserved for future filtering functionality).\n   * @returns {Promise<PromptSFL[]>} A promise that resolves to an array of prompts in SFL format.\n   * \n   * @example\n   * ```typescript\n   * const allPrompts = await promptService.getPrompts({});\n   * console.log(`Found ${allPrompts.length} prompts`);\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async getPrompts(filters: any): Promise<PromptSFL[]> {\n    const result = await pool.query('SELECT * FROM prompts ORDER BY updated_at DESC');\n    return result.rows.map(row => this.mapPromptToSFL(row));\n  }\n\n  /**\n   * Retrieves a single prompt by its ID.\n   * \n   * @param {string} id - The UUID of the prompt to retrieve.\n   * @returns {Promise<PromptSFL | null>} A promise that resolves to the prompt in SFL format, or null if not found.\n   * \n   * @example\n   * ```typescript\n   * const prompt = await promptService.getPromptById('123e4567-e89b-12d3-a456-426614174000');\n   * if (prompt) {\n   *   console.log(`Found prompt: ${prompt.title}`);\n   * } else {\n   *   console.log('Prompt not found');\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async getPromptById(id: string): Promise<PromptSFL | null> {\n    const result = await pool.query('SELECT * FROM prompts WHERE id = $1', [id]);\n    if (!result.rows[0]) return null;\n    return this.mapPromptToSFL(result.rows[0]);\n  }\n\n  /**\n   * Updates an existing prompt in the database.\n   * Performs partial updates by merging the provided data with the existing prompt.\n   * Validates that title and promptText remain non-empty if they are being updated.\n   * \n   * @param {string} id - The UUID of the prompt to update.\n   * @param {Partial<PromptSFL>} promptData - An object containing the fields to update.\n   * @param {string} userId - The ID of the authenticated user updating the prompt.\n   * @returns {Promise<PromptSFL | null>} A promise that resolves to the updated prompt, or null if not found.\n   * @throws {Error} If the title or prompt text is being updated to an empty value.\n   * \n   * @example\n   * ```typescript\n   * const updates = {\n   *   title: \"Updated Prompt Title\",\n   *   sflField: { ...existingField, topic: \"New Topic\" }\n   * };\n   * const updatedPrompt = await promptService.updatePrompt(promptId, updates, userId);\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async updatePrompt(id: string, promptData: Partial<PromptSFL>, userId: string): Promise<PromptSFL | null> {\n    if (promptData.title !== undefined && !promptData.title?.trim()) {\n      throw new Error('Title cannot be empty');\n    }\n    if (promptData.promptText !== undefined && !promptData.promptText?.trim()) {\n      throw new Error('Prompt text cannot be empty');\n    }\n    if (!userId?.trim()) {\n      throw new Error('User ID is required');\n    }\n\n    const existing = await pool.query('SELECT * FROM prompts WHERE id = $1', [id]);\n    if (!existing.rows[0]) return null;\n\n    const existingSFL = this.mapPromptToSFL(existing.rows[0]);\n    const updatedSFL = { ...existingSFL, ...promptData };\n    const mappedData = this.mapSFLToPrompt(updatedSFL, userId);\n\n    const result = await pool.query(\n      'UPDATE prompts SET user_id = $1, title = $2, body = $3, metadata = $4, updated_at = now() WHERE id = $5 RETURNING *',\n      [mappedData.user_id, mappedData.title, mappedData.body, mappedData.metadata, id]\n    );\n    \n    return result.rows[0] ? this.mapPromptToSFL(result.rows[0]) : null;\n  }\n\n  /**\n   * Deletes a prompt from the database.\n   * \n   * @param {string} id - The UUID of the prompt to delete.\n   * @returns {Promise<boolean>} A promise that resolves to true if the deletion was successful, false if the prompt was not found.\n   * \n   * @example\n   * ```typescript\n   * const deleted = await promptService.deletePrompt('123e4567-e89b-12d3-a456-426614174000');\n   * if (deleted) {\n   *   console.log('Prompt successfully deleted');\n   * } else {\n   *   console.log('Prompt not found or could not be deleted');\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async deletePrompt(id: string): Promise<boolean> {\n    const result = await pool.query('DELETE FROM prompts WHERE id = $1', [id]);\n    return !!result.rowCount;\n  }\n}\n\n/**\n * @exports {PromptService} promptService\n * @description Singleton instance of the PromptService class, ready to be used across the application.\n * This exported instance provides all prompt-related database operations and data transformations.\n * \n * @since 0.5.1\n */\nexport default new PromptService();\n",
      "metadata": {
        "filename": "promptService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/providerValidationService.ts\n\n/**\n * @file providerValidationService.ts\n * @description Service for validating AI provider API keys and detecting available providers from environment variables\n * @since 0.6.0\n */\n\nimport config from '../config/env';\n\nexport type AIProvider = 'google' | 'openai' | 'openrouter' | 'anthropic';\n\nexport interface ProviderConfig {\n  apiKey: string;\n  defaultModel: string;\n  baseUrl?: string;\n}\n\nexport interface ProviderValidationResult {\n  success: boolean;\n  error?: string;\n}\n\nexport interface ProviderAvailability {\n  provider: AIProvider;\n  hasApiKey: boolean;\n  isConfigured: boolean;\n  validationResult?: ProviderValidationResult;\n}\n\n/**\n * Detects which AI providers are configured via environment variables\n * @returns Array of provider availability information\n */\nexport function detectAvailableProviders(): ProviderAvailability[] {\n  const providers: ProviderAvailability[] = [\n    {\n      provider: 'google',\n      hasApiKey: !!config.geminiApiKey,\n      isConfigured: !!(config.geminiApiKey && config.googleDefaultModel),\n    },\n    {\n      provider: 'openai',\n      hasApiKey: !!config.openaiApiKey,\n      isConfigured: !!(config.openaiApiKey && config.openaiDefaultModel),\n    },\n    {\n      provider: 'openrouter',\n      hasApiKey: !!config.openrouterApiKey,\n      isConfigured: !!(config.openrouterApiKey && config.openrouterDefaultModel && config.openrouterBaseUrl),\n    },\n    {\n      provider: 'anthropic',\n      hasApiKey: !!config.anthropicApiKey,\n      isConfigured: !!(config.anthropicApiKey && config.anthropicDefaultModel),\n    },\n  ];\n\n  return providers;\n}\n\n/**\n * Gets the configured provider settings\n * @param provider The AI provider\n * @returns Provider configuration or null if not configured\n */\nexport function getProviderConfig(provider: AIProvider): ProviderConfig | null {\n  switch (provider) {\n    case 'google':\n      if (!config.geminiApiKey) return null;\n      return {\n        apiKey: config.geminiApiKey,\n        defaultModel: config.googleDefaultModel,\n      };\n\n    case 'openai':\n      if (!config.openaiApiKey) return null;\n      return {\n        apiKey: config.openaiApiKey,\n        defaultModel: config.openaiDefaultModel,\n      };\n\n    case 'openrouter':\n      if (!config.openrouterApiKey) return null;\n      return {\n        apiKey: config.openrouterApiKey,\n        defaultModel: config.openrouterDefaultModel,\n        baseUrl: config.openrouterBaseUrl,\n      };\n\n    case 'anthropic':\n      if (!config.anthropicApiKey) return null;\n      return {\n        apiKey: config.anthropicApiKey,\n        defaultModel: config.anthropicDefaultModel,\n      };\n\n    default:\n      return null;\n  }\n}\n\n/**\n * Validates an API key by making a request to the provider's API\n * @param provider The AI provider\n * @param apiKey The API key to validate\n * @param baseUrl Optional base URL for OpenRouter/custom providers\n * @returns Promise resolving to validation result\n */\nexport async function validateProviderApiKey(\n  provider: AIProvider,\n  apiKey: string,\n  baseUrl?: string\n): Promise<ProviderValidationResult> {\n  if (!apiKey || apiKey.trim().length === 0) {\n    return { success: false, error: 'API key cannot be empty' };\n  }\n\n  try {\n    switch (provider) {\n      case 'google': {\n        const response = await fetch('https://generativelanguage.googleapis.com/v1beta/models', {\n          method: 'GET',\n          headers: {\n            'x-goog-api-key': apiKey,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            return { success: false, error: 'Invalid Google API key' };\n          } else if (response.status === 403) {\n            return { success: false, error: 'Google API key does not have permission to access Generative AI models' };\n          } else if (response.status === 429) {\n            return { success: false, error: 'Rate limit exceeded for Google API' };\n          } else {\n            return { success: false, error: `Google API error: ${response.status} ${response.statusText}` };\n          }\n        }\n\n        return { success: true };\n      }\n\n      case 'openai': {\n        const url = baseUrl || 'https://api.openai.com';\n        const response = await fetch(`${url}/v1/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            return { success: false, error: 'Invalid OpenAI API key' };\n          } else if (response.status === 403) {\n            return { success: false, error: 'OpenAI API key does not have permission to access models' };\n          } else if (response.status === 429) {\n            return { success: false, error: 'Rate limit exceeded for OpenAI API' };\n          } else {\n            return { success: false, error: `OpenAI API error: ${response.status} ${response.statusText}` };\n          }\n        }\n\n        return { success: true };\n      }\n\n      case 'openrouter': {\n        const url = baseUrl || config.openrouterBaseUrl;\n        const response = await fetch(`${url}/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            return { success: false, error: 'Invalid OpenRouter API key' };\n          } else if (response.status === 403) {\n            return { success: false, error: 'OpenRouter API key does not have permission to access models' };\n          } else if (response.status === 429) {\n            return { success: false, error: 'Rate limit exceeded for OpenRouter API' };\n          } else {\n            return { success: false, error: `OpenRouter API error: ${response.status} ${response.statusText}` };\n          }\n        }\n\n        return { success: true };\n      }\n\n      case 'anthropic': {\n        // Note: Anthropic doesn't have a simple models endpoint like others\n        // We'll do a minimal completion request to validate the key\n        const response = await fetch('https://api.anthropic.com/v1/messages', {\n          method: 'POST',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n            'anthropic-version': '2023-06-01',\n          },\n          body: JSON.stringify({\n            model: 'claude-3-haiku-20240307',\n            max_tokens: 1,\n            messages: [{ role: 'user', content: 'test' }],\n          }),\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            return { success: false, error: 'Invalid Anthropic API key' };\n          } else if (response.status === 403) {\n            return { success: false, error: 'Anthropic API key does not have permission to access Claude' };\n          } else if (response.status === 429) {\n            return { success: false, error: 'Rate limit exceeded for Anthropic API' };\n          } else {\n            return { success: false, error: `Anthropic API error: ${response.status} ${response.statusText}` };\n          }\n        }\n\n        return { success: true };\n      }\n\n      default:\n        return { success: false, error: `Unsupported provider: ${provider}` };\n    }\n  } catch (error) {\n    return {\n      success: false,\n      error: `Network error validating ${provider} API key: ${error instanceof Error ? error.message : String(error)}`,\n    };\n  }\n}\n\n/**\n * Validates all configured providers\n * @returns Promise resolving to array of provider availability with validation results\n */\nexport async function validateAllProviders(): Promise<ProviderAvailability[]> {\n  const providers = detectAvailableProviders();\n  \n  const validationPromises = providers.map(async (provider) => {\n    if (!provider.hasApiKey) {\n      return { ...provider, validationResult: { success: false, error: 'No API key configured' } };\n    }\n\n    const config = getProviderConfig(provider.provider);\n    if (!config) {\n      return { ...provider, validationResult: { success: false, error: 'Provider not configured' } };\n    }\n\n    const validationResult = await validateProviderApiKey(\n      provider.provider,\n      config.apiKey,\n      config.baseUrl\n    );\n\n    return { ...provider, validationResult };\n  });\n\n  return await Promise.all(validationPromises);\n}\n\n/**\n * Checks if at least one provider is valid and configured\n * @returns Promise resolving to boolean indicating if any provider is available\n */\nexport async function hasValidProvider(): Promise<boolean> {\n  const results = await validateAllProviders();\n  return results.some(result => result.validationResult?.success === true);\n}\n\n/**\n * Gets the preferred provider based on configuration and availability\n * @returns Promise resolving to the preferred provider or null if none available\n */\nexport async function getPreferredProvider(): Promise<AIProvider | null> {\n  const results = await validateAllProviders();\n  \n  // First try the default provider\n  const defaultProvider = results.find(r => r.provider === config.defaultAiProvider);\n  if (defaultProvider?.validationResult?.success) {\n    return defaultProvider.provider;\n  }\n\n  // Then try the fallback provider\n  const fallbackProvider = results.find(r => r.provider === config.fallbackAiProvider);\n  if (fallbackProvider?.validationResult?.success) {\n    return fallbackProvider.provider;\n  }\n\n  // Finally, return the first valid provider\n  const validProvider = results.find(r => r.validationResult?.success);\n  return validProvider?.provider || null;\n}\n",
      "metadata": {
        "filename": "providerValidationService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/unifiedAIService.ts\n\n/**\n * @file unifiedAIService.ts\n * @description Unified AI service that provides dynamic provider switching while maintaining\n * compatibility with existing SFL prompt generation and workflow creation functionality.\n * Acts as a bridge between the legacy GeminiService interface and the new multi-provider architecture.\n */\n\nimport { aiProviderFactory } from './ai/AIProviderFactory';\nimport { BaseAIService, AIServiceConfig } from './ai/BaseAIService';\nimport { AIProvider, AIRequest, ModelParameters } from '../types/aiProvider';\nimport { PromptSFL, Workflow } from '../types';\nimport GeminiService from './geminiService';\n\n/**\n * Request configuration for provider-aware AI operations\n */\nexport interface ProviderAwareRequest {\n  provider?: AIProvider;\n  model?: string;\n  parameters?: ModelParameters;\n  apiKey?: string;\n  baseUrl?: string;\n}\n\n/**\n * Configuration for default provider fallback\n */\ninterface DefaultProviderConfig {\n  provider: AIProvider;\n  model: string;\n  parameters: ModelParameters;\n}\n\n/**\n * Unified AI service that supports multiple providers while maintaining backward compatibility\n */\nexport class UnifiedAIService {\n  private static instance: UnifiedAIService;\n  private defaultProvider: DefaultProviderConfig;\n\n  private constructor() {\n    // Set default provider configuration (fallback to Gemini for backward compatibility)\n    this.defaultProvider = {\n      provider: 'google',\n      model: 'gemini-2.5-flash',\n      parameters: {\n        temperature: 0.7,\n        maxTokens: 4096\n      }\n    };\n  }\n\n  /**\n   * Get singleton instance\n   */\n  static getInstance(): UnifiedAIService {\n    if (!UnifiedAIService.instance) {\n      UnifiedAIService.instance = new UnifiedAIService();\n    }\n    return UnifiedAIService.instance;\n  }\n\n  /**\n   * Test a prompt with specified or default provider\n   */\n  async testPrompt(\n    promptText: string, \n    providerConfig?: ProviderAwareRequest\n  ): Promise<string> {\n    if (!providerConfig?.provider || providerConfig.provider === 'google') {\n      // Use legacy Gemini service for backward compatibility\n      return await GeminiService.testPrompt(promptText);\n    }\n\n    // Use new provider system\n    const aiService = this.createAIService(providerConfig);\n    const request: AIRequest = {\n      provider: providerConfig.provider,\n      model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n      parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n      prompt: promptText\n    };\n\n    const response = await aiService.generateCompletion(request);\n    return response.text;\n  }\n\n  /**\n   * Generate SFL prompt from goal with specified or default provider\n   */\n  async generateSFLFromGoal(\n    goal: string,\n    sourceDocContent?: string,\n    providerConfig?: ProviderAwareRequest\n  ): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> {\n    if (!providerConfig?.provider || providerConfig.provider === 'google') {\n      // Use legacy Gemini service for backward compatibility\n      return await GeminiService.generateSFLFromGoal(goal, sourceDocContent);\n    }\n\n    // For non-Gemini providers, we need to adapt the prompt structure\n    const aiService = this.createAIService(providerConfig);\n    const systemInstruction = this.getSFLSystemInstruction();\n    \n    const userContent = sourceDocContent\n      ? `Source document for style reference:\\n\\n---\\n\\n${sourceDocContent}\\n\\n----\\n\\nUser's goal: \"${goal}\"`\n      : `Here is the user's goal: \"${goal}\"`;\n\n    const request: AIRequest = {\n      provider: providerConfig.provider,\n      model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n      parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n      prompt: userContent,\n      systemMessage: systemInstruction\n    };\n\n    const response = await aiService.generateCompletion(request);\n    const jsonData = this.parseJsonFromText(response.text);\n    \n    // Ensure targetAudience is an array\n    if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n      jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n    }\n    if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n      jsonData.sflTenor.targetAudience = [];\n    }\n\n    return jsonData as Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>;\n  }\n\n  /**\n   * Regenerate SFL prompt from suggestion with specified or default provider\n   */\n  async regenerateSFLFromSuggestion(\n    currentPrompt: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>,\n    suggestion: string,\n    providerConfig?: ProviderAwareRequest\n  ): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> {\n    if (!providerConfig?.provider || providerConfig.provider === 'google') {\n      // Use legacy Gemini service for backward compatibility\n      return await GeminiService.regenerateSFLFromSuggestion(currentPrompt, suggestion);\n    }\n\n    // For non-Gemini providers, we need to adapt the prompt structure\n    const aiService = this.createAIService(providerConfig);\n    const systemInstruction = this.getSFLRegenerationSystemInstruction();\n    \n    const { sourceDocument, ...promptForPayload } = currentPrompt;\n    const userContent = `\n    Here is the current prompt JSON:\n    ${JSON.stringify(promptForPayload)}\n    \n    ${sourceDocument ? `This prompt is associated with the following source document for stylistic reference:\\n---\\n${sourceDocument.content}\\n---\\n` : ''}\n\n    Here is my suggestion for how to change it:\n    \"${suggestion}\"\n\n    Now, provide the complete, revised JSON object.\n    `;\n\n    const request: AIRequest = {\n      provider: providerConfig.provider,\n      model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n      parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n      prompt: userContent,\n      systemMessage: systemInstruction\n    };\n\n    const response = await aiService.generateCompletion(request);\n    const jsonData = this.parseJsonFromText(response.text);\n    \n    // Ensure targetAudience is an array\n    if (jsonData.sflTenor && typeof jsonData.sflTenor.targetAudience === 'string') {\n      jsonData.sflTenor.targetAudience = [jsonData.sflTenor.targetAudience];\n    }\n    if (jsonData.sflTenor && !jsonData.sflTenor.targetAudience) {\n      jsonData.sflTenor.targetAudience = [];\n    }\n    \n    // Preserve the source document from the original prompt\n    jsonData.sourceDocument = sourceDocument;\n\n    return jsonData as Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>;\n  }\n\n  /**\n   * Generate workflow from goal with specified or default provider\n   */\n  async generateWorkflowFromGoal(\n    goal: string,\n    providerConfig?: ProviderAwareRequest\n  ): Promise<Workflow> {\n    if (!providerConfig?.provider || providerConfig.provider === 'google') {\n      // Use legacy Gemini service for backward compatibility\n      return await GeminiService.generateWorkflowFromGoal(goal);\n    }\n\n    // For non-Gemini providers, we need to adapt the prompt structure\n    const aiService = this.createAIService(providerConfig);\n    const systemInstruction = this.getWorkflowSystemInstruction();\n\n    const request: AIRequest = {\n      provider: providerConfig.provider,\n      model: providerConfig.model || this.getDefaultModelForProvider(providerConfig.provider),\n      parameters: providerConfig.parameters || this.getDefaultParametersForProvider(providerConfig.provider),\n      prompt: `User's goal: \"${goal}\"`,\n      systemMessage: systemInstruction\n    };\n\n    const response = await aiService.generateCompletion(request);\n    const jsonData = this.parseJsonFromText(response.text);\n    \n    if (!jsonData.name || !jsonData.description || !Array.isArray(jsonData.tasks)) {\n      throw new Error(\"Generated workflow is missing required fields (name, description, tasks).\");\n    }\n    \n    jsonData.id = `wf-custom-${Date.now()}-${Math.random().toString(36).substring(2, 10)}`;\n\n    return jsonData as Workflow;\n  }\n\n  /**\n   * Create AI service instance for the specified provider\n   */\n  private createAIService(config: ProviderAwareRequest): BaseAIService {\n    if (!config.provider) {\n      throw new Error('Provider is required');\n    }\n\n    if (!config.apiKey) {\n      // Try to get API key from environment variables\n      config.apiKey = this.getApiKeyFromEnv(config.provider);\n    }\n\n    const serviceConfig: AIServiceConfig = {\n      apiKey: config.apiKey,\n      baseUrl: config.baseUrl,\n      timeout: 30000\n    };\n\n    return aiProviderFactory.createService(config.provider, serviceConfig);\n  }\n\n  /**\n   * Get API key from environment variables\n   */\n  private getApiKeyFromEnv(provider: AIProvider): string {\n    switch (provider) {\n      case 'openai':\n        return process.env.OPENAI_API_KEY || '';\n      case 'anthropic':\n        return process.env.ANTHROPIC_API_KEY || '';\n      case 'google':\n        return process.env.GEMINI_API_KEY || '';\n      case 'openrouter':\n        return process.env.OPENROUTER_API_KEY || '';\n      default:\n        throw new Error(`No API key found for provider: ${provider}`);\n    }\n  }\n\n  /**\n   * Get default model for provider\n   */\n  private getDefaultModelForProvider(provider: AIProvider): string {\n    switch (provider) {\n      case 'openai':\n        return 'gpt-4';\n      case 'anthropic':\n        return 'claude-3-5-sonnet-20241022';\n      case 'google':\n        return 'gemini-2.5-flash';\n      case 'openrouter':\n        return 'openai/gpt-4';\n      default:\n        throw new Error(`No default model configured for provider: ${provider}`);\n    }\n  }\n\n  /**\n   * Get default parameters for provider\n   */\n  private getDefaultParametersForProvider(provider: AIProvider): ModelParameters {\n    const baseParams = {\n      temperature: 0.7,\n      maxTokens: 4096\n    };\n\n    switch (provider) {\n      case 'openai':\n        return {\n          ...baseParams,\n          top_p: 1.0,\n          presence_penalty: 0,\n          frequency_penalty: 0\n        };\n      case 'anthropic':\n        return {\n          ...baseParams,\n          top_p: 1.0,\n          top_k: 0\n        };\n      case 'google':\n        return {\n          ...baseParams,\n          topP: 1.0,\n          topK: 40\n        };\n      case 'openrouter':\n        return {\n          ...baseParams,\n          top_p: 1.0,\n          presence_penalty: 0,\n          frequency_penalty: 0\n        };\n      default:\n        return baseParams;\n    }\n  }\n\n  /**\n   * Get system instruction for SFL generation\n   */\n  private getSFLSystemInstruction(): string {\n    return `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to analyze a user's goal and structure it into a detailed SFL-based prompt.\n    If a source document is provided for stylistic reference, you MUST analyze its style (e.g., tone, complexity, vocabulary, sentence structure) and incorporate those stylistic qualities into the SFL fields and the final promptText. For example, update the 'desiredTone', 'aiPersona', and 'textualDirectives' to match the source. The generated 'promptText' should be a complete, standalone prompt that implicitly carries the desired style.\n    The output MUST be a single, valid JSON object. Do not include any text, notes, or explanations outside of the JSON object.\n    The JSON object should have the following structure: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string }.\n    \n    - title: Create a concise, descriptive title based on the user's goal.\n    - promptText: Synthesize all the SFL elements into a complete, well-formed prompt that can be sent directly to an AI.\n    - sflField (What is happening?): Analyze the subject matter.\n    - sflTenor (Who is taking part?): Define the roles and relationships. The \"targetAudience\" field must be an array of strings, even if only one audience is identified.\n    - sflMode (How is it being communicated?): Specify the format and structure of the output.\n    - exampleOutput: Provide a brief but illustrative example of the expected output.\n    - notes: Add any relevant notes or suggestions for the user.\n    - All fields in the JSON must be filled with meaningful content.`;\n  }\n\n  /**\n   * Get system instruction for SFL regeneration\n   */\n  private getSFLRegenerationSystemInstruction(): string {\n    return `You are an expert in Systemic Functional Linguistics (SFL) and AI prompt engineering. Your task is to revise an existing SFL prompt based on a user's suggestion.\n    The user will provide a JSON object representing the current prompt and a text string with their requested change.\n    If a source document is provided (as part of the prompt object or separately), its style should be analyzed and take precedence, influencing the revision.\n    You MUST return a single, valid JSON object that represents the *revised* prompt. Do not include any text, notes, or explanations outside of the JSON object.\n    The output JSON object must have the exact same structure as the input, containing all the original fields, but with values updated according to the suggestion and stylistic source.\n    The structure is: { \"title\": string, \"promptText\": string, \"sflField\": { \"topic\": string, \"taskType\": string, \"domainSpecifics\": string, \"keywords\": string }, \"sflTenor\": { \"aiPersona\": string, \"targetAudience\": string[], \"desiredTone\": string, \"interpersonalStance\": string }, \"sflMode\": { \"outputFormat\": string, \"rhetoricalStructure\": string, \"lengthConstraint\": string, \"textualDirectives\": string }, \"exampleOutput\": string, \"notes\": string, \"sourceDocument\": { \"name\": string, \"content\": string } | undefined }.\n    \n    - Critically analyze the user's suggestion and apply it to all relevant fields in the prompt.\n    - If a 'sourceDocument' is present, ensure its style is reflected in the revised SFL fields and 'promptText'.\n    - The 'promptText' field is the most important; it must be re-written to reflect the change.\n    - Other SFL fields (Field, Tenor, Mode) should be updated logically to align with the new 'promptText' and the user's suggestion.\n    - Even update the 'title', 'exampleOutput', and 'notes' if the suggestion implies it.\n    - Ensure 'targetAudience' remains an array of strings.\n    - Preserve the 'sourceDocument' field in the output if it existed in the input.`;\n  }\n\n  /**\n   * Get system instruction for workflow generation\n   */\n  private getWorkflowSystemInstruction(): string {\n    return `You are an expert AI workflow orchestrator. Your task is to analyze a user's goal and generate a complete, multi-task workflow as a valid JSON object.\n    \nThe user goal will be provided. Based on this, create a workflow with a series of tasks. The output MUST be a single, valid JSON object representing the workflow. Do not include any text or explanations outside the JSON.\n\nThe root JSON object must have 'name', 'description', and 'tasks' fields. Each task in the 'tasks' array must have the following fields:\n- id: A unique string identifier for the task (e.g., \"task-1\").\n- name: A short, descriptive name for the task.\n- description: A one-sentence explanation of what the task does.\n- type: One of \"DATA_INPUT\", \"GEMINI_PROMPT\", \"IMAGE_ANALYSIS\", \"TEXT_MANIPULATION\", \"DISPLAY_CHART\", \"GEMINI_GROUNDED\".\n- dependencies: An array of task IDs that this task depends on. Empty for initial tasks.\n- inputKeys: An array of strings representing keys from the Data Store needed for this task. Use dot notation for nested keys (e.g., \"userInput.text\").\n- outputKey: A string for the key where the task's result will be stored in the Data Store.\n\nRules for specific task types:\n- GEMINI_PROMPT/IMAGE_ANALYSIS: Must include a 'promptTemplate' field. Use {{key}} for placeholders.\n- TEXT_MANIPULATION: Must include a 'functionBody' field containing a JavaScript function body as a string. E.g., \"return \\`Report: \\${inputs.summary}\\`\".\n- DATA_INPUT: Must include a 'staticValue' field. Use \"{{userInput.text}}\", \"{{userInput.image}}\", or \"{{userInput.file}}\" to get data from the user input area.\n- DISPLAY_CHART: Must include a 'dataKey' field pointing to data in the Data Store suitable for charting.\n- GEMINI_GROUNDED: For tasks requiring up-to-date information. Should have a 'promptTemplate'.`;\n  }\n\n  /**\n   * Parse JSON content from AI-generated text (adapted from geminiService)\n   */\n  private parseJsonFromText(text: string): any {\n    console.log(\"Attempting to parse JSON from text:\", text.substring(0, 200) + \"...\");\n    \n    // Try multiple extraction strategies\n    const strategies = [\n      // Strategy 1: Extract code block content\n      () => {\n        const fenceRegex = /```(?:json)?\\s*\\n?([\\s\\S]*?)\\n?\\s*```/;\n        const match = text.match(fenceRegex);\n        return match && match[1] ? match[1].trim() : null;\n      },\n      \n      // Strategy 2: Extract content between first { and last }\n      () => {\n        const firstBrace = text.indexOf('{');\n        const lastBrace = text.lastIndexOf('}');\n        if (firstBrace !== -1 && lastBrace > firstBrace) {\n          return text.substring(firstBrace, lastBrace + 1);\n        }\n        return null;\n      },\n      \n      // Strategy 3: Try the text as-is if it starts with {\n      () => {\n        const trimmed = text.trim();\n        return trimmed.startsWith('{') ? trimmed : null;\n      },\n      \n      // Strategy 4: Remove common prefixes and try again\n      () => {\n        const cleaned = text.replace(/^(bash\\s*|```\\s*|json\\s*|```json\\s*)/i, '').trim();\n        const firstBrace = cleaned.indexOf('{');\n        const lastBrace = cleaned.lastIndexOf('}');\n        if (firstBrace !== -1 && lastBrace > firstBrace) {\n          return cleaned.substring(firstBrace, lastBrace + 1);\n        }\n        return null;\n      }\n    ];\n\n    // Try each strategy\n    for (let i = 0; i < strategies.length; i++) {\n      const jsonStr = strategies[i]();\n      if (jsonStr) {\n        try {\n          console.log(`Strategy ${i + 1} extracted JSON:`, jsonStr.substring(0, 100) + \"...\");\n          const parsed = JSON.parse(jsonStr);\n          console.log(\"Successfully parsed JSON with strategy\", i + 1);\n          return parsed;\n        } catch (e) {\n          console.log(`Strategy ${i + 1} failed to parse:`, e);\n          continue;\n        }\n      }\n    }\n\n    // If all strategies fail, log detailed error info\n    console.error(\"All JSON parsing strategies failed\");\n    console.error(\"Raw text length:\", text.length);\n    console.error(\"Raw text preview:\", text.substring(0, 500));\n    console.error(\"Text ends with:\", text.substring(Math.max(0, text.length - 100)));\n    \n    throw new Error(\"The AI returned a response that could not be parsed as JSON using any available strategy.\");\n  }\n}\n\n// Export singleton instance\nexport default UnifiedAIService.getInstance();\n",
      "metadata": {
        "filename": "unifiedAIService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/webSocketService.ts\n\n/**\n * @file webSocketService.ts\n * @description WebSocket service for real-time communication with clients.\n * Manages WebSocket connections and broadcasts workflow execution updates.\n */\n\nimport { WebSocketServer, WebSocket } from 'ws';\nimport { Server } from 'http';\nimport logger from '../config/logger';\n\n/**\n * @interface WebSocketMessage\n * @description Structure of messages sent over WebSocket\n */\nexport interface WebSocketMessage {\n  type: 'workflow_progress' | 'task_status' | 'workflow_complete' | 'workflow_failed' | 'workflow_stopped';\n  jobId: string;\n  workflowId?: string;\n  taskId?: string;\n  taskName?: string;\n  status?: string;\n  result?: any;\n  error?: string;\n  reason?: string;\n  progress?: number;\n  timestamp?: string;\n}\n\n/**\n * @interface ClientConnection\n * @description Represents a connected WebSocket client\n */\ninterface ClientConnection {\n  ws: WebSocket;\n  subscriptions: Set<string>; // Set of jobIds this client is subscribed to\n  id: string;\n}\n\n/**\n * Service class for managing WebSocket connections and real-time updates\n */\nclass WebSocketService {\n  private wss: WebSocketServer | null = null;\n  private clients: Map<string, ClientConnection> = new Map();\n\n  /**\n   * Initializes the WebSocket server\n   * @param server - HTTP server to attach WebSocket server to\n   */\n  initialize(server: Server): void {\n    this.wss = new WebSocketServer({ \n      server,\n      path: '/ws',\n    });\n\n    this.wss.on('connection', this.handleConnection.bind(this));\n    logger.info('WebSocket server initialized');\n  }\n\n  /**\n   * Handles new WebSocket connections\n   * @param ws - The WebSocket connection\n   */\n  private handleConnection(ws: WebSocket): void {\n    const clientId = this.generateClientId();\n    const client: ClientConnection = {\n      ws,\n      subscriptions: new Set(),\n      id: clientId,\n    };\n\n    this.clients.set(clientId, client);\n    logger.info(`New WebSocket client connected: ${clientId}`);\n\n    // Send welcome message\n    this.sendToClient(clientId, {\n      type: 'workflow_progress',\n      jobId: 'system',\n      status: 'connected',\n      timestamp: new Date().toISOString(),\n    });\n\n    // Handle incoming messages\n    ws.on('message', (data: Buffer) => {\n      try {\n        const message = JSON.parse(data.toString());\n        this.handleClientMessage(clientId, message);\n      } catch (error) {\n        logger.error(`Failed to parse WebSocket message from ${clientId}:`, error);\n      }\n    });\n\n    // Handle connection close\n    ws.on('close', () => {\n      this.clients.delete(clientId);\n      logger.info(`WebSocket client disconnected: ${clientId}`);\n    });\n\n    // Handle errors\n    ws.on('error', (error: Error) => {\n      logger.error(`WebSocket error for client ${clientId}:`, error);\n      this.clients.delete(clientId);\n    });\n  }\n\n  /**\n   * Handles messages from clients\n   * @param clientId - The client ID\n   * @param message - The message from the client\n   */\n  private handleClientMessage(clientId: string, message: any): void {\n    const client = this.clients.get(clientId);\n    if (!client) return;\n\n    switch (message.type) {\n      case 'subscribe':\n        if (message.jobId) {\n          client.subscriptions.add(message.jobId);\n          logger.info(`Client ${clientId} subscribed to job ${message.jobId}`);\n        }\n        break;\n      case 'unsubscribe':\n        if (message.jobId) {\n          client.subscriptions.delete(message.jobId);\n          logger.info(`Client ${clientId} unsubscribed from job ${message.jobId}`);\n        }\n        break;\n      default:\n        logger.warn(`Unknown message type from client ${clientId}:`, message.type);\n    }\n  }\n\n  /**\n   * Sends a message to a specific client\n   * @param clientId - The client ID\n   * @param message - The message to send\n   */\n  private sendToClient(clientId: string, message: WebSocketMessage): void {\n    const client = this.clients.get(clientId);\n    if (!client || client.ws.readyState !== WebSocket.OPEN) {\n      return;\n    }\n\n    try {\n      client.ws.send(JSON.stringify(message));\n    } catch (error) {\n      logger.error(`Failed to send message to client ${clientId}:`, error);\n      this.clients.delete(clientId);\n    }\n  }\n\n  /**\n   * Broadcasts a message to all clients subscribed to a specific job\n   * @param jobId - The job ID\n   * @param message - The message to broadcast\n   */\n  broadcastToJob(jobId: string, message: Omit<WebSocketMessage, 'jobId'>): void {\n    const fullMessage: WebSocketMessage = {\n      ...message,\n      jobId,\n      timestamp: new Date().toISOString(),\n    };\n\n    let sentCount = 0;\n    for (const [clientId, client] of this.clients) {\n      if (client.subscriptions.has(jobId)) {\n        this.sendToClient(clientId, fullMessage);\n        sentCount++;\n      }\n    }\n\n    logger.debug(`Broadcasted message to ${sentCount} clients for job ${jobId}`);\n  }\n\n  /**\n   * Broadcasts a message to all connected clients\n   * @param message - The message to broadcast\n   */\n  broadcastToAll(message: WebSocketMessage): void {\n    const fullMessage: WebSocketMessage = {\n      ...message,\n      timestamp: new Date().toISOString(),\n    };\n\n    let sentCount = 0;\n    for (const [clientId] of this.clients) {\n      this.sendToClient(clientId, fullMessage);\n      sentCount++;\n    }\n\n    logger.debug(`Broadcasted message to ${sentCount} clients`);\n  }\n\n  /**\n   * Gets the number of connected clients\n   * @returns The number of connected clients\n   */\n  getClientCount(): number {\n    return this.clients.size;\n  }\n\n  /**\n   * Gets the number of clients subscribed to a specific job\n   * @param jobId - The job ID\n   * @returns The number of subscribed clients\n   */\n  getSubscribedClientCount(jobId: string): number {\n    let count = 0;\n    for (const client of this.clients.values()) {\n      if (client.subscriptions.has(jobId)) {\n        count++;\n      }\n    }\n    return count;\n  }\n\n  /**\n   * Generates a unique client ID\n   * @returns A unique client ID\n   */\n  private generateClientId(): string {\n    return `client_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n  }\n\n  /**\n   * Shuts down the WebSocket service\n   */\n  shutdown(): void {\n    if (this.wss) {\n      this.wss.close(() => {\n        logger.info('WebSocket server closed');\n      });\n    }\n\n    for (const [clientId, client] of this.clients) {\n      client.ws.close();\n    }\n    this.clients.clear();\n  }\n}\n\nexport default new WebSocketService();\n",
      "metadata": {
        "filename": "webSocketService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/workflowExecutionService.ts\n\nimport { GoogleGenAI, GenerateContentResponse, Part } from \"@google/genai\";\nimport { Task, DataStore, AgentConfig, PromptSFL, Workflow } from '../types';\n\nconst API_KEY = process.env.GEMINI_API_KEY;\n\nif (!API_KEY) {\n  console.error(\"Gemini API Key is missing. Please set the GEMINI_API_KEY environment variable.\");\n}\n\nconst ai = new GoogleGenAI({ apiKey: API_KEY || \"MISSING_API_KEY\" });\n\nconst getNested = (obj: Record<string, any>, path: string): any => {\n    return path.split('.').reduce((acc, part) => acc && acc[part], obj);\n};\n\nconst templateString = (template: string, dataStore: DataStore): any => {\n    const singleVarMatch = template.trim().match(/^\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}$/);\n    if (singleVarMatch) {\n        const key = singleVarMatch[1];\n        const value = getNested(dataStore, key);\n        return value !== undefined ? value : template;\n    }\n\n    return template.replace(/\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}/g, (match, key) => {\n        const value = getNested(dataStore, key);\n        if (value === undefined || value === null) {\n            console.warn(`Template key \"${key}\" not found in data store.`);\n            return match;\n        }\n        if (typeof value === 'object') {\n            return JSON.stringify(value, null, 2);\n        }\n        return String(value);\n    });\n};\n\nconst executeGeminiPrompt = async (prompt: string, agentConfig?: AgentConfig): Promise<string> => {\n    const model = agentConfig?.model || 'gemini-2.5-flash';\n    const response = await ai.models.generateContent({\n        model: model,\n        contents: [{ role: \"user\", parts: [{ text: prompt }] }],\n        config: {\n            temperature: agentConfig?.temperature,\n            topK: agentConfig?.topK,\n            topP: agentConfig?.topP,\n            systemInstruction: agentConfig?.systemInstruction ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n        },\n    });\n    return response.candidates?.[0]?.content?.parts?.[0]?.text || \"\";\n};\n\nconst executeImageAnalysis = async (prompt: string, imagePart: Part, agentConfig?: AgentConfig): Promise<string> => {\n    const model = agentConfig?.model || 'gemini-2.5-flash';\n    const textPart = { text: prompt };\n\n    const response: GenerateContentResponse = await ai.models.generateContent({\n        model,\n        contents: [{ role: \"user\", parts: [textPart, imagePart] }],\n        config: {\n            temperature: agentConfig?.temperature,\n            systemInstruction: agentConfig?.systemInstruction ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n        },\n    });\n\n    return response.candidates?.[0]?.content?.parts?.[0]?.text || \"\";\n};\n\nconst executeGroundedGeneration = async (prompt: string, agentConfig?: AgentConfig): Promise<{ text: string, sources: any[] }> => {\n    const model = agentConfig?.model || 'gemini-2.5-flash';\n    const response = await ai.models.generateContent({\n        model,\n        contents: [{ role: \"user\", parts: [{ text: prompt }] }],\n        config: {\n            tools: [{ googleSearch: {} }],\n            systemInstruction: agentConfig?.systemInstruction ? { role: \"system\", parts: [{ text: agentConfig.systemInstruction }] } : undefined,\n            temperature: agentConfig?.temperature,\n        }\n    });\n\n    const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];\n    const sources = groundingChunks\n        .map((chunk: any) => chunk.web)\n        .filter((web: any) => web && web.uri);\n\n    return {\n        text: response.candidates?.[0]?.content?.parts?.[0]?.text || \"\",\n        sources: sources,\n    };\n};\n\nconst executeTextManipulation = (funcBody: string, inputs: Record<string, any>): any => {\n    try {\n        const func = new Function('inputs', funcBody);\n        return func(inputs);\n    } catch (e: any) {\n        throw new Error(`Error in custom function: ${e.message}`);\n    }\n};\n\n/**\n * Performs topological sort on workflow tasks using Kahn's algorithm\n * @param tasks Array of tasks to sort\n * @returns Object containing sorted tasks and any error feedback\n */\nconst topologicalSort = (tasks: Task[]): { sortedTasks: Task[], feedback: string[] } => {\n    const feedback: string[] = [];\n    \n    // Create adjacency list and in-degree count\n    const adjList = new Map<string, string[]>();\n    const inDegree = new Map<string, number>();\n    const taskMap = new Map<string, Task>();\n    \n    // Initialize all tasks\n    for (const task of tasks) {\n        taskMap.set(task.id, task);\n        adjList.set(task.id, []);\n        inDegree.set(task.id, 0);\n    }\n    \n    // Build dependency graph\n    for (const task of tasks) {\n        for (const depId of task.dependencies) {\n            if (!taskMap.has(depId)) {\n                feedback.push(`Task \"${task.name}\" depends on non-existent task ID: ${depId}`);\n                continue;\n            }\n            \n            // Add edge from dependency to current task\n            adjList.get(depId)!.push(task.id);\n            inDegree.set(task.id, inDegree.get(task.id)! + 1);\n        }\n    }\n    \n    // Kahn's algorithm\n    const queue: string[] = [];\n    const result: Task[] = [];\n    \n    // Find all nodes with no incoming edges\n    for (const [taskId, degree] of inDegree) {\n        if (degree === 0) {\n            queue.push(taskId);\n        }\n    }\n    \n    while (queue.length > 0) {\n        const currentId = queue.shift()!;\n        const currentTask = taskMap.get(currentId)!;\n        result.push(currentTask);\n        \n        // Remove this node from the graph\n        for (const neighborId of adjList.get(currentId)!) {\n            inDegree.set(neighborId, inDegree.get(neighborId)! - 1);\n            if (inDegree.get(neighborId) === 0) {\n                queue.push(neighborId);\n            }\n        }\n    }\n    \n    // Check for cycles\n    if (result.length !== tasks.length) {\n        feedback.push('Cycle detected in task dependencies - workflow cannot be executed');\n        return { sortedTasks: [], feedback };\n    }\n    \n    return { sortedTasks: result, feedback };\n};\n\n/**\n * Resolves input dependencies and interpolates prompt templates\n * @param task The task to process\n * @param dataStore The current data store\n * @returns The interpolated prompt template and resolved inputs\n */\nconst resolveTaskInputs = (task: Task, dataStore: DataStore): { resolvedInputs: Record<string, any>, interpolatedPrompt?: string } => {\n    const resolvedInputs: Record<string, any> = {};\n    \n    // Resolve inputs from data store using inputKeys\n    for (const key of task.inputKeys) {\n        const value = getNested(dataStore, key);\n        if (value === undefined) {\n            throw new Error(`Missing required input key \"${key}\" in data store for task \"${task.name}\"`);\n        }\n        \n        // Use simple key for the resolved inputs (remove dot notation)\n        const simpleKey = key.split('.').pop() || key;\n        resolvedInputs[simpleKey] = value;\n    }\n    \n    // If task has input mappings, resolve those as well\n    if (task.inputs) {\n        for (const [inputName, mapping] of Object.entries(task.inputs)) {\n            const { nodeId, outputName } = mapping;\n            \n            // Look for the output in the data store\n            const outputValue = dataStore[nodeId];\n            if (outputValue === undefined) {\n                throw new Error(`Task \"${task.name}\" depends on output from task \"${nodeId}\" which has not been executed`);\n            }\n            \n            // If outputName is specified, get that specific property\n            let resolvedValue = outputValue;\n            if (outputName && outputName !== nodeId) {\n                if (typeof outputValue === 'object' && outputValue !== null) {\n                    resolvedValue = outputValue[outputName];\n                    if (resolvedValue === undefined) {\n                        throw new Error(`Task \"${task.name}\" expects output \"${outputName}\" from task \"${nodeId}\" but it was not found`);\n                    }\n                }\n            }\n            \n            resolvedInputs[inputName] = resolvedValue;\n        }\n    }\n    \n    // Interpolate prompt template if present\n    let interpolatedPrompt: string | undefined;\n    if (task.promptTemplate) {\n        interpolatedPrompt = templateString(task.promptTemplate, { ...dataStore, ...resolvedInputs });\n    }\n    \n    return { resolvedInputs, interpolatedPrompt };\n};\n\nclass WorkflowExecutionService {\n    async executeTask(task: Task, dataStore: DataStore, prompt?: PromptSFL): Promise<any> {\n        // Resolve task inputs and interpolate templates\n        const { resolvedInputs, interpolatedPrompt } = resolveTaskInputs(task, dataStore);\n\n\n        switch (task.type) {\n            case 'DATA_INPUT':\n                if (task.staticValue && typeof task.staticValue === 'string') {\n                    return templateString(task.staticValue, dataStore);\n                }\n                return task.staticValue;\n\n            case 'GEMINI_PROMPT': {\n                if (task.promptId) {\n                    if (!prompt) {\n                        throw new Error(`Task \"${task.name}\" requires prompt ID \"${task.promptId}\" but no prompt was provided.`);\n                    }\n                    const linkedPrompt = prompt;\n                    \n                    const { sflTenor, sflMode } = linkedPrompt;\n                    \n                    const instructionParts = [];\n                    if (sflTenor.aiPersona) instructionParts.push(`You will act as a ${sflTenor.aiPersona}.`);\n                    if (sflTenor.desiredTone) instructionParts.push(`Your tone should be ${sflTenor.desiredTone}.`);\n                    if (sflTenor.targetAudience?.length) instructionParts.push(`You are writing for ${sflTenor.targetAudience.join(', ')}.`);\n                    if (sflMode.textualDirectives) instructionParts.push(`Follow these directives: ${sflMode.textualDirectives}.`);\n                    \n                    const systemInstruction = instructionParts.join(' ');\n                    \n                    // Use enhanced interpolation with resolved inputs\n                    const finalPromptText = templateString(linkedPrompt.promptText, { ...dataStore, ...resolvedInputs });\n                    const finalAgentConfig = { ...task.agentConfig, systemInstruction };\n                    \n                    return executeGeminiPrompt(finalPromptText, finalAgentConfig);\n\n                } else {\n                    if (!interpolatedPrompt) throw new Error(\"Prompt template is missing for non-linked prompt task.\");\n                    return executeGeminiPrompt(interpolatedPrompt, task.agentConfig);\n                }\n            }\n            \n            case 'GEMINI_GROUNDED':\n                if (!interpolatedPrompt) throw new Error(\"Prompt template is missing.\");\n                return executeGroundedGeneration(interpolatedPrompt, task.agentConfig);\n\n            case 'IMAGE_ANALYSIS': {\n                if (!interpolatedPrompt) throw new Error(\"Prompt template is missing.\");\n\n                const imageInputKey = task.inputKeys[0];\n                if (!imageInputKey) {\n                    throw new Error(\"IMAGE_ANALYSIS task must have at least one input key pointing to the image data.\");\n                }\n                \n                const imageData = resolvedInputs[imageInputKey.split('.').pop() || imageInputKey];\n                if (!imageData || typeof imageData.base64 !== 'string' || typeof imageData.type !== 'string') {\n                    throw new Error(`Image data from key \"${imageInputKey}\" is missing, malformed, or not found in inputs.`);\n                }\n\n                const imagePart: Part = {\n                    inlineData: {\n                        data: imageData.base64,\n                        mimeType: imageData.type,\n                    },\n                };\n\n                return executeImageAnalysis(interpolatedPrompt, imagePart, task.agentConfig);\n            }\n\n            case 'TEXT_MANIPULATION':\n                if (!task.functionBody) throw new Error(\"Function body is missing.\");\n                return executeTextManipulation(task.functionBody, resolvedInputs);\n\n            default:\n                throw new Error(`Unsupported task type: ${task.type}`);\n        }\n    }\n\n    /**\n     * Executes a complete workflow with proper dependency resolution\n     * @param workflow The workflow to execute\n     * @param userInput Initial user input\n     * @param prompts Array of available prompts\n     * @returns Execution results with data store and task results\n     */\n    async executeWorkflow(\n        workflow: Workflow, \n        userInput: Record<string, any> = {}, \n        prompts: PromptSFL[] = []\n    ): Promise<{ dataStore: DataStore, results: Record<string, any>, feedback: string[] }> {\n        // Perform topological sort to determine execution order\n        const { sortedTasks, feedback } = topologicalSort(workflow.tasks || []);\n        \n        if (sortedTasks.length === 0) {\n            throw new Error('Cannot execute workflow: ' + feedback.join(', '));\n        }\n\n        // Initialize data store with user input\n        const dataStore: DataStore = { userInput };\n        const results: Record<string, any> = {};\n\n        // Execute tasks in topologically sorted order\n        for (const task of sortedTasks) {\n            try {\n                // Find linked prompt if task has one\n                const linkedPrompt = task.promptId \n                    ? prompts.find(p => p.id === task.promptId)\n                    : undefined;\n\n                // Execute the task\n                const result = await this.executeTask(task, dataStore, linkedPrompt);\n                \n                // Store result in data store for subsequent tasks\n                dataStore[task.outputKey] = result;\n                results[task.id] = result;\n\n            } catch (error) {\n                const errorMessage = error instanceof Error ? error.message : 'Unknown error';\n                throw new Error(`Task \"${task.name}\" failed: ${errorMessage}`);\n            }\n        }\n\n        return { dataStore, results, feedback };\n    }\n}\n\nexport default new WorkflowExecutionService();\n",
      "metadata": {
        "filename": "workflowExecutionService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/services/workflowService.ts\n\n/**\n * @file workflowService.ts\n * @description This service handles all business logic and database operations related to workflows.\n * It provides methods for creating, retrieving, updating, and deleting workflows.\n * Workflows contain task definitions and their execution logic stored as JSON in the graph_data column.\n *\n * @requires ../config/database\n * @requires ../types\n * @since 0.5.1\n */\n\nimport pool from '../config/database';\nimport { Workflow } from '../types';\n\n/**\n * @class WorkflowService\n * @description A class to encapsulate all business logic for workflows.\n * Provides CRUD operations for workflows and handles the complex graph_data structure\n * that defines the workflow's tasks and their relationships.\n * \n * @since 0.5.1\n */\nclass WorkflowService {\n  /**\n   * Creates a new workflow in the database.\n   * Stores the workflow definition including its task graph structure.\n   * \n   * @param {Omit<Workflow, 'id' | 'created_at' | 'updated_at'>} workflowData - The data for the new workflow.\n   * @returns {Promise<Workflow>} A promise that resolves to the newly created workflow.\n   * @throws {Error} If required fields are missing or database operation fails.\n   * \n   * @example\n   * ```typescript\n   * const newWorkflow = {\n   *   user_id: '123e4567-e89b-12d3-a456-426614174000',\n   *   name: 'Document Analysis Workflow',\n   *   graph_data: {\n   *     tasks: [...],\n   *     connections: [...]\n   *   }\n   * };\n   * const created = await workflowService.createWorkflow(newWorkflow);\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async createWorkflow(workflowData: Omit<Workflow, 'id' | 'created_at' | 'updated_at'>): Promise<Workflow> {\n    const { user_id, name, graph_data } = workflowData;\n    const result = await pool.query(\n      'INSERT INTO workflows (user_id, name, graph_data) VALUES ($1, $2, $3) RETURNING *',\n      [user_id, name, graph_data]\n    );\n    return result.rows[0];\n  }\n\n  /**\n   * Retrieves all workflows from the database.\n   * Returns workflows ordered by most recently updated first.\n   * \n   * @returns {Promise<Workflow[]>} A promise that resolves to an array of workflows.\n   * \n   * @example\n   * ```typescript\n   * const allWorkflows = await workflowService.getWorkflows();\n   * console.log(`Found ${allWorkflows.length} workflows`);\n   * allWorkflows.forEach(wf => console.log(`- ${wf.name}`));\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async getWorkflows(): Promise<Workflow[]> {\n    const result = await pool.query('SELECT * FROM workflows ORDER BY updated_at DESC');\n    return result.rows;\n  }\n\n  /**\n   * Retrieves a single workflow by its ID.\n   * \n   * @param {string} id - The UUID of the workflow to retrieve.\n   * @returns {Promise<Workflow | null>} A promise that resolves to the workflow, or null if not found.\n   * \n   * @example\n   * ```typescript\n   * const workflow = await workflowService.getWorkflowById('123e4567-e89b-12d3-a456-426614174000');\n   * if (workflow) {\n   *   console.log(`Found workflow: ${workflow.name}`);\n   *   console.log(`Tasks: ${workflow.graph_data.tasks?.length || 0}`);\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async getWorkflowById(id: string): Promise<Workflow | null> {\n    const result = await pool.query('SELECT * FROM workflows WHERE id = $1', [id]);\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Updates an existing workflow in the database.\n   * Performs partial updates by merging the provided data with existing workflow.\n   * Preserves existing data for fields not specified in the update.\n   * \n   * @param {string} id - The UUID of the workflow to update.\n   * @param {Partial<Workflow>} workflowData - An object containing the fields to update.\n   * @returns {Promise<Workflow | null>} A promise that resolves to the updated workflow, or null if not found.\n   * \n   * @example\n   * ```typescript\n   * const updates = {\n   *   name: 'Updated Workflow Name',\n   *   graph_data: {\n   *     ...existingGraphData,\n   *     tasks: [...modifiedTasks]\n   *   }\n   * };\n   * const updated = await workflowService.updateWorkflow(workflowId, updates);\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async updateWorkflow(id: string, workflowData: Partial<Workflow>): Promise<Workflow | null> {\n    // First, fetch the existing workflow from the database\n    const existing = await pool.query('SELECT * FROM workflows WHERE id = $1', [id]);\n    if (!existing.rows[0]) return null;\n\n    // Create a merged object by combining existing data with new data\n    const name = workflowData.name ?? existing.rows[0].name;\n    const graph_data = workflowData.graph_data ?? existing.rows[0].graph_data;\n\n    // Update with the merged values to ensure partial updates don't overwrite existing data\n    const result = await pool.query(\n      'UPDATE workflows SET name = $1, graph_data = $2, updated_at = now() WHERE id = $3 RETURNING *',\n      [name, graph_data, id]\n    );\n    return result.rows[0] || null;\n  }\n\n  /**\n   * Deletes a workflow from the database.\n   * \n   * @param {string} id - The UUID of the workflow to delete.\n   * @returns {Promise<boolean>} A promise that resolves to true if the deletion was successful, false if the workflow was not found.\n   * \n   * @example\n   * ```typescript\n   * const deleted = await workflowService.deleteWorkflow('123e4567-e89b-12d3-a456-426614174000');\n   * if (deleted) {\n   *   console.log('Workflow successfully deleted');\n   * } else {\n   *   console.log('Workflow not found');\n   * }\n   * ```\n   * \n   * @since 0.5.1\n   */\n  async deleteWorkflow(id: string): Promise<boolean> {\n    const result = await pool.query('DELETE FROM workflows WHERE id = $1', [id]);\n    return !!result.rowCount;\n  }\n}\n\n/**\n * @exports {WorkflowService} workflowService\n * @description Singleton instance of the WorkflowService class, ready to be used across the application.\n * This exported instance provides all workflow-related database operations.\n * \n * @since 0.5.1\n */\nexport default new WorkflowService();\n",
      "metadata": {
        "filename": "workflowService.ts",
        "path": "/backend/src/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/setupTests.ts\n\n// Global test setup\nimport { jest } from '@jest/globals';\n\n// Increase test timeout for integration tests\njest.setTimeout(30000);\n",
      "metadata": {
        "filename": "setupTests.ts",
        "path": "/backend/src/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/types/aiProvider.ts\n\n/**\n * @file aiProvider.ts\n * @description Backend type definitions for AI provider management and parameter configuration.\n * These types mirror the frontend types to ensure consistency across the application.\n */\n\nexport type AIProvider = 'google' | 'openai' | 'openrouter' | 'anthropic';\n\n/**\n * Base parameters that all AI providers support\n */\nexport interface BaseModelParameters {\n  /** Controls randomness in generation (0.0 to 2.0) */\n  temperature?: number;\n  /** Maximum tokens to generate */\n  maxTokens?: number;\n}\n\n/**\n * Google Gemini specific parameters\n */\nexport interface GeminiParameters extends BaseModelParameters {\n  /** Top-K sampling parameter (1 to 40) */\n  topK?: number;\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  topP?: number;\n  /** System instruction for the model */\n  systemInstruction?: string;\n  /** Safety settings for content filtering */\n  safetySettings?: Array<{\n    category: string;\n    threshold: string;\n  }>;\n}\n\n/**\n * OpenAI specific parameters\n */\nexport interface OpenAIParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Number between -2.0 and 2.0. Positive values penalize new tokens */\n  presence_penalty?: number;\n  /** Number between -2.0 and 2.0. Positive values penalize repeated tokens */\n  frequency_penalty?: number;\n  /** System message for chat models */\n  systemMessage?: string;\n  /** Number of completions to generate */\n  n?: number;\n  /** Sequences where the API will stop generating */\n  stop?: string | string[];\n}\n\n/**\n * Anthropic Claude specific parameters\n */\nexport interface AnthropicParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Top-K sampling parameter (0 to 200) */\n  top_k?: number;\n  /** System prompt for Claude */\n  system?: string;\n  /** Stop sequences */\n  stop_sequences?: string[];\n}\n\n/**\n * OpenRouter parameters (supports various provider-specific params)\n */\nexport interface OpenRouterParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Top-K sampling parameter */\n  top_k?: number;\n  /** Presence penalty */\n  presence_penalty?: number;\n  /** Frequency penalty */\n  frequency_penalty?: number;\n  /** Repetition penalty */\n  repetition_penalty?: number;\n  /** Min P sampling parameter */\n  min_p?: number;\n  /** System message */\n  system?: string;\n}\n\n/**\n * Union type for all provider-specific parameters\n */\nexport type ModelParameters = \n  | GeminiParameters \n  | OpenAIParameters \n  | AnthropicParameters \n  | OpenRouterParameters;\n\n/**\n * Request configuration for AI API calls\n */\nexport interface AIRequest {\n  provider: AIProvider;\n  model: string;\n  parameters: ModelParameters;\n  prompt: string;\n  systemMessage?: string;\n  conversationHistory?: Array<{\n    role: 'user' | 'assistant' | 'system';\n    content: string;\n  }>;\n}\n\n/**\n * Active provider configuration for runtime use\n */\nexport interface ActiveProviderConfig {\n  provider: AIProvider;\n  model: string;\n  parameters: ModelParameters;\n  apiKey: string;\n  baseUrl?: string;\n}\n",
      "metadata": {
        "filename": "aiProvider.ts",
        "path": "/backend/src/types/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/types/express.ts\n\n/**\n * @file express.ts\n * @description Express.js type extensions for authentication middleware integration\n */\n\nimport { Request } from 'express';\n\ndeclare global {\n  namespace Express {\n    interface Request {\n      user?: {\n        id: string;\n        [key: string]: any;\n      };\n    }\n  }\n}\n\nexport {};\n",
      "metadata": {
        "filename": "express.ts",
        "path": "/backend/src/types/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/src/types.ts\n\n/**\n * @file types.ts\n * @description This file contains TypeScript type definitions and interfaces for the backend.\n * It defines the data structures for database entities like Prompts and Workflows,\n * as well as the detailed SFL-structured prompt types that align with the frontend.\n */\n\n/**\n * @interface Prompt\n * @description Represents the structure of a prompt record in the database.\n */\nexport interface Prompt {\n  id: string;\n  user_id: string;\n  title: string;\n  body: string;\n  metadata: Record<string, any>;\n  created_at: string;\n  updated_at: string;\n}\n\n/**\n * @interface SFLField\n * @description Defines the structure for the \"Field\" component of the SFL framework.\n * Aligns with the frontend `SFLField` type.\n */\nexport interface SFLField {\n  topic: string;\n  taskType: string;\n  domainSpecifics: string;\n  keywords: string;\n}\n\n/**\n * @interface SFLTenor\n * @description Defines the structure for the \"Tenor\" component of the SFL framework.\n * Aligns with the frontend `SFLTenor` type.\n */\nexport interface SFLTenor {\n  aiPersona: string;\n  targetAudience: string[];\n  desiredTone: string;\n  interpersonalStance: string;\n}\n\n/**\n * @interface SFLMode\n * @description Defines the structure for the \"Mode\" component of the SFL framework.\n * Aligns with the frontend `SFLMode` type.\n */\nexport interface SFLMode {\n  outputFormat: string;\n  rhetoricalStructure: string;\n  lengthConstraint: string;\n  textualDirectives: string;\n}\n\n/**\n * @interface PromptSFL\n * @description Represents a complete SFL-structured prompt, aligning with the frontend `PromptSFL` type.\n * This is the primary data structure for prompts used in the API.\n */\nexport interface PromptSFL {\n  id: string;\n  title: string;\n  promptText: string;\n  sflField: SFLField;\n  sflTenor: SFLTenor;\n  sflMode: SFLMode;\n  exampleOutput?: string;\n  notes?: string;\n  createdAt: string;\n  updatedAt: string;\n  geminiResponse?: string;\n  geminiTestError?: string;\n  isTesting?: boolean;\n  sourceDocument?: {\n    name: string;\n    content: string;\n  };\n}\n\n/**\n * @interface Workflow\n * @description Represents the structure of a workflow record in the database.\n */\nexport interface Workflow {\n  id: string;\n  user_id: string;\n  name: string;\n  graph_data: Record<string, any>;\n  created_at: string;\n  updated_at: string;\n  tasks?: Task[]; // Tasks are part of the graph_data but can be represented here\n}\n\n/**\n * @enum {string} TaskType\n * @description Enumerates the different types of tasks that can be part of a workflow.\n */\nexport enum TaskType {\n  DATA_INPUT = \"DATA_INPUT\",\n  GEMINI_PROMPT = \"GEMINI_PROMPT\",\n  IMAGE_ANALYSIS = \"IMAGE_ANALYSIS\",\n  TEXT_MANIPULATION = \"TEXT_MANIPULATION\",\n  SIMULATE_PROCESS = \"SIMULATE_PROCESS\",\n  DISPLAY_CHART = \"DISPLAY_CHART\",\n  GEMINI_GROUNDED = \"GEMINI_GROUNDED\",\n}\n\n/**\n * @interface AgentConfig\n * @description Defines the configuration for an AI agent used in a task.\n */\nexport interface AgentConfig {\n  model?: string;\n  temperature?: number;\n  topK?: number;\n  topP?: number;\n  systemInstruction?: string;\n}\n\n/**\n * @interface Task\n * @description Represents a single task within a workflow.\n */\nexport interface Task {\n  id: string;\n  name: string;\n  description: string;\n  type: TaskType;\n  dependencies: string[];\n  inputKeys: string[];\n  outputKey: string;\n  inputs?: Record<string, { nodeId: string; outputName: string; }>;\n  promptId?: string;\n  promptTemplate?: string;\n  agentConfig?: AgentConfig;\n  functionBody?: string;\n  staticValue?: any;\n  dataKey?: string;\n  positionX?: number;\n  positionY?: number;\n}\n\n/**\n * @type DataStore\n * @description Represents the data store for a workflow run, which is a key-value map.\n */\nexport type DataStore = Record<string, any>;\n\n/**\n * @interface WorkflowExecution\n * @description Represents a workflow execution record in the database.\n */\nexport interface WorkflowExecution {\n  id: string;\n  workflow_id: string;\n  job_id?: string;\n  status: 'pending' | 'running' | 'completed' | 'failed';\n  result?: Record<string, any>;\n  user_input?: Record<string, any>;\n  error_message?: string;\n  started_at?: string;\n  completed_at?: string;\n  created_at: string;\n  updated_at: string;\n}\n",
      "metadata": {
        "filename": "types.ts",
        "path": "/backend/src/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/backend/test-provider-switching.js\n\n/**\n * Test script for dynamic provider switching functionality\n */\n\nconst axios = require('axios');\n\nconst BASE_URL = 'http://localhost:5001/api';\n\nasync function testProviderSwitching() {\n  console.log('🧪 Testing Dynamic Provider Switching\\n');\n\n  // Test 1: Legacy Gemini endpoint (should default to Google/Gemini)\n  console.log('Test 1: Legacy Gemini endpoint (backward compatibility)');\n  try {\n    const response = await axios.post(`${BASE_URL}/gemini/test-prompt`, {\n      promptText: 'Say \"Hello from legacy endpoint\" in a friendly way.'\n    });\n    console.log('✅ Legacy endpoint response:', response.data.text.substring(0, 100) + '...\\n');\n  } catch (error) {\n    console.log('❌ Legacy endpoint failed:', error.response?.data || error.message, '\\n');\n  }\n\n  // Test 2: Dynamic provider switching to OpenAI (if API key available)\n  if (process.env.OPENAI_API_KEY) {\n    console.log('Test 2: Dynamic provider switching to OpenAI');\n    try {\n      const response = await axios.post(`${BASE_URL}/gemini/test-prompt`, {\n        promptText: 'Say \"Hello from OpenAI\" in a friendly way.',\n        provider: 'openai',\n        model: 'gpt-3.5-turbo',\n        parameters: {\n          temperature: 0.7,\n          maxTokens: 100\n        },\n        apiKey: process.env.OPENAI_API_KEY\n      });\n      console.log('✅ OpenAI response:', response.data.text.substring(0, 100) + '...\\n');\n    } catch (error) {\n      console.log('❌ OpenAI request failed:', error.response?.data || error.message, '\\n');\n    }\n  } else {\n    console.log('⚠️ Skipping OpenAI test - no API key provided\\n');\n  }\n\n  // Test 3: Dynamic provider switching to Anthropic (if API key available)\n  if (process.env.ANTHROPIC_API_KEY) {\n    console.log('Test 3: Dynamic provider switching to Anthropic');\n    try {\n      const response = await axios.post(`${BASE_URL}/gemini/test-prompt`, {\n        promptText: 'Say \"Hello from Anthropic\" in a friendly way.',\n        provider: 'anthropic',\n        model: 'claude-3-5-sonnet-20241022',\n        parameters: {\n          temperature: 0.7,\n          maxTokens: 100\n        },\n        apiKey: process.env.ANTHROPIC_API_KEY\n      });\n      console.log('✅ Anthropic response:', response.data.text.substring(0, 100) + '...\\n');\n    } catch (error) {\n      console.log('❌ Anthropic request failed:', error.response?.data || error.message, '\\n');\n    }\n  } else {\n    console.log('⚠️ Skipping Anthropic test - no API key provided\\n');\n  }\n\n  // Test 4: SFL Generation with dynamic provider\n  console.log('Test 4: SFL Generation with dynamic provider');\n  try {\n    const response = await axios.post(`${BASE_URL}/gemini/generate-sfl`, {\n      goal: 'Write a professional email to a client',\n      provider: 'google', // Use Google/Gemini for this test\n      model: 'gemini-2.5-flash',\n      parameters: {\n        temperature: 0.7,\n        maxTokens: 2048\n      }\n    });\n    console.log('✅ SFL Generation successful, title:', response.data.title, '\\n');\n  } catch (error) {\n    console.log('❌ SFL Generation failed:', error.response?.data || error.message, '\\n');\n  }\n\n  // Test 5: Provider validation\n  console.log('Test 5: Provider validation');\n  try {\n    const response = await axios.get(`${BASE_URL}/providers/available`);\n    console.log('✅ Available providers:', response.data, '\\n');\n  } catch (error) {\n    console.log('❌ Provider validation failed:', error.response?.data || error.message, '\\n');\n  }\n\n  console.log('🏁 Testing complete!');\n}\n\n// Run the tests\nif (require.main === module) {\n  testProviderSwitching().catch(console.error);\n}\n\nmodule.exports = { testProviderSwitching };\n",
      "metadata": {
        "filename": "test-provider-switching.js",
        "path": "/backend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/App.tsx\n\n/**\n * @file App.tsx\n * @description This is the root component of the SFL Prompt Studio application.\n * It serves as the main controller, managing the application's core state, including the list of prompts,\n * active modals, filters, and the current page. It orchestrates all the main components like the Sidebar,\n * TopBar, and the main content area, and wires up all the event handling logic for prompt management,\n * navigation, and interaction with AI services.\n *\n * @requires react\n * @requires ./types\n * @requires ./components/Sidebar\n * @requires ./components/TopBar\n * @requires ./components/Stats\n * @requires ./components/PromptList\n * @requires ./components/PromptFormModal\n * @requires ./components/PromptDetailModal\n * @requires ./components/PromptWizardModal\n * @requires ./components/HelpModal\n * @requires ./components/Documentation\n * @requires ./components/lab/PromptLabPage\n * @requires ./services/geminiService\n * @requires ./services/promptApiService\n * @requires ./constants\n */\n\nimport React, { useState, useEffect, useCallback, useMemo, useRef } from 'react';\nimport { PromptSFL, Filters, ModalType } from './types';\nimport Sidebar from './components/Sidebar';\nimport TopBar from './components/TopBar';\nimport Stats from './components/Stats';\nimport PromptList from './components/PromptList';\nimport PromptFormModal from './components/PromptFormModal';\nimport PromptDetailModal from './components/PromptDetailModal';\nimport PromptWizardModal from './components/PromptWizardModal';\nimport HelpModal from './components/HelpModal';\nimport Documentation from './components/Documentation';\nimport PromptLabPage from './components/lab/PromptLabPage';\nimport ProviderSetupPage from './components/settings/ProviderSetupPage';\nimport { testPromptWithGemini } from './services/geminiService';\nimport { getPrompts, savePrompt, deletePrompt as apiDeletePrompt } from './services/promptApiService';\nimport { useProviderValidation } from './hooks/useProviderValidation';\nimport { TASK_TYPES, AI_PERSONAS, TARGET_AUDIENCES, DESIRED_TONES, OUTPUT_FORMATS, LENGTH_CONSTRAINTS, POPULAR_TAGS } from './constants';\n\n/**\n * @constant {Filters} initialFilters - The default state for the prompt filters.\n * @private\n */\nconst initialFilters: Filters = {\n  searchTerm: '',\n  topic: '',\n  taskType: '',\n  aiPersona: '',\n  outputFormat: '',\n};\n\n/**\n * Converts a `PromptSFL` object into a well-formatted Markdown string.\n * This is used for exporting prompts in a human-readable format.\n *\n * @param {PromptSFL} prompt - The prompt object to convert.\n * @returns {string} The Markdown representation of the prompt.\n * @private\n */\nconst promptToMarkdown = (prompt: PromptSFL): string => {\n    const { \n        title, updatedAt, promptText, sflField, sflTenor, sflMode, exampleOutput, notes, sourceDocument\n    } = prompt;\n\n    const sections = [\n        `# ${title || 'Untitled Prompt'}`, \n        `**Last Updated:** ${new Date(updatedAt).toLocaleString()}`,\n        '---',\n        '## Prompt Text',\n        '```',\n        promptText || '',\n        '```',\n    ];\n\n    if (sourceDocument) {\n        sections.push(\n            '---',\n            '## Source Document',\n            `**Filename:** \\`${sourceDocument.name}\\`\n`,            '> This document was used as a stylistic reference during prompt generation.',\n            '',\n            '<details>',\n            '<summary>View Content</summary>',\n            '',\n            '```',\n            sourceDocument.content,\n            '```',\n            '</details>'\n        );\n    }\n\n    const keywordsString = sflField.keywords ? `\\`${sflField.keywords.split(',').map(k => k.trim()).join('`, `')}\\`` : 'N/A';\n\n    sections.push(\n        '---',\n        '## SFL Metadata',\n        '### Field (What is happening?)',\n        `- **Topic:** ${sflField.topic || 'N/A'}`, \n        `- **Task Type:** ${sflField.taskType || 'N/A'}`, \n        `- **Domain Specifics:** ${sflField.domainSpecifics || 'N/A'}`, \n        `- **Keywords:** ${keywordsString}`,\n        '',\n        '### Tenor (Who is taking part?)',\n        `- **AI Persona:** ${sflTenor.aiPersona || 'N/A'}`, \n        `- **Target Audience:** ${sflTenor.targetAudience.join(', ') || 'N/A'}`, \n        `- **Desired Tone:** ${sflTenor.desiredTone || 'N/A'}`, \n        `- **Interpersonal Stance:** ${sflTenor.interpersonalStance || 'N/A'}`,\n        '',\n        '### Mode (What role is language playing?)',\n        `- **Output Format:** ${sflMode.outputFormat || 'N/A'}`, \n        `- **Rhetorical Structure:** ${sflMode.rhetoricalStructure || 'N/A'}`, \n        `- **Length Constraint:** ${sflMode.lengthConstraint || 'N/A'}`, \n        `- **Textual Directives:** ${sflMode.textualDirectives || 'N/A'}`,\n    );\n\n    if (exampleOutput) {\n        sections.push(\n            '---',\n            '## Example Output',\n            '```',\n            exampleOutput,\n            '```'\n        );\n    }\n\n    if (notes) {\n        sections.push(\n            '---',\n            '## Notes',\n            notes\n        );\n    }\n    \n    return sections.join('\\n');\n};\n\n/**\n * @typedef {'dashboard' | 'lab' | 'documentation' | 'settings'}\n * @description Represents the possible main pages the user can navigate to.\n */\ntype Page = 'dashboard' | 'lab' | 'documentation' | 'settings';\n\n/**\n * The main `App` component. It acts as the root of the application,\n * managing state, handling side effects, and composing the UI from smaller components.\n *\n * @returns {JSX.Element} The rendered application UI.\n */\nconst App: React.FC = () => {\n  /**\n   * @hook useProviderValidation - Manages AI provider validation and routing\n   */\n  const {\n    isReady: providersReady,\n    isLoading: providersLoading,\n    error: providerError,\n    requiresSetup,\n    checkSetupComplete,\n  } = useProviderValidation();\n\n  /**\n   * @state {PromptSFL[]} prompts - The master list of all SFL prompts loaded in the application.\n   */\n  const [prompts, setPrompts] = useState<PromptSFL[]>([]);\n  \n  /**\n   * @state {ModalType} activeModal - The type of the currently active modal, or `ModalType.NONE` if no modal is open.\n   */\n  const [activeModal, setActiveModal] = useState<ModalType>(ModalType.NONE);\n  \n  /**\n   * @state {PromptSFL | null} selectedPrompt - The prompt that is currently selected for viewing or editing.\n   */\n  const [selectedPrompt, setSelectedPrompt] = useState<PromptSFL | null>(null);\n  \n  /**\n   * @state {Filters} filters - The current state of the filters used to narrow down the list of prompts.\n   */\n  const [filters, setFilters] = useState<Filters>(initialFilters);\n  \n  /**\n   * @state {Page} activePage - The currently displayed main page of the application.\n   */\n  const [activePage, setActivePage] = useState<Page>(requiresSetup ? 'settings' : 'dashboard');\n  \n  /**\n   * @state {boolean} hasUserNavigated - Tracks if user has manually navigated to prevent auto-redirects\n   */\n  const [hasUserNavigated, setHasUserNavigated] = useState<boolean>(false);\n  \n  /**\n   * @ref {HTMLInputElement} importFileRef - A ref to a hidden file input element, used to trigger the file import dialog programmatically.\n   */\n  const importFileRef = useRef<HTMLInputElement>(null);\n\n  /**\n   * @state {object} appConstants - The state holding the dynamic lists of options for SFL fields (e.g., Task Types, AI Personas).\n   * This allows users to add new options at runtime.\n   */\n  const [appConstants, setAppConstants] = useState({\n    taskTypes: TASK_TYPES,\n    aiPersonas: AI_PERSONAS,\n    targetAudiences: TARGET_AUDIENCES,\n    desiredTones: DESIRED_TONES,\n    outputFormats: OUTPUT_FORMATS,\n    lengthConstraints: LENGTH_CONSTRAINTS,\n    popularTags: POPULAR_TAGS,\n  });\n\n  /**\n   * @effect Handles routing based on provider validation status\n   * Only auto-redirects on initial load, not after manual navigation\n   */\n  useEffect(() => {\n    if (!providersLoading) {\n      if (requiresSetup) {\n        setActivePage('settings');\n      } else if (activePage === 'settings' && providersReady && !hasUserNavigated) {\n        // Only redirect to dashboard if this is initial load (user hasn't manually navigated)\n        setActivePage('dashboard');\n      }\n    }\n  }, [providersLoading, requiresSetup, providersReady, activePage, hasUserNavigated]);\n\n  /**\n   * @effect Fetches the initial list of prompts from the API when providers are ready.\n   */\n  useEffect(() => {\n    if (providersReady) {\n      const fetchPrompts = async () => {\n        try {\n          const fetchedPrompts = await getPrompts();\n          setPrompts(fetchedPrompts);\n        } catch (error) {\n          console.error(\"Failed to fetch prompts:\", error);\n        }\n      };\n      fetchPrompts();\n    }\n  }, [providersReady]);\n\n  /**\n   * @callback handleNavigate\n   * @description Handles navigation between the main pages of the application.\n   * Also checks provider setup when navigating to non-settings pages.\n   * @param {Page} page - The page to navigate to.\n   */\n  const handleNavigate = useCallback(async (page: Page) => {\n    // Mark that user has manually navigated to prevent auto-redirects\n    setHasUserNavigated(true);\n    \n    // If user tries to navigate away from settings, check if setup is complete\n    if (page !== 'settings' && requiresSetup) {\n      const setupComplete = await checkSetupComplete();\n      if (!setupComplete) {\n        // Redirect to settings if setup is not complete\n        setActivePage('settings');\n        return;\n      }\n    }\n    setActivePage(page);\n  }, [requiresSetup, checkSetupComplete]);\n\n  /**\n   * @callback handleAddConstant\n   * @description Adds a new, user-defined option to one of the SFL dropdown lists (e.g., a new 'Task Type').\n   * It ensures the new value is unique before adding it to the state.\n   * @param {keyof typeof appConstants} key - The category of the constant to add (e.g., 'taskTypes').\n   * @param {string} value - The new string value to add.\n   */\n  const handleAddConstant = useCallback((key: keyof typeof appConstants, value: string) => {\n    if (!value || !value.trim()) return;\n    const trimmedValue = value.trim();\n    setAppConstants(prev => {\n        const currentValues = prev[key];\n        if (!Array.isArray(currentValues)) return prev;\n\n        const lowerCaseValue = trimmedValue.toLowerCase();\n        const existingValues = currentValues.map(v => String(v).toLowerCase());\n\n        if (existingValues.includes(lowerCaseValue)) {\n            return prev;\n        }\n        return {\n            ...prev,\n            [key]: [...currentValues, trimmedValue]\n        };\n    });\n  }, []);\n\n  /**\n   * @function handleOpenCreateModal\n   * @description Opens the modal for creating a new prompt.\n   */\n  const handleOpenCreateModal = () => {\n    setSelectedPrompt(null);\n    setActiveModal(ModalType.CREATE_EDIT_PROMPT);\n  };\n  \n  /**\n   * @function handleOpenHelpModal\n   * @description Opens the help guide modal.\n   */\n  const handleOpenHelpModal = () => {\n    setActiveModal(ModalType.HELP);\n  };\n\n  /**\n   * @function handleOpenWizard\n   * @description Opens the prompt creation wizard modal.\n   */\n  const handleOpenWizard = () => {\n    setActiveModal(ModalType.WIZARD);\n  };\n\n  /**\n   * @function handleOpenEditModal\n   * @description Opens the modal to edit an existing prompt.\n   * @param {PromptSFL} prompt - The prompt to be edited.\n   */\n  const handleOpenEditModal = (prompt: PromptSFL) => {\n    setSelectedPrompt(prompt);\n    setActiveModal(ModalType.CREATE_EDIT_PROMPT);\n  };\n\n  /**\n   * @function handleOpenDetailModal\n   * @description Opens the modal to view the full details of a prompt.\n   * @param {PromptSFL} prompt - The prompt to be viewed.\n   */\n  const handleOpenDetailModal = (prompt: PromptSFL) => {\n    setSelectedPrompt(prompt);\n    setActiveModal(ModalType.VIEW_PROMPT_DETAIL);\n  };\n\n  /**\n   * @function handleCloseModal\n   * @description Closes any currently active modal.\n   */\n  const handleCloseModal = () => {\n    setActiveModal(ModalType.NONE);\n  };\n\n  /**\n   * @callback handleSavePrompt\n   * @description Handles saving a new or updated prompt. It calls the API service\n   * and then updates the local state with the returned prompt data.\n   * @param {PromptSFL} prompt - The prompt to be saved.\n   * @throws {Error} Propagates any errors from the API service.\n   */\n  const handleSavePrompt = async (prompt: PromptSFL) => {\n    try {\n      const saved = await savePrompt(prompt);\n      setPrompts(prevPrompts => {\n        const existingIndex = prevPrompts.findIndex(p => p.id === saved.id);\n        if (existingIndex > -1) {\n          const updatedPrompts = [...prevPrompts];\n          updatedPrompts[existingIndex] = saved;\n          return updatedPrompts;\n        }\n        return [saved, ...prevPrompts].sort((a,b) => new Date(b.updatedAt).getTime() - new Date(a.updatedAt).getTime());\n      });\n    } catch (error) {\n      console.error(\"Failed to save prompt:\", error);\n      throw error;\n    }\n  };\n\n  /**\n   * @callback handleDeletePrompt\n   * @description Handles the deletion of a prompt after user confirmation.\n   * It calls the API service and then removes the prompt from the local state.\n   * @param {string} promptId - The ID of the prompt to delete.\n   */\n  const handleDeletePrompt = async (promptId: string) => {\n    if(window.confirm('Are you sure you want to delete this prompt?')){\n      try {\n        await apiDeletePrompt(promptId);\n        setPrompts(prevPrompts => prevPrompts.filter(p => p.id !== promptId));\n        if (selectedPrompt && selectedPrompt.id === promptId) {\n            setSelectedPrompt(null);\n            handleCloseModal();\n        }\n      } catch (error) {\n        console.error(\"Failed to delete prompt:\", error);\n        alert(\"Failed to delete prompt. Please try again.\");\n      }\n    }\n  };\n\n  /**\n   * @callback handleFilterChange\n   * @description Updates the filter state based on user input.\n   * @param {K} key - The filter key to update.\n   * @param {Filters[K]} value - The new value for the filter.\n   */\n  const handleFilterChange = useCallback(<K extends keyof Filters>(key: K, value: Filters[K]) => {\n    setFilters(prev => ({ ...prev, [key]: value }));\n  }, []);\n  \n  /**\n   * @callback handleResetFilters\n   * @description Resets all filters to their initial, empty state.\n   */\n  const handleResetFilters = useCallback(() => {\n    setFilters(initialFilters);\n  }, []);\n\n  /**\n   * @memorized {PromptSFL[]} filteredPrompts\n   * @description A memoized list of prompts that have been filtered based on the current `filters` state.\n   * This prevents re-filtering on every render.\n   */\n  const filteredPrompts = useMemo(() => {\n    return prompts.filter(p => {\n      const searchTermLower = filters.searchTerm.toLowerCase();\n      \n      const searchFields = [\n        p.title,\n        p.promptText,\n        p.sflField.keywords,\n        p.sflField.topic,\n        p.sflField.domainSpecifics,\n        p.sflTenor.aiPersona,\n        p.sflTenor.targetAudience.join(' '),\n        p.sflMode.outputFormat\n      ];\n\n      const matchesSearchTerm = filters.searchTerm === '' || searchFields.some(field => field && field.toLowerCase().includes(searchTermLower));\n      const matchesTaskType = filters.taskType === '' || p.sflField.taskType === filters.taskType;\n      const matchesAiPersona = filters.aiPersona === '' || p.sflTenor.aiPersona === filters.aiPersona;\n      \n      return matchesSearchTerm && matchesTaskType && matchesAiPersona;\n    }).sort((a,b) => new Date(b.updatedAt).getTime() - new Date(a.updatedAt).getTime());\n  }, [prompts, filters]);\n\n  /**\n   * @callback handleTestWithGemini\n   * @description Handles testing a prompt with the Gemini API. It updates the prompt's state to show\n   * loading, interpolates any variables into the prompt text, calls the API, and then updates the state\n   * with the response or error.\n   * @param {PromptSFL} promptToTest - The prompt to be tested.\n   * @param {Record<string, string>} variables - A map of variable names to their values for interpolation.\n   */\n  const handleTestWithGemini = async (promptToTest: PromptSFL, variables: Record<string, string>) => {\n    const updatePromptState = (id: string, updates: Partial<PromptSFL>) => {\n        setPrompts(prev => prev.map(p => p.id === id ? { ...p, ...updates } : p));\n        setSelectedPrompt(prev => prev && prev.id === id ? { ...prev, ...updates } : prev);\n    };\n\n    updatePromptState(promptToTest.id, { isTesting: true, geminiResponse: undefined, geminiTestError: undefined });\n    \n    let finalPromptText = promptToTest.promptText;\n    Object.keys(variables).forEach(key => {\n      const regex = new RegExp(`{{\\s*${key}\\s*}}`, 'g');\n      finalPromptText = finalPromptText.replace(regex, variables[key] || '');\n    });\n\n    try {\n      const responseText = await testPromptWithGemini(finalPromptText);\n      updatePromptState(promptToTest.id, { isTesting: false, geminiResponse: responseText, geminiTestError: undefined });\n    } catch (error: any) {\n      updatePromptState(promptToTest.id, { isTesting: false, geminiTestError: error.message, geminiResponse: undefined });\n    }\n  };\n\n  /**\n   * @function sanitizeFilename\n   * @description A utility function to sanitize a string for use as a filename.\n   * @param {string} filename - The string to sanitize.\n   * @returns {string} The sanitized filename.\n   * @private\n   */\n  const sanitizeFilename = (filename: string): string => {\n    return filename.replace(/[^a-z0-9_\\-\\s]/gi, '_').replace(/\\s+/g, '_');\n  };\n\n  /**\n   * @function handleExportSinglePrompt\n   * @description Exports a single prompt as a JSON file.\n   * @param {PromptSFL} promptToExport - The prompt to export.\n   */\n  const handleExportSinglePrompt = (promptToExport: PromptSFL) => {\n    if (!promptToExport) {\n      alert(\"No prompt selected for export.\");\n      return;\n    }\n    try {\n      const { isTesting, geminiResponse, geminiTestError, ...exportablePrompt } = promptToExport;\n      const jsonData = JSON.stringify(exportablePrompt, null, 2);\n      const blob = new Blob([jsonData], { type: 'application/json' });\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      const date = new Date().toISOString().slice(0, 10);\n      const sanitizedTitle = sanitizeFilename(promptToExport.title || \"untitled\");\n      a.href = url;\n      a.download = `sfl-prompt_${sanitizedTitle}_${date}.json`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(url);\n    } catch (error) {\n      console.error(\"Error exporting prompt:\", error);\n      alert(\"An error occurred while exporting the prompt. Please check the console for details.\");\n    }\n  };\n\n  /**\n   * @function handleExportSinglePromptMarkdown\n   * @description Exports a single prompt as a Markdown file.\n   * @param {PromptSFL} promptToExport - The prompt to export.\n   */\n  const handleExportSinglePromptMarkdown = (promptToExport: PromptSFL) => {\n    if (!promptToExport) {\n      alert(\"No prompt selected for export.\");\n      return;\n    }\n    try {\n      const markdownData = promptToMarkdown(promptToExport);\n      const blob = new Blob([markdownData], { type: 'text/markdown' });\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      const date = new Date().toISOString().slice(0, 10);\n      const sanitizedTitle = sanitizeFilename(promptToExport.title || \"untitled\");\n      a.href = url;\n      a.download = `sfl-prompt_${sanitizedTitle}_${date}.md`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(url);\n    } catch (error) {\n      console.error(\"Error exporting prompt as markdown:\", error);\n      alert(\"An error occurred while exporting the prompt as markdown. Please check the console for details.\");\n    }\n  };\n\n  /**\n   * @function handleExportAllPrompts\n   * @description Exports all prompts in the library as a single JSON file.\n   */\n  const handleExportAllPrompts = () => {\n    if (prompts.length === 0) {\n      alert(\"There are no prompts to export.\");\n      return;\n    }\n    try {\n      const exportablePrompts = prompts.map(p => {\n        const { isTesting, geminiResponse, geminiTestError, ...rest } = p;\n        return rest;\n      });\n      const jsonData = JSON.stringify(exportablePrompts, null, 2);\n      const blob = new Blob([jsonData], { type: 'application/json' });\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      const date = new Date().toISOString().slice(0, 10);\n      a.href = url;\n      a.download = `sfl-prompt-library_${date}.json`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(url);\n    } catch (error) {\n      console.error(\"Error exporting prompts:\", error);\n      alert(\"An error occurred while exporting prompts. Please check the console for details.\");\n    }\n  };\n\n  /**\n   * @function handleExportAllPromptsMarkdown\n   * @description Exports all prompts in the library as a single Markdown file.\n   */\n  const handleExportAllPromptsMarkdown = () => {\n    if (prompts.length === 0) {\n      alert(\"There are no prompts to export.\");\n      return;\n    }\n    try {\n      const allPromptsMarkdown = prompts\n        .map(p => promptToMarkdown(p))\n        .join('\\n\\n---\\n\\n');\n        \n      const blob = new Blob([allPromptsMarkdown], { type: 'text/markdown' });\n      const url = URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      const date = new Date().toISOString().slice(0, 10);\n      a.href = url;\n      a.download = `sfl-prompt-library_${date}.md`;\n      document.body.appendChild(a);\n      a.click();\n      document.body.removeChild(a);\n      URL.revokeObjectURL(url);\n    } catch (error) {\n      console.error(\"Error exporting all prompts as markdown:\", error);\n      alert(\"An error occurred while exporting prompts as markdown. Please check the console for details.\");\n    }\n  };\n\n  /**\n   * @function handleImportPrompts\n   * @description Programmatically clicks the hidden file input to open the file import dialog.\n   */\n  const handleImportPrompts = () => {\n      importFileRef.current?.click();\n  };\n\n  /**\n   * @callback onFileImport\n   * @description Handles the file import process once a user selects a file.\n   * It reads, parses, and validates the JSON file, then merges the imported prompts\n   * into the existing state, updating existing prompts and adding new ones.\n   * @param {React.ChangeEvent<HTMLInputElement>} event - The file input change event.\n   */\n  const onFileImport = (event: React.ChangeEvent<HTMLInputElement>) => {\n      const file = event.target.files?.[0];\n      if (!file) return;\n\n      const reader = new FileReader();\n      reader.onload = (e) => {\n          try {\n              const text = e.target?.result;\n              if (typeof text !== 'string') {\n                  throw new Error(\"File content is not readable.\");\n              }\n              const importedData = JSON.parse(text);\n\n              if (!Array.isArray(importedData)) {\n                  throw new Error(\"Imported file is not a valid prompt array.\");\n              }\n\n              const isValid = importedData.every(p => p.id && p.title && p.promptText);\n              if (!isValid) {\n                  throw new Error(\"Some prompts in the imported file are malformed.\");\n              }\n              const importedPrompts = importedData as PromptSFL[];\n              \n              setPrompts(prevPrompts => {\n                  const promptsMap = new Map(prevPrompts.map(p => [p.id, p]));\n                  let newPromptsCount = 0;\n                  let updatedPromptsCount = 0;\n\n                  importedPrompts.forEach(importedPrompt => {\n                      if (promptsMap.has(importedPrompt.id)) {\n                          updatedPromptsCount++;\n                      } else {\n                          newPromptsCount++;\n                      }\n                      promptsMap.set(importedPrompt.id, {\n                          ...importedPrompt,\n                          geminiResponse: undefined,\n                          geminiTestError: undefined,\n                          isTesting: false,\n                      });\n                  });\n                  alert(`Import successful!\\n\\nNew prompts: ${newPromptsCount}\\nUpdated prompts: ${updatedPromptsCount}`);\n                  return Array.from(promptsMap.values());\n              });\n\n          } catch (error: any) {\n              console.error(\"Error importing prompts:\", error);\n              alert(`Import failed: ${error.message}`);\n          } finally {\n              if (event.target) {\n                  event.target.value = '';\n              }\n          }\n      };\n      reader.readAsText(file);\n  };\n\n  /**\n   * @function renderMainContent\n   * @description A router-like function that renders the main content area based on the `activePage` state.\n   * @returns {JSX.Element} The component for the currently active page.\n   * @private\n   */\n  const renderMainContent = () => {\n    switch(activePage) {\n        case 'dashboard':\n            return (\n                <>\n                    <Stats totalPrompts={prompts.length}/>\n                    <div className=\"mt-8\">\n                        <PromptList \n                            prompts={filteredPrompts} \n                            onViewPrompt={handleOpenDetailModal}\n                            onEditPrompt={handleOpenEditModal}\n                            onDeletePrompt={handleDeletePrompt}\n                            onExportJSON={handleExportSinglePrompt}\n                            onExportMarkdown={handleExportSinglePromptMarkdown}\n                        />\n                    </div>\n                </>\n            );\n        case 'lab':\n            return <PromptLabPage prompts={prompts} />;\n        case 'documentation':\n            return <Documentation />;\n        case 'settings':\n            return <ProviderSetupPage onSetupComplete={checkSetupComplete} />;\n        default:\n             return (\n                <div className=\"text-center py-20 bg-[#333e48] rounded-lg border border-[#5c6f7e]\">\n                    <h2 className=\"text-2xl font-bold text-gray-200\">Coming Soon!</h2>\n                    <p className=\"text-[#95aac0] mt-2\">This page is under construction.</p>\n                </div>\n            );\n    }\n  }\n\n  // Show loading screen while checking providers\n  if (providersLoading) {\n    return (\n      <div className=\"flex h-screen bg-[#212934] font-sans\">\n        <div className=\"flex flex-col items-center justify-center w-full\">\n          <div className=\"animate-spin rounded-full h-12 w-12 border-b-2 border-accent-primary mb-4\"></div>\n          <h2 className=\"text-xl font-semibold text-gray-200\">Initializing AI Providers...</h2>\n          <p className=\"text-[#95aac0] mt-2\">Checking available AI provider configurations</p>\n        </div>\n      </div>\n    );\n  }\n\n  // Show error screen if provider validation failed\n  if (providerError) {\n    return (\n      <div className=\"flex h-screen bg-[#212934] font-sans\">\n        <div className=\"flex flex-col items-center justify-center w-full max-w-md mx-auto\">\n          <div className=\"bg-red-500/20 border border-red-500 rounded-lg p-6 mb-4\">\n            <h2 className=\"text-xl font-semibold text-red-200 mb-2\">Provider Error</h2>\n            <p className=\"text-red-300\">{providerError}</p>\n          </div>\n          <button\n            onClick={() => window.location.reload()}\n            className=\"px-6 py-2 bg-accent-primary text-white rounded-lg hover:bg-accent-primary/80 transition-colors\"\n          >\n            Retry\n          </button>\n        </div>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"flex h-screen bg-[#212934] font-sans\">\n      <Sidebar \n        filters={filters}\n        onFilterChange={handleFilterChange}\n        popularTags={appConstants.popularTags}\n        activePage={activePage}\n        onNavigate={handleNavigate}\n      />\n       <input\n            type=\"file\"\n            ref={importFileRef}\n            onChange={onFileImport}\n            className=\"hidden\"\n            accept=\"application/json\"\n        />\n\n      <div className=\"flex-1 flex flex-col overflow-hidden\">\n        <TopBar \n          onAddNewPrompt={handleOpenCreateModal}\n          onOpenWizard={handleOpenWizard}\n          searchTerm={filters.searchTerm}\n          onSearchChange={(value) => handleFilterChange('searchTerm', value)}\n        />\n        <main className=\"flex-1 overflow-x-hidden overflow-y-auto p-6\">\n          {renderMainContent()}\n        </main>\n      </div>\n\n      {activeModal === ModalType.CREATE_EDIT_PROMPT && (\n        <PromptFormModal\n          isOpen={true}\n          onClose={handleCloseModal}\n          onSave={handleSavePrompt}\n          promptToEdit={selectedPrompt}\n          appConstants={appConstants}\n          onAddConstant={handleAddConstant}\n        />\n      )}\n\n      {activeModal === ModalType.VIEW_PROMPT_DETAIL && selectedPrompt && (\n         <PromptDetailModal\n          isOpen={true}\n          onClose={handleCloseModal}\n          prompt={selectedPrompt}\n          onEdit={handleOpenEditModal}\n          onDelete={handleDeletePrompt}\n          onTestWithGemini={handleTestWithGemini}\n        />\n      )}\n\n      {activeModal === ModalType.WIZARD && (\n        <PromptWizardModal\n          isOpen={true}\n          onClose={handleCloseModal}\n          onSave={handleSavePrompt}\n          appConstants={appConstants}\n          onAddConstant={handleAddConstant}\n        />\n      )}\n\n      {activeModal === ModalType.HELP && (\n        <HelpModal\n          isOpen={true}\n          onClose={handleCloseModal}\n        />\n      )}\n    </div>\n  );\n};\n\nexport default App;\n",
      "metadata": {
        "filename": "App.tsx",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/Dockerfile\n\n# Stage 1: Build the React app\nFROM docker.io/library/node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\n# Stage 2: Serve with Nginx\nFROM docker.io/library/nginx:stable-alpine\nCOPY --from=builder /app/dist /usr/share/nginx/html\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nEXPOSE 80\n# USER nginx\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n",
      "metadata": {
        "filename": "Dockerfile",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/Documentation.tsx\n\n/**\n * @file Documentation.tsx\n * @description This component renders the main documentation page for the SFL Prompt Studio.\n * It explains the core concepts of Systemic Functional Linguistics (SFL) and highlights the key features of the application.\n * It is composed of several sub-components: `FeatureCard`, `SFLConcept`, and `Step` to structure the information clearly.\n *\n * @requires react\n * @requires ./icons/BookOpenIcon\n * @requires ./icons/CubeIcon\n * @requires ./icons/UsersIcon\n * @requires ./icons/DocumentTextIcon\n * @requires ./icons/MagicWandIcon\n * @requires ./icons/SparklesIcon\n * @requires ./icons/BeakerIcon\n * @requires ./icons/ArrowDownTrayIcon\n * @requires ./icons/FlaskIcon\n * @requires ./icons/ArrowsRightLeftIcon\n * @requires ./icons/PlayIcon\n * @requires ./icons/CodeBracketIcon\n */\n\nimport React from 'react';\nimport BookOpenIcon from './icons/BookOpenIcon';\nimport CubeIcon from './icons/CubeIcon';\nimport UsersIcon from './icons/UsersIcon';\nimport DocumentTextIcon from './icons/DocumentTextIcon';\nimport MagicWandIcon from './icons/MagicWandIcon';\nimport SparklesIcon from './icons/SparklesIcon';\nimport BeakerIcon from './icons/BeakerIcon';\nimport ArrowDownTrayIcon from './icons/ArrowDownTrayIcon';\nimport FlaskIcon from './icons/FlaskIcon';\nimport ArrowsRightLeftIcon from './icons/ArrowsRightLeftIcon';\nimport PlayIcon from './icons/PlayIcon';\nimport CodeBracketIcon from './icons/CodeBracketIcon';\n\n/**\n * A reusable card component to display a key feature of the application.\n * It combines an icon, a title, and a description in a visually distinct block.\n *\n * @param {object} props - The component props.\n * @param {React.ReactNode} props.icon - The icon element to display for the feature.\n * @param {string} props.title - The title of the feature.\n * @param {React.ReactNode} props.children - The descriptive text for the feature.\n * @returns {JSX.Element} A styled card element for showcasing a feature.\n * @private\n */\nconst FeatureCard: React.FC<{ icon: React.ReactNode; title: string; children: React.ReactNode; }> = ({ icon, title, children }) => (\n    <div className=\"bg-[#333e48] p-6 rounded-lg border border-[#5c6f7e] h-full\">\n        <div className=\"flex items-center space-x-4 mb-3\">\n            <div className=\"bg-blue-900/20 p-3 rounded-lg text-blue-400\">\n                {icon}\n            </div>\n            <h3 className=\"text-xl font-semibold text-gray-800\">{title}</h3>\n        </div>\n        <p className=\"text-gray-600 text-sm leading-relaxed\">{children}</p>\n    </div>\n);\n\n/**\n * A component designed to explain a single SFL concept (Field, Tenor, or Mode).\n * It presents the concept's name, its guiding question, and a detailed explanation.\n *\n * @param {object} props - The component props.\n * @param {React.ReactNode} props.icon - The icon representing the SFL concept.\n * @param {string} props.title - The name of the concept (e.g., \"Field\").\n * @param {string} props.question - The key question the concept answers (e.g., \"What is happening?\").\n * @param {React.ReactNode} props.children - The detailed explanation of the concept.\n * @returns {JSX.Element} A styled component that clearly explains an SFL concept.\n * @private\n */\nconst SFLConcept: React.FC<{ icon: React.ReactNode; title: string; question: string; children: React.ReactNode; }> = ({ icon, title, question, children }) => (\n    <div className=\"bg-[#212934]/70 p-5 rounded-lg border border-[#5c6f7e]/80\">\n        <div className=\"flex items-center space-x-3 mb-2\">\n            {icon}\n            <div>\n                <h4 className=\"font-bold text-gray-900\">{title}</h4>\n                <p className=\"text-sm text-gray-500 italic\">\"{question}\"</p>\n            </div>\n        </div>\n        <p className=\"text-sm text-gray-700 pl-9\">{children}</p>\n    </div>\n);\n\n/**\n * A component to display a single step in a process or instructional guide.\n * It combines an icon, a title, and a description to clearly outline each step.\n *\n * @param {object} props - The component props.\n * @param {React.ReactNode} props.icon - The icon for the step.\n * @param {string} props.title - The title of the step.\n * @param {React.ReactNode} props.children - The description of the step's action.\n * @returns {JSX.Element} A styled step component.\n * @private\n */\nconst Step: React.FC<{ icon: React.ReactNode; title: string; children: React.ReactNode; }> = ({ icon, title, children }) => (\n    <div className=\"flex space-x-4\">\n        <div className=\"flex-shrink-0 w-12 h-12 bg-blue-600 text-gray-200 rounded-full flex items-center justify-center\">\n            {icon}\n        </div>\n        <div>\n            <h4 className=\"text-lg font-semibold text-gray-800 mb-1\">{title}</h4>\n            <p className=\"text-gray-600 text-sm\">{children}</p>\n        </div>\n    </div>\n);\n\n/**\n * The main documentation component for the application.\n * It provides a comprehensive, user-friendly guide to using the SFL Prompt Studio.\n * The page is structured into sections covering the SFL framework, key application features,\n * and a step-by-step guide on how to create and use prompts and workflows effectively.\n *\n * @returns {JSX.Element} The rendered documentation page.\n */\nconst Documentation: React.FC = () => {\n    return (\n        <div className=\"space-y-12\">\n            {/* Header */}\n            <header className=\"bg-gradient-to-r from-blue-900/20 to-indigo-900/20 p-8 rounded-xl border border-[#5c6f7e] text-center\">\n                <BookOpenIcon className=\"w-16 h-16 text-blue-600 mx-auto mb-4\" />\n                <h1 className=\"text-4xl font-extrabold text-gray-800 mb-2\">Welcome to SFL Prompt Studio</h1>\n                <p className=\"text-lg text-gray-600 max-w-3xl mx-auto\">\n                    This guide provides everything you need to know to harness the power of Systemic Functional Linguistics (SFL) for precise and effective AI prompt engineering.\n                </p>\n            </header>\n\n            {/* SFL Concepts */}\n            <section>\n                <h2 className=\"text-3xl font-bold text-gray-800 mb-1 text-center\">The SFL Framework</h2>\n                <p className=\"text-center text-gray-500 mb-8 max-w-2xl mx-auto\">SFL helps you control AI output by defining the context of communication. By specifying the Field, Tenor, and Mode, you tell the AI exactly what to do, how to behave, and what structure to use.</p>\n                <div className=\"grid grid-cols-1 lg:grid-cols-3 gap-6\">\n                    <SFLConcept icon={<CubeIcon className=\"w-6 h-6 text-blue-600\" />} title=\"Field\" question=\"What is happening?\">\n                        Specifies the subject matter and knowledge domain. This tells the model <span className=\"font-semibold\">what to talk about</span> (e.g., 'Quantum Physics', 'Python Programming').\n                    </SFLConcept>\n                    <SFLConcept icon={<UsersIcon className=\"w-6 h-6 text-indigo-600\" />} title=\"Tenor\" question=\"Who is taking part?\">\n                        Defines the social roles and relationships. This tells the model <span className=\"font-semibold\">how to behave</span> (e.g., 'Expert Persona', 'Friendly Tone').\n                    </SFLConcept>\n                    <SFLConcept icon={<DocumentTextIcon className=\"w-6 h-6 text-green-600\" />} title=\"Mode\" question=\"What is language doing?\">\n                        Relates to the text's organization and format. This tells the model <span className=\"font-semibold\">how to structure its response</span> (e.g., 'JSON format', 'Bulleted List').\n                    </SFLConcept>\n                </div>\n            </section>\n\n            {/* Key Features */}\n            <section>\n                <h2 className=\"text-3xl font-bold text-gray-800 mb-8 text-center\">Key Features</h2>\n                <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\n                    <FeatureCard icon={<MagicWandIcon className=\"w-6 h-6\" />} title=\"Prompt Wizard\">\n                        Don't know where to start? Just describe your goal, and the wizard will generate a complete, SFL-structured prompt for you using Gemini.\n                    </FeatureCard>\n                    <FeatureCard icon={<SparklesIcon className=\"w-6 h-6\" />} title=\"AI-Powered Refinement\">\n                        Already have a prompt? Use natural language to refine it. Tell the AI \"make this more formal\" and it will update all SFL fields accordingly.\n                    </FeatureCard>\n                    <FeatureCard icon={<BeakerIcon className=\"w-6 h-6\" />} title=\"Direct Gemini Testing\">\n                        Instantly test your prompts with Gemini directly within the app. See the AI's response and iterate quickly without leaving the page.\n                    </FeatureCard>\n                     <FeatureCard icon={<FlaskIcon className=\"w-6 h-6\" />} title=\"Prompt Lab & Workflows\">\n                        Move beyond single prompts. Chain multiple prompts and logic steps together in the Prompt Lab to create powerful, automated workflows and sophisticated AI agents.\n                    </FeatureCard>\n                    <FeatureCard icon={<ArrowDownTrayIcon className=\"w-6 h-6\" />} title=\"Import & Export\">\n                        Easily share your prompt libraries and workflows with your team. Export all prompts as a single JSON or Markdown file, and import libraries from others.\n                    </FeatureCard>\n                </div>\n            </section>\n\n            {/* How to use */}\n            <section>\n                <h2 className=\"text-3xl font-bold text-gray-800 mb-8 text-center\">Your Path to Mastery: From Prompt to Workflow</h2>\n                <div className=\"max-w-3xl mx-auto space-y-8\">\n                    <Step icon={<MagicWandIcon className=\"w-6 h-6\"/>} title=\"1. Build Your Library\">\n                        Use the SFL editor or the AI Wizard to craft high-quality, reusable prompts. A strong, well-defined library is the foundation of powerful and consistent workflows.\n                    </Step>\n                    <Step icon={<FlaskIcon className=\"w-6 h-6\"/>} title=\"2. Enter the Prompt Lab\">\n                        Navigate to the Lab to design your automated agent. Add tasks like Gemini prompts, data inputs, and custom text manipulation to build your workflow's structure.\n                    </Step>\n                    <Step icon={<ArrowsRightLeftIcon className=\"w-6 h-6\"/>} title=\"3. Link Prompts & Define Logic\">\n                        The real power comes from connecting your library. Link a `GEMINI_PROMPT` task to a prompt from your SFL library. Define dependencies to control the flow of data from one task to the next.\n                    </Step>\n                    <Step icon={<PlayIcon className=\"w-6 h-6\"/>} title=\"4. Provide Input & Run\">\n                        Use the User Input Area to stage any necessary text or images for your workflow's starting tasks. Hit \"Run Workflow\" and watch your automated agent execute step by step.\n                    </Step>\n                     <Step icon={<CodeBracketIcon className=\"w-6 h-6\"/>} title=\"5. Analyze & Iterate\">\n                        Examine the final output and inspect the `Data Store` to see the result of each individual step. Use these insights to refine your SFL prompts or workflow logic and run again.\n                    </Step>\n                </div>\n            </section>\n        </div>\n    );\n};\n\nexport default Documentation;\n",
      "metadata": {
        "filename": "Documentation.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/FilterControls.tsx\n\n/**\n * @file FilterControls.tsx\n * @description This component provides a set of UI controls for filtering a list of prompts.\n * It allows users to filter by a search term, topic, task type, AI persona, and output format.\n * The component is designed to be a controlled component, receiving the current filter state and\n * callback functions from its parent to handle state changes.\n *\n * @requires react\n * @requires ../types\n * @requires ../constants\n */\n\nimport React from 'react';\nimport { Filters } from '../types';\nimport { TASK_TYPES, AI_PERSONAS, OUTPUT_FORMATS } from '../constants';\n\n/**\n * @interface FilterControlsProps\n * @description Defines the props for the `FilterControls` component.\n * @property {Filters} filters - The current state of the filters. This object's values populate the form fields.\n * @property {(key: K, value: Filters[K]) => void} onFilterChange - A generic callback function to update a specific filter property in the parent component's state.\n * @property {() => void} onResetFilters - A callback function to reset all filters to their default state in the parent component.\n */\ninterface FilterControlsProps {\n  filters: Filters;\n  onFilterChange: <K extends keyof Filters>(key: K, value: Filters[K]) => void;\n  onResetFilters: () => void;\n}\n\n/**\n * A component that renders a form with a set of controls for filtering prompts.\n * It includes text inputs for free-form searching and select dropdowns for\n * filtering based on predefined SFL categories.\n *\n * @param {FilterControlsProps} props - The props for the component, including the current filter values and change handlers.\n * @returns {JSX.Element} The rendered filter controls form.\n */\nconst FilterControls: React.FC<FilterControlsProps> = ({ filters, onFilterChange, onResetFilters }) => {\n  /**\n   * Handles `onChange` events from any of the input or select elements within the form.\n   * It extracts the `name` and `value` from the event target and calls the `onFilterChange`\n   * prop to update the parent component's state.\n   *\n   * @param {React.ChangeEvent<HTMLInputElement | HTMLSelectElement>} e - The DOM change event.\n   * @private\n   */\n  const handleInputChange = (e: React.ChangeEvent<HTMLInputElement | HTMLSelectElement>) => {\n    const { name, value } = e.target;\n    onFilterChange(name as keyof Filters, value);\n  };\n\n  return (\n    <div className=\"bg-[#333e48] p-4 shadow-lg rounded-lg h-full flex flex-col text-gray-200\">\n      <h2 className=\"text-xl font-semibold text-[#e2a32d] mb-4 border-b pb-2 border-[#5c6f7e]\">Filter Prompts</h2>\n      <div className=\"space-y-4 flex-grow overflow-y-auto pr-2\">\n        <div>\n          <label htmlFor=\"searchTerm\" className=\"block text-sm font-medium text-[#95aac0] mb-1\">Search Term</label>\n          <input\n            type=\"text\"\n            id=\"searchTerm\"\n            name=\"searchTerm\"\n            value={filters.searchTerm}\n            onChange={handleInputChange}\n            placeholder=\"Search in title, text...\"\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors placeholder-[#95aac0]\"\n          />\n        </div>\n        <div>\n          <label htmlFor=\"topic\" className=\"block text-sm font-medium text-[#95aac0] mb-1\">Topic</label>\n          <input\n            type=\"text\"\n            id=\"topic\"\n            name=\"topic\"\n            value={filters.topic}\n            onChange={handleInputChange}\n            placeholder=\"e.g., History, Coding\"\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors placeholder-[#95aac0]\"\n          />\n        </div>\n        <div>\n          <label htmlFor=\"taskType\" className=\"block text-sm font-medium text-[#95aac0] mb-1\">Task Type</label>\n          <select\n            id=\"taskType\"\n            name=\"taskType\"\n            value={filters.taskType}\n            onChange={handleInputChange}\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors\"\n          >\n            <option value=\"\" className=\"text-[#95aac0]\">All Task Types</option>\n            {TASK_TYPES.map(type => <option key={type} value={type} className=\"bg-[#212934] text-gray-200\">{type}</option>)}\n          </select>\n        </div>\n        <div>\n          <label htmlFor=\"aiPersona\" className=\"block text-sm font-medium text-[#95aac0] mb-1\">AI Persona</label>\n          <select\n            id=\"aiPersona\"\n            name=\"aiPersona\"\n            value={filters.aiPersona}\n            onChange={handleInputChange}\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors\"\n          >\n            <option value=\"\" className=\"text-[#95aac0]\">All Personas</option>\n            {AI_PERSONAS.map(persona => <option key={persona} value={persona} className=\"bg-[#212934] text-gray-200\">{persona}</option>)}\n          </select>\n        </div>\n        <div>\n          <label htmlFor=\"outputFormat\" className=\"block text-sm font-medium text-[#95aac0] mb-1\">Output Format</label>\n          <select\n            id=\"outputFormat\"\n            name=\"outputFormat\"\n            value={filters.outputFormat}\n            onChange={handleInputChange}\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors\"\n          >\n            <option value=\"\" className=\"text-[#95aac0]\">All Formats</option>\n            {OUTPUT_FORMATS.map(format => <option key={format} value={format} className=\"bg-[#212934] text-gray-200\">{format}</option>)}\n          </select>\n        </div>\n      </div>\n      <button\n        onClick={onResetFilters}\n        className=\"mt-6 w-full bg-[#5c6f7e] hover:bg-opacity-90 text-gray-200 font-semibold py-2 px-4 rounded-lg transition-colors focus:outline-none focus:ring-2 focus:ring-[#95aac0] focus:ring-offset-2 focus:ring-offset-[#333e48]\"\n      >\n        Reset Filters\n      </button>\n    </div>\n  );\n};\n\nexport default FilterControls;\n",
      "metadata": {
        "filename": "FilterControls.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/Header.tsx\n\n/**\n * @file Header.tsx\n * @description This component renders the main application header.\n * It includes the application title and a set of primary action buttons for creating, importing,\n * exporting, and getting help with prompts. It is a stateless component that receives all its\n * functionality via props.\n *\n * @requires react\n * @requires ./icons/PlusIcon\n * @requires ./icons/MagicWandIcon\n * @requires ./icons/ArrowUpTrayIcon\n * @requires ./icons/ArrowDownTrayIcon\n * @requires ./icons/QuestionMarkCircleIcon\n * @requires ./icons/DocumentTextIcon\n */\n\nimport React from 'react';\nimport PlusIcon from './icons/PlusIcon';\nimport MagicWandIcon from './icons/MagicWandIcon';\nimport ArrowUpTrayIcon from './icons/ArrowUpTrayIcon';\nimport ArrowDownTrayIcon from './icons/ArrowDownTrayIcon';\nimport QuestionMarkCircleIcon from './icons/QuestionMarkCircleIcon';\nimport DocumentTextIcon from './icons/DocumentTextIcon';\n\n/**\n * @interface HeaderProps\n * @description Defines the props for the `Header` component.\n * It consists of a collection of callback functions to be triggered by the various action buttons in the header.\n * @property {() => void} onAddNewPrompt - Callback function invoked when the \"New Prompt\" button is clicked.\n * @property {() => void} onOpenWizard - Callback function invoked when the \"Prompt Wizard\" button is clicked.\n * @property {() => void} onImportPrompts - Callback function invoked when the \"Import Prompts\" button is clicked.\n * @property {() => void} onExportAllPrompts - Callback function invoked when the \"Export All as JSON\" button is clicked.\n * @property {() => void} onExportAllPromptsMarkdown - Callback function invoked when the \"Export All as Markdown\" button is clicked.\n * @property {() => void} onOpenHelp - Callback function invoked when the \"Help Guide\" button is clicked.\n */\ninterface HeaderProps {\n  onAddNewPrompt: () => void;\n  onOpenWizard: () => void;\n  onImportPrompts: () => void;\n  onExportAllPrompts: () => void;\n  onExportAllPromptsMarkdown: () => void;\n  onOpenHelp: () => void;\n}\n\n/**\n * The main header component for the application.\n * It displays the application title and provides a set of globally-relevant action buttons\n * for managing the prompt library.\n *\n * @param {HeaderProps} props - The props for the component, containing the necessary event handlers.\n * @returns {JSX.Element} The rendered header element.\n */\nconst Header: React.FC<HeaderProps> = ({ onAddNewPrompt, onOpenWizard, onImportPrompts, onExportAllPrompts, onExportAllPromptsMarkdown, onOpenHelp }) => {\n  return (\n    <header className=\"mb-6 flex items-center justify-between\">\n      <h1 className=\"text-3xl font-bold text-[#e2a32d]\">SFL Prompt Studio</h1>\n      <div className=\"flex items-center space-x-3\">\n        <div className=\"flex space-x-2 border-r border-[#5c6f7e] pr-3 mr-1\">\n            <button\n              onClick={onOpenHelp}\n              className=\"bg-transparent border border-[#5c6f7e] hover:bg-[#5c6f7e] text-gray-200 font-semibold py-2 px-3 rounded-lg shadow-sm hover:shadow-md transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#95aac0] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n              aria-label=\"Open help guide\"\n              title=\"Help Guide\"\n            >\n              <QuestionMarkCircleIcon className=\"w-5 h-5\" />\n            </button>\n            <button\n              onClick={onImportPrompts}\n              className=\"bg-transparent border border-[#5c6f7e] hover:bg-[#5c6f7e] text-gray-200 font-semibold py-2 px-3 rounded-lg shadow-sm hover:shadow-md transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#95aac0] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n              aria-label=\"Import prompts\"\n              title=\"Import Prompts\"\n            >\n              <ArrowUpTrayIcon className=\"w-5 h-5\" />\n            </button>\n            <button\n              onClick={onExportAllPrompts}\n              className=\"bg-transparent border border-[#5c6f7e] hover:bg-[#5c6f7e] text-gray-200 font-semibold py-2 px-3 rounded-lg shadow-sm hover:shadow-md transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#95aac0] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n              aria-label=\"Export all prompts as JSON\"\n              title=\"Export All as JSON\"\n            >\n              <ArrowDownTrayIcon className=\"w-5 h-5\" />\n            </button>\n             <button\n              onClick={onExportAllPromptsMarkdown}\n              className=\"bg-transparent border border-[#5c6f7e] hover:bg-[#5c6f7e] text-gray-200 font-semibold py-2 px-3 rounded-lg shadow-sm hover:shadow-md transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#95aac0] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n              aria-label=\"Export all prompts as Markdown\"\n              title=\"Export All as Markdown\"\n            >\n              <DocumentTextIcon className=\"w-5 h-5\" />\n            </button>\n        </div>\n        <button\n          onClick={onOpenWizard}\n          className=\"bg-[#5c6f7e] hover:bg-opacity-90 text-gray-200 font-semibold py-2 px-4 rounded-lg shadow-md hover:shadow-lg transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n          aria-label=\"Open Prompt Wizard\"\n        >\n          <MagicWandIcon className=\"w-5 h-5 mr-2\" />\n          Prompt Wizard\n        </button>\n        <button\n          onClick={onAddNewPrompt}\n          className=\"bg-[#c36e26] hover:bg-opacity-90 text-gray-200 font-semibold py-2 px-4 rounded-lg shadow-md hover:shadow-lg transition-all duration-150 ease-in-out flex items-center focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:ring-offset-2 focus:ring-offset-[#212934]\"\n          aria-label=\"Create new prompt\"\n        >\n          <PlusIcon className=\"w-5 h-5 mr-2\" />\n          New Prompt\n        </button>\n      </div>\n    </header>\n  );\n};\n\nexport default Header;\n",
      "metadata": {
        "filename": "Header.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/HelpModal.tsx\n\n/**\n * @file HelpModal.tsx\n * @description This component renders a detailed help and guidance modal for SFL Prompt Engineering.\n * It explains the three SFL metafunctions (Field, Tenor, Mode) and their constituent parameters,\n * providing both a user-friendly definition and an \"algorithmic representation\" of how each parameter\n * influences an AI model's behavior.\n *\n * @requires react\n * @requires ./ModalShell\n */\n\nimport React from 'react';\nimport ModalShell from './ModalShell';\n\n/**\n * A presentational component to structure a major section within the help modal (e.g., Field, Tenor, Mode).\n *\n * @param {object} props - The component props.\n * @param {string} props.title - The main title of the section (e.g., \"Field (Ideational Metafunction)\").\n * @param {string} props.subtitle - The guiding question for the section (e.g., \"What is happening?\").\n * @param {React.ReactNode} props.children - The content of the section, typically a series of `DetailBlock` components.\n * @returns {JSX.Element} A styled section element for organizing help content.\n * @private\n */\nconst HelpSection: React.FC<{ title: string; subtitle: string; children: React.ReactNode }> = ({ title, subtitle, children }) => (\n    <div className=\"mb-8\">\n        <h3 className=\"text-2xl font-bold text-gray-200\">{title}</h3>\n        <p className=\"text-md text-[#95aac0] mb-3 italic\">\"{subtitle}\"</p>\n        <div className=\"space-y-4 text-gray-200 text-sm leading-relaxed pl-4 border-l-2 border-[#5c6f7e]\">\n            {children}\n        </div>\n    </div>\n);\n\n/**\n * A presentational component to display the detailed explanation of a single SFL parameter.\n * It separates the parameter's name, its definition, and a technical explanation of its effect on the AI.\n *\n * @param {object} props - The component props.\n * @param {string} props.term - The name of the SFL parameter (e.g., \"Topic\").\n * @param {string} props.definition - A user-friendly definition of the parameter.\n * @param {string} props.algo - An \"algorithmic representation\" explaining how the parameter affects the AI model's token generation.\n * @returns {JSX.Element} A styled block containing the detailed explanation of an SFL parameter.\n * @private\n */\nconst DetailBlock: React.FC<{ term: string; definition: string; algo: string }> = ({ term, definition, algo }) => (\n    <div>\n        <h4 className=\"font-semibold text-gray-800 text-base\">{term}</h4>\n        <p className=\"mb-1\">{definition}</p>\n        <div className=\"bg-[#212934] p-3 rounded-md border border-[#5c6f7e]\">\n            <p className=\"font-mono text-xs text-gray-600\"><span className=\"font-semibold text-[#4A69E2]\">Algorithmic Representation:</span> {algo}</p>\n        </div>\n    </div>\n);\n\n/**\n * @interface HelpModalProps\n * @description Defines the props for the `HelpModal` component.\n * @property {boolean} isOpen - Controls the visibility of the modal.\n * @property {() => void} onClose - Callback function to close the modal.\n */\ninterface HelpModalProps {\n    isOpen: boolean;\n    onClose: () => void;\n}\n\n/**\n * The main modal component that provides a comprehensive guide to SFL prompt engineering.\n * It uses `ModalShell` as its base and is composed of `HelpSection` and `DetailBlock` components\n * to present the information in a structured and easy-to-digest format for the user.\n *\n * @param {HelpModalProps} props - The props for the component.\n * @returns {JSX.Element | null} The rendered modal, or `null` if `isOpen` is false.\n */\nconst HelpModal: React.FC<HelpModalProps> = ({ isOpen, onClose }) => {\n    return (\n        <ModalShell isOpen={isOpen} onClose={onClose} title=\"SFL Prompt Engineering Guide\" size=\"4xl\">\n            <div className=\"prose max-w-none text-gray-800\">\n                <p className=\"text-md mb-6 border-b border-gray-200 pb-4\">\n                    Systemic Functional Linguistics (SFL) provides a powerful framework for engineering prompts. By systematically defining the context of communication, you gain precise control over the AI's generation process. This guide explains each SFL parameter in terms of its effect on the AI model's behavior.\n                </p>\n\n                <HelpSection title=\"Field (Ideational Metafunction)\" subtitle=\"What is happening?\">\n                    <p>\n                        'Field' specifies the subject matter and the nature of the activity. For an AI, this sets the knowledge domain and the type of process it should execute. It tells the model what to talk about.\n                    </p>\n                    <DetailBlock\n                        term=\"Topic\"\n                        definition=\"The high-level subject area of the prompt.\"\n                        algo=\"Directly maps to high-dimensional vector spaces where related concepts are clustered. Providing a 'Topic' primes the model's attention mechanism to focus on specific sub-regions of its knowledge graph (e.g., 'Astrophysics' activates neurons associated with space, physics, stars).\"\n                    />\n                    <DetailBlock\n                        term=\"Task Type\"\n                        definition=\"The specific action the AI should perform with the information.\"\n                        algo=\"Configures the model's internal 'mode of operation'. 'Code Generation' activates different sequence-to-sequence pathways than 'Creative Writing'. This parameter influences the choice of syntax, logical flow, and token generation patterns. For example, 'Summarization' prioritizes information compression, while 'Explanation' prioritizes building logical connections and using analogies.\"\n                    />\n                    <DetailBlock\n                        term=\"Domain Specifics\"\n                        definition=\"Fine-grained contextual details, constraints, or specific sub-fields.\"\n                        algo=\"Acts as a powerful filter within the activated 'Topic' vector space. It constrains the model's vocabulary and factual recall. 'Python 3.9, pandas' instructs the model to use the syntax and library functions specific to that environment, avoiding anachronisms or irrelevant libraries.\"\n                    />\n                    <DetailBlock\n                        term=\"Keywords\"\n                        definition=\"Explicit terms that must be included or are central to the response.\"\n                        algo=\"Act as explicit 'attention magnets'. Each keyword strongly biases the model to include or relate to the concept represented by that keyword's embedding. It's a direct way to ensure certain concepts are present in the output, guiding token selection at multiple points during generation.\"\n                    />\n                </HelpSection>\n\n                <HelpSection title=\"Tenor (Interpersonal Metafunction)\" subtitle=\"Who is taking part?\">\n                     <p>\n                        'Tenor' defines the social roles and relationships between the participants. For an AI, this dictates its persona, the assumed knowledge of the audience, and the desired social tone. It tells the model how to behave.\n                    </p>\n                    <DetailBlock\n                        term=\"AI Persona\"\n                        definition=\"The character or role the AI should adopt.\"\n                        algo=\"Loads a 'behavioral model' or 'character' from the AI's training data. The persona 'Sarcastic Bot' will apply a filter to its word choices, favoring tokens associated with irony and wit. 'Expert' will increase the probability of using technical jargon and a formal sentence structure. It's a high-level instruction that conditions the entire generation process.\"\n                    />\n                     <DetailBlock\n                        term=\"Target Audience\"\n                        definition=\"The intended recipient of the AI's response.\"\n                        algo=\"Adjusts the model's 'complexity dial'. It directly influences vocabulary choice and sentence structure. 'Experts' allows for dense, technical language. 'Children' forces the model to select simpler words, use shorter sentences, and rely on concrete examples, effectively pruning the search space of possible next tokens.\"\n                    />\n                    <DetailBlock\n                        term=\"Desired Tone\"\n                        definition=\"The emotional and stylistic attitude of the response.\"\n                        algo=\"Modifies the emotional and stylistic valence of the generated text. 'Formal' will up-weight tokens and grammatical structures associated with academic writing. 'Humorous' will activate pathways related to wordplay and irony. It's a fine-tuning parameter applied over the persona and content.\"\n                    />\n                    <DetailBlock\n                        term=\"Interpersonal Stance\"\n                        definition=\"The social relationship and power dynamic between the AI and the user.\"\n                        algo=\"Defines the pragmatic function of the language. 'Act as a mentor' biases the model to be encouraging and provide guidance. 'Be a collaborative partner' encourages more tentative language and suggestions, influencing turn-taking and politeness strategies in the model's output.\"\n                    />\n                </HelpSection>\n                \n                <HelpSection title=\"Mode (Textual Metafunction)\" subtitle=\"What role is language playing?\">\n                     <p>\n                        'Mode' relates to how the text is organized and its function in the context. For an AI, this is about the channel, structure, and format of the output. It tells the model how to structure the text.\n                    </p>\n                    <DetailBlock\n                        term=\"Output Format\"\n                        definition=\"The required syntactical structure of the output (e.g., JSON, Markdown).\"\n                        algo={`A hard constraint on the output's structure. 'JSON' forces the model's generation to be heavily constrained by a finite state machine representing JSON syntax. This dramatically alters token probabilities to fit the required structure (e.g., high probability of a '\"' after a '{'). It is a powerful structural control.`}\n                    />\n                    <DetailBlock\n                        term=\"Rhetorical Structure\"\n                        definition=\"The high-level organizational pattern of the text.\"\n                        algo=\"Provides a 'scaffold' or 'template' for the text. 'Problem-Solution' instructs the model to generate text in two distinct parts, guiding the discourse structure and ensuring a logical flow from one part to the next. The model plans its output to fit this narrative arc.\"\n                    />\n                    <DetailBlock\n                        term=\"Length Constraint\"\n                        definition=\"The desired length of the response.\"\n                        algo=\"Directly influences the model's internal stopping criteria. 'Short Paragraph (~50 words)' sets a target token count. The model will try to generate a coherent thought within that limit, adjusting its level of detail to fit. It's a 'soft' guide for composition, distinct from a hard API token limit.\"\n                    />\n                    <DetailBlock\n                        term=\"Textual Directives\"\n                        definition=\"Specific, micro-level rules about style or grammar.\"\n                        algo=\"These are fine-grained filters on the final token selection. 'Use active voice' will down-weight the probability of generating passive constructions (e.g., 'was done by'). 'Avoid jargon' acts as a negative constraint, telling the model to avoid specific tokens or classes of tokens.\"\n                    />\n                </HelpSection>\n            </div>\n             <div className=\"flex justify-end pt-4 mt-6 border-t border-gray-200\">\n                <button\n                    onClick={onClose}\n                    className=\"px-4 py-2 text-sm font-medium text-gray-200 bg-[#333e48] border border-[#5c6f7e] rounded-md hover:bg-[#212934] focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-[#e2a32d]\"\n                >\n                    Close\n                </button>\n            </div>\n        </ModalShell>\n    );\n};\n\nexport default HelpModal;\n",
      "metadata": {
        "filename": "HelpModal.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/ModalShell.tsx\n\n/**\n * @file ModalShell.tsx\n * @description This component provides a reusable, styled wrapper for all modal dialogs in the application.\n * It handles the modal's open/close state, provides a background overlay, and includes a consistent header with a title and close button.\n * The size of the modal can be customized via props to accommodate different content needs.\n *\n * @requires react\n */\n\nimport React from 'react';\n\n/**\n * @interface ModalShellProps\n * @description Defines the props for the `ModalShell` component.\n * @property {boolean} isOpen - Determines if the modal is visible. When `false`, the component returns `null`.\n * @property {() => void} onClose - Callback function to be invoked when the modal should be closed, typically triggered by the close button.\n * @property {string} title - The title to be displayed in the modal's header.\n * @property {React.ReactNode} children - The content to be rendered inside the modal's body.\n * @property {'sm' | 'md' | 'lg' | 'xl' | '2xl' | '3xl' | '4xl' | '5xl'} [size='xl'] - The maximum width of the modal, corresponding to Tailwind CSS max-width classes. Defaults to 'xl'.\n */\ninterface ModalShellProps {\n  isOpen: boolean;\n  onClose: () => void;\n  title: string;\n  children: React.ReactNode;\n  size?: 'sm' | 'md' | 'lg' | 'xl' | '2xl' | '3xl' | '4xl' | '5xl';\n}\n\n/**\n * A reusable shell component for creating consistent modal dialogs across the application.\n * It provides the basic structure, styling, and behavior for a modal, including:\n * - A semi-transparent backdrop overlay.\n * - A centered container with a configurable maximum width.\n * - A header with a title and a close button.\n * - A scrollable content area for the modal's body.\n *\n * @param {ModalShellProps} props - The props for the component.\n * @returns {JSX.Element | null} The rendered modal component, or `null` if `isOpen` is `false`.\n *\n * @example\n * <ModalShell isOpen={isModalOpen} onClose={() => setModalOpen(false)} title=\"My Modal\">\n *   <p>This is the content of the modal.</p>\n * </ModalShell>\n */\nconst ModalShell: React.FC<ModalShellProps> = ({ isOpen, onClose, title, children, size = 'xl' }) => {\n  if (!isOpen) return null;\n\n  /**\n   * @constant {Record<string, string>} sizeClasses\n   * @description A mapping of size keys to their corresponding Tailwind CSS max-width classes.\n   * @private\n   */\n  const sizeClasses: Record<string, string> = {\n    sm: 'max-w-sm',\n    md: 'max-w-md',\n    lg: 'max-w-lg',\n    xl: 'max-w-xl',\n    '2xl': 'max-w-2xl',\n    '3xl': 'max-w-3xl',\n    '4xl': 'max-w-4xl',\n    '5xl': 'max-w-5xl',\n  };\n\n  return (\n    <div\n      className=\"fixed inset-0 z-50 flex items-center justify-center bg-black bg-opacity-70 backdrop-blur-sm p-4\"\n      role=\"dialog\"\n      aria-modal=\"true\"\n      aria-labelledby=\"modal-title\"\n    >\n      <div className={`bg-[#333e48] rounded-lg shadow-xl w-full ${sizeClasses[size]} flex flex-col max-h-[90vh] border border-[#5c6f7e]`}>\n        <div className=\"flex items-center justify-between p-4 border-b border-[#5c6f7e]\">\n          <h3 id=\"modal-title\" className=\"text-xl font-semibold text-gray-200\">{title}</h3>\n          <button\n            onClick={onClose}\n            className=\"text-[#95aac0] hover:text-gray-200 transition-colors\"\n            aria-label=\"Close modal\"\n          >\n            <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" className=\"w-6 h-6\">\n              <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M6 18L18 6M6 6l12 12\" />\n            </svg>\n          </button>\n        </div>\n        <div className=\"p-6 overflow-y-auto\">\n          {children}\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ModalShell;\n",
      "metadata": {
        "filename": "ModalShell.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/ParameterControls.tsx\n\n/**\n * @file ParameterControls.tsx\n * @description This component provides detailed parameter configuration controls for AI models.\n * It offers advanced parameter tuning with validation, presets, and real-time feedback\n * on parameter effects and constraints.\n *\n * @requires react\n * @requires ../types/aiProvider\n * @requires ../config/modelCapabilities\n */\n\nimport React, { useState, useEffect } from 'react';\nimport { AIProvider, ModelParameters, ParameterPreset } from '../types/aiProvider';\nimport { \n  getParameterConstraints, \n  getProviderPresets, \n  validateParameters,\n  PARAMETER_PRESETS \n} from '../config/modelCapabilities';\nimport CogIcon from './icons/CogIcon';\nimport BeakerIcon from './icons/BeakerIcon';\nimport CheckCircleIcon from './icons/CheckCircleIcon';\nimport XCircleIcon from './icons/XCircleIcon';\nimport QuestionMarkCircleIcon from './icons/QuestionMarkCircleIcon';\n\n/**\n * @interface ParameterControlsProps\n * @description Defines the props for the ParameterControls component.\n */\ninterface ParameterControlsProps {\n  /** Current AI provider */\n  provider: AIProvider;\n  /** Current model ID */\n  modelId: string;\n  /** Current parameter values */\n  parameters: ModelParameters;\n  /** Callback when parameters change */\n  onParametersChange: (parameters: ModelParameters) => void;\n  /** Whether to show advanced controls */\n  showAdvanced?: boolean;\n  /** Whether to show parameter descriptions */\n  showDescriptions?: boolean;\n}\n\n/**\n * Parameter information for user guidance\n */\nconst PARAMETER_INFO: Record<string, { description: string; effect: string }> = {\n  temperature: {\n    description: \"Controls randomness in generation\",\n    effect: \"Higher values (0.8-2.0) = more creative, lower values (0.1-0.5) = more focused\"\n  },\n  maxTokens: {\n    description: \"Maximum number of tokens to generate\",\n    effect: \"Higher values = longer responses, lower values = shorter responses\"\n  },\n  topK: {\n    description: \"Limits vocabulary to top K most likely tokens\",\n    effect: \"Lower values = more focused, higher values = more diverse\"\n  },\n  topP: {\n    description: \"Nucleus sampling threshold\",\n    effect: \"Lower values (0.1-0.5) = more focused, higher values (0.8-1.0) = more diverse\"\n  },\n  top_p: {\n    description: \"Nucleus sampling threshold (OpenAI format)\",\n    effect: \"Lower values (0.1-0.5) = more focused, higher values (0.8-1.0) = more diverse\"\n  },\n  top_k: {\n    description: \"Top-K sampling parameter\",\n    effect: \"Lower values = more focused, higher values = more diverse\"\n  },\n  presence_penalty: {\n    description: \"Penalizes tokens based on presence in text\",\n    effect: \"Positive values discourage repetition, negative values encourage repetition\"\n  },\n  frequency_penalty: {\n    description: \"Penalizes tokens based on frequency in text\",\n    effect: \"Positive values reduce repetitive content, negative values increase repetition\"\n  },\n  repetition_penalty: {\n    description: \"Penalizes repeated tokens\",\n    effect: \"Values > 1.0 discourage repetition, values < 1.0 encourage repetition\"\n  },\n  min_p: {\n    description: \"Minimum probability threshold for token selection\",\n    effect: \"Higher values = more conservative choices, lower values = more creative\"\n  }\n};\n\n/**\n * A comprehensive component for configuring AI model parameters with\n * validation, presets, and detailed control over generation behavior.\n *\n * @param {ParameterControlsProps} props - The component props\n * @returns {JSX.Element} The rendered parameter controls\n */\nconst ParameterControls: React.FC<ParameterControlsProps> = ({\n  provider,\n  modelId,\n  parameters,\n  onParametersChange,\n  showAdvanced = true,\n  showDescriptions = true\n}) => {\n  // Local state\n  const [constraints, setConstraints] = useState<any>({});\n  const [validation, setValidation] = useState<{ valid: boolean; errors: string[] }>({ valid: true, errors: [] });\n  const [availablePresets, setAvailablePresets] = useState<ParameterPreset[]>([]);\n  const [selectedPreset, setSelectedPreset] = useState<string>('');\n  const [showTooltip, setShowTooltip] = useState<string>('');\n\n  // Load constraints and presets when provider/model changes\n  useEffect(() => {\n    const modelConstraints = getParameterConstraints(provider, modelId);\n    setConstraints(modelConstraints);\n    \n    const presets = getProviderPresets(provider);\n    setAvailablePresets(presets);\n    \n    // Validate current parameters\n    const validationResult = validateParameters(provider, modelId, parameters);\n    setValidation(validationResult);\n  }, [provider, modelId]);\n\n  // Validate parameters when they change\n  useEffect(() => {\n    const validationResult = validateParameters(provider, modelId, parameters);\n    setValidation(validationResult);\n  }, [parameters, provider, modelId]);\n\n  /**\n   * Handle parameter value change\n   */\n  const handleParameterChange = (paramName: string, value: number | string) => {\n    const newParameters = {\n      ...parameters,\n      [paramName]: value\n    };\n    \n    onParametersChange(newParameters);\n    setSelectedPreset(''); // Clear preset selection when manually changing parameters\n  };\n\n  /**\n   * Apply a parameter preset\n   */\n  const applyPreset = (presetName: string) => {\n    const preset = availablePresets.find(p => p.name === presetName);\n    if (preset) {\n      onParametersChange(preset.parameters);\n      setSelectedPreset(presetName);\n    }\n  };\n\n  /**\n   * Reset parameters to defaults\n   */\n  const resetToDefaults = () => {\n    const defaultPreset = availablePresets.find(p => p.name.toLowerCase().includes('balanced'));\n    if (defaultPreset) {\n      onParametersChange(defaultPreset.parameters);\n      setSelectedPreset(defaultPreset.name);\n    }\n  };\n\n  /**\n   * Render a single parameter control\n   */\n  const renderParameterControl = (paramName: string, constraint: any) => {\n    const currentValue = (parameters as any)[paramName] ?? constraint.default;\n    const paramInfo = PARAMETER_INFO[paramName];\n    const hasError = validation.errors.some(error => error.includes(paramName));\n\n    return (\n      <div key={paramName} className=\"space-y-2\">\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center space-x-2\">\n            <label className=\"text-sm font-medium text-[#95aac0] capitalize\">\n              {paramName.replace(/([A-Z])/g, ' $1').replace(/_/g, ' ')}\n            </label>\n            {paramInfo && showDescriptions && (\n              <div className=\"relative\">\n                <button\n                  onMouseEnter={() => setShowTooltip(paramName)}\n                  onMouseLeave={() => setShowTooltip('')}\n                  className=\"text-[#95aac0] hover:text-[#e2a32d]\"\n                >\n                  <QuestionMarkCircleIcon className=\"w-4 h-4\" />\n                </button>\n                {showTooltip === paramName && (\n                  <div className=\"absolute z-10 bottom-full left-0 mb-2 w-64 p-3 bg-[#212934] border border-[#5c6f7e] rounded-lg shadow-lg\">\n                    <p className=\"text-xs text-gray-200 mb-2\">{paramInfo.description}</p>\n                    <p className=\"text-xs text-[#95aac0]\">{paramInfo.effect}</p>\n                  </div>\n                )}\n              </div>\n            )}\n          </div>\n          <div className=\"flex items-center space-x-2\">\n            {hasError && <XCircleIcon className=\"w-4 h-4 text-red-500\" />}\n            <span className=\"text-xs text-[#95aac0]\">\n              {constraint.min} - {constraint.max}\n            </span>\n          </div>\n        </div>\n\n        <div className=\"space-y-2\">\n          {/* Range Slider */}\n          <div className=\"flex items-center space-x-3\">\n            <input\n              type=\"range\"\n              min={constraint.min}\n              max={constraint.max}\n              step={constraint.step}\n              value={currentValue}\n              onChange={(e) => handleParameterChange(paramName, parseFloat(e.target.value))}\n              className={`flex-1 h-2 rounded-lg appearance-none cursor-pointer ${\n                hasError ? 'bg-red-900' : 'bg-[#5c6f7e]'\n              } slider`}\n            />\n            <input\n              type=\"number\"\n              min={constraint.min}\n              max={constraint.max}\n              step={constraint.step}\n              value={currentValue}\n              onChange={(e) => handleParameterChange(paramName, parseFloat(e.target.value))}\n              className={`w-20 px-2 py-1 text-sm bg-[#212934] border rounded text-gray-200 focus:outline-none ${\n                hasError \n                  ? 'border-red-500 focus:border-red-400' \n                  : 'border-[#5c6f7e] focus:border-[#e2a32d]'\n              }`}\n            />\n          </div>\n\n          {/* Quick Value Buttons */}\n          <div className=\"flex space-x-1\">\n            <button\n              onClick={() => handleParameterChange(paramName, constraint.min)}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Min\n            </button>\n            <button\n              onClick={() => handleParameterChange(paramName, constraint.default)}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Default\n            </button>\n            <button\n              onClick={() => handleParameterChange(paramName, constraint.max)}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Max\n            </button>\n          </div>\n        </div>\n      </div>\n    );\n  };\n\n  const sortedConstraints = Object.entries(constraints).sort(([a], [b]) => {\n    // Sort temperature and maxTokens first, then alphabetically\n    const priority = ['temperature', 'maxTokens', 'topK', 'topP', 'top_p', 'top_k'];\n    const aIndex = priority.indexOf(a);\n    const bIndex = priority.indexOf(b);\n    \n    if (aIndex !== -1 && bIndex !== -1) return aIndex - bIndex;\n    if (aIndex !== -1) return -1;\n    if (bIndex !== -1) return 1;\n    return a.localeCompare(b);\n  });\n\n  return (\n    <div className=\"bg-[#333e48] border border-[#5c6f7e] rounded-lg p-4 space-y-4\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between\">\n        <div className=\"flex items-center space-x-2\">\n          <CogIcon className=\"w-5 h-5 text-[#e2a32d]\" />\n          <h3 className=\"text-sm font-semibold text-[#e2a32d]\">Model Parameters</h3>\n        </div>\n        <div className=\"flex items-center space-x-2\">\n          {validation.valid ? (\n            <div className=\"flex items-center space-x-1\">\n              <CheckCircleIcon className=\"w-4 h-4 text-green-500\" />\n              <span className=\"text-xs text-green-500\">Valid</span>\n            </div>\n          ) : (\n            <div className=\"flex items-center space-x-1\">\n              <XCircleIcon className=\"w-4 h-4 text-red-500\" />\n              <span className=\"text-xs text-red-500\">{validation.errors.length} errors</span>\n            </div>\n          )}\n        </div>\n      </div>\n\n      {/* Validation Errors */}\n      {!validation.valid && (\n        <div className=\"p-3 bg-red-900 bg-opacity-20 border border-red-500 rounded space-y-1\">\n          {validation.errors.map((error, index) => (\n            <p key={index} className=\"text-xs text-red-400\">{error}</p>\n          ))}\n        </div>\n      )}\n\n      {/* Presets */}\n      {availablePresets.length > 0 && (\n        <div className=\"space-y-2\">\n          <div className=\"flex items-center space-x-2\">\n            <BeakerIcon className=\"w-4 h-4 text-[#95aac0]\" />\n            <label className=\"text-sm font-medium text-[#95aac0]\">Presets</label>\n          </div>\n          <div className=\"grid grid-cols-2 gap-2\">\n            {availablePresets.map((preset) => (\n              <button\n                key={preset.name}\n                onClick={() => applyPreset(preset.name)}\n                className={`p-2 text-left rounded border transition-colors ${\n                  selectedPreset === preset.name\n                    ? 'border-[#e2a32d] bg-[#e2a32d] bg-opacity-10'\n                    : 'border-[#5c6f7e] hover:border-[#95aac0]'\n                }`}\n              >\n                <div className=\"text-sm font-medium text-gray-200\">{preset.name}</div>\n                <div className=\"text-xs text-[#95aac0]\">{preset.description}</div>\n              </button>\n            ))}\n          </div>\n        </div>\n      )}\n\n      {/* Parameter Controls */}\n      {sortedConstraints.length > 0 && (\n        <div className=\"space-y-4\">\n          <label className=\"text-sm font-medium text-[#95aac0]\">Parameters</label>\n          <div className=\"space-y-4\">\n            {sortedConstraints.map(([paramName, constraint]) =>\n              renderParameterControl(paramName, constraint)\n            )}\n          </div>\n        </div>\n      )}\n\n      {/* Advanced Parameters */}\n      {showAdvanced && sortedConstraints.length === 0 && (\n        <div className=\"text-center py-4\">\n          <p className=\"text-sm text-[#95aac0]\">No parameters available for this model</p>\n        </div>\n      )}\n\n      {/* Reset Button */}\n      <div className=\"flex justify-end pt-2 border-t border-[#5c6f7e]\">\n        <button\n          onClick={resetToDefaults}\n          className=\"px-3 py-1 text-sm bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n        >\n          Reset to Defaults\n        </button>\n      </div>\n    </div>\n  );\n};\n\nexport default ParameterControls;\n",
      "metadata": {
        "filename": "ParameterControls.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/PromptCard.tsx\n\n/**\n * @file PromptCard.tsx\n * @description This component renders a single card representing an SFL prompt.\n * It displays key information such as the title, task type, persona, and format,\n * providing a quick, scannable overview. It also includes a dropdown menu with\n * actions like View, Edit, and Delete.\n *\n * @requires react\n * @requires ../types\n * @requires ./icons/EllipsisVerticalIcon\n * @requires ./icons/CodeBracketIcon\n * @requires ./icons/ChatBubbleLeftRightIcon\n * @requires ./icons/DocumentTextIcon\n * @requires ./icons/ArrowsRightLeftIcon\n * @requires ./icons/GlobeAltIcon\n * @requires ./icons/WrenchScrewdriverIcon\n * @requires ./icons/AcademicCapIcon\n */\n\nimport React, { useState, useRef, useEffect } from 'react';\nimport { PromptSFL } from '../types';\nimport EllipsisVerticalIcon from './icons/EllipsisVerticalIcon';\nimport CodeBracketIcon from './icons/CodeBracketIcon';\nimport ChatBubbleLeftRightIcon from './icons/ChatBubbleLeftRightIcon';\nimport DocumentTextIcon from './icons/DocumentTextIcon';\nimport ArrowsRightLeftIcon from './icons/ArrowsRightLeftIcon';\nimport GlobeAltIcon from './icons/GlobeAltIcon';\nimport WrenchScrewdriverIcon from './icons/WrenchScrewdriverIcon';\nimport AcademicCapIcon from './icons/AcademicCapIcon';\nimport ArrowDownTrayIcon from './icons/ArrowDownTrayIcon';\n\n/**\n * @interface PromptCardProps\n * @description Defines the props for the `PromptCard` component.\n * @property {PromptSFL} prompt - The SFL prompt object to display.\n * @property {(prompt: PromptSFL) => void} onView - Callback function invoked when the \"View\" action is selected from the menu.\n * @property {(prompt: PromptSFL) => void} onEdit - Callback function invoked when the \"Edit\" action is selected from the menu.\n * @property {(promptId: string) => void} onDelete - Callback function invoked when the \"Delete\" action is selected from the menu.\n * @property {(prompt: PromptSFL) => void} onExportJSON - Callback function invoked when the \"Export JSON\" action is selected from the menu.\n * @property {(prompt: PromptSFL) => void} onExportMarkdown - Callback function invoked when the \"Export MD\" action is selected from the menu.\n */\ninterface PromptCardProps {\n  prompt: PromptSFL;\n  onView: (prompt: PromptSFL) => void;\n  onEdit: (prompt: PromptSFL) => void;\n  onDelete: (promptId: string) => void;\n  onExportJSON: (prompt: PromptSFL) => void;\n  onExportMarkdown: (prompt: PromptSFL) => void;\n}\n\n/**\n * A utility function that returns a specific icon component based on the task type string.\n * This helps in visually distinguishing different types of prompts in the UI.\n *\n * @param {string} taskType - The task type from the prompt's SFL Field (e.g., \"Code Generation\").\n * @returns {React.ReactElement} A React icon component corresponding to the task type.\n * @private\n */\nconst getTaskIcon = (taskType: string): React.ReactElement => {\n    const iconProps = { className: \"w-5 h-5\" };\n    switch (taskType) {\n        case 'Explanation': return <ChatBubbleLeftRightIcon {...iconProps} />;\n        case 'Code Generation': return <CodeBracketIcon {...iconProps} />;\n        case 'Summarization': return <DocumentTextIcon {...iconProps} />;\n        case 'Translation': return <GlobeAltIcon {...iconProps} />;\n        case 'Code Debugging Assistant': return <WrenchScrewdriverIcon {...iconProps} />;\n        case 'JSON Data Transformation': return <ArrowsRightLeftIcon {...iconProps} />;\n        case 'Technical Concept Explanation': return <AcademicCapIcon {...iconProps} />;\n        default: return <DocumentTextIcon {...iconProps} />;\n    }\n}\n\n/**\n * A card component that displays a summary of an SFL prompt and provides actions.\n * It shows the prompt's title, a snippet of its text, key SFL parameters (Task, Persona, Format),\n * and associated keywords. An options menu allows the user to view, edit, or delete the prompt.\n *\n * @param {PromptCardProps} props - The props for the component.\n * @returns {JSX.Element} The rendered prompt card.\n */\nconst PromptCard: React.FC<PromptCardProps> = ({ prompt, onView, onEdit, onDelete, onExportJSON, onExportMarkdown }) => {\n  /**\n   * @state {boolean} menuOpen - Manages the visibility of the dropdown actions menu.\n   */\n  const [menuOpen, setMenuOpen] = useState(false);\n  \n  /**\n   * @ref {HTMLDivElement} menuRef - A ref attached to the menu container to detect clicks outside of it for closing.\n   */\n  const menuRef = useRef<HTMLDivElement>(null);\n\n  const isTested = !!prompt.geminiResponse;\n\n  /**\n   * @constant {Record<string, string>} cardIconColorMapping - A mapping of task types to Tailwind CSS classes for styling the card's icon.\n   * @private\n   */\n  const cardIconColorMapping: Record<string, string> = {\n    Explanation: 'text-blue-400 bg-blue-900/20',\n    'Code Generation': 'text-green-400 bg-green-900/20',\n    Summarization: 'text-purple-400 bg-purple-900/20',\n    Translation: 'text-sky-400 bg-sky-900/20',\n    'Code Debugging Assistant': 'text-red-400 bg-red-900/20',\n    'JSON Data Transformation': 'text-indigo-400 bg-indigo-900/20',\n    'Technical Concept Explanation': 'text-[#e2a32d] bg-[#e2a32d]/20',\n    default: 'text-[#95aac0] bg-[#333e48]',\n  }\n\n  const iconColor = cardIconColorMapping[prompt.sflField.taskType] || cardIconColorMapping.default;\n\n  /**\n   * @effect Adds a global click listener to close the actions menu when the user clicks outside of it.\n   */\n  useEffect(() => {\n    const handleClickOutside = (event: MouseEvent) => {\n      if (menuRef.current && !menuRef.current.contains(event.target as Node)) {\n        setMenuOpen(false);\n      }\n    };\n    document.addEventListener(\"mousedown\", handleClickOutside);\n    return () => document.removeEventListener(\"mousedown\", handleClickOutside);\n  }, [menuRef]);\n\n  return (\n    <div className=\"bg-[#333e48] shadow-sm rounded-lg p-5 border border-[#5c6f7e] hover:shadow-md transition-shadow duration-200 flex flex-col justify-between\">\n      <div>\n        <div className=\"flex justify-between items-start mb-3\">\n            <div className=\"flex items-center gap-3\">\n                <div className={`p-2 rounded-md ${iconColor}`}>\n                    {getTaskIcon(prompt.sflField.taskType)}\n                </div>\n                <h3 className=\"text-md font-semibold text-gray-200\" title={prompt.title}>\n                    {prompt.title}\n                </h3>\n            </div>\n            <div className=\"relative\" ref={menuRef}>\n                <button\n                    onClick={() => setMenuOpen(prev => !prev)}\n                    className=\"p-1 text-[#95aac0] hover:text-gray-200 rounded-full hover:bg-[#333e48]\"\n                    aria-label=\"Options\"\n                >\n                    <EllipsisVerticalIcon className=\"w-5 h-5\" />\n                </button>\n                {menuOpen && (\n                    <div className=\"absolute right-0 mt-2 w-48 bg-[#333e48] rounded-md shadow-lg z-10 border border-[#5c6f7e]\">\n                    <button onClick={() => { onView(prompt); setMenuOpen(false); }} className=\"block w-full text-left px-4 py-2 text-sm text-gray-200 hover:bg-[#212934]\">View Details</button>\n                    <button onClick={() => { onEdit(prompt); setMenuOpen(false); }} className=\"block w-full text-left px-4 py-2 text-sm text-gray-200 hover:bg-[#212934]\">Edit</button>\n                    <div className=\"border-t border-[#5c6f7e] my-1\"></div>\n                    <button onClick={() => { onExportJSON(prompt); setMenuOpen(false); }} className=\"block w-full text-left px-4 py-2 text-sm text-gray-200 hover:bg-[#212934] flex items-center\">\n                      <ArrowDownTrayIcon className=\"w-4 h-4 mr-2\" /> Export JSON\n                    </button>\n                    <button onClick={() => { onExportMarkdown(prompt); setMenuOpen(false); }} className=\"block w-full text-left px-4 py-2 text-sm text-gray-200 hover:bg-[#212934] flex items-center\">\n                      <DocumentTextIcon className=\"w-4 h-4 mr-2\" /> Export MD\n                    </button>\n                    <div className=\"border-t border-[#5c6f7e] my-1\"></div>\n                    <button onClick={() => { onDelete(prompt.id); setMenuOpen(false); }} className=\"block w-full text-left px-4 py-2 text-sm text-red-300 hover:bg-red-900/20\">Delete</button>\n                    </div>\n                )}\n            </div>\n        </div>\n\n        <p className=\"text-[#95aac0] text-sm mb-3 line-clamp-2\" title={prompt.promptText}>{prompt.promptText}</p>\n        \n        <div className=\"space-y-2 text-sm mb-4\">\n            <div className=\"flex\"><p className=\"w-16 font-medium text-[#95aac0] shrink-0\">Task:</p> <p className=\"text-gray-200 truncate\">{prompt.sflField.taskType}</p></div>\n            <div className=\"flex\"><p className=\"w-16 font-medium text-[#95aac0] shrink-0\">Persona:</p> <p className=\"text-gray-200 truncate\">{prompt.sflTenor.aiPersona}</p></div>\n            <div className=\"flex\"><p className=\"w-16 font-medium text-[#95aac0] shrink-0\">Format:</p> <p className=\"text-gray-200 truncate\">{prompt.sflMode.outputFormat}</p></div>\n        </div>\n\n        <div className=\"flex flex-wrap gap-2 mb-4\">\n          {prompt.sflField.keywords.split(',').slice(0, 3).map((keyword) => (\n            keyword.trim() && (\n              <span key={keyword} className=\"px-2 py-0.5 text-xs font-medium text-[#95aac0] bg-[#212934] rounded-full\">\n                #{keyword.trim()}\n              </span>\n            )\n          ))}\n        </div>\n      </div>\n      \n      <div className=\"border-t border-[#5c6f7e] pt-4 flex justify-between items-center text-sm\">\n        <p className=\"text-[#95aac0]\">Updated {new Date(prompt.updatedAt).toLocaleDateString()}</p>\n        {isTested ? (\n          <span className=\"px-2 py-1 text-xs font-semibold text-green-400 bg-green-900/20 rounded-md\">Tested</span>\n        ) : (\n          <span className=\"px-2 py-1 text-xs font-semibold text-amber-400 bg-amber-900/20 rounded-md\">Not Tested</span>\n        )}\n      </div>\n    </div>\n  );\n};\n\nexport default PromptCard;\n",
      "metadata": {
        "filename": "PromptCard.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/PromptDetailModal.tsx\n\n/**\n * @file PromptDetailModal.tsx\n * @description This component displays the full details of a selected SFL prompt in a modal dialog.\n * It provides a comprehensive, read-only view of all SFL parameters, the prompt text, and any associated metadata.\n * It also includes controls for testing the prompt with Gemini (handling variables), editing, deleting, and exporting the prompt.\n *\n * @requires react\n * @requires ../types\n * @requires ./ModalShell\n * @requires ./icons/SparklesIcon\n * @requires ./icons/PencilIcon\n * @requires ./icons/TrashIcon\n * @requires ./icons/ArrowDownTrayIcon\n * @requires ./icons/DocumentTextIcon\n * @requires ./icons/ClipboardIcon\n */\n\nimport React, { useMemo, useState, useEffect } from 'react';\nimport { PromptSFL } from '../types';\nimport ModalShell from './ModalShell';\nimport SparklesIcon from './icons/SparklesIcon';\nimport PencilIcon from './icons/PencilIcon';\nimport TrashIcon from './icons/TrashIcon';\nimport ClipboardIcon from './icons/ClipboardIcon';\n\n/**\n * @interface PromptDetailModalProps\n * @description Defines the props for the `PromptDetailModal` component.\n * @property {boolean} isOpen - Controls the visibility of the modal.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {PromptSFL | null} prompt - The prompt object to display. If `null`, the modal will not render.\n * @property {(prompt: PromptSFL) => void} onEdit - Callback to trigger the editing mode for the current prompt.\n * @property {(promptId: string) => void} onDelete - Callback to trigger the deletion of the current prompt.\n * @property {(prompt: PromptSFL, variables: Record<string, string>) => void} onTestWithGemini - Callback to test the prompt with the Gemini API, passing any interpolated variable values.\n */\ninterface PromptDetailModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  prompt: PromptSFL | null;\n  onEdit: (prompt: PromptSFL) => void;\n  onDelete: (promptId: string) => void;\n  onTestWithGemini: (prompt: PromptSFL, variables: Record<string, string>) => void;\n}\n\n/**\n * A small, reusable component to display a single piece of detail (a label and its value).\n * It handles conditional rendering and provides an option for code-like formatting.\n *\n * @param {object} props - The component props.\n * @param {string} props.label - The label for the detail item.\n * @param {string | null} [props.value] - The value to display. If falsy, the component renders nothing.\n * @param {boolean} [props.isCode=false] - If `true`, formats the value in a `<pre>` tag for a code-like appearance.\n * @param {boolean} [props.isEmpty=false] - If `true`, the component will not render, regardless of the value.\n * @returns {JSX.Element | null} The rendered detail item or `null`.\n * @private\n */\nconst DetailItem: React.FC<{ label: string; value?: string | null; isCode?: boolean; isEmpty?: boolean }> = ({ label, value, isCode, isEmpty }) => {\n  if (isEmpty || !value) return null;\n  return (\n    <div className=\"mb-3\">\n      <h4 className=\"text-sm font-semibold text-gray-500 mb-0.5\">{label}</h4>\n      {isCode ? (\n        <pre className=\"bg-[#212934] p-3 rounded-md text-sm text-gray-200 whitespace-pre-wrap break-all border border-[#5c6f7e]\">{value}</pre>\n      ) : (\n        <p className=\"text-gray-800 text-sm whitespace-pre-wrap break-words\">{value}</p>\n      )}\n    </div>\n  );\n};\n\n/**\n * A modal component that displays the complete details of an SFL prompt.\n * It organizes all SFL parameters into Field, Tenor, and Mode sections for clarity.\n * It automatically detects `{{variables}}` in the prompt text and provides input fields for them.\n * Users can test the prompt with Gemini, view results or errors, and access other management actions.\n *\n * @param {PromptDetailModalProps} props - The props for the component.\n * @returns {JSX.Element | null} The rendered modal, or `null` if no prompt is provided or `isOpen` is false.\n */\nconst PromptDetailModal: React.FC<PromptDetailModalProps> = ({ isOpen, onClose, prompt, onEdit, onDelete, onTestWithGemini }) => {\n  if (!prompt) return null;\n\n  /**\n   * @state {Record<string, string>} variableValues - Stores the current values for any variables found in the prompt text.\n   */\n  const [variableValues, setVariableValues] = useState<Record<string, string>>({});\n  \n  /**\n   * @state {boolean} isDocVisible - Toggles the visibility of the source document's content.\n   */\n  const [isDocVisible, setDocVisible] = useState(false);\n  \n  /**\n   * @state {boolean} docCopied - A transient state to provide feedback when the source document content is copied.\n   */\n  const [docCopied, setDocCopied] = useState(false);\n\n  /**\n   * @memorized {string[]} variables - A memoized array of unique variable names extracted from the prompt text.\n   */\n  const variables = useMemo(() => {\n    if (!prompt?.promptText) return [];\n    const regex = /{{\\s*(\\w+)\\s*}}/g;\n    const matches = prompt.promptText.match(regex);\n    if (!matches) return [];\n    return [...new Set(matches.map(v => v.replace(/{{\\s*|\\s*}}/g, '')))];\n  }, [prompt?.promptText]);\n\n  /**\n   * @effect Resets the state of the modal (variable values, document visibility) whenever it is opened or the prompt changes.\n   */\n  useEffect(() => {\n    if (isOpen && prompt) {\n      const initialValues: Record<string, string> = {};\n      variables.forEach(v => {\n        initialValues[v] = '';\n      });\n      setVariableValues(initialValues);\n      setDocVisible(false);\n      setDocCopied(false);\n    }\n  }, [isOpen, prompt, variables]);\n\n  /**\n   * @callback handleVariableChange\n   * @description Updates the state for a single prompt variable.\n   * @param {string} variableName - The name of the variable to update.\n   * @param {string} value - The new value for the variable.\n   */\n  const handleVariableChange = (variableName: string, value: string) => {\n    setVariableValues(prev => ({ ...prev, [variableName]: value }));\n  };\n  \n  /**\n   * @callback handleCopyDocContent\n   * @description Copies the content of the attached source document to the clipboard and provides user feedback.\n   */\n  const handleCopyDocContent = () => {\n    if (prompt?.sourceDocument?.content) {\n      navigator.clipboard.writeText(prompt.sourceDocument.content);\n      setDocCopied(true);\n      setTimeout(() => setDocCopied(false), 2000);\n    }\n  };\n\n  return (\n    <ModalShell isOpen={isOpen} onClose={onClose} title={prompt.title} size=\"4xl\">\n      <div className=\"space-y-6 text-gray-800\">\n        <DetailItem label=\"Prompt Text\" value={prompt.promptText} isCode />\n\n        {prompt.sourceDocument && (\n            <div className=\"mb-3\">\n                <h4 className=\"text-sm font-semibold text-gray-500 mb-0.5\">Source Document</h4>\n                <div className=\"flex items-center justify-between bg-[#212934] p-3 rounded-md text-sm border border-[#5c6f7e]\">\n                    <span className=\"italic\">{prompt.sourceDocument.name}</span>\n                    <button onClick={() => setDocVisible(!isDocVisible)} className=\"text-xs font-semibold text-[#4A69E2] hover:underline\">\n                        {isDocVisible ? 'Hide Content' : 'View Content'}\n                    </button>\n                </div>\n                {isDocVisible && (\n                    <div className=\"relative mt-2\">\n                        <pre className=\"bg-[#212934] p-3 rounded-md text-sm text-gray-200 whitespace-pre-wrap break-all max-h-48 overflow-y-auto border border-[#5c6f7e]\">\n                           {prompt.sourceDocument.content}\n                        </pre>\n                        <button onClick={handleCopyDocContent} className=\"absolute top-2 right-2 p-1.5 bg-[#333e48] rounded-md text-[#95aac0] hover:text-gray-200 transition-colors border border-[#5c6f7e]\">\n                           {docCopied ? <span className=\"text-xs\">Copied!</span> : <ClipboardIcon className=\"w-4 h-4\" />}\n                        </button>\n                    </div>\n                )}\n            </div>\n        )}\n\n        <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6\">\n          <section className=\"border border-[#5c6f7e] p-4 rounded-lg bg-[#212934]/50\">\n            <h3 className=\"text-md font-semibold text-gray-800 mb-2 border-b pb-1 border-gray-200\">Field</h3>\n            <DetailItem label=\"Topic\" value={prompt.sflField.topic} />\n            <DetailItem label=\"Task Type\" value={prompt.sflField.taskType} />\n            <DetailItem label=\"Domain Specifics\" value={prompt.sflField.domainSpecifics} />\n            <DetailItem label=\"Keywords\" value={prompt.sflField.keywords} />\n          </section>\n\n          <section className=\"border border-[#5c6f7e] p-4 rounded-lg bg-[#212934]/50\">\n            <h3 className=\"text-md font-semibold text-gray-800 mb-2 border-b pb-1 border-gray-200\">Tenor</h3>\n            <DetailItem label=\"AI Persona\" value={prompt.sflTenor.aiPersona} />\n            <DetailItem label=\"Target Audience\" value={prompt.sflTenor.targetAudience.join(', ')} />\n            <DetailItem label=\"Desired Tone\" value={prompt.sflTenor.desiredTone} />\n            <DetailItem label=\"Interpersonal Stance\" value={prompt.sflTenor.interpersonalStance} />\n          </section>\n\n          <section className=\"border border-[#5c6f7e] p-4 rounded-lg bg-[#212934]/50\">\n            <h3 className=\"text-md font-semibold text-gray-800 mb-2 border-b pb-1 border-gray-200\">Mode</h3>\n            <DetailItem label=\"Output Format\" value={prompt.sflMode.outputFormat} />\n            <DetailItem label=\"Rhetorical Structure\" value={prompt.sflMode.rhetoricalStructure} />\n            <DetailItem label=\"Length Constraint\" value={prompt.sflMode.lengthConstraint} />\n            <DetailItem label=\"Textual Directives\" value={prompt.sflMode.textualDirectives} />\n          </section>\n        </div>\n        \n        <DetailItem label=\"Example Output\" value={prompt.exampleOutput} isEmpty={!prompt.exampleOutput} isCode/>\n        <DetailItem label=\"Notes\" value={prompt.notes} isEmpty={!prompt.notes} />\n        \n        <div className=\"mt-3\">\n            <p className=\"text-xs text-gray-400\">Created: {new Date(prompt.createdAt).toLocaleString()}</p>\n            <p className=\"text-xs text-gray-400\">Last Updated: {new Date(prompt.updatedAt).toLocaleString()}</p>\n        </div>\n\n        {variables.length > 0 && (\n          <section className=\"space-y-4 border border-[#5c6f7e] p-4 rounded-lg bg-[#212934]/50\">\n            <h3 className=\"text-md font-semibold text-gray-800 mb-2 border-b pb-1 border-gray-200\">Prompt Variables</h3>\n            <div className=\"space-y-4\">\n              {variables.map((varName) => (\n                <div key={varName}>\n                  <label htmlFor={`var-${varName}`} className=\"block text-sm font-medium text-gray-600 mb-1\">{`{{${varName}}}`}</label>\n                  <textarea\n                    id={`var-${varName}`}\n                    value={variableValues[varName] || ''}\n                    onChange={(e) => handleVariableChange(varName, e.target.value)}\n                    placeholder={`Enter value for ${varName}...`}\n                    rows={2}\n                    className=\"w-full px-3 py-2 bg-[#333e48] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors placeholder-[#95aac0]\"\n                  />\n                </div>\n              ))}\n            </div>\n          </section>\n        )}\n\n        {prompt.isTesting && (\n          <div className=\"my-4 p-4 border border-blue-600 rounded-md bg-blue-900/20 flex items-center justify-center\">\n            <div className=\"spinner\"></div>\n            <p className=\"ml-3 text-blue-700\">Testing with Gemini...</p>\n          </div>\n        )}\n\n        {prompt.geminiResponse && (\n          <div className=\"my-4\">\n            <h3 className=\"text-md font-semibold text-green-700 mb-2\">Gemini Response:</h3>\n            <pre className=\"bg-green-50 p-4 rounded-md text-sm text-green-800 whitespace-pre-wrap break-all border border-green-200\">{prompt.geminiResponse}</pre>\n          </div>\n        )}\n\n        {prompt.geminiTestError && (\n          <div className=\"my-4\">\n            <h3 className=\"text-md font-semibold text-red-700 mb-2\">Gemini Test Error:</h3>\n            <pre className=\"bg-red-50 p-4 rounded-md text-sm text-red-800 whitespace-pre-wrap break-all border border-red-200\">{prompt.geminiTestError}</pre>\n          </div>\n        )}\n\n        <div className=\"flex flex-wrap justify-end gap-3 pt-6 border-t border-gray-200 mt-6\">\n          <button\n            onClick={() => onTestWithGemini(prompt, variableValues)}\n            disabled={prompt.isTesting}\n            className=\"px-3 py-2 text-sm font-medium text-white bg-[#4A69E2] rounded-md hover:bg-opacity-90 disabled:bg-opacity-50 disabled:cursor-not-allowed flex items-center\"\n          >\n            <SparklesIcon className=\"w-5 h-5 mr-2\"/>\n            {prompt.isTesting ? 'Testing...' : 'Test with Gemini'}\n          </button>\n          <button\n            onClick={() => { onEdit(prompt); onClose(); }}\n            className=\"px-3 py-2 text-sm font-medium text-gray-700 bg-white border border-gray-300 rounded-md hover:bg-gray-50 flex items-center\"\n          >\n           <PencilIcon className=\"w-5 h-5 mr-2\"/> Edit\n          </button>\n          <button\n            onClick={() => { if(window.confirm('Are you sure you want to delete this prompt?')) { onDelete(prompt.id); onClose(); }}}\n            className=\"px-3 py-2 text-sm font-medium text-white bg-red-600 rounded-md hover:bg-red-700 flex items-center\"\n          >\n           <TrashIcon className=\"w-5 h-5 mr-2\"/> Delete\n          </button>\n        </div>\n      </div>\n    </ModalShell>\n  );\n};\n\nexport default PromptDetailModal;\n",
      "metadata": {
        "filename": "PromptDetailModal.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/PromptFormModal.tsx\n\n/**\n * @file PromptFormModal.tsx\n * @description This component provides a modal form for creating and editing SFL prompts.\n * It includes fields for all SFL parameters, a title, notes, and the main prompt text.\n * It also features an AI-powered regeneration capability and allows attaching a source document for stylistic reference.\n *\n * @requires react\n * @requires ../types\n * @requires ../constants\n * @requires ../utils/generateId\n * @requires ./ModalShell\n * @requires ../services/geminiService\n * @requires ./icons/SparklesIcon\n * @requires ./icons/PaperClipIcon\n * @requires ./icons/XCircleIcon\n */\n\nimport React, { useState, useEffect, useRef } from 'react';\nimport { PromptSFL } from '../types';\nimport { INITIAL_PROMPT_SFL } from '../constants';\nimport { generateId } from '../utils/generateId';\nimport ModalShell from './ModalShell';\nimport { regenerateSFLFromSuggestion } from '../services/geminiService';\nimport SparklesIcon from './icons/SparklesIcon';\nimport PaperClipIcon from './icons/PaperClipIcon';\nimport XCircleIcon from './icons/XCircleIcon';\n\n/**\n * @interface PromptFormModalProps\n * @description Defines the props for the `PromptFormModal` component.\n * @property {boolean} isOpen - Controls the visibility of the modal.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {(prompt: PromptSFL) => Promise<void>} onSave - Async callback function to save the prompt data.\n * @property {PromptSFL | null} [promptToEdit] - The prompt object to edit. If `null` or `undefined`, the form operates in creation mode.\n * @property {object} appConstants - An object containing arrays of predefined options for various SFL fields (e.g., taskTypes, aiPersonas).\n * @property {(key: keyof PromptFormModalProps['appConstants'], value: string) => void} onAddConstant - Callback to add a new user-defined option to the application's constants.\n */\ninterface PromptFormModalProps {\n  isOpen: boolean;\n  onClose: () => void;\n  onSave: (prompt: PromptSFL) => Promise<void>;\n  promptToEdit?: PromptSFL | null;\n  appConstants: {\n    taskTypes: string[];\n    aiPersonas: string[];\n    targetAudiences: string[];\n    desiredTones: string[];\n    outputFormats: string[];\n    lengthConstraints: string[];\n  };\n  onAddConstant: (key: keyof PromptFormModalProps['appConstants'], value: string) => void;\n}\n\n/**\n * A comprehensive modal form for creating and editing SFL prompts.\n * It manages the form's state, handles user input for all SFL fields, and provides advanced\n * functionality such as AI-powered regeneration and attaching source documents for context.\n *\n * @param {PromptFormModalProps} props - The props for the component.\n * @returns {JSX.Element} The rendered form modal.\n */\nconst PromptFormModal: React.FC<PromptFormModalProps> = ({ isOpen, onClose, onSave, promptToEdit, appConstants, onAddConstant }) => {\n  /**\n   * @state {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} formData - The main state object for the form, holding all prompt data.\n   */\n  const [formData, setFormData] = useState<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>(INITIAL_PROMPT_SFL);\n  \n  /**\n   * @state {Record<string, string>} newOptionValues - Holds the input values for new, user-defined options for the creatable select fields.\n   */\n  const [newOptionValues, setNewOptionValues] = useState<Record<string, string>>({});\n  \n  /**\n   * @state {object} regenState - Manages the state of the AI regeneration feature, including visibility, user input, and loading status.\n   */\n  const [regenState, setRegenState] = useState({ shown: false, suggestion: '', loading: false });\n  \n  /**\n   * @state {object} saveState - Manages the state of the save operation, including loading status and any error messages.\n   */\n  const [saveState, setSaveState] = useState({ saving: false, error: '' });\n  \n  /**\n   * @ref {HTMLInputElement} fileInputRef - A ref to a hidden file input for programmatically triggering the file selection dialog.\n   */\n  const fileInputRef = useRef<HTMLInputElement>(null);\n\n  /**\n   * @effect Populates the form with data when `promptToEdit` is provided, or resets to the initial state for a new prompt.\n   * This runs whenever the modal is opened or the `promptToEdit` prop changes.\n   */\n  useEffect(() => {\n    if (promptToEdit) {\n      // eslint-disable-next-line @typescript-eslint/no-unused-vars\n      const { id, createdAt, updatedAt, geminiResponse, geminiTestError, isTesting, ...editableData } = promptToEdit;\n      setFormData(editableData);\n    } else {\n      setFormData(INITIAL_PROMPT_SFL);\n    }\n     setRegenState({ shown: false, suggestion: '', loading: false });\n     setSaveState({ saving: false, error: '' });\n  }, [promptToEdit, isOpen]);\n\n  /**\n   * @callback handleChange\n   * @description A generic handler for updating top-level fields in the `formData` state.\n   * @param {T} field - The name of the field to update.\n   * @param {Omit<PromptSFL, ...>[T]} value - The new value for the field.\n   */\n  const handleChange = <T extends keyof Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'sflField' | 'sflTenor' | 'sflMode' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>>(\n    field: T,\n    value: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>[T]\n  ) => {\n    setFormData(prev => ({ ...prev, [field]: value }));\n  };\n\n  /**\n   * @callback handleSFLChange\n   * @description A specific handler for updating nested fields within the SFL objects (`sflField`, `sflTenor`, `sflMode`).\n   * @param {K} sflType - The top-level SFL category ('sflField', 'sflTenor', 'sflMode').\n   * @param {F} field - The specific field within the SFL category to update.\n   * @param {*} value - The new value for the field.\n   */\n  const handleSFLChange = <\n    K extends 'sflField' | 'sflTenor' | 'sflMode',\n    F extends keyof PromptSFL[K],\n  >(\n    sflType: K,\n    field: F,\n    value: any\n  ) => {\n    setFormData(prev => ({\n      ...prev,\n      [sflType]: {\n        ...prev[sflType],\n        [field]: value,\n      },\n    }));\n  };\n  \n  /**\n   * @callback handleTargetAudienceChange\n   * @description Handles changes to the 'targetAudience' checkboxes, adding or removing audiences from the array.\n   * @param {string} audience - The audience string to toggle.\n   */\n  const handleTargetAudienceChange = (audience: string) => {\n    const currentAudiences = formData.sflTenor.targetAudience || [];\n    const newAudiences = currentAudiences.includes(audience)\n      ? currentAudiences.filter(a => a !== audience)\n      : [...currentAudiences, audience];\n    handleSFLChange('sflTenor', 'targetAudience', newAudiences);\n  };\n\n  /**\n   * @callback handleAddNewOption\n   * @description Handles the submission of a new, user-defined option for a creatable select field.\n   * It calls the `onAddConstant` prop to update the global list and then sets the new value in the form.\n   * @param {keyof typeof appConstants} constantsKey - The key for the global constants array.\n   * @param {K} sflKey - The SFL category key.\n   * @param {F} fieldKey - The SFL field key.\n   */\n  const handleAddNewOption = <\n    K extends 'sflField' | 'sflTenor' | 'sflMode',\n    F extends keyof PromptSFL[K]\n  >(constantsKey: keyof typeof appConstants, sflKey: K, fieldKey: F) => {\n    const value = newOptionValues[String(fieldKey)];\n    if(value && value.trim()){\n      onAddConstant(constantsKey, value);\n      handleSFLChange(sflKey, fieldKey, value);\n      setNewOptionValues(prev => ({...prev, [String(fieldKey)]: ''}));\n    }\n  };\n\n  /**\n   * @callback handleRegeneratePrompt\n   * @description Initiates an AI-powered regeneration of the prompt based on the user's suggestion.\n   * It calls the `regenerateSFLFromSuggestion` service and updates the entire form with the new data.\n   */\n  const handleRegeneratePrompt = async () => {\n    if (!regenState.suggestion.trim()) return;\n    setRegenState(prev => ({ ...prev, loading: true }));\n    try {\n      const regeneratedData = await regenerateSFLFromSuggestion(formData, regenState.suggestion);\n      setFormData(regeneratedData);\n      setRegenState({ shown: false, suggestion: '', loading: false });\n    } catch (error) {\n      console.error(error);\n      alert('Failed to regenerate prompt: ' + (error instanceof Error ? error.message : String(error)));\n      setRegenState(prev => ({ ...prev, loading: false }));\n    }\n  };\n\n  /**\n   * @callback handleFileChange\n   * @description Handles the selection of a source document file. Reads the file content\n   * and stores it along with the filename in the form state.\n   * @param {React.ChangeEvent<HTMLInputElement>} event - The file input change event.\n   */\n  const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {\n    const file = event.target.files?.[0];\n    if (file) {\n      const reader = new FileReader();\n      reader.onload = (e) => {\n        const content = e.target?.result as string;\n        setFormData(prev => ({ ...prev, sourceDocument: { name: file.name, content } }));\n      };\n      reader.readAsText(file);\n    }\n    if(event.target) event.target.value = '';\n  };\n\n  /**\n   * @function handleRemoveFile\n   * @description Removes the attached source document from the form state.\n   */\n  const handleRemoveFile = () => {\n    setFormData(prev => ({...prev, sourceDocument: undefined }));\n  };\n\n  /**\n   * @callback handleSubmit\n   * @description Handles the form submission. It performs validation, constructs the final\n   * `PromptSFL` object with necessary metadata, calls the `onSave` prop, and closes the modal on success.\n   * @param {React.FormEvent} e - The form submission event.\n   */\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n    setSaveState({ saving: true, error: '' });\n    \n    if (!formData.title?.trim()) {\n      setSaveState({ saving: false, error: 'Title is required' });\n      return;\n    }\n    if (!formData.promptText?.trim()) {\n      setSaveState({ saving: false, error: 'Prompt text is required' });\n      return;\n    }\n\n    try {\n      const now = new Date().toISOString();\n      const finalPrompt: PromptSFL = {\n        ...formData,\n        id: promptToEdit?.id || generateId(),\n        createdAt: promptToEdit?.createdAt || now,\n        updatedAt: now,\n        geminiResponse: promptToEdit?.geminiResponse, \n        geminiTestError: promptToEdit?.geminiTestError,\n        isTesting: promptToEdit?.isTesting ?? false,\n      };\n      \n      await onSave(finalPrompt);\n      setSaveState({ saving: false, error: '' });\n      onClose();\n    } catch (error) {\n      setSaveState({ \n        saving: false, \n        error: error instanceof Error ? error.message : 'Failed to save prompt' \n      });\n    }\n  };\n\n  const commonInputClasses = \"w-full px-3 py-2 bg-[#333e48] border border-[#5c6f7e] text-gray-200 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] transition-colors placeholder-[#95aac0]\";\n  const labelClasses = \"block text-sm font-medium text-gray-200 mb-1\";\n\n  /**\n   * @function renderTextField\n   * @description A helper function to render a standard text input or textarea field.\n   * @returns {JSX.Element}\n   * @private\n   */\n  const renderTextField = (label: string, name: keyof Omit<PromptSFL, 'id'|'createdAt'|'updatedAt'|'sflField'|'sflTenor'|'sflMode' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>, placeholder?: string, isTextArea = false) => (\n    <div>\n      <label htmlFor={name} className={labelClasses}>{label}</label>\n      {isTextArea ? (\n        <textarea\n          id={name}\n          name={name}\n          value={String(formData[name] || '')}\n          onChange={(e) => handleChange(name, e.target.value)}\n          placeholder={placeholder}\n          rows={3}\n          className={commonInputClasses}\n        />\n      ) : (\n        <input\n          type=\"text\"\n          id={name}\n          name={name}\n          value={String(formData[name] || '')}\n          onChange={(e) => handleChange(name, e.target.value)}\n          placeholder={placeholder}\n          className={commonInputClasses}\n        />\n      )}\n    </div>\n  );\n\n  /**\n   * @function renderSFLTextField\n   * @description A helper function to render a text input or textarea for a nested SFL field.\n   * @returns {JSX.Element}\n   * @private\n   */\n  const renderSFLTextField = <\n    K extends 'sflField' | 'sflTenor' | 'sflMode',\n    F extends keyof PromptSFL[K],\n  >(\n    sflType: K, \n    name: F, \n    label: string, \n    placeholder?: string, \n    isTextArea = false\n  ) => (\n    <div>\n      <label htmlFor={`${sflType}-${String(name)}`} className={labelClasses}>{label}</label>\n      {isTextArea ? (\n        <textarea\n          id={`${sflType}-${String(name)}`}\n          name={String(name)}\n          value={String(formData[sflType][name] || '')}\n          onChange={(e) => handleSFLChange(sflType, name, e.target.value)}\n          placeholder={placeholder}\n          rows={3}\n          className={commonInputClasses}\n        />\n      ) : (\n        <input\n          type=\"text\"\n          id={`${sflType}-${String(name)}`}\n          name={String(name)}\n          value={String(formData[sflType][name] || '')}\n          onChange={(e) => handleSFLChange(sflType, name, e.target.value)}\n          placeholder={placeholder}\n          className={commonInputClasses}\n        />\n      )}\n    </div>\n  );\n\n  /**\n   * @function renderCreatableSFLSelectField\n   * @description A helper function to render a select dropdown that also allows users to add new options.\n   * @returns {JSX.Element}\n   * @private\n   */\n  const renderCreatableSFLSelectField = <\n    K extends 'sflField' | 'sflTenor' | 'sflMode',\n    F extends keyof PromptSFL[K],\n  >(\n    sflType: K, \n    name: F, \n    label: string, \n    options: string[],\n    constantsKey: keyof typeof appConstants\n  ) => (\n    <div>\n      <label htmlFor={`${sflType}-${String(name)}`} className={labelClasses}>{label}</label>\n      <select\n        id={`${sflType}-${String(name)}`}\n        name={String(name)}\n        value={String(formData[sflType][name] || '')}\n        onChange={(e) => handleSFLChange(sflType, name, e.target.value)}\n        className={`${commonInputClasses} appearance-none`}\n      >\n        {options.map(option => <option key={option} value={option}>{option}</option>)}\n      </select>\n      <div className=\"flex items-center space-x-2 mt-2\">\n        <input\n            type=\"text\"\n            placeholder=\"Add new option...\"\n            value={newOptionValues[String(name)] || ''}\n            onChange={e => setNewOptionValues(prev => ({...prev, [String(name)]: e.target.value}))}\n            className={`${commonInputClasses} text-sm`}\n        />\n        <button type=\"button\" onClick={() => handleAddNewOption(constantsKey, sflType, name)} className=\"px-3 py-2 text-sm bg-[#c36e26] hover:bg-[#c36e26]/90 rounded-md shrink-0 text-gray-200\">Add</button>\n      </div>\n    </div>\n  );\n  \n  return (\n    <ModalShell isOpen={isOpen} onClose={onClose} title={promptToEdit ? \"Edit Prompt\" : \"Create New Prompt\"} size=\"3xl\">\n      <form onSubmit={handleSubmit} className=\"space-y-6\">\n        <input type=\"file\" ref={fileInputRef} onChange={handleFileChange} className=\"hidden\" accept=\".txt,.md,.text\" />\n        {renderTextField('Title', 'title', 'Enter a concise title for the prompt')}\n        \n        <div>\n            <label htmlFor=\"promptText\" className={labelClasses}>Prompt Text</label>\n            <textarea\n              id=\"promptText\"\n              name=\"promptText\"\n              value={String(formData['promptText'] || '')}\n              onChange={(e) => handleChange('promptText', e.target.value)}\n              placeholder=\"Enter the full prompt text here\"\n              rows={4}\n              className={commonInputClasses}\n            />\n        </div>\n\n         <div>\n          <label className={labelClasses}>Source Document (Optional)</label>\n          <p className=\"text-xs text-[#95aac0] mb-2\">Attach a text file for stylistic reference. Its style will be analyzed when using the AI regeneration feature.</p>\n          {formData.sourceDocument ? (\n            <div className=\"flex items-center justify-between bg-[#212934] p-2 rounded-md border border-[#5c6f7e]\">\n              <span className=\"text-sm text-gray-200 truncate pr-2\">{formData.sourceDocument.name}</span>\n              <button type=\"button\" onClick={handleRemoveFile} className=\"text-red-300 hover:text-red-400 shrink-0\" aria-label=\"Remove source document\">\n                <XCircleIcon className=\"w-5 h-5\"/>\n              </button>\n            </div>\n          ) : (\n            <button\n              type=\"button\"\n              onClick={() => fileInputRef.current?.click()}\n              className=\"w-full flex items-center justify-center px-3 py-2 bg-[#212934] border-2 border-dashed border-[#5c6f7e] text-[#95aac0] rounded-md hover:bg-[#333e48] hover:border-[#95aac0] transition-colors\"\n            >\n              <PaperClipIcon className=\"w-5 h-5 mr-2\" />\n              Attach Document\n            </button>\n          )}\n        </div>\n\n        <div className=\"my-2 text-right\">\n          <button type=\"button\" onClick={() => setRegenState(prev => ({...prev, shown: !prev.shown, suggestion: ''}))} className=\"text-sm text-[#e2a32d] hover:text-[#e2a32d]/80 flex items-center justify-end\">\n              <SparklesIcon className=\"w-5 h-5 mr-1\"/> Regenerate Prompt with AI\n          </button>\n        </div>\n        \n        {regenState.shown && (\n            <div className=\"space-y-2 p-3 bg-[#212934] rounded-md border border-[#5c6f7e]\">\n                <label htmlFor=\"regenSuggestion\" className={`${labelClasses} text-gray-200`}>How should this prompt be changed?</label>\n                <textarea id=\"regenSuggestion\" value={regenState.suggestion} onChange={e => setRegenState(prev => ({...prev, suggestion: e.target.value}))} rows={2} placeholder=\"e.g., Make the tone more formal, target it to experts...\" className={commonInputClasses} />\n                <div className=\"flex justify-end space-x-2\">\n                    <button type=\"button\" onClick={() => setRegenState({ shown: false, suggestion: '', loading: false })} className=\"px-3 py-1 text-xs bg-[#333e48] text-gray-200 rounded-md hover:bg-[#5c6f7e]\">Cancel</button>\n                    <button type=\"button\" onClick={handleRegeneratePrompt} disabled={regenState.loading || !regenState.suggestion.trim()} className=\"px-3 py-1 text-xs bg-[#c36e26] text-gray-200 rounded-md hover:bg-opacity-90 disabled:bg-opacity-50 disabled:cursor-not-allowed flex items-center\">\n                        {regenState.loading && <div className=\"w-3 h-3 border-2 border-t-transparent border-white rounded-full animate-spin mr-2\"></div>}\n                        {regenState.loading ? 'Regenerating...' : 'Regenerate'}\n                    </button>\n                </div>\n            </div>\n        )}\n\n        <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n          <legend className=\"text-lg font-medium text-gray-200 px-2\">SFL: Field (What is happening?)</legend>\n          <div className=\"space-y-4 mt-2\">\n            {renderSFLTextField('sflField', 'topic', 'Topic', 'e.g., Quantum Physics, Recipe Generation')}\n            {renderCreatableSFLSelectField('sflField', 'taskType', 'Task Type', appConstants.taskTypes, 'taskTypes')}\n            {renderSFLTextField('sflField', 'domainSpecifics', 'Domain Specifics', 'e.g., Python 3.9, pandas; Italian cuisine', true)}\n            {renderSFLTextField('sflField', 'keywords', 'Keywords', 'Comma-separated, e.g., sfl, linguistics, AI')}\n          </div>\n        </fieldset>\n\n        <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n          <legend className=\"text-lg font-medium text-gray-200 px-2\">SFL: Tenor (Who is taking part?)</legend>\n          <div className=\"space-y-4 mt-2\">\n            {renderCreatableSFLSelectField('sflTenor', 'aiPersona', 'AI Persona', appConstants.aiPersonas, 'aiPersonas')}\n            \n            <div>\n                <label className={labelClasses}>Target Audience</label>\n                <div className=\"grid grid-cols-2 gap-2 mt-1 max-h-40 overflow-y-auto p-2 border border-[#5c6f7e] rounded-md bg-[#212934]\">\n                    {(appConstants.targetAudiences || []).map(audience => (\n                        <div key={audience} className=\"flex items-center\">\n                            <input\n                                id={`audience-${audience}`}\n                                type=\"checkbox\"\n                                checked={(formData.sflTenor.targetAudience || []).includes(audience)}\n                                onChange={() => handleTargetAudienceChange(audience)}\n                                className=\"h-4 w-4 rounded border-[#5c6f7e] text-[#e2a32d] focus:ring-[#e2a32d] bg-[#333e48]\"\n                            />\n                            <label htmlFor={`audience-${audience}`} className=\"ml-2 text-sm text-gray-200 select-none\">{audience}</label>\n                        </div>\n                    ))}\n                </div>\n                 <div className=\"flex items-center space-x-2 mt-2\">\n                    <input type=\"text\" placeholder=\"Add new audience...\" value={newOptionValues['targetAudience'] || ''} onChange={e => setNewOptionValues(prev => ({...prev, 'targetAudience': e.target.value}))} className={`${commonInputClasses} text-sm`} />\n                    <button type=\"button\" onClick={() => {\n                        const value = newOptionValues['targetAudience'];\n                        if(value && value.trim()){\n                            onAddConstant('targetAudiences', value);\n                            handleTargetAudienceChange(value);\n                            setNewOptionValues(prev => ({...prev, 'targetAudience': ''}));\n                        }\n                    }} className=\"px-3 py-2 text-sm bg-[#c36e26] hover:bg-[#c36e26]/90 rounded-md shrink-0 text-gray-200\">Add</button>\n                </div>\n            </div>\n\n            {renderCreatableSFLSelectField('sflTenor', 'desiredTone', 'Desired Tone', appConstants.desiredTones, 'desiredTones')}\n            {renderSFLTextField('sflTenor', 'interpersonalStance', 'Interpersonal Stance', 'e.g., Act as a mentor, Be a collaborative partner', true)}\n          </div>\n        </fieldset>\n\n        <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n          <legend className=\"text-lg font-medium text-gray-200 px-2\">SFL: Mode (What role is language playing?)</legend>\n          <div className=\"space-y-4 mt-2\">\n            {renderCreatableSFLSelectField('sflMode', 'outputFormat', 'Output Format', appConstants.outputFormats, 'outputFormats')}\n            {renderSFLTextField('sflMode', 'rhetoricalStructure', 'Rhetorical Structure', 'e.g., Intro, 3 points, conclusion; Problem-Solution', true)}\n            {renderCreatableSFLSelectField('sflMode', 'lengthConstraint', 'Length Constraint', appConstants.lengthConstraints, 'lengthConstraints')}\n            {renderSFLTextField('sflMode', 'textualDirectives', 'Textual Directives', 'e.g., Use active voice, Avoid jargon', true)}\n          </div>\n        </fieldset>\n        \n        <div>\n            <label htmlFor=\"exampleOutput\" className={labelClasses}>Example Output (Optional)</label>\n            <textarea id=\"exampleOutput\" name=\"exampleOutput\" value={formData.exampleOutput || ''} onChange={e => handleChange('exampleOutput', e.target.value)} placeholder=\"Provide an example of a good response\" rows={3} className={commonInputClasses} />\n        </div>\n\n        {renderTextField('Notes (Optional)', 'notes', 'Your private notes about this prompt', true)}\n\n        {saveState.error && (\n          <div className=\"bg-red-900/20 border border-red-600 rounded-md p-3\">\n            <div className=\"flex\">\n              <div className=\"flex-shrink-0\">\n                <XCircleIcon className=\"h-5 w-5 text-red-300\" />\n              </div>\n              <div className=\"ml-3\">\n                <p className=\"text-sm text-red-300\">{saveState.error}</p>\n              </div>\n            </div>\n          </div>\n        )}\n\n        <div className=\"flex justify-end space-x-3 pt-4 border-t border-gray-200 mt-6\">\n          <button\n            type=\"button\"\n            onClick={onClose}\n            disabled={saveState.saving}\n            className=\"px-4 py-2 text-sm font-medium text-gray-200 bg-[#333e48] border border-[#5c6f7e] rounded-md hover:bg-[#212934] focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-[#e2a32d] disabled:opacity-50 disabled:cursor-not-allowed\"\n          >\n            Cancel\n          </button>\n          <button\n            type=\"submit\"\n            disabled={saveState.saving}\n            className=\"px-4 py-2 text-sm font-medium text-gray-200 bg-[#c36e26] rounded-md hover:bg-opacity-90 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-[#e2a32d] disabled:opacity-50 disabled:cursor-not-allowed flex items-center\"\n          >\n            {saveState.saving && (\n              <div className=\"w-4 h-4 border-2 border-t-transparent border-white rounded-full animate-spin mr-2\"></div>\n            )}\n            {saveState.saving \n              ? (promptToEdit ? 'Saving...' : 'Creating...') \n              : (promptToEdit ? 'Save Changes' : 'Create Prompt')\n            }\n          </button>\n        </div>\n      </form>\n    </ModalShell>\n  );\n};\n\nexport default PromptFormModal;\n",
      "metadata": {
        "filename": "PromptFormModal.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/PromptList.tsx\n\n/**\n * @file PromptList.tsx\n * @description This component is responsible for rendering a list of SFL prompts.\n * It takes an array of prompt objects and maps each one to a `PromptCard` component,\n * arranging them in a responsive grid. If the list of prompts is empty, it displays a\n * user-friendly message indicating that no prompts were found.\n *\n * @requires react\n * @requires ../types\n * @requires ./PromptCard\n * @requires ./icons/ClipboardDocumentListIcon\n */\n\nimport React from 'react';\nimport { PromptSFL } from '../types';\nimport PromptCard from './PromptCard';\nimport ClipboardDocumentListIcon from './icons/ClipboardDocumentListIcon';\n\n/**\n * @interface PromptListProps\n * @description Defines the props for the `PromptList` component.\n * @property {PromptSFL[]} prompts - An array of SFL prompt objects to be displayed.\n * @property {(prompt: PromptSFL) => void} onViewPrompt - Callback function passed down to each `PromptCard` to handle viewing a prompt's details.\n * @property {(prompt: PromptSFL) => void} onEditPrompt - Callback function passed down to each `PromptCard` to handle editing a prompt.\n * @property {(promptId: string) => void} onDeletePrompt - Callback function passed down to each `PromptCard` to handle deleting a prompt.\n * @property {(prompt: PromptSFL) => void} onExportJSON - Callback function passed down to each `PromptCard` to handle exporting a prompt as JSON.\n * @property {(prompt: PromptSFL) => void} onExportMarkdown - Callback function passed down to each `PromptCard` to handle exporting a prompt as Markdown.\n */\ninterface PromptListProps {\n  prompts: PromptSFL[];\n  onViewPrompt: (prompt: PromptSFL) => void;\n  onEditPrompt: (prompt: PromptSFL) => void;\n  onDeletePrompt: (promptId: string) => void;\n  onExportJSON: (prompt: PromptSFL) => void;\n  onExportMarkdown: (prompt: PromptSFL) => void;\n}\n\n/**\n * A component that renders a grid of `PromptCard` components.\n * It serves as the main display area for the collection of prompts. If the `prompts` array\n * is empty, it renders a helpful \"empty state\" message to the user.\n *\n * @param {PromptListProps} props - The props for the component.\n * @returns {JSX.Element} The rendered list of prompts as a grid, or an empty state message.\n */\nconst PromptList: React.FC<PromptListProps> = ({ prompts, onViewPrompt, onEditPrompt, onDeletePrompt, onExportJSON, onExportMarkdown }) => {\n  if (prompts.length === 0) {\n    return (\n      <div className=\"text-center py-10 bg-[#333e48] rounded-lg border border-[#5c6f7e]\">\n        <ClipboardDocumentListIcon className=\"w-16 h-16 text-[#95aac0] mx-auto mb-4\"/>\n        <p className=\"text-xl text-gray-200 font-semibold\">No prompts found.</p>\n        <p className=\"text-sm text-[#95aac0]\">Try adjusting your filters or adding a new prompt.</p>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"grid grid-cols-1 md:grid-cols-2 xl:grid-cols-3 gap-6\">\n      {prompts.map(prompt => (\n        <PromptCard \n          key={prompt.id} \n          prompt={prompt} \n          onView={onViewPrompt}\n          onEdit={onEditPrompt}\n          onDelete={onDeletePrompt}\n          onExportJSON={onExportJSON}\n          onExportMarkdown={onExportMarkdown}\n        />\n      ))}\n    </div>\n  );\n};\n\nexport default PromptList;\n",
      "metadata": {
        "filename": "PromptList.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/PromptWizardModal.tsx\n\n/**\n * @file PromptWizardModal.tsx\n * @description This component provides a step-by-step wizard in a modal for creating a new SFL prompt.\n * It guides the user through providing a high-level goal, generates an initial SFL structure using an AI service,\n * and then allows the user to refine the generated prompt before saving. This simplifies the prompt creation\n * process for users who may not be familiar with the SFL framework.\n *\n * @requires react\n * @requires ../types\n * @requires ../services/geminiService\n * @requires ../constants\n * @requires ./ModalShell\n * @requires ./icons/SparklesIcon\n * @requires ./icons/PaperClipIcon\n * @requires ./icons/XCircleIcon\n */\n\nimport React, { useState, useRef } from 'react';\nimport { PromptSFL } from '../types';\nimport { generateSFLFromGoal, regenerateSFLFromSuggestion } from '../services/geminiService';\nimport { INITIAL_PROMPT_SFL } from '../constants';\nimport ModalShell from './ModalShell';\nimport SparklesIcon from './icons/SparklesIcon';\nimport PaperClipIcon from './icons/PaperClipIcon';\nimport XCircleIcon from './icons/XCircleIcon';\n\n/**\n * @interface PromptWizardModalProps\n * @description Defines the props for the `PromptWizardModal` component.\n * @property {boolean} isOpen - Controls the visibility of the modal.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {(prompt: PromptSFL) => void} onSave - Callback function to save the newly created prompt.\n * @property {object} appConstants - An object containing arrays of predefined options for SFL fields, used in the refinement step.\n * @property {(key: keyof PromptWizardModalProps['appConstants'], value: string) => void} onAddConstant - Callback to add a new user-defined option to the application's constants.\n */\ninterface PromptWizardModalProps {\n    isOpen: boolean;\n    onClose: () => void;\n    onSave: (prompt: PromptSFL) => void;\n    appConstants: {\n        taskTypes: string[];\n        aiPersonas: string[];\n        targetAudiences: string[];\n        desiredTones: string[];\n        outputFormats: string[];\n        lengthConstraints: string[];\n    };\n    onAddConstant: (key: keyof PromptWizardModalProps['appConstants'], value: string) => void;\n}\n\n/**\n * @typedef {'input' | 'loading' | 'refinement' | 'error'} WizardStep\n * @description Represents the current step of the wizard workflow, controlling which UI is displayed.\n */\ntype WizardStep = 'input' | 'loading' | 'refinement' | 'error';\n\n/**\n * A modal wizard that guides users through creating a new SFL prompt using AI assistance.\n * It manages the state for each step of the process:\n * 1. **Input**: User provides a high-level goal.\n * 2. **Loading**: The component calls an AI service to generate an SFL structure.\n * 3. **Refinement**: The user can review and edit the AI-generated prompt in a form.\n * 4. **Error**: Displays an error message if the generation fails.\n *\n * @param {PromptWizardModalProps} props - The props for the component.\n * @returns {JSX.Element} The rendered wizard modal.\n */\nconst PromptWizardModal: React.FC<PromptWizardModalProps> = ({ isOpen, onClose, onSave, appConstants, onAddConstant }) => {\n    const [step, setStep] = useState<WizardStep>('input');\n    const [goal, setGoal] = useState('');\n    const [errorMessage, setErrorMessage] = useState('');\n    const [formData, setFormData] = useState<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>(INITIAL_PROMPT_SFL);\n    const [newOptionValues, setNewOptionValues] = useState<Record<string, string>>({});\n    const [regenState, setRegenState] = useState({ shown: false, suggestion: '', loading: false });\n    const [saveState, setSaveState] = useState({ saving: false, error: '' });\n    const [sourceDoc, setSourceDoc] = useState<{name: string, content: string} | null>(null);\n    const fileInputRef = useRef<HTMLInputElement>(null);\n\n    /**\n     * @callback handleGenerate\n     * @description Initiates the AI generation process. It validates the user's goal,\n     * calls the `generateSFLFromGoal` service, and transitions the wizard to the next step.\n     */\n    const handleGenerate = async () => {\n        if (!goal.trim()) {\n            setErrorMessage('Please enter your goal.');\n            setStep('error');\n            setTimeout(() => setStep('input'), 3000);\n            return;\n        }\n        setStep('loading');\n        setErrorMessage('');\n\n        try {\n            const generatedData = await generateSFLFromGoal(goal, sourceDoc?.content);\n            setFormData({...generatedData, sourceDocument: sourceDoc || undefined });\n            setStep('refinement');\n        } catch (error: any) {\n            setErrorMessage(error.message || 'An unknown error occurred.');\n            setStep('error');\n        }\n    };\n    \n    /**\n     * @function handleReset\n     * @description Resets the wizard to its initial state.\n     */\n    const handleReset = () => {\n        setGoal('');\n        setFormData(INITIAL_PROMPT_SFL);\n        setErrorMessage('');\n        setStep('input');\n        setRegenState({ shown: false, suggestion: '', loading: false });\n        setSaveState({ saving: false, error: '' });\n        setSourceDoc(null);\n    };\n\n    /**\n     * @callback handleSave\n     * @description Saves the refined prompt. It performs validation and calls the `onSave` prop.\n     */\n    const handleSave = async () => {\n        setSaveState({ saving: true, error: '' });\n        \n        if (!formData.title?.trim()) {\n            setSaveState({ saving: false, error: 'Title is required' });\n            return;\n        }\n        if (!formData.promptText?.trim()) {\n            setSaveState({ saving: false, error: 'Prompt text is required' });\n            return;\n        }\n\n        try {\n            const finalPrompt: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'> = {\n                ...formData,\n                isTesting: false,\n            };\n            \n            await onSave(finalPrompt as PromptSFL);\n            setSaveState({ saving: false, error: '' });\n            onClose();\n        } catch (error) {\n            setSaveState({ \n                saving: false, \n                error: error instanceof Error ? error.message : 'Failed to save prompt' \n            });\n        }\n    };\n    \n    /**\n     * @function handleCloseAndReset\n     * @description A wrapper function that resets the wizard's state before calling the `onClose` prop.\n     */\n    const handleCloseAndReset = () => {\n        handleReset();\n        onClose();\n    };\n\n    /**\n     * @callback handleFileChange\n     * @description Handles the selection of a source document file.\n     * @param {React.ChangeEvent<HTMLInputElement>} event - The file input change event.\n     */\n    const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {\n        const file = event.target.files?.[0];\n        if (file) {\n            const reader = new FileReader();\n            reader.onload = (e) => {\n                const content = e.target?.result as string;\n                setSourceDoc({ name: file.name, content });\n            };\n            reader.readAsText(file);\n        }\n        if(event.target) event.target.value = '';\n    };\n    \n    const commonInputClasses = \"w-full px-3 py-2 bg-gray-50 border border-gray-300 text-gray-900 rounded-md shadow-sm focus:outline-none focus:ring-2 focus:ring-[#4A69E2] focus:border-[#4A69E2] transition-colors placeholder-gray-400\";\n    const labelClasses = \"block text-sm font-medium text-gray-700 mb-1\";\n    \n    /**\n     * @callback handleFormChange\n     * @description Generic change handler for top-level form fields in the refinement step.\n     * @param {React.ChangeEvent<HTMLInputElement | HTMLTextAreaElement>} e - The input change event.\n     */\n    const handleFormChange = (e: React.ChangeEvent<HTMLInputElement | HTMLTextAreaElement>) => {\n        const { name, value } = e.target;\n        setFormData(prev => ({...prev, [name]: value}));\n    };\n\n    /**\n     * @callback handleSFLChange\n     * @description Change handler for nested SFL fields in the refinement step.\n     * @param {React.ChangeEvent<HTMLInputElement | HTMLTextAreaElement | HTMLSelectElement>} e - The input change event.\n     */\n    const handleSFLChange = (e: React.ChangeEvent<HTMLInputElement | HTMLTextAreaElement | HTMLSelectElement>) => {\n        const { name, value } = e.target;\n        const [sflType, field] = name.split('.');\n        setFormData(prev => ({\n            ...prev,\n            [sflType]: {\n                ...prev[sflType],\n                [field]: value,\n            },\n        }));\n    };\n\n    /**\n     * @callback handleSFLDirectChange\n     * @description A direct state updater for SFL fields, used by complex inputs like checkboxes.\n     */\n    const handleSFLDirectChange = <K extends 'sflField' | 'sflTenor' | 'sflMode', F extends keyof PromptSFL[K]>(sflType: K, field: F, value: any) => {\n        setFormData(prev => ({\n            ...prev,\n            [sflType]: {\n                ...prev[sflType],\n                [field]: value,\n            },\n        }));\n    }\n    \n    /**\n     * @callback handleTargetAudienceChange\n     * @description Toggles an audience in the `targetAudience` array.\n     * @param {string} audience - The audience to toggle.\n     */\n    const handleTargetAudienceChange = (audience: string) => {\n        const currentAudiences = formData.sflTenor.targetAudience || [];\n        const newAudiences = currentAudiences.includes(audience)\n          ? currentAudiences.filter(a => a !== audience)\n          : [...currentAudiences, audience];\n        handleSFLDirectChange('sflTenor', 'targetAudience', newAudiences);\n    };\n\n    /**\n     * @callback handleAddNewOption\n     * @description Adds a new user-defined option to a creatable select field.\n     */\n    const handleAddNewOption = <\n        K extends 'sflField' | 'sflTenor' | 'sflMode',\n        F extends keyof PromptSFL[K]\n    >(constantsKey: keyof typeof appConstants, sflKey: K, fieldKey: F) => {\n        const value = newOptionValues[String(fieldKey)];\n        if(value && value.trim()){\n          onAddConstant(constantsKey, value);\n          handleSFLDirectChange(sflKey, fieldKey, value);\n          setNewOptionValues(prev => ({...prev, [String(fieldKey)]: ''}));\n        }\n    };\n    \n    /**\n     * @callback handleRegeneratePrompt\n     * @description Handles AI-powered refinement of the generated prompt during the refinement step.\n     */\n    const handleRegeneratePrompt = async () => {\n        if (!regenState.suggestion.trim()) return;\n        setRegenState(prev => ({ ...prev, loading: true }));\n        try {\n          const result = await regenerateSFLFromSuggestion(formData, regenState.suggestion);\n          setFormData(result);\n          setRegenState({ shown: false, suggestion: '', loading: false });\n        } catch (error) {\n          console.error(error);\n          alert('Failed to regenerate prompt: ' + (error instanceof Error ? error.message : String(error)));\n          setRegenState(prev => ({ ...prev, loading: false }));\n        }\n    };\n    \n    /**\n     * @function renderCreatableSelect\n     * @description Renders a creatable select dropdown component.\n     * @returns {JSX.Element}\n     * @private\n     */\n    const renderCreatableSelect = <\n        K extends 'sflField' | 'sflTenor' | 'sflMode',\n        F extends keyof PromptSFL[K]\n    >(label: string, name: string, value: string, onChange: (e: React.ChangeEvent<HTMLSelectElement>) => void, options: string[], constantsKey: keyof typeof appConstants, sflKey: K, fieldKey: F) => (\n        <div>\n            <label className={labelClasses}>{label}</label>\n            <select name={name} value={value} onChange={onChange} className={commonInputClasses}>\n                <option value=\"\">Select...</option>\n                {options.map(o => <option key={o} value={o}>{o}</option>)}\n            </select>\n             <div className=\"flex items-center space-x-2 mt-2\">\n                <input type=\"text\" placeholder=\"Add new option...\" value={newOptionValues[String(fieldKey)] || ''} onChange={e => setNewOptionValues(prev => ({...prev, [String(fieldKey)]: e.target.value}))} className={`${commonInputClasses} text-sm`} />\n                <button type=\"button\" onClick={() => handleAddNewOption(constantsKey, sflKey, fieldKey)} className=\"px-3 py-2 text-sm bg-gray-200 hover:bg-gray-300 rounded-md shrink-0 text-gray-800\">Add</button>\n            </div>\n        </div>\n    );\n\n    /**\n     * @function renderRefinementForm\n     * @description Renders the full prompt editing form for the 'refinement' step.\n     * @returns {JSX.Element}\n     * @private\n     */\n    const renderRefinementForm = () => (\n        <form className=\"space-y-6\" onSubmit={(e) => { e.preventDefault(); handleSave(); }}>\n             <div>\n                <label htmlFor=\"title\" className={labelClasses}>Title</label>\n                <input type=\"text\" id=\"title\" name=\"title\" value={formData.title} onChange={handleFormChange} className={commonInputClasses} />\n            </div>\n            <div>\n                <label htmlFor=\"promptText\" className={labelClasses}>Prompt Text</label>\n                <textarea id=\"promptText\" name=\"promptText\" value={formData.promptText} onChange={handleFormChange} rows={5} className={commonInputClasses} />\n            </div>\n            \n             {formData.sourceDocument && (\n                <div>\n                    <label className={labelClasses}>Source Document</label>\n                     <div className=\"flex items-center justify-between bg-gray-100 p-2 rounded-md border border-gray-300\">\n                        <span className=\"text-sm text-gray-800 truncate pr-2\">{formData.sourceDocument.name}</span>\n                        <button type=\"button\" onClick={() => setFormData(prev => ({...prev, sourceDocument: undefined}))} className=\"text-red-500 hover:text-red-700 shrink-0\" aria-label=\"Remove source document\">\n                            <XCircleIcon className=\"w-5 h-5\"/>\n                        </button>\n                    </div>\n                </div>\n            )}\n\n            <div className=\"my-2 text-right\">\n                <button type=\"button\" onClick={() => setRegenState(prev => ({...prev, shown: !prev.shown, suggestion: ''}))} className=\"text-sm text-[#4A69E2] hover:text-blue-700 flex items-center justify-end\">\n                    <SparklesIcon className=\"w-5 h-5 mr-1\"/> Refine Prompt with AI\n                </button>\n            </div>\n            \n            {regenState.shown && (\n                <div className=\"space-y-2 p-3 bg-gray-50 rounded-md border border-gray-200\">\n                    <label htmlFor=\"regenSuggestion-wiz\" className={`${labelClasses} text-gray-800`}>How should this prompt be changed?</label>\n                    <textarea id=\"regenSuggestion-wiz\" value={regenState.suggestion} onChange={e => setRegenState(prev => ({...prev, suggestion: e.target.value}))} rows={2} placeholder=\"e.g., Make the tone more formal...\" className={commonInputClasses} />\n                    <div className=\"flex justify-end space-x-2\">\n                        <button type=\"button\" onClick={() => setRegenState({ shown: false, suggestion: '', loading: false })} className=\"px-3 py-1 text-xs bg-gray-200 text-gray-800 rounded-md hover:bg-gray-300\">Cancel</button>\n                        <button type=\"button\" onClick={handleRegeneratePrompt} disabled={regenState.loading || !regenState.suggestion.trim()} className=\"px-3 py-1 text-xs bg-[#4A69E2] text-white rounded-md hover:bg-opacity-90 disabled:bg-opacity-50 disabled:cursor-not-allowed flex items-center\">\n                            {regenState.loading && <div className=\"w-3 h-3 border-2 border-t-transparent border-white rounded-full animate-spin mr-2\"></div>}\n                            {regenState.loading ? 'Refining...' : 'Refine'}\n                        </button>\n                    </div>\n                </div>\n            )}\n\n            <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n              <legend className=\"text-lg font-medium text-gray-800 px-2\">SFL: Field</legend>\n              <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 mt-2\">\n                <div><label className={labelClasses}>Topic</label><input type=\"text\" name=\"sflField.topic\" value={formData.sflField.topic} onChange={handleSFLChange} className={commonInputClasses}/></div>\n                {renderCreatableSelect('Task Type', 'sflField.taskType', formData.sflField.taskType, handleSFLChange, appConstants.taskTypes, 'taskTypes', 'sflField', 'taskType')}\n                <div className=\"md:col-span-2\"><label className={labelClasses}>Domain Specifics</label><input type=\"text\" name=\"sflField.domainSpecifics\" value={formData.sflField.domainSpecifics} onChange={handleSFLChange} className={commonInputClasses}/></div>\n                <div className=\"md:col-span-2\"><label className={labelClasses}>Keywords</label><input type=\"text\" name=\"sflField.keywords\" value={formData.sflField.keywords} onChange={handleSFLChange} className={commonInputClasses}/></div>\n              </div>\n            </fieldset>\n            \n            <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n              <legend className=\"text-lg font-medium text-gray-800 px-2\">SFL: Tenor</legend>\n               <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 mt-2\">\n                {renderCreatableSelect('AI Persona', 'sflTenor.aiPersona', formData.sflTenor.aiPersona, handleSFLChange, appConstants.aiPersonas, 'aiPersonas', 'sflTenor', 'aiPersona')}\n                {renderCreatableSelect('Desired Tone', 'sflTenor.desiredTone', formData.sflTenor.desiredTone, handleSFLChange, appConstants.desiredTones, 'desiredTones', 'sflTenor', 'desiredTone')}\n                <div className=\"md:col-span-2\">\n                     <label className={labelClasses}>Target Audience</label>\n                    <div className=\"grid grid-cols-2 sm:grid-cols-3 gap-2 mt-1 max-h-40 overflow-y-auto p-2 border border-gray-300 rounded-md bg-white\">\n                        {(appConstants.targetAudiences || []).map(audience => (\n                            <div key={audience} className=\"flex items-center\">\n                                <input id={`wiz-audience-${audience}`} type=\"checkbox\" checked={(formData.sflTenor.targetAudience || []).includes(audience)} onChange={() => handleTargetAudienceChange(audience)} className=\"h-4 w-4 rounded border-gray-300 text-[#4A69E2] focus:ring-[#4A69E2]\" />\n                                <label htmlFor={`wiz-audience-${audience}`} className=\"ml-2 text-sm text-gray-800 select-none\">{audience}</label>\n                            </div>\n                        ))}\n                    </div>\n                     <div className=\"flex items-center space-x-2 mt-2\">\n                        <input type=\"text\" placeholder=\"Add new audience...\" value={newOptionValues['targetAudience'] || ''} onChange={e => setNewOptionValues(prev => ({...prev, 'targetAudience': e.target.value}))} className={`${commonInputClasses} text-sm`} />\n                        <button type=\"button\" onClick={() => {\n                            const value = newOptionValues['targetAudience'];\n                            if(value && value.trim()){\n                                onAddConstant('targetAudiences', value);\n                                handleTargetAudienceChange(value);\n                                setNewOptionValues(prev => ({...prev, 'targetAudience': ''}));\n                            }\n                        }} className=\"px-3 py-2 text-sm bg-gray-200 hover:bg-gray-300 rounded-md shrink-0 text-gray-800\">Add</button>\n                    </div>\n                </div>\n                <div className=\"md:col-span-2\"><label className={labelClasses}>Interpersonal Stance</label><input type=\"text\" name=\"sflTenor.interpersonalStance\" value={formData.sflTenor.interpersonalStance} onChange={handleSFLChange} className={commonInputClasses}/></div>\n              </div>\n            </fieldset>\n\n            <fieldset className=\"border border-gray-300 p-4 rounded-md\">\n              <legend className=\"text-lg font-medium text-gray-800 px-2\">SFL: Mode</legend>\n              <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 mt-2\">\n                {renderCreatableSelect('Output Format', 'sflMode.outputFormat', formData.sflMode.outputFormat, handleSFLChange, appConstants.outputFormats, 'outputFormats', 'sflMode', 'outputFormat')}\n                {renderCreatableSelect('Length Constraint', 'sflMode.lengthConstraint', formData.sflMode.lengthConstraint, handleSFLChange, appConstants.lengthConstraints, 'lengthConstraints', 'sflMode', 'lengthConstraint')}\n                <div className=\"md:col-span-2\"><label className={labelClasses}>Rhetorical Structure</label><input type=\"text\" name=\"sflMode.rhetoricalStructure\" value={formData.sflMode.rhetoricalStructure} onChange={handleSFLChange} className={commonInputClasses}/></div>\n                <div className=\"md:col-span-2\"><label className={labelClasses}>Textual Directives</label><input type=\"text\" name=\"sflMode.textualDirectives\" value={formData.sflMode.textualDirectives} onChange={handleSFLChange} className={commonInputClasses}/></div>\n              </div>\n            </fieldset>\n\n            <div>\n                <label htmlFor=\"exampleOutput\" className={labelClasses}>Example Output (Optional)</label>\n                <textarea id=\"exampleOutput\" name=\"exampleOutput\" value={formData.exampleOutput || ''} onChange={handleFormChange} rows={3} className={commonInputClasses} />\n            </div>\n            \n            <div>\n                <label htmlFor=\"notes\" className={labelClasses}>Notes (Optional)</label>\n                <textarea id=\"notes\" name=\"notes\" value={formData.notes || ''} onChange={handleFormChange} rows={2} className={commonInputClasses} />\n            </div>\n\n            {saveState.error && (\n                <div className=\"bg-red-50 border border-red-200 rounded-md p-3\">\n                    <div className=\"flex\">\n                        <div className=\"flex-shrink-0\">\n                            <XCircleIcon className=\"h-5 w-5 text-red-400\" />\n                        </div>\n                        <div className=\"ml-3\">\n                            <p className=\"text-sm text-red-800\">{saveState.error}</p>\n                        </div>\n                    </div>\n                </div>\n            )}\n        </form>\n    );\n\n    /**\n     * @function renderContent\n     * @description A router-like function that renders the content for the current wizard step.\n     * @returns {JSX.Element} The UI for the current step.\n     * @private\n     */\n    const renderContent = () => {\n        switch (step) {\n            case 'input':\n                return (\n                    <form className=\"space-y-4\" onSubmit={(e) => { e.preventDefault(); handleGenerate(); }}>\n                        <input type=\"file\" ref={fileInputRef} onChange={handleFileChange} className=\"hidden\" accept=\".txt,.md,.text\"/>\n                        <div>\n                            <label htmlFor=\"goal\" className=\"block text-lg text-gray-700 mb-2\">Describe your prompt's goal</label>\n                            <textarea\n                                id=\"goal\"\n                                value={goal}\n                                onChange={(e) => setGoal(e.target.value)}\n                                placeholder=\"e.g., I want a short, funny poem about a cat who is a senior software engineer.\"\n                                rows={6}\n                                className={commonInputClasses}\n                                aria-label=\"Your prompt goal\"\n                            />\n                        </div>\n                        <div>\n                            <label className={labelClasses}>Source Document (Optional)</label>\n                            <p className=\"text-xs text-gray-500 mb-2\">Attach a text file for stylistic reference. The AI will analyze its style to generate the prompt.</p>\n                            {sourceDoc ? (\n                                <div className=\"flex items-center justify-between bg-gray-100 p-2 rounded-md border border-gray-300\">\n                                <span className=\"text-sm text-gray-800 truncate pr-2\">{sourceDoc.name}</span>\n                                <button type=\"button\" onClick={() => setSourceDoc(null)} className=\"text-red-500 hover:text-red-700 shrink-0\" aria-label=\"Remove source document\">\n                                    <XCircleIcon className=\"w-5 h-5\"/>\n                                </button>\n                                </div>\n                            ) : (\n                                <button\n                                type=\"button\"\n                                onClick={() => fileInputRef.current?.click()}\n                                className=\"w-full flex items-center justify-center px-3 py-2 bg-white border-2 border-dashed border-gray-300 text-gray-500 rounded-md hover:bg-gray-50 hover:border-gray-400 transition-colors\"\n                                >\n                                <PaperClipIcon className=\"w-5 h-5 mr-2\" />\n                                Attach Document\n                                </button>\n                            )}\n                        </div>\n                         <div className=\"flex justify-end space-x-3 pt-4\">\n                            <button type=\"button\" onClick={handleCloseAndReset} className=\"px-4 py-2 text-sm font-medium text-gray-700 bg-white border border-gray-300 rounded-md hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-indigo-500\">Cancel</button>\n                            <button type=\"submit\" className=\"px-4 py-2 text-sm font-medium text-white bg-[#4A69E2] rounded-md hover:bg-opacity-90 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-[#4A69E2]\">Generate SFL Prompt</button>\n                        </div>\n                    </form>\n                );\n            case 'loading':\n                return (\n                    <div className=\"flex flex-col items-center justify-center p-8 text-center h-64\">\n                        <div className=\"spinner mb-4\"></div>\n                        <p className=\"text-lg text-gray-800\">Generating SFL structure...</p>\n                        <p className=\"text-gray-500 text-sm\">This may take a moment.</p>\n                    </div>\n                );\n            case 'refinement':\n                return (\n                   <div className=\"space-y-6\">\n                       {renderRefinementForm()}\n                       <div className=\"flex justify-end space-x-3 pt-4 border-t border-gray-200 mt-6\">\n                            <button \n                                type=\"button\" \n                                onClick={handleReset} \n                                disabled={saveState.saving}\n                                className=\"px-4 py-2 text-sm font-medium text-gray-700 bg-white border border-gray-300 rounded-md hover:bg-gray-50 disabled:opacity-50 disabled:cursor-not-allowed\"\n                            >\n                                Start Over\n                            </button>\n                            <button \n                                type=\"button\" \n                                onClick={handleSave} \n                                disabled={saveState.saving}\n                                className=\"px-4 py-2 text-sm font-medium text-white bg-[#4A69E2] rounded-md hover:bg-opacity-90 disabled:opacity-50 disabled:cursor-not-allowed flex items-center\"\n                            >\n                                {saveState.saving && (\n                                    <div className=\"w-4 h-4 border-2 border-t-transparent border-white rounded-full animate-spin mr-2\"></div>\n                                )}\n                                {saveState.saving ? 'Saving...' : 'Save Prompt'}\n                            </button>\n                       </div>\n                   </div>\n                );\n            case 'error':\n                 return (\n                    <div className=\"flex flex-col items-center justify-center p-8 text-center bg-red-50 border border-red-200 rounded-lg\">\n                        <h4 className=\"text-lg font-bold text-red-700 mb-2\">Error</h4>\n                        <p className=\"text-red-600 mb-4\">{errorMessage}</p>\n                        <button onClick={handleReset} className=\"px-4 py-2 text-sm font-medium text-gray-700 bg-white border border-gray-300 rounded-md hover:bg-gray-50\">Try Again</button>\n                    </div>\n                );\n        }\n    };\n\n    return (\n        <ModalShell isOpen={isOpen} onClose={handleCloseAndReset} title=\"Prompt Wizard\" size=\"4xl\">\n            {renderContent()}\n        </ModalShell>\n    );\n};\n\nexport default PromptWizardModal;\n",
      "metadata": {
        "filename": "PromptWizardModal.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/ProviderSwitcher.tsx\n\n/**\n * @file ProviderSwitcher.tsx\n * @description This component provides dynamic AI provider switching functionality.\n * It allows users to quickly switch between configured providers, select models,\n * and adjust parameters in real-time without needing to navigate to settings.\n *\n * @requires react\n * @requires ../types/aiProvider\n * @requires ../config/modelCapabilities\n */\n\nimport React, { useState, useEffect } from 'react';\nimport { AIProvider, ActiveProviderConfig, ModelParameters } from '../types/aiProvider';\nimport { PROVIDER_CONFIGS, getProviderModels, getParameterConstraints } from '../config/modelCapabilities';\nimport CogIcon from './icons/CogIcon';\nimport ArrowsRightLeftIcon from './icons/ArrowsRightLeftIcon';\nimport CheckCircleIcon from './icons/CheckCircleIcon';\nimport XCircleIcon from './icons/XCircleIcon';\n\n/**\n * @interface ProviderSwitcherProps\n * @description Defines the props for the ProviderSwitcher component.\n */\ninterface ProviderSwitcherProps {\n  /** Current active provider configuration */\n  currentConfig: ActiveProviderConfig;\n  /** Callback when provider configuration changes */\n  onConfigChange: (config: ActiveProviderConfig) => void;\n  /** Whether the switcher is in compact mode */\n  compact?: boolean;\n  /** Whether to show advanced parameters */\n  showAdvanced?: boolean;\n}\n\n/**\n * A compact component for switching AI providers and configuring parameters\n * at runtime. Designed to be embedded in other interfaces where quick\n * provider switching is needed.\n *\n * @param {ProviderSwitcherProps} props - The component props\n * @returns {JSX.Element} The rendered provider switcher\n */\nconst ProviderSwitcher: React.FC<ProviderSwitcherProps> = ({\n  currentConfig,\n  onConfigChange,\n  compact = false,\n  showAdvanced = false\n}) => {\n  // Local state for UI management\n  const [isExpanded, setIsExpanded] = useState(!compact);\n  const [availableModels, setAvailableModels] = useState<string[]>([]);\n  const [parameterConstraints, setParameterConstraints] = useState<any>({});\n  const [hasValidApiKey, setHasValidApiKey] = useState(false);\n\n  // Load available models when provider changes\n  useEffect(() => {\n    const models = getProviderModels(currentConfig.provider);\n    setAvailableModels(models.map(model => model.id));\n    \n    // Update parameter constraints for current model\n    const constraints = getParameterConstraints(currentConfig.provider, currentConfig.model);\n    setParameterConstraints(constraints);\n  }, [currentConfig.provider, currentConfig.model]);\n\n  // Check if API key is configured for the current provider\n  useEffect(() => {\n    const hasKey = Boolean(currentConfig.apiKey);\n    setHasValidApiKey(hasKey);\n  }, [currentConfig.apiKey, currentConfig.provider]);\n\n  /**\n   * Handle provider change\n   */\n  const handleProviderChange = (newProvider: AIProvider) => {\n    const providerConfig = PROVIDER_CONFIGS[newProvider];\n    const firstModel = providerConfig.models[0];\n    \n    // Load API key from localStorage\n    const savedApiKey = localStorage.getItem(`sfl-api-key-${newProvider}`) || '';\n    \n    const newConfig: ActiveProviderConfig = {\n      provider: newProvider,\n      model: firstModel.id,\n      parameters: providerConfig.defaultParameters,\n      apiKey: savedApiKey,\n      baseUrl: providerConfig.baseUrl\n    };\n    \n    onConfigChange(newConfig);\n  };\n\n  /**\n   * Handle model change\n   */\n  const handleModelChange = (modelId: string) => {\n    const providerConfig = PROVIDER_CONFIGS[currentConfig.provider];\n    const newConfig: ActiveProviderConfig = {\n      ...currentConfig,\n      model: modelId,\n      parameters: providerConfig.defaultParameters\n    };\n    \n    onConfigChange(newConfig);\n  };\n\n  /**\n   * Handle parameter change\n   */\n  const handleParameterChange = (paramName: string, value: number | string) => {\n    const newParameters = {\n      ...currentConfig.parameters,\n      [paramName]: value\n    };\n    \n    const newConfig: ActiveProviderConfig = {\n      ...currentConfig,\n      parameters: newParameters\n    };\n    \n    onConfigChange(newConfig);\n  };\n\n  /**\n   * Render parameter control for a specific parameter\n   */\n  const renderParameterControl = (paramName: string, constraint: any) => {\n    const currentValue = (currentConfig.parameters as any)[paramName] ?? constraint.default;\n    \n    return (\n      <div key={paramName} className=\"space-y-1\">\n        <label className=\"block text-xs font-medium text-[#95aac0] capitalize\">\n          {paramName.replace(/([A-Z])/g, ' $1').replace(/_/g, ' ')}\n        </label>\n        <div className=\"flex items-center space-x-2\">\n          <input\n            type=\"range\"\n            min={constraint.min}\n            max={constraint.max}\n            step={constraint.step}\n            value={currentValue}\n            onChange={(e) => handleParameterChange(paramName, parseFloat(e.target.value))}\n            className=\"flex-1 h-1 bg-[#5c6f7e] rounded-lg appearance-none cursor-pointer slider\"\n          />\n          <input\n            type=\"number\"\n            min={constraint.min}\n            max={constraint.max}\n            step={constraint.step}\n            value={currentValue}\n            onChange={(e) => handleParameterChange(paramName, parseFloat(e.target.value))}\n            className=\"w-16 px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 focus:border-[#e2a32d]\"\n          />\n        </div>\n      </div>\n    );\n  };\n\n  const currentProviderConfig = PROVIDER_CONFIGS[currentConfig.provider];\n\n  if (compact && !isExpanded) {\n    return (\n      <div className=\"flex items-center space-x-2 bg-[#333e48] px-3 py-2 rounded-lg border border-[#5c6f7e]\">\n        <div className=\"flex items-center space-x-1\">\n          <div className={`w-2 h-2 rounded-full ${hasValidApiKey ? 'bg-green-500' : 'bg-red-500'}`} />\n          <span className=\"text-sm text-gray-200 font-medium\">\n            {currentProviderConfig.name}\n          </span>\n        </div>\n        <div className=\"text-xs text-[#95aac0]\">\n          {currentConfig.model}\n        </div>\n        <button\n          onClick={() => setIsExpanded(true)}\n          className=\"p-1 hover:bg-[#5c6f7e] rounded transition-colors\"\n        >\n          <CogIcon className=\"w-4 h-4 text-[#95aac0]\" />\n        </button>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"bg-[#333e48] border border-[#5c6f7e] rounded-lg p-4 space-y-4\">\n      {/* Header */}\n      <div className=\"flex items-center justify-between\">\n        <div className=\"flex items-center space-x-2\">\n          <ArrowsRightLeftIcon className=\"w-5 h-5 text-[#e2a32d]\" />\n          <h3 className=\"text-sm font-semibold text-[#e2a32d]\">AI Provider</h3>\n        </div>\n        {compact && (\n          <button\n            onClick={() => setIsExpanded(false)}\n            className=\"p-1 hover:bg-[#5c6f7e] rounded transition-colors\"\n          >\n            <XCircleIcon className=\"w-4 h-4 text-[#95aac0]\" />\n          </button>\n        )}\n      </div>\n\n      {/* Provider Selection */}\n      <div className=\"space-y-2\">\n        <label className=\"block text-xs font-medium text-[#95aac0]\">Provider</label>\n        <div className=\"grid grid-cols-2 gap-2\">\n          {(Object.keys(PROVIDER_CONFIGS) as AIProvider[]).map((provider) => {\n            const config = PROVIDER_CONFIGS[provider];\n            const isSelected = currentConfig.provider === provider;\n            const hasKey = Boolean(localStorage.getItem(`sfl-api-key-${provider}`));\n            \n            return (\n              <button\n                key={provider}\n                onClick={() => handleProviderChange(provider)}\n                className={`flex items-center space-x-2 p-2 rounded border text-left transition-colors ${\n                  isSelected\n                    ? 'border-[#e2a32d] bg-[#e2a32d] bg-opacity-10'\n                    : 'border-[#5c6f7e] hover:border-[#95aac0]'\n                }`}\n              >\n                <div className={`w-2 h-2 rounded-full ${hasKey ? 'bg-green-500' : 'bg-red-500'}`} />\n                <span className=\"text-xs text-gray-200\">{config.name}</span>\n              </button>\n            );\n          })}\n        </div>\n      </div>\n\n      {/* API Key Status */}\n      {!hasValidApiKey && (\n        <div className=\"flex items-center space-x-2 p-2 bg-red-900 bg-opacity-20 border border-red-500 rounded\">\n          <XCircleIcon className=\"w-4 h-4 text-red-500\" />\n          <span className=\"text-xs text-red-400\">\n            API key not configured. Visit Settings to configure.\n          </span>\n        </div>\n      )}\n\n      {/* Model Selection */}\n      {hasValidApiKey && (\n        <div className=\"space-y-2\">\n          <label className=\"block text-xs font-medium text-[#95aac0]\">Model</label>\n          <select\n            value={currentConfig.model}\n            onChange={(e) => handleModelChange(e.target.value)}\n            className=\"w-full px-3 py-2 bg-[#212934] border border-[#5c6f7e] text-gray-200 rounded text-sm focus:border-[#e2a32d] focus:outline-none\"\n          >\n            {availableModels.map((modelId) => {\n              const modelInfo = getProviderModels(currentConfig.provider).find(m => m.id === modelId);\n              return (\n                <option key={modelId} value={modelId}>\n                  {modelInfo?.name || modelId}\n                </option>\n              );\n            })}\n          </select>\n        </div>\n      )}\n\n      {/* Parameters */}\n      {hasValidApiKey && showAdvanced && Object.keys(parameterConstraints).length > 0 && (\n        <div className=\"space-y-3\">\n          <label className=\"block text-xs font-medium text-[#95aac0]\">Parameters</label>\n          <div className=\"grid grid-cols-1 gap-3\">\n            {Object.entries(parameterConstraints).map(([paramName, constraint]) =>\n              renderParameterControl(paramName, constraint)\n            )}\n          </div>\n        </div>\n      )}\n\n      {/* Quick Parameter Presets */}\n      {hasValidApiKey && showAdvanced && (\n        <div className=\"space-y-2\">\n          <label className=\"block text-xs font-medium text-[#95aac0]\">Quick Presets</label>\n          <div className=\"grid grid-cols-3 gap-1\">\n            <button\n              onClick={() => handleParameterChange('temperature', 0.2)}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Precise\n            </button>\n            <button\n              onClick={() => {\n                const defaultParams = currentProviderConfig.defaultParameters;\n                Object.entries(defaultParams).forEach(([key, value]) => {\n                  if (typeof value === 'number') {\n                    handleParameterChange(key, value);\n                  }\n                });\n              }}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Balanced\n            </button>\n            <button\n              onClick={() => {\n                const constraint = parameterConstraints.temperature;\n                if (constraint) {\n                  handleParameterChange('temperature', Math.min(1.5, constraint.max));\n                }\n              }}\n              className=\"px-2 py-1 text-xs bg-[#212934] border border-[#5c6f7e] rounded text-gray-200 hover:border-[#e2a32d] transition-colors\"\n            >\n              Creative\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default ProviderSwitcher;\n",
      "metadata": {
        "filename": "ProviderSwitcher.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/Sidebar.tsx\n\n/**\n * @file Sidebar.tsx\n * @description This component renders the main sidebar for the application.\n * It includes primary navigation links, quick filters for task types and AI personas,\n * and a section for popular tags. It also displays the status of the connected AI model.\n *\n * @requires react\n * @requires ../types\n * @requires ./icons/BrainCircuitIcon\n * @requires ./icons/HomeIcon\n * @requires ./icons/FlaskIcon\n * @requires ./icons/BookOpenIcon\n * @requires ./icons/CogIcon\n * @requires ./icons/ChatBubbleLeftRightIcon\n * @requires ./icons/CodeBracketIcon\n * @requires ./icons/DocumentTextIcon\n * @requires ./icons/LanguageIcon\n * @requires ./icons/UserCircleIcon\n * @requires ./icons/FaceSmileIcon\n * @requires ./icons/BeakerIcon\n * @requires ./icons/PlusIcon\n */\n\nimport React from 'react';\nimport { Filters } from '../types';\nimport BrainCircuitIcon from './icons/BrainCircuitIcon';\nimport HomeIcon from './icons/HomeIcon';\nimport FlaskIcon from './icons/FlaskIcon';\nimport BookOpenIcon from './icons/BookOpenIcon';\nimport CogIcon from './icons/CogIcon';\nimport ChatBubbleLeftRightIcon from './icons/ChatBubbleLeftRightIcon';\nimport CodeBracketIcon from './icons/CodeBracketIcon';\nimport DocumentTextIcon from './icons/DocumentTextIcon';\nimport LanguageIcon from './icons/LanguageIcon';\nimport UserCircleIcon from './icons/UserCircleIcon';\nimport FaceSmileIcon from './icons/FaceSmileIcon';\nimport BeakerIcon from './icons/BeakerIcon';\nimport PlusIcon from './icons/PlusIcon';\n\n/**\n * @typedef {'dashboard' | 'lab' | 'documentation' | 'settings'} Page\n * @description Represents the possible main pages the user can navigate to.\n */\ntype Page = 'dashboard' | 'lab' | 'documentation' | 'settings';\n\n/**\n * @interface SidebarProps\n * @description Defines the props for the `Sidebar` component.\n * @property {Filters} filters - The current state of the filters, used to highlight active filter buttons.\n * @property {(key: K, value: Filters[K]) => void} onFilterChange - Callback to update a filter property in the parent component's state.\n * @property {string[]} popularTags - An array of popular tags to display as quick filter buttons.\n * @property {Page} activePage - The currently active page, used to highlight the active navigation item.\n * @property {(page: Page) => void} onNavigate - Callback to handle navigation to a different page.\n */\ninterface SidebarProps {\n  filters: Filters;\n  onFilterChange: <K extends keyof Filters>(key: K, value: Filters[K]) => void;\n  popularTags: string[];\n  activePage: Page;\n  onNavigate: (page: Page) => void;\n}\n\n/**\n * A reusable, styled button component for primary navigation links in the sidebar.\n *\n * @param {object} props - The component props.\n * @param {React.ComponentType<{ className?: string }>} props.icon - The icon component to display.\n * @param {string} props.label - The text label for the navigation item.\n * @param {boolean} [props.active=false] - Whether the item is currently active.\n * @param {() => void} props.onClick - The click handler for the navigation item.\n * @returns {JSX.Element} A styled button for navigation.\n * @private\n */\nconst NavItem: React.FC<{ icon: React.ComponentType<{ className?: string }>; label: string; active?: boolean, onClick: () => void; }> = ({ icon: Icon, label, active, onClick }) => (\n  <button onClick={onClick} className={`flex items-center w-full px-3 py-2 rounded-md text-sm font-medium transition-colors text-left ${\n      active ? 'bg-[#e2a32d] text-gray-200' : 'text-[#95aac0] hover:bg-[#333e48]'\n    }`}\n  >\n    <Icon className=\"w-5 h-5 mr-3\" />\n    {label}\n  </button>\n);\n\n/**\n * A reusable, styled button component for quick filter items in the sidebar.\n *\n * @param {object} props - The component props.\n * @param {React.ComponentType<{ className?: string }>} props.icon - The icon component to display.\n * @param {string} props.label - The text label for the filter.\n * @param {() => void} props.onClick - The click handler to apply the filter.\n * @param {boolean} props.selected - Whether the filter is currently selected.\n * @returns {JSX.Element} A styled button for applying a filter.\n * @private\n */\nconst FilterItem: React.FC<{ icon: React.ComponentType<{ className?: string }>; label: string; onClick: () => void; selected: boolean }> = ({ icon: Icon, label, onClick, selected }) => (\n    <button onClick={onClick} className={`flex w-full items-center px-3 py-2 rounded-md text-sm font-medium transition-colors ${\n        selected ? 'text-gray-200 bg-[#333e48]' : 'text-[#95aac0] hover:bg-[#333e48]'\n      }`}\n    >\n      <Icon className=\"w-5 h-5 mr-3\" />\n      {label}\n    </button>\n);\n\n/**\n * The main sidebar component for the application.\n * It provides primary navigation, quick filtering capabilities for prompts,\n * and status information about the connected AI model.\n *\n * @param {SidebarProps} props - The props for the component.\n * @returns {JSX.Element} The rendered sidebar.\n */\nconst Sidebar: React.FC<SidebarProps> = ({ filters, onFilterChange, popularTags, activePage, onNavigate }) => {\n    const taskTypes = [\"Explanation\", \"Code Generation\", \"Summarization\", \"Translation\"];\n    const taskIcons: { [key: string]: React.ComponentType<{ className?: string }> } = {\n        \"Explanation\": ChatBubbleLeftRightIcon,\n        \"Code Generation\": CodeBracketIcon,\n        \"Summarization\": DocumentTextIcon,\n        \"Translation\": LanguageIcon,\n    };\n\n    const aiPersonas = [\"Expert\", \"Friendly Assistant\", \"Sarcastic Bot\"];\n    const personaIcons: { [key: string]: React.ComponentType<{ className?: string }> } = {\n        \"Expert\": UserCircleIcon,\n        \"Friendly Assistant\": FaceSmileIcon,\n        \"Sarcastic Bot\": BeakerIcon,\n    };\n\n  return (\n    <aside className=\"w-72 bg-[#212934] text-gray-200 flex flex-col p-4 space-y-4 overflow-y-auto border-r border-[#5c6f7e]\">\n      <div className=\"flex items-center space-x-2 px-3 pt-2 pb-4\">\n        <BrainCircuitIcon className=\"w-8 h-8 text-[#e2a32d]\" />\n        <span className=\"text-xl font-bold\">SFL Prompt Knowledge Base</span>\n      </div>\n\n      <div className=\"flex-grow space-y-6\">\n        <div>\n          <h3 className=\"px-3 text-xs font-semibold text-[#95aac0] uppercase tracking-wider mb-2\">Navigation</h3>\n          <nav className=\"space-y-1\">\n            <NavItem icon={HomeIcon} label=\"Dashboard\" active={activePage === 'dashboard'} onClick={() => onNavigate('dashboard')} />\n            <NavItem icon={FlaskIcon} label=\"Prompt Lab\" active={activePage === 'lab'} onClick={() => onNavigate('lab')} />\n            <NavItem icon={BookOpenIcon} label=\"Documentation\" active={activePage === 'documentation'} onClick={() => onNavigate('documentation')} />\n            <NavItem icon={CogIcon} label=\"Settings\" active={activePage === 'settings'} onClick={() => onNavigate('settings')} />\n          </nav>\n        </div>\n\n        <div>\n            <h3 className=\"px-3 text-xs font-semibold text-[#95aac0] uppercase tracking-wider mb-2\">Filter by Task Type</h3>\n            <div className=\"space-y-1\">\n                {taskTypes.map(type => (\n                    <FilterItem \n                        key={type}\n                        icon={taskIcons[type]} \n                        label={type} \n                        onClick={() => onFilterChange('taskType', filters.taskType === type ? '' : type)}\n                        selected={filters.taskType === type}\n                    />\n                ))}\n            </div>\n        </div>\n\n        <div>\n            <h3 className=\"px-3 text-xs font-semibold text-[#95aac0] uppercase tracking-wider mb-2\">Filter by AI Persona</h3>\n            <div className=\"space-y-1\">\n                 {aiPersonas.map(persona => (\n                    <FilterItem \n                        key={persona}\n                        icon={personaIcons[persona]} \n                        label={persona} \n                        onClick={() => onFilterChange('aiPersona', filters.aiPersona === persona ? '' : persona)}\n                        selected={filters.aiPersona === persona}\n                    />\n                ))}\n            </div>\n        </div>\n        \n        <div>\n          <h3 className=\"px-3 text-xs font-semibold text-[#95aac0] uppercase tracking-wider mb-2\">Popular Tags</h3>\n          <div className=\"flex flex-wrap gap-2 px-3\">\n            {popularTags.map(tag => (\n                <button \n                  key={tag}\n                  onClick={() => onFilterChange('searchTerm', filters.searchTerm === tag ? '' : tag)}\n                  className={`px-2 py-1 text-xs rounded-full transition-colors ${\n                    filters.searchTerm === tag ? 'bg-[#e2a32d] text-gray-200' : 'bg-[#333e48] text-[#95aac0] hover:bg-[#e2a32d]/80'\n                  }`}\n                >\n                    {tag}\n                </button>\n            ))}\n          </div>\n        </div>\n      </div>\n      \n      <div className=\"flex-shrink-0 space-y-4\">\n        <div className=\"bg-[#333e48] rounded-lg p-3 border border-[#5c6f7e]\">\n            <div className=\"flex justify-between items-center\">\n                <div className=\"flex items-center space-x-2\">\n                    <div className=\"w-2 h-2 rounded-full bg-green-400\"></div>\n                    <span className=\"text-sm font-medium\">Gemini Flash</span>\n                </div>\n                <span className=\"text-xs font-semibold bg-green-500/20 text-green-300 px-2 py-0.5 rounded-full\">Active</span>\n            </div>\n        </div>\n        <button className=\"w-full flex items-center justify-center space-x-2 px-3 py-2 rounded-md text-sm font-medium text-[#95aac0] hover:bg-[#333e48] transition-colors border border-[#5c6f7e]\">\n            <PlusIcon className=\"w-5 h-5\" />\n            <span>Add Model</span>\n        </button>\n      </div>\n    </aside>\n  );\n};\n\nexport default Sidebar;\n",
      "metadata": {
        "filename": "Sidebar.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/Stats.tsx\n\n/**\n * @file Stats.tsx\n * @description This component displays a row of key statistics for the application,\n * such as the total number of prompts, available AI personas, and test coverage.\n * It is composed of multiple `StatCard` sub-components to present the data clearly.\n *\n * @requires react\n * @requires ./icons/ClipboardDocumentListIcon\n * @requires ./icons/UsersIcon\n * @requires ./icons/PresentationChartLineIcon\n * @requires ./icons/ClockIcon\n */\n\nimport React from 'react';\nimport ClipboardDocumentListIcon from './icons/ClipboardDocumentListIcon';\nimport UsersIcon from './icons/UsersIcon';\nimport PresentationChartLineIcon from './icons/PresentationChartLineIcon';\nimport ClockIcon from './icons/ClockIcon';\n\n/**\n * @interface StatsProps\n * @description Defines the props for the `Stats` component.\n * @property {number} totalPrompts - The total number of prompts currently in the library.\n */\ninterface StatsProps {\n    totalPrompts: number;\n}\n\n/**\n * @interface StatCardProps\n * @description Defines the props for the `StatCard` sub-component.\n * @property {React.ReactNode} icon - The icon element to display in the card.\n * @property {string} label - The text label describing the statistic.\n * @property {string | number} value - The value of the statistic to display.\n * @property {string} iconBgColor - The Tailwind CSS background color class for the icon container.\n */\ninterface StatCardProps {\n    icon: React.ReactNode;\n    label: string;\n    value: string | number;\n    iconBgColor: string;\n}\n\n/**\n * A reusable card component for displaying a single statistic with an icon, label, and value.\n *\n * @param {StatCardProps} props - The props for the component.\n * @returns {JSX.Element} A styled card displaying a single piece of statistical data.\n * @private\n */\nconst StatCard: React.FC<StatCardProps> = ({ icon, label, value, iconBgColor }) => {\n    return (\n        <div className=\"bg-[#333e48] p-5 rounded-lg shadow-sm border border-[#5c6f7e] flex items-center space-x-4\">\n            <div className={`p-3 rounded-full ${iconBgColor}`}>\n                {icon}\n            </div>\n            <div>\n                <p className=\"text-sm text-[#95aac0]\">{label}</p>\n                <p className=\"text-2xl font-bold text-gray-200\">{value}</p>\n            </div>\n        </div>\n    );\n};\n\n/**\n * The main statistics component that displays a grid of `StatCard` components.\n * It provides a high-level overview of the prompt library's status.\n * Note: Some values like \"AI Personas\" and \"Test Coverage\" are currently hardcoded for demonstration.\n *\n * @param {StatsProps} props - The props for the component, including the total number of prompts.\n * @returns {JSX.Element} The rendered grid of statistics cards.\n */\nconst Stats: React.FC<StatsProps> = ({ totalPrompts }) => {\n    return (\n        <div className=\"grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-6 mb-6\">\n            <StatCard \n                icon={<ClipboardDocumentListIcon className=\"w-6 h-6 text-blue-400\"/>} \n                label=\"Total Prompts\" \n                value={totalPrompts}\n                iconBgColor=\"bg-blue-900/20\"\n            />\n            <StatCard \n                icon={<UsersIcon className=\"w-6 h-6 text-indigo-400\"/>} \n                label=\"AI Personas\" \n                value={8} // Note: This is currently a static value.\n                iconBgColor=\"bg-indigo-900/20\"\n            />\n            <StatCard \n                icon={<PresentationChartLineIcon className=\"w-6 h-6 text-green-400\"/>} \n                label=\"Test Coverage\" \n                value=\"87%\" // Note: This is currently a static value.\n                iconBgColor=\"bg-green-900/20\"\n            />\n            <StatCard \n                icon={<ClockIcon className=\"w-6 h-6 text-[#e2a32d]\"/>} \n                label=\"Last Tested\" \n                value=\"2h ago\" // Note: This is currently a static value.\n                iconBgColor=\"bg-[#e2a32d]/20\"\n            />\n        </div>\n    );\n};\n\nexport default Stats;\n",
      "metadata": {
        "filename": "Stats.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/TopBar.tsx\n\n/**\n * @file TopBar.tsx\n * @description This component renders the top bar of the application's main content area.\n * It includes a search input field and primary action buttons for creating a new prompt\n * manually or using the Prompt Wizard.\n *\n * @requires react\n * @requires ./icons/MagnifyingGlassIcon\n * @requires ./icons/PlusIcon\n * @requires ./icons/MagicWandIcon\n */\n\nimport React from 'react';\nimport MagnifyingGlassIcon from './icons/MagnifyingGlassIcon';\nimport PlusIcon from './icons/PlusIcon';\nimport MagicWandIcon from './icons/MagicWandIcon';\n\n/**\n * @interface TopBarProps\n * @description Defines the props for the `TopBar` component.\n * @property {() => void} onAddNewPrompt - Callback function invoked when the \"Create New Prompt\" button is clicked.\n * @property {() => void} onOpenWizard - Callback function invoked when the \"Prompt Wizard\" button is clicked.\n * @property {string} searchTerm - The current value of the search input, making it a controlled component.\n * @property {(value: string) => void} onSearchChange - Callback function to handle changes to the search term, lifting the state up.\n */\ninterface TopBarProps {\n  onAddNewPrompt: () => void;\n  onOpenWizard: () => void;\n  searchTerm: string;\n  onSearchChange: (value: string) => void;\n}\n\n/**\n * The top bar component that sits above the main content area.\n * It provides a persistent search field and the primary \"create\" actions for prompts.\n *\n * @param {TopBarProps} props - The props for the component.\n * @returns {JSX.Element} The rendered top bar header element.\n */\nconst TopBar: React.FC<TopBarProps> = ({ onAddNewPrompt, onOpenWizard, searchTerm, onSearchChange }) => {\n  return (\n    <header className=\"bg-[#333e48]/80 backdrop-blur-lg border-b border-[#5c6f7e] px-6 py-4 flex items-center justify-between sticky top-0 z-20\">\n      <div className=\"relative w-full max-w-sm\">\n        <MagnifyingGlassIcon className=\"w-5 h-5 text-[#95aac0] absolute left-3 top-1/2 -translate-y-1/2\" />\n        <input\n          type=\"text\"\n          placeholder=\"Search prompts...\"\n          value={searchTerm}\n          onChange={(e) => onSearchChange(e.target.value)}\n          className=\"w-full pl-10 pr-4 py-2 bg-[#333e48] border border-[#5c6f7e] rounded-lg text-sm text-gray-200 placeholder-[#95aac0] focus:ring-2 focus:ring-[#e2a32d] focus:border-[#e2a32d] outline-none\"\n          aria-label=\"Search prompts\"\n        />\n      </div>\n      <div className=\"flex items-center space-x-4\">\n          <button\n            onClick={onOpenWizard}\n            className=\"flex items-center space-x-2 bg-[#333e48] text-gray-200 border border-[#5c6f7e] px-4 py-2 rounded-lg text-sm font-semibold hover:bg-[#333e48]/80 transition-colors shadow-sm\"\n          >\n            <MagicWandIcon className=\"w-5 h-5\" />\n            <span>Prompt Wizard</span>\n          </button>\n          <button\n            onClick={onAddNewPrompt}\n            className=\"flex items-center space-x-2 bg-[#c36e26] text-gray-200 px-4 py-2 rounded-lg text-sm font-semibold hover:bg-opacity-90 transition-colors shadow-sm\"\n          >\n            <PlusIcon className=\"w-5 h-5\" />\n            <span>Create New Prompt</span>\n          </button>\n      </div>\n    </header>\n  );\n};\n\nexport default TopBar;\n",
      "metadata": {
        "filename": "TopBar.tsx",
        "path": "/frontend/components/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/AcademicCapIcon.tsx\n\n/**\n * @file AcademicCapIcon.tsx\n * @description AcademicCapIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst AcademicCapIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M4.26 10.147a60.438 60.438 0 0 0-.491 6.347A48.627 48.627 0 0 1 12 20.904a48.627 48.627 0 0 1 8.232-4.41 60.46 60.46 0 0 0-.491-6.347m-15.482 0a50.57 50.57 0 0 0-2.658-.813A59.906 59.906 0 0 1 12 3.493a59.903 59.903 0 0 1 10.399 5.84c-.896.248-1.783.52-2.658.814m-15.482 0A50.697 50.697 0 0 1 12 13.489a50.702 50.702 0 0 1 7.74-3.342M6.75 15a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm0 0v-3.675A55.378 55.378 0 0 1 12 8.443m-7.007 11.55A5.981 5.981 0 0 0 6.75 15.75v-1.5\" />\n  </svg>\n);\nexport default AcademicCapIcon;\n",
      "metadata": {
        "filename": "AcademicCapIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ArrowDownTrayIcon.tsx\n\n/**\n * @file ArrowDownTrayIcon.tsx\n * @description ArrowDownTrayIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ArrowDownTrayIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3\" />\n  </svg>\n);\n\nexport default ArrowDownTrayIcon;\n",
      "metadata": {
        "filename": "ArrowDownTrayIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ArrowPathIcon.tsx\n\n/**\n * @file ArrowPathIcon.tsx\n * @description ArrowPathIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ArrowPathIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0 3.181 3.183a8.25 8.25 0 0 0 11.664 0l3.181-3.183m-11.664 0-3.181 3.183m0 0-3.181-3.183m3.181 3.183L9.348 16.023m-3.182-3.182L2.985 9.347m0 0h4.992m-4.993 0 3.181-3.182a8.25 8.25 0 0 1 11.664 0l3.181 3.182m-11.664 0-3.181-3.182\" />\n  </svg>\n);\nexport default ArrowPathIcon;\n",
      "metadata": {
        "filename": "ArrowPathIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ArrowUpTrayIcon.tsx\n\n/**\n * @file ArrowUpTrayIcon.tsx\n * @description ArrowUpTrayIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ArrowUpTrayIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5m-13.5-9L12 3m0 0 4.5 4.5M12 3v13.5\" />\n  </svg>\n);\n\nexport default ArrowUpTrayIcon;\n",
      "metadata": {
        "filename": "ArrowUpTrayIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ArrowsRightLeftIcon.tsx\n\n/**\n * @file ArrowsRightLeftIcon.tsx\n * @description ArrowsRightLeftIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ArrowsRightLeftIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M7.5 21 3 16.5m0 0L7.5 12M3 16.5h13.5m0-13.5L21 7.5m0 0L16.5 12M21 7.5H7.5\" />\n  </svg>\n);\nexport default ArrowsRightLeftIcon;\n",
      "metadata": {
        "filename": "ArrowsRightLeftIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ArrowsUpDownIcon.tsx\n\n/**\n * @file ArrowsUpDownIcon.tsx\n * @description ArrowsUpDownIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ArrowsUpDownIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M3 7.5L7.5 3m0 0L12 7.5M7.5 3v13.5m13.5 0L16.5 21m0 0L12 16.5m4.5 4.5V7.5\" />\n  </svg>\n);\nexport default ArrowsUpDownIcon;\n",
      "metadata": {
        "filename": "ArrowsUpDownIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/BeakerIcon.tsx\n\n/**\n * @file BeakerIcon.tsx\n * @description BeakerIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst BeakerIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n    <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.75 3.104v5.714a2.25 2.25 0 0 1-.659 1.591L5 14.5M9.75 3.104c.102.043.204.085.306.127C12.42 4.4 14.88 5.617 16.5 7.5c1.62 1.883 2.16 4.143 2.16 6.347v1.85a2.25 2.25 0 0 1-2.25 2.25H7.5a2.25 2.25 0 0 1-2.25-2.25v-1.85c0-2.204.54-4.464 2.16-6.347C9.12 5.617 11.58 4.4 13.926 3.231c.102-.042.204-.084.306-.127m-4.47 0c-.09.042-.18.083-.27.126-1.584.84-2.913 2.05-3.693 3.496M18 14.5a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z\" />\n    </svg>\n);\nexport default BeakerIcon;\n",
      "metadata": {
        "filename": "BeakerIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/BookOpenIcon.tsx\n\n/**\n * @file BookOpenIcon.tsx\n * @description BookOpenIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst BookOpenIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 6.042A8.967 8.967 0 0 0 6 3.75c-1.052 0-2.062.18-3 .512v14.25A8.987 8.987 0 0 1 6 18c2.305 0 4.408.867 6 2.292m0-14.25a8.966 8.966 0 0 1 6-2.292c1.052 0 2.062.18 3 .512v14.25A8.987 8.987 0 0 0 18 18a8.967 8.967 0 0 0-6 2.292m0-14.25v14.25\" />\n  </svg>\n);\nexport default BookOpenIcon;\n",
      "metadata": {
        "filename": "BookOpenIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/BrainCircuitIcon.tsx\n\n/**\n * @file BrainCircuitIcon.tsx\n * @description BrainCircuitIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst BrainCircuitIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n    <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.53 16.122a3 3 0 0 0-3.48-2.14-3 3 0 0 0-2.14 3.48l1.045 3.656a2.121 2.121 0 0 0 3.976-.632l1.04-3.655a2.12 2.12 0 0 0-.632-3.975zM12.75 12.75a3 3 0 0 0-3.48-2.14-3 3 0 0 0-2.14 3.48l-.522 1.829a2.121 2.121 0 0 0 3.976-.632l.522-1.829a2.12 2.12 0 0 0-.632-3.975zM16 9.75a3 3 0 0 0-3.48-2.14-3 3 0 0 0-2.14 3.48l-.522 1.829a2.121 2.121 0 0 0 3.976-.632l.522-1.829a2.12 2.12 0 0 0-.632-3.975z\" />\n        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 21a9 9 0 1 1 0-18 9 9 0 0 1 0 18Z\" />\n    </svg>\n);\nexport default BrainCircuitIcon;\n",
      "metadata": {
        "filename": "BrainCircuitIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ChatBubbleLeftRightIcon.tsx\n\n/**\n * @file ChatBubbleLeftRightIcon.tsx\n * @description ChatBubbleLeftRightIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ChatBubbleLeftRightIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M20.25 8.511c.884.284 1.5 1.128 1.5 2.097v4.286c0 1.136-.847 2.1-1.98 2.193l-3.72.372a3.527 3.527 0 0 1-3.114-2.193-24.255 24.255 0 0 0-5.632 0A3.527 3.527 0 0 1 3.75 17.25l-3.72-.372C.847 16.781 0 15.823 0 14.687V10.4c0-.97.616-1.813 1.5-2.097m17.25 0a24.255 24.255 0 0 0-5.632 0m5.632 0a24.21 24.21 0 0 1 3.32 0m-11.257 0a24.226 24.226 0 0 1-5.632 0m5.632 0A24.21 24.21 0 0 0 3.75 8.511\" />\n  </svg>\n);\nexport default ChatBubbleLeftRightIcon;\n",
      "metadata": {
        "filename": "ChatBubbleLeftRightIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/CheckCircleIcon.tsx\n\n/**\n * @file CheckCircleIcon.tsx\n * @description CheckCircleIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst CheckCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9 12.75L11.25 15 15 9.75M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z\" />\n  </svg>\n);\n\nexport default CheckCircleIcon;\n",
      "metadata": {
        "filename": "CheckCircleIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ClipboardDocumentListIcon.tsx\n\n/**\n * @file ClipboardDocumentListIcon.tsx\n * @description ClipboardDocumentListIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ClipboardDocumentListIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9 12h3.75M9 15h3.75M9 18h3.75m3 .75H18a2.25 2.25 0 0 0 2.25-2.25V6.108c0-1.135-.845-2.098-1.976-2.192a48.424 48.424 0 0 0-1.123-.08m-5.801 0c-.065.21-.1.433-.1.664 0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75c0-.231-.035-.454-.1-.664M6.75 7.5H18a2.25 2.25 0 0 1 2.25 2.25v9a2.25 2.25 0 0 1-2.25 2.25H6.75a2.25 2.25 0 0 1-2.25-2.25v-9a2.25 2.25 0 0 1 2.25-2.25Z\" />\n  </svg>\n);\nexport default ClipboardDocumentListIcon;\n",
      "metadata": {
        "filename": "ClipboardDocumentListIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ClipboardIcon.tsx\n\n/**\n * @file ClipboardIcon.tsx\n * @description ClipboardIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ClipboardIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M15.666 3.888A2.25 2.25 0 0 0 13.5 2.25h-3c-1.03 0-1.9.693-2.166 1.638m7.332 0c.055.194.084.4.084.612v3.042m-7.416 0v3.042c0 .212.03.418.084.612m7.332 0c.646.049 1.288.11 1.927.184 1.1.128 1.907 1.077 1.907 2.185V19.5a2.25 2.25 0 0 1-2.25 2.25H6.75A2.25 2.25 0 0 1 4.5 19.5V6.257c0-1.108.806-2.057 1.907-2.185a48.208 48.208 0 0 1 1.927-.184\" />\n  </svg>\n);\nexport default ClipboardIcon;\n",
      "metadata": {
        "filename": "ClipboardIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/ClockIcon.tsx\n\n/**\n * @file ClockIcon.tsx\n * @description ClockIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst ClockIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 6v6h4.5m4.5 0a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z\" />\n  </svg>\n);\nexport default ClockIcon;\n",
      "metadata": {
        "filename": "ClockIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/CodeBracketIcon.tsx\n\n/**\n * @file CodeBracketIcon.tsx\n * @description CodeBracketIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst CodeBracketIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M17.25 6.75 22.5 12l-5.25 5.25m-10.5 0L1.5 12l5.25-5.25m7.5 0-4.5 16.5\" />\n  </svg>\n);\nexport default CodeBracketIcon;\n",
      "metadata": {
        "filename": "CodeBracketIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/CogIcon.tsx\n\n/**\n * @file CogIcon.tsx\n * @description CogIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst CogIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.594 3.94c.09-.542.56-.94 1.11-.94h2.593c.55 0 1.02.398 1.11.94l.213 1.281c.063.374.313.686.645.87.074.04.147.083.22.127.325.196.72.257 1.075.124l1.217-.456a1.125 1.125 0 0 1 1.37.49l1.296 2.247a1.125 1.125 0 0 1-.26 1.431l-1.003.827c-.293.24-.438.613-.43.992a6.759 6.759 0 0 1 0 1.905c.008.379.137.752.43.992l1.003.827c.424.35.534.955.26 1.431l-1.296 2.247a1.125 1.125 0 0 1-1.37.49l-1.217-.456c-.355-.133-.75-.072-1.076.124a6.47 6.47 0 0 1-.22.128c-.331.183-.581.495-.644.869l-.213 1.281c-.09.543-.56.94-1.11.94h-2.594c-.55 0-1.019-.398-1.11-.94l-.213-1.281c-.062-.374-.312-.686-.644-.87a6.52 6.52 0 0 1-.22-.127c-.325-.196-.72-.257-1.076-.124l-1.217.456a1.125 1.125 0 0 1-1.37-.49l-1.296-2.247a1.125 1.125 0 0 1 .26-1.431l1.004-.827c.292-.24.437-.613.43-.992a6.932 6.932 0 0 1 0-1.905c-.007-.379-.137-.752-.43-.992l-1.004-.827a1.125 1.125 0 0 1-.26-1.431l1.296-2.247a1.125 1.125 0 0 1 1.37-.49l1.217.456c.355.133.75.072 1.076-.124.072-.044.146-.087.22-.128.332-.183.582-.495.644-.869l.214-1.28Z\" />\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M15 12a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z\" />\n  </svg>\n);\nexport default CogIcon;\n",
      "metadata": {
        "filename": "CogIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/CubeIcon.tsx\n\n/**\n * @file CubeIcon.tsx\n * @description CubeIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst CubeIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M21 7.5l-9-5.25L3 7.5m18 0l-9 5.25m9-5.25v9l-9 5.25M3 7.5l9 5.25M3 7.5v9l9 5.25m0-9v9\" />\n  </svg>\n);\nexport default CubeIcon;\n",
      "metadata": {
        "filename": "CubeIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/DocumentTextIcon.tsx\n\n/**\n * @file DocumentTextIcon.tsx\n * @description DocumentTextIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst DocumentTextIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9Z\" />\n  </svg>\n);\n\nexport default DocumentTextIcon;\n",
      "metadata": {
        "filename": "DocumentTextIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/EllipsisVerticalIcon.tsx\n\n/**\n * @file EllipsisVerticalIcon.tsx\n * @description EllipsisVerticalIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst EllipsisVerticalIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 6.75a.75.75 0 1 1 0-1.5.75.75 0 0 1 0 1.5ZM12 12.75a.75.75 0 1 1 0-1.5.75.75 0 0 1 0 1.5ZM12 18.75a.75.75 0 1 1 0-1.5.75.75 0 0 1 0 1.5Z\" />\n  </svg>\n);\nexport default EllipsisVerticalIcon;\n",
      "metadata": {
        "filename": "EllipsisVerticalIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/EyeIcon.tsx\n\n/**\n * @file EyeIcon.tsx\n * @description EyeIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst EyeIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M2.036 12.322a1.012 1.012 0 0 1 0-.639C3.423 7.51 7.36 4.5 12 4.5c4.638 0 8.573 3.007 9.963 7.178.07.207.07.431 0 .639C20.577 16.49 16.64 19.5 12 19.5c-4.638 0-8.573-3.007-9.963-7.178Z\" />\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M15 12a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z\" />\n  </svg>\n);\nexport default EyeIcon;\n",
      "metadata": {
        "filename": "EyeIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/FaceSmileIcon.tsx\n\n/**\n * @file FaceSmileIcon.tsx\n * @description FaceSmileIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst FaceSmileIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M15.182 15.182a4.5 4.5 0 0 1-6.364 0M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0ZM9 9.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm6 0a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Z\" />\n  </svg>\n);\nexport default FaceSmileIcon;\n",
      "metadata": {
        "filename": "FaceSmileIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/FlaskIcon.tsx\n\n/**\n * @file FlaskIcon.tsx\n * @description FlaskIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst FlaskIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.75 3.104v5.714a2.25 2.25 0 0 1-.659 1.591L5 14.5M9.75 3.104c.102.043.204.085.306.127C12.42 4.4 14.88 5.617 16.5 7.5c1.62 1.883 2.16 4.143 2.16 6.347v1.85a2.25 2.25 0 0 1-2.25 2.25H7.5a2.25 2.25 0 0 1-2.25-2.25v-1.85c0-2.204.54-4.464 2.16-6.347C9.12 5.617 11.58 4.4 13.926 3.231c.102-.042.204-.084.306-.127m-4.47 0c-.09.042-.18.083-.27.126-1.584.84-2.913 2.05-3.693 3.496\" />\n  </svg>\n);\nexport default FlaskIcon;\n",
      "metadata": {
        "filename": "FlaskIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/FunnelIcon.tsx\n\n/**\n * @file FunnelIcon.tsx\n * @description FunnelIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst FunnelIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 3c2.755 0 5.455.232 8.083.678.533.09.917.556.917 1.096v1.044a2.25 2.25 0 0 1-.659 1.591l-5.432 5.432a2.25 2.25 0 0 0-.659 1.591v2.927a2.25 2.25 0 0 1-1.244 2.013l-2.5 1a2.25 2.25 0 0 1-2.557-2.013v-2.927a2.25 2.25 0 0 0-.659-1.591L2.659 6.42A2.25 2.25 0 0 1 2 4.828V3.784c0-.54.384-1.006.917-1.096A48.32 48.32 0 0 1 12 3Z\" />\n  </svg>\n);\nexport default FunnelIcon;\n",
      "metadata": {
        "filename": "FunnelIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/GlobeAltIcon.tsx\n\n/**\n * @file GlobeAltIcon.tsx\n * @description GlobeAltIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst GlobeAltIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 21a9.004 9.004 0 0 0 8.716-6.747M12 21a9.004 9.004 0 0 1-8.716-6.747M12 21c2.485 0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485 0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997 0 0 1 7.843 4.582M12 3a8.997 8.997 0 0 0-7.843 4.582m15.686 0A11.953 11.953 0 0 1 12 10.5c-2.998 0-5.74-1.1-7.843-2.918m15.686 0A8.959 8.959 0 0 1 21 12c0 .778-.099 1.533-.284 2.253m0 0A11.953 11.953 0 0 1 12 13.5c-2.998 0-5.74-1.1-7.843-2.918\" />\n  </svg>\n);\nexport default GlobeAltIcon;\n",
      "metadata": {
        "filename": "GlobeAltIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/HomeIcon.tsx\n\n/**\n * @file HomeIcon.tsx\n * @description HomeIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst HomeIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m2.25 12 8.954-8.955c.44-.439 1.152-.439 1.591 0L21.75 12M4.5 9.75v10.125c0 .621.504 1.125 1.125 1.125H9.75v-4.875c0-.621.504-1.125 1.125-1.125h2.25c.621 0 1.125.504 1.125 1.125V21h4.125c.621 0 1.125-.504 1.125-1.125V9.75M8.25 21h7.5\" />\n  </svg>\n);\nexport default HomeIcon;\n",
      "metadata": {
        "filename": "HomeIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/LanguageIcon.tsx\n\n/**\n * @file LanguageIcon.tsx\n * @description LanguageIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst LanguageIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m10.5 21 5.25-11.25L21 21m-9-3h7.5M3 5.621a48.474 48.474 0 0 1 6-.371m0 0c1.12 0 2.233.038 3.334.114M9 5.25V3m3.334 2.364C11.176 10.658 7.69 15.08 3 17.502m9.334-12.138c.896.061 1.785.147 2.666.257m-4.589 8.495a18.023 18.023 0 0 1-3.827-5.802\" />\n  </svg>\n);\nexport default LanguageIcon;\n",
      "metadata": {
        "filename": "LanguageIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/LinkIcon.tsx\n\n/**\n * @file LinkIcon.tsx\n * @description LinkIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst LinkIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M13.19 8.688a4.5 4.5 0 0 1 1.242 7.244l-4.5 4.5a4.5 4.5 0 0 1-6.364-6.364l1.757-1.757m13.35-.622 1.757-1.757a4.5 4.5 0 0 0-6.364-6.364l-4.5 4.5a4.5 4.5 0 0 0 1.242 7.244\" />\n  </svg>\n);\nexport default LinkIcon;\n",
      "metadata": {
        "filename": "LinkIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/MagicWandIcon.tsx\n\n/**\n * @file MagicWandIcon.tsx\n * @description MagicWandIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst MagicWandIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.53 16.122a3 3 0 00-3.48-2.14-3 3 0 00-2.14 3.48l1.045 3.656a2.121 2.121 0 003.976-.632l1.04-3.655a2.12 2.12 0 00-.632-3.975zM12.75 12.75a3 3 0 00-3.48-2.14-3 3 0 00-2.14 3.48l-.522 1.829a2.121 2.121 0 003.976-.632l.522-1.829a2.12 2.12 0 00-.632-3.975zM16 9.75a3 3 0 00-3.48-2.14-3 3 0 00-2.14 3.48l-.522 1.829a2.121 2.121 0 003.976-.632l.522-1.829a2.12 2.12 0 00-.632-3.975z\" />\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M19.5 13.5 18 12m1.5-1.5L18 12m0 0-1.5-1.5M18 12l1.5 1.5M4.875 16.125l-1.625 1.625m1.625-1.625L3.25 14.5m1.625 1.625 1.625 1.625m-1.625-1.625L6.5 14.5m-3.25 3.25 1.625-1.625M21 4.875l-1.625 1.625m1.625-1.625L19.375 3.25m1.625 1.625 1.625 1.625m-1.625-1.625L22.625 3.25\" />\n  </svg>\n);\n\nexport default MagicWandIcon;\n",
      "metadata": {
        "filename": "MagicWandIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/MagnifyingGlassIcon.tsx\n\n/**\n * @file MagnifyingGlassIcon.tsx\n * @description MagnifyingGlassIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst MagnifyingGlassIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m21 21-5.197-5.197m0 0A7.5 7.5 0 1 0 5.196 5.196a7.5 7.5 0 0 0 10.607 10.607Z\" />\n  </svg>\n);\nexport default MagnifyingGlassIcon;\n",
      "metadata": {
        "filename": "MagnifyingGlassIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/PaperClipIcon.tsx\n\n/**\n * @file PaperClipIcon.tsx\n * @description PaperClipIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst PaperClipIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m18.375 12.739-7.693 7.693a4.5 4.5 0 0 1-6.364-6.364l10.94-10.94A3 3 0 1 1 19.5 7.372L8.552 18.32m.009-.01-.01.01m5.699-9.941-7.81 7.81a1.5 1.5 0 0 0 2.122 2.122l7.81-7.81\" />\n  </svg>\n);\nexport default PaperClipIcon;\n",
      "metadata": {
        "filename": "PaperClipIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/PencilIcon.tsx\n\n/**\n * @file PencilIcon.tsx\n * @description PencilIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst PencilIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10\" />\n  </svg>\n);\nexport default PencilIcon;\n",
      "metadata": {
        "filename": "PencilIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/PlayIcon.tsx\n\n/**\n * @file PlayIcon.tsx\n * @description PlayIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst PlayIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M5.25 5.653c0-.856.917-1.398 1.667-.986l11.54 6.347a1.125 1.125 0 0 1 0 1.972l-11.54 6.347a1.125 1.125 0 0 1-1.667-.986V5.653Z\" />\n  </svg>\n);\nexport default PlayIcon;\n",
      "metadata": {
        "filename": "PlayIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/PlusIcon.tsx\n\n/**\n * @file PlusIcon.tsx\n * @description PlusIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst PlusIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M12 4.5v15m7.5-7.5h-15\" />\n  </svg>\n);\nexport default PlusIcon;\n",
      "metadata": {
        "filename": "PlusIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/PresentationChartLineIcon.tsx\n\n/**\n * @file PresentationChartLineIcon.tsx\n * @description PresentationChartLineIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst PresentationChartLineIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M3.375 19.5h17.25m-17.25 0a1.125 1.125 0 0 1-1.125-1.125v-1.5c0-.621.504-1.125 1.125-1.125h17.25c.621 0 1.125.504 1.125 1.125v1.5c0 .621-.504 1.125-1.125 1.125m-17.25 0h.008v.015h-.008V19.5Zm17.25 0h.008v.015h-.008V19.5Zm-17.25-3.375h17.25m-17.25 0a2.25 2.25 0 0 0-2.25-2.25V5.25c0-1.242 1.008-2.25 2.25-2.25h17.25c1.242 0 2.25 1.008 2.25 2.25v8.625c0 1.242-1.008 2.25-2.25 2.25m-17.25-3.375-1.125-1.5L4.5 12l2.25 3 2.25-3L12 15l2.25-3 2.25 3 2.25-3 1.125 1.5m-17.25-3.375h17.25\" />\n  </svg>\n);\nexport default PresentationChartLineIcon;\n",
      "metadata": {
        "filename": "PresentationChartLineIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/QuestionMarkCircleIcon.tsx\n\n/**\n * @file QuestionMarkCircleIcon.tsx\n * @description QuestionMarkCircleIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst QuestionMarkCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.879 7.519c1.171-1.025 3.071-1.025 4.242 0 1.172 1.025 1.172 2.687 0 3.712-.203.179-.43.326-.67.442-.745.361-1.45.999-1.45 1.827v.75M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9 5.25h.008v.008H12v-.008Z\" />\n  </svg>\n);\n\nexport default QuestionMarkCircleIcon;\n",
      "metadata": {
        "filename": "QuestionMarkCircleIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/SparklesIcon.tsx\n\n/**\n * @file SparklesIcon.tsx\n * @description SparklesIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst SparklesIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.813 15.904L9 18.75l-.813-2.846a4.5 4.5 0 00-3.09-3.09L1.25 12l2.846-.813a4.5 4.5 0 003.09-3.09L9 5.25l.813 2.846a4.5 4.5 0 003.09 3.09L15.75 12l-2.846.813a4.5 4.5 0 00-3.09 3.09zM18.25 12L17 14.25l-1.25-2.25L13.5 11l2.25-1.25L17 7.5l1.25 2.25L20.5 11l-2.25 1.25z\"/>\n  </svg>\n);\nexport default SparklesIcon;\n",
      "metadata": {
        "filename": "SparklesIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/StopIcon.tsx\n\n/**\n * @file StopIcon.tsx\n * @description StopIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst StopIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z\" />\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9 9.563C9 9.252 9.252 9 9.563 9h4.874c.311 0 .563.252.563.563v4.874c0 .311-.252.563-.563.563H9.564A.562.562 0 0 1 9 14.437V9.564Z\" />\n  </svg>\n);\nexport default StopIcon;\n",
      "metadata": {
        "filename": "StopIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/TrashIcon.tsx\n\n/**\n * @file TrashIcon.tsx\n * @description TrashIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst TrashIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"m14.74 9-.346 9m-4.788 0L9.26 9m9.968-3.21c.342.052.682.107 1.022.166m-1.022-.165L18.16 19.673a2.25 2.25 0 0 1-2.244 2.077H8.084a2.25 2.25 0 0 1-2.244-2.077L4.772 5.79m14.456 0a48.108 48.108 0 0 0-3.478-.397m-12.56 0c1.153 0 2.24.032 3.287.094M7.08 5.79L5.28 5.79m0 0a1.5 1.5 0 0 1 1.5-1.5H15a1.5 1.5 0 0 1 1.5 1.5m-3.879 0L12 1.5M7.08 5.79c.068.16.126.324.168.493m0 0v1.17c0 .094.015.19.042.284m0 0c.026.095.058.19.095.283m0 0l.003.012a5.092 5.092 0 0 0 .69 1.085l2.16 2.89m0 0l2.16-2.89a5.092 5.092 0 0 0 .69-1.085l.003-.012m0 0c.037-.093.07-.188.095-.283m0 0A.996.996 0 0 0 12 7.005v-1.17m0 0c-.026-.094-.04-.19-.042-.284m0 0c-.042-.169-.1-.333-.168-.493\" />\n  </svg>\n);\nexport default TrashIcon;\n",
      "metadata": {
        "filename": "TrashIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/UserCircleIcon.tsx\n\n/**\n * @file UserCircleIcon.tsx\n * @description UserCircleIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst UserCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M17.982 18.725A7.488 7.488 0 0 0 12 15.75a7.488 7.488 0 0 0-5.982 2.975m11.963 0a9 9 0 1 0-11.963 0m11.963 0A8.966 8.966 0 0 1 12 21a8.966 8.966 0 0 1-5.982-2.275M15 9.75a3 3 0 1 1-6 0 3 3 0 0 1 6 0Z\" />\n  </svg>\n);\nexport default UserCircleIcon;\n",
      "metadata": {
        "filename": "UserCircleIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/UsersIcon.tsx\n\n/**\n * @file UsersIcon.tsx\n * @description UsersIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst UsersIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M15 19.128a9.38 9.38 0 0 0 2.625.372 9.337 9.337 0 0 0 4.121-2.272M15 19.128v-3.872M15 19.128c-1.529 0-2.922-.656-3.898-1.724M15 19.128c.118.02.239.034.362.043a9.337 9.337 0 0 1-4.12-2.272M15 15.256c.118.02.239.034.362.043m-4.234 2.153a9.337 9.337 0 0 1-4.12-2.272M8.898 17.404c-1.529 0-2.922-.656-3.898-1.724m-3.898 1.724a9.337 9.337 0 0 1-4.12-2.272M5 19.128v-3.872m0 3.872c.118.02.239.034.362.043a9.337 9.337 0 0 0 4.12-2.272M5 15.256c.118.02.239.034.362.043m0 0a9.337 9.337 0 0 0 4.12 2.272M5 15.256a9.38 9.38 0 0 1-2.625-.372M5 15.256c-1.529 0-2.922.656-3.898 1.724M12 12.75a3 3 0 1 1 0-6 3 3 0 0 1 0 6Zm0 0a9.38 9.38 0 0 0-2.625-.372M12 12.75c1.529 0 2.922.656 3.898 1.724M12 12.75a9.38 9.38 0 0 1 2.625-.372m0 0a9.337 9.337 0 0 1 4.12 2.272M12 12.75c-2.922.656-3.898 1.724-3.898 1.724M12 12.75c2.922.656 3.898 1.724 3.898 1.724\" />\n  </svg>\n);\nexport default UsersIcon;\n",
      "metadata": {
        "filename": "UsersIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/WorkflowIcon.tsx\n\n/**\n * @file WorkflowIcon.tsx\n * @description WorkflowIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst WorkflowIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n    <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n        <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M3.75 3v11.25A2.25 2.25 0 0 0 6 16.5h2.25M3.75 3h-1.5m1.5 0h16.5m0 0h1.5m-1.5 0v11.25A2.25 2.25 0 0 1 18 16.5h-2.25m-7.5 0h7.5m-7.5 0-1 3m8.5-3 1 3m0 0 .5 1.5m-.5-1.5h-9.5m0 0-.5 1.5M9 11.25v1.5M12 9v3.75m3-6v6\" />\n    </svg>\n);\nexport default WorkflowIcon;\n",
      "metadata": {
        "filename": "WorkflowIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/WrenchScrewdriverIcon.tsx\n\n/**\n * @file WrenchScrewdriverIcon.tsx\n * @description WrenchScrewdriverIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst WrenchScrewdriverIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M11.42 15.17 17.25 21A2.652 2.652 0 0 0 21 17.25l-5.83-5.83m-3.58-3.58a3 3 0 0 1 4.243 0l5.83 5.83a3 3 0 0 1 0 4.242l-5.83 5.83a3 3 0 0 1-4.242 0l-5.83-5.83a3 3 0 0 1 0-4.242l5.83-5.83Zm0 0a3 3 0 0 0-4.243 0l-5.83 5.83a3 3 0 0 0 0 4.242l5.83 5.83a3 3 0 0 0 4.242 0l5.83-5.83a3 3 0 0 0 0-4.242l-5.83-5.83Z\" />\n  </svg>\n);\nexport default WrenchScrewdriverIcon;\n",
      "metadata": {
        "filename": "WrenchScrewdriverIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/icons/XCircleIcon.tsx\n\n/**\n * @file XCircleIcon.tsx\n * @description XCircleIcon component.\n * @author Stephen Kaplan\n * @see {@link https://heroicons.com/|Heroicons}\n */\n\nimport React from 'react';\n\nconst XCircleIcon: React.FC<React.SVGProps<SVGSVGElement>> = (props) => (\n  <svg xmlns=\"http://www.w3.org/2000/svg\" fill=\"none\" viewBox=\"0 0 24 24\" strokeWidth={1.5} stroke=\"currentColor\" {...props}>\n    <path strokeLinecap=\"round\" strokeLinejoin=\"round\" d=\"M9.75 9.75l4.5 4.5m0-4.5l-4.5 4.5M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z\" />\n  </svg>\n);\nexport default XCircleIcon;\n",
      "metadata": {
        "filename": "XCircleIcon.tsx",
        "path": "/frontend/components/icons/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/DataStoreViewer.tsx\n\n/**\n * @file DataStoreViewer.tsx\n * @description This component provides a read-only, collapsible JSON viewer for inspecting the state of the workflow's Data Store.\n * It includes a button to copy the entire Data Store content as a JSON string.\n *\n * @requires react\n * @requires ../types\n * @requires ../icons/ClipboardIcon\n */\n\nimport React, { useState } from 'react';\nimport { DataStore } from '../../types';\nimport ClipboardIcon from '../icons/ClipboardIcon';\n\n/**\n * A recursive component to render a collapsible JSON tree.\n * @param {object} props - The component props.\n * @param {any} props.data - The JSON data to render.\n * @param {number} [props.level=0] - The current nesting level, used for indentation.\n * @returns {JSX.Element} A styled, interactive JSON tree view.\n */\nconst JsonViewer: React.FC<{ data: any; level?: number }> = ({ data, level = 0 }) => {\n    const [isCollapsed, setIsCollapsed] = useState(level > 0);\n\n    if (data === null || data === undefined) {\n        return <span className=\"text-text-tertiary\">null</span>;\n    }\n    if (typeof data !== 'object') {\n        return <span className={typeof data === 'string' ? 'text-success' : 'text-info'}>{JSON.stringify(data)}</span>;\n    }\n\n    const entries = Object.entries(data);\n    const prefix = Array.isArray(data) ? '[' : '{';\n    const suffix = Array.isArray(data) ? ']' : '}';\n\n    return (\n        <div>\n            <button onClick={() => setIsCollapsed(!isCollapsed)} className=\"cursor-pointer\">\n                <span className=\"text-text-secondary\">{prefix}</span>\n                {isCollapsed && <span className=\"text-text-tertiary mx-1\">...</span>}\n                <span className=\"text-text-secondary\">{suffix}</span>\n                <span className=\"text-xs text-text-tertiary ml-1\">{entries.length} items</span>\n            </button>\n            {!isCollapsed && (\n                <div style={{ paddingLeft: `${(level + 1) * 15}px` }} className=\"border-l border-border-primary ml-1.5\">\n                    {entries.map(([key, value]) => (\n                        <div key={key} className=\"flex text-sm\">\n                            {!Array.isArray(data) && <span className=\"text-accent-primary mr-1\">\"{key}\":</span>}\n                            <JsonViewer data={value} level={level + 1} />\n                        </div>\n                    ))}\n                </div>\n            )}\n        </div>\n    );\n};\n\n/**\n * A component that displays the entire Data Store of a workflow run.\n * It uses the `JsonViewer` to render the data and provides a copy-to-clipboard functionality.\n *\n * @param {object} props - The component props.\n * @param {DataStore} props.dataStore - The Data Store object to display.\n * @returns {JSX.Element} The rendered Data Store viewer component.\n */\nconst DataStoreViewer: React.FC<{ dataStore: DataStore }> = ({ dataStore }) => {\n    const [copied, setCopied] = useState(false);\n\n    /**\n     * Copies the Data Store content to the clipboard as a formatted JSON string.\n     */\n    const handleCopy = () => {\n        navigator.clipboard.writeText(JSON.stringify(dataStore, null, 2));\n        setCopied(true);\n        setTimeout(() => setCopied(false), 2000);\n    };\n\n    return (\n        <div className=\"p-4 h-full font-mono\">\n            <div className=\"flex justify-between items-center mb-4\">\n                <h3 className=\"text-lg font-semibold text-text-primary\">Data Store</h3>\n                <button\n                    onClick={handleCopy}\n                    className=\"p-1.5 bg-surface-hover rounded-md text-text-tertiary hover:text-text-primary transition-colors border border-border-primary\"\n                    title=\"Copy DataStore JSON\"\n                >\n                    {copied ? <span className=\"text-xs\">Copied!</span> : <ClipboardIcon className=\"w-4 h-4\" />}\n                </button>\n            </div>\n            <div className=\"bg-surface p-3 rounded-md text-sm border border-border-primary h-[calc(100%-50px)] overflow-auto\">\n                {Object.keys(dataStore).length > 0 ? (\n                    <JsonViewer data={dataStore} />\n                ) : (\n                    <p className=\"text-text-tertiary text-xs\">Data Store is empty. Run a workflow to populate it.</p>\n                )}\n            </div>\n        </div>\n    );\n};\n\nexport default DataStoreViewer;\n",
      "metadata": {
        "filename": "DataStoreViewer.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/PromptLabPage.tsx\n\n/**\n * @file PromptLabPage.tsx\n * @description This is the main component for the \"Prompt Lab\" page. It orchestrates the entire workflow management UI,\n * including the workflow selection controls, user input area, and the main workflow canvas. It also manages the state\n * for the active workflow and modals for editing or creating new workflows.\n *\n * @requires react\n * @requires ../../types\n * @requires ../../hooks/useWorkflowManager\n * @requires ./WorkflowControls\n * @requires ./UserInputArea\n * @requires ./DataStoreViewer\n * @requires ./WorkflowCanvas\n * @requires ./modals/WorkflowEditorModal\n * @requires ./modals/WorkflowWizardModal\n */\n\nimport React, { useState, useEffect } from 'react';\nimport { Workflow, ModalType, StagedUserInput, PromptSFL } from '../../types';\nimport { useWorkflowManager } from '../../hooks/useWorkflowManager';\nimport WorkflowControls from './WorkflowControls';\nimport UserInputArea from './UserInputArea';\nimport WorkflowCanvas from './WorkflowCanvas';\nimport WorkflowEditorModal from './modals/WorkflowEditorModal';\nimport WorkflowWizardModal from './modals/WorkflowWizardModal';\n\n/**\n * @interface PromptLabPageProps\n * @description Defines the props for the PromptLabPage component.\n * @property {PromptSFL[]} prompts - An array of all available SFL prompts from the library.\n */\ninterface PromptLabPageProps {\n    prompts: PromptSFL[];\n}\n\n/**\n * The main page component for the Prompt Lab feature.\n * It integrates all the necessary components to provide a complete workflow management experience.\n *\n * @param {PromptLabPageProps} props - The props for the component.\n * @returns {JSX.Element} The rendered Prompt Lab page.\n */\nconst PromptLabPage: React.FC<PromptLabPageProps> = ({ prompts }) => {\n    const { workflows, saveWorkflow, deleteWorkflow, isLoading, saveCustomWorkflows } = useWorkflowManager();\n    const [activeWorkflowId, setActiveWorkflowId] = useState<string | null>(null);\n    const [activeModal, setActiveModal] = useState<ModalType>(ModalType.NONE);\n    const [stagedInput, setStagedInput] = useState<StagedUserInput>({});\n\n    const activeWorkflow = workflows.find(wf => wf.id === activeWorkflowId) || null;\n\n    useEffect(() => {\n        if (!isLoading && workflows.length > 0 && !activeWorkflowId) {\n            setActiveWorkflowId(workflows[0].id);\n        }\n    }, [isLoading, workflows, activeWorkflowId]);\n\n    const handleOpenModal = (modalType: ModalType) => setActiveModal(modalType);\n    const handleCloseModal = () => setActiveModal(ModalType.NONE);\n\n    const handleSaveWorkflow = (workflow: Workflow) => {\n        saveWorkflow(workflow);\n        setActiveWorkflowId(workflow.id);\n        handleCloseModal();\n    };\n    \n    const handleImportWorkflows = (importedWorkflows: Workflow[]) => {\n        const customWorkflows = workflows.filter(wf => !wf.isDefault);\n        const merged = [...customWorkflows];\n        \n        importedWorkflows.forEach(iw => {\n            const index = merged.findIndex(cw => cw.id === iw.id);\n            if (index !== -1) {\n                merged[index] = iw;\n            } else {\n                merged.push(iw);\n            }\n        });\n        \n        saveCustomWorkflows(merged);\n        alert(`Import successful. ${importedWorkflows.length} workflows imported/updated.`);\n    };\n\n    if (isLoading) {\n        return <div className=\"flex items-center justify-center h-full\"><div className=\"spinner\"></div></div>;\n    }\n\n    return (\n        <div className=\"flex h-full bg-app-bg font-sans\">\n            <aside className=\"w-[350px] bg-surface border-r border-border-primary flex flex-col p-4 space-y-4 overflow-y-auto\">\n                <WorkflowControls\n                    workflows={workflows}\n                    activeWorkflow={activeWorkflow}\n                    onSelectWorkflow={setActiveWorkflowId}\n                    onOpenEditor={() => handleOpenModal(ModalType.WORKFLOW_EDITOR)}\n                    onOpenWizard={() => handleOpenModal(ModalType.WORKFLOW_WIZARD)}\n                    onDeleteWorkflow={deleteWorkflow}\n                    onImportWorkflows={handleImportWorkflows}\n                />\n                <UserInputArea onStageInput={setStagedInput} onWorkflowGenerated={handleSaveWorkflow} />\n            </aside>\n            \n            <main className=\"flex-1 flex flex-col overflow-hidden\">\n                 {activeWorkflow ? (\n                    <WorkflowCanvas\n                        key={activeWorkflow.id}\n                        workflow={activeWorkflow}\n                        stagedInput={stagedInput}\n                        prompts={prompts}\n                    />\n                ) : (\n                    <div className=\"flex items-center justify-center h-full text-center text-text-secondary\">\n                        <div>\n                            <h2 className=\"text-xl font-semibold text-text-primary\">No Workflow Selected</h2>\n                            <p>Please select a workflow from the sidebar, or create a new one.</p>\n                        </div>\n                    </div>\n                )}\n            </main>\n\n            {activeModal === ModalType.WORKFLOW_EDITOR && (\n                <WorkflowEditorModal\n                    isOpen={true}\n                    onClose={handleCloseModal}\n                    onSave={handleSaveWorkflow}\n                    workflowToEdit={activeWorkflow?.isDefault ? null : activeWorkflow}\n                    prompts={prompts}\n                />\n            )}\n            \n            {activeModal === ModalType.WORKFLOW_WIZARD && (\n                <WorkflowWizardModal\n                    isOpen={true}\n                    onClose={handleCloseModal}\n                    onSave={handleSaveWorkflow}\n                    prompts={prompts}\n                />\n            )}\n        </div>\n    );\n};\n\nexport default PromptLabPage;\n",
      "metadata": {
        "filename": "PromptLabPage.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/TaskNode.tsx\n\n/**\n * @file TaskNode.tsx\n * @description This component renders a single node within the workflow canvas, representing a task.\n * It displays the task's name, description, inputs, and outputs. The appearance of the node\n * changes based on its current execution status (e.g., pending, running, completed, failed).\n *\n * @requires react\n * @requires ../../types\n * @requires ../icons/CodeBracketIcon\n * @requires ../icons/SparklesIcon\n * @requires ../icons/DocumentTextIcon\n * @requires ../icons/PresentationChartLineIcon\n * @requires ../icons/EyeIcon\n * @requires ../icons/LinkIcon\n */\n\nimport React from 'react';\nimport { Task, TaskState, TaskStatus, TaskType } from '../../types';\nimport CodeBracketIcon from '../icons/CodeBracketIcon';\nimport SparklesIcon from '../icons/SparklesIcon';\nimport DocumentTextIcon from '../icons/DocumentTextIcon';\nimport PresentationChartLineIcon from '../icons/PresentationChartLineIcon';\nimport EyeIcon from '../icons/EyeIcon';\nimport LinkIcon from '../icons/LinkIcon';\n\n/**\n * A component that returns an appropriate icon for a given task type.\n * @param {object} props - The component props.\n * @param {TaskType} props.type - The type of the task.\n * @returns {JSX.Element} A styled icon component.\n */\nconst TaskIcon: React.FC<{ type: TaskType }> = ({ type }) => {\n    const commonClasses = \"w-5 h-5\";\n    switch (type) {\n        case TaskType.DATA_INPUT: return <DocumentTextIcon className={commonClasses} />;\n        case TaskType.GEMINI_PROMPT: return <SparklesIcon className={commonClasses} />;\n        case TaskType.GEMINI_GROUNDED: return <SparklesIcon className={commonClasses} />;\n        case TaskType.IMAGE_ANALYSIS: return <EyeIcon className={commonClasses} />;\n        case TaskType.TEXT_MANIPULATION: return <CodeBracketIcon className={commonClasses} />;\n        case TaskType.DISPLAY_CHART: return <PresentationChartLineIcon className={commonClasses} />;\n        default: return <DocumentTextIcon className={commonClasses} />;\n    }\n};\n\n/**\n * A configuration object that maps task statuses to specific CSS classes for styling.\n */\nconst statusConfig = {\n    [TaskStatus.PENDING]: { bg: 'bg-surface', border: 'border-border-primary', text: 'text-text-tertiary', iconBg: 'bg-surface-hover' },\n    [TaskStatus.RUNNING]: { bg: 'bg-info-bg', border: 'border-info ring-2 ring-info/20', text: 'text-info', iconBg: 'bg-info/20' },\n    [TaskStatus.COMPLETED]: { bg: 'bg-success-bg', border: 'border-success', text: 'text-success', iconBg: 'bg-success/20' },\n    [TaskStatus.FAILED]: { bg: 'bg-error-bg', border: 'border-error', text: 'text-error', iconBg: 'bg-error/20' },\n    [TaskStatus.SKIPPED]: { bg: 'bg-warning-bg', border: 'border-warning', text: 'text-warning', iconBg: 'bg-warning/20' },\n};\n\n/**\n * @interface TaskNodeProps\n * @description Defines the props for the TaskNode component.\n * @property {Task} task - The task object to render.\n * @property {TaskState} state - The current execution state of the task.\n * @property {() => void} onClick - Callback function to be invoked when the node is clicked.\n */\ninterface TaskNodeProps {\n    task: Task;\n    state: TaskState;\n    onClick: () => void;\n}\n\n/**\n * A component that renders a visual representation of a workflow task.\n * It displays the task's details and dynamically changes its style based on the execution status.\n *\n * @param {TaskNodeProps} props - The props for the component.\n * @returns {JSX.Element} The rendered task node.\n */\nconst TaskNode: React.FC<TaskNodeProps> = ({ task, state, onClick }) => {\n    const config = statusConfig[state.status];\n\n    const getResultSummary = () => {\n        if (state.status !== TaskStatus.COMPLETED || !state.result) return null;\n        if(typeof state.result === 'string') return state.result.substring(0, 50) + (state.result.length > 50 ? '...' : '');\n        if(typeof state.result === 'object') return `[Object] Keys: ${Object.keys(state.result).slice(0,3).join(', ')}`;\n        return String(state.result);\n    }\n    \n    const duration = (state.startTime && state.endTime) ? `${((state.endTime - state.startTime)/1000).toFixed(2)}s` : null;\n\n    return (\n        <div \n            onClick={onClick}\n            className={`p-4 rounded-lg border cursor-pointer transition-all duration-200 hover:shadow-md ${config.bg} ${config.border}`}\n        >\n            <div className=\"flex items-start justify-between\">\n                <div className=\"flex items-center space-x-3\">\n                    <div className={`p-2 rounded-md ${config.iconBg}`}>\n                        <TaskIcon type={task.type} />\n                    </div>\n                    <div className=\"flex items-center space-x-2\">\n                        <h3 className=\"font-semibold text-text-primary\">{task.name}</h3>\n                        {task.promptId && <span title=\"Linked to SFL Prompt Library\"><LinkIcon className=\"w-4 h-4 text-text-tertiary\" /></span>}\n                    </div>\n                </div>\n                <span className={`px-2 py-0.5 text-xs font-semibold rounded-full ${config.bg} ${config.text}`}>\n                    {state.status}\n                </span>\n            </div>\n            <p className=\"text-xs text-text-tertiary mt-2 h-8 overflow-hidden\">{task.description}</p>\n            \n            <div className=\"mt-3 pt-3 border-t border-border-primary text-xs space-y-1\">\n                <p><span className=\"font-medium text-text-secondary\">Inputs:</span> <span className=\"text-text-tertiary truncate\">{task.inputKeys.join(', ') || 'None'}</span></p>\n                <p><span className=\"font-medium text-text-secondary\">Output:</span> <span className=\"text-text-tertiary\">{task.outputKey}</span></p>\n            </div>\n            \n             {state.status === TaskStatus.COMPLETED && (\n                <div className=\"mt-2 pt-2 border-t border-border-primary text-xs\">\n                    <p className=\"font-medium text-success\">Result:</p>\n                    <p className=\"text-text-secondary break-words h-6 overflow-hidden\">{getResultSummary()}</p>\n                </div>\n            )}\n            \n            {state.status === TaskStatus.FAILED && state.error && (\n                <div className=\"mt-2 pt-2 border-t border-border-primary text-xs\">\n                    <p className=\"font-medium text-error\">Error:</p>\n                    <p className=\"text-error break-words h-6 overflow-hidden\">{state.error}</p>\n                </div>\n            )}\n            \n            {duration && (\n                <div className=\"text-right text-xs text-text-tertiary mt-2\">\n                    {duration}\n                </div>\n            )}\n        </div>\n    );\n};\n\nexport default TaskNode;\n",
      "metadata": {
        "filename": "TaskNode.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/UserInputArea.tsx\n\n/**\n * @file UserInputArea.tsx\n * @description This component provides a tabbed interface for users to input text, upload an image, or upload a text file.\n * The provided input is then \"staged\" to be used as the initial data for a workflow run.\n *\n * @requires react\n * @requires ../../types\n * @requires ../icons/PaperClipIcon\n * @requires ../icons/DocumentTextIcon\n */\n\nimport React, { useState } from 'react';\nimport { StagedUserInput, Workflow } from '../../types';\nimport PaperClipIcon from '../icons/PaperClipIcon';\nimport DocumentTextIcon from '../icons/DocumentTextIcon';\nimport MagicWandIcon from '../icons/MagicWandIcon';\nimport { orchestrateWorkflow } from '../../services/workflowEngine';\n\ntype Tab = 'text' | 'image' | 'file';\n\n/**\n * @interface UserInputAreaProps\n * @description Defines the props for the UserInputArea component.\n * @property {(input: StagedUserInput) => void} onStageInput - Callback function to stage the user's input for the workflow.\n * @property {(workflow: Workflow) => void} onWorkflowGenerated - Callback function when AI generates a workflow from user input.\n */\ninterface UserInputAreaProps {\n    onStageInput: (input: StagedUserInput) => void;\n    onWorkflowGenerated: (workflow: Workflow) => void;\n}\n\n/**\n * A component that allows users to provide various types of input for a workflow.\n * It features tabs for text, image, and file inputs and a button to stage the data.\n * Also includes AI orchestration functionality for generating workflows from natural language descriptions.\n *\n * @param {UserInputAreaProps} props - The props for the component.\n * @returns {JSX.Element} The rendered user input area.\n */\nconst UserInputArea: React.FC<UserInputAreaProps> = ({ onStageInput, onWorkflowGenerated }) => {\n    const [activeTab, setActiveTab] = useState<Tab>('text');\n    const [text, setText] = useState('');\n    const [image, setImage] = useState<{ name: string; type: string; base64: string, preview: string } | null>(null);\n    const [file, setFile] = useState<{ name: string; content: string } | null>(null);\n    const [isOrchestrating, setIsOrchestrating] = useState(false);\n\n    const handleImageUpload = (e: React.ChangeEvent<HTMLInputElement>) => {\n        const uploadedFile = e.target.files?.[0];\n        if (uploadedFile && uploadedFile.type.startsWith('image/')) {\n            const reader = new FileReader();\n            reader.onload = (event) => {\n                const base64 = (event.target?.result as string).split(',')[1];\n                const preview = URL.createObjectURL(uploadedFile);\n                setImage({ name: uploadedFile.name, type: uploadedFile.type, base64, preview });\n            };\n            reader.readAsDataURL(uploadedFile);\n        }\n    };\n    \n    const handleFileUpload = (e: React.ChangeEvent<HTMLInputElement>) => {\n        const uploadedFile = e.target.files?.[0];\n        if(uploadedFile && uploadedFile.type.startsWith('text/')) {\n            const reader = new FileReader();\n            reader.onload = (event) => {\n                setFile({ name: uploadedFile.name, content: event.target?.result as string });\n            };\n            reader.readAsText(uploadedFile);\n        }\n    }\n\n    const handleStage = () => {\n        onStageInput({ text, image, file });\n        alert('Input has been staged for the workflow.');\n    };\n\n    const handleOrchestrate = async () => {\n        if (!text.trim()) {\n            alert('Please enter a text description in the Text tab to generate a workflow.');\n            setActiveTab('text');\n            return;\n        }\n\n        if (text.length > 2000) {\n            alert('Request description is too long. Please limit to 2000 characters.');\n            return;\n        }\n\n        setIsOrchestrating(true);\n        try {\n            const generatedWorkflow = await orchestrateWorkflow(text.trim());\n            onWorkflowGenerated(generatedWorkflow);\n            alert(`Successfully generated workflow: \"${generatedWorkflow.name}\" with ${generatedWorkflow.tasks.length} tasks!`);\n        } catch (error: any) {\n            console.error('Workflow orchestration failed:', error);\n            alert(`Failed to generate workflow: ${error.message}`);\n        } finally {\n            setIsOrchestrating(false);\n        }\n    };\n\n    const TabButton: React.FC<{ tabId: Tab, children: React.ReactNode }> = ({ tabId, children }) => (\n        <button\n            onClick={() => setActiveTab(tabId)}\n            className={`px-4 py-2 text-sm font-medium rounded-t-lg border-b-2 ${\n                activeTab === tabId\n                    ? 'border-accent-primary text-accent-primary'\n                    : 'border-transparent text-text-secondary hover:text-text-primary hover:border-border-secondary'\n            }`}\n        >\n            {children}\n        </button>\n    );\n\n    return (\n        <div className=\"flex-grow flex flex-col p-4 bg-surface rounded-lg border border-border-primary\">\n            <h2 className=\"text-lg font-bold text-text-primary mb-2\">User Input</h2>\n            <div className=\"border-b border-border-primary -mx-4 px-4\">\n                <nav className=\"-mb-px flex space-x-4\">\n                    <TabButton tabId=\"text\">Text</TabButton>\n                    <TabButton tabId=\"image\">Image</TabButton>\n                    <TabButton tabId=\"file\">File</TabButton>\n                </nav>\n            </div>\n            <div className=\"flex-grow pt-4\">\n                {activeTab === 'text' && (\n                    <textarea\n                        value={text}\n                        onChange={(e) => setText(e.target.value)}\n                        placeholder=\"Paste article text or other content here...\"\n                        className=\"input-field w-full h-full resize-none\"\n                    />\n                )}\n                {activeTab === 'image' && (\n                    <div className=\"flex flex-col items-center justify-center h-full\">\n                        <input type=\"file\" id=\"image-upload\" className=\"hidden\" accept=\"image/*\" onChange={handleImageUpload} />\n                        {image ? (\n                            <div className=\"text-center\">\n                                <img src={image.preview} alt={image.name} className=\"max-h-40 rounded-md border border-border-primary\" />\n                                <p className=\"text-xs mt-2 text-text-secondary truncate\">{image.name}</p>\n                                <button onClick={() => setImage(null)} className=\"text-xs text-error mt-1\">Remove</button>\n                            </div>\n                        ) : (\n                            <label htmlFor=\"image-upload\" className=\"cursor-pointer p-6 border-2 border-dashed border-border-secondary rounded-md text-center hover:bg-surface-hover\">\n                                <PaperClipIcon className=\"w-8 h-8 mx-auto text-text-tertiary mb-2\" />\n                                <span className=\"text-sm text-text-secondary\">Click to upload image</span>\n                            </label>\n                        )}\n                    </div>\n                )}\n                 {activeTab === 'file' && (\n                    <div className=\"flex flex-col items-center justify-center h-full\">\n                        <input type=\"file\" id=\"file-upload\" className=\"hidden\" accept=\".txt,.md\" onChange={handleFileUpload} />\n                        {file ? (\n                            <div className=\"text-center\">\n                                <DocumentTextIcon className=\"w-12 h-12 mx-auto text-text-tertiary\"/>\n                                <p className=\"text-sm mt-2 text-text-primary\">{file.name}</p>\n                                <button onClick={() => setFile(null)} className=\"text-xs text-error mt-1\">Remove</button>\n                            </div>\n                        ) : (\n                             <label htmlFor=\"file-upload\" className=\"cursor-pointer p-6 border-2 border-dashed border-border-secondary rounded-md text-center hover:bg-surface-hover\">\n                                <PaperClipIcon className=\"w-8 h-8 mx-auto text-text-tertiary mb-2\" />\n                                <span className=\"text-sm text-text-secondary\">Click to upload text file</span>\n                            </label>\n                        )}\n                    </div>\n                )}\n            </div>\n            <div className=\"mt-4 flex gap-2\">\n                <button\n                    onClick={handleStage}\n                    className=\"btn-primary flex-1 py-2 rounded-md font-semibold\"\n                >\n                    Stage Input for Workflow\n                </button>\n                <button\n                    onClick={handleOrchestrate}\n                    disabled={isOrchestrating || !text.trim()}\n                    className=\"flex-1 bg-accent-secondary text-white py-2 rounded-md font-semibold hover:bg-accent-tertiary transition-colors disabled:bg-text-disabled disabled:cursor-not-allowed flex items-center justify-center gap-2\"\n                    title={!text.trim() ? \"Enter a description in the Text tab to generate a workflow\" : \"Generate workflow from description using AI\"}\n                >\n                    <MagicWandIcon className=\"w-4 h-4\" />\n                    {isOrchestrating ? 'Generating...' : 'Magic Wand'}\n                </button>\n            </div>\n        </div>\n    );\n};\n\nexport default UserInputArea;\n",
      "metadata": {
        "filename": "UserInputArea.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/WorkflowCanvas.tsx\n\n/**\n * @file WorkflowCanvas.tsx\n * @description This component serves as the main interactive area for a selected workflow.\n * It displays all the tasks as nodes, provides controls to run or reset the workflow,\n * and shows the live state of the Data Store as the workflow executes.\n *\n * @requires react\n * @requires ../../types\n * @requires ../../hooks/useWorkflowRunner\n * @requires ./TaskNode\n * @requires ./DataStoreViewer\n * @requires ../icons/PlayIcon\n * @requires ../icons/ArrowPathIcon\n * @requires ./modals/TaskDetailModal\n */\n\nimport React, { useState } from 'react';\nimport { Workflow, StagedUserInput, TaskStatus, PromptSFL } from '../../types';\nimport { useWorkflowRunner } from '../../hooks/useWorkflowRunner';\nimport TaskNode from './TaskNode';\nimport DataStoreViewer from './DataStoreViewer';\nimport PlayIcon from '../icons/PlayIcon';\nimport StopIcon from '../icons/StopIcon';\nimport ArrowPathIcon from '../icons/ArrowPathIcon';\nimport TaskDetailModal from './modals/TaskDetailModal';\n\n/**\n * @interface WorkflowCanvasProps\n * @description Defines the props for the WorkflowCanvas component.\n * @property {Workflow} workflow - The workflow object to be displayed and executed.\n * @property {StagedUserInput} stagedInput - The user input that has been staged for the workflow run.\n * @property {PromptSFL[]} prompts - The library of available SFL prompts.\n */\ninterface WorkflowCanvasProps {\n    workflow: Workflow;\n    stagedInput: StagedUserInput;\n    prompts: PromptSFL[];\n}\n\n/**\n * The main canvas for visualizing and running a workflow.\n * It uses the `useWorkflowRunner` hook to manage the execution logic and state.\n *\n * @param {WorkflowCanvasProps} props - The props for the component.\n * @returns {JSX.Element} The rendered workflow canvas.\n */\nconst WorkflowCanvas: React.FC<WorkflowCanvasProps> = ({ workflow, stagedInput, prompts }) => {\n    const { \n        dataStore, \n        taskStates, \n        isRunning, \n        run, \n        stop, \n        reset, \n        runFeedback, \n        currentExecution, \n        executionMode, \n        setExecutionMode \n    } = useWorkflowRunner(workflow, prompts);\n    const [selectedTaskForDetail, setSelectedTaskForDetail] = useState<string | null>(null);\n\n    const handleTaskClick = (taskId: string) => {\n        setSelectedTaskForDetail(taskId);\n    };\n    \n    const taskForModal = workflow.tasks.find(t => t.id === selectedTaskForDetail);\n    const taskStateForModal = selectedTaskForDetail ? taskStates[selectedTaskForDetail] : undefined;\n\n    return (\n        <div className=\"flex-1 flex flex-col h-full\">\n            <header className=\"flex-shrink-0 bg-surface-elevated/80 backdrop-blur-lg border-b border-border-primary px-6 py-4 flex items-center justify-between sticky top-0 z-10\">\n                <div>\n                    <h2 className=\"text-xl font-bold text-text-primary\">{workflow.name}</h2>\n                    <p className=\"text-sm text-text-secondary\">{workflow.description}</p>\n                </div>\n                <div className=\"flex items-center space-x-3\">\n                    <div className=\"flex items-center space-x-2\">\n                        <label className=\"text-sm text-text-secondary\">Mode:</label>\n                        <select\n                            value={executionMode}\n                            onChange={(e) => setExecutionMode(e.target.value as 'local' | 'async')}\n                            disabled={isRunning}\n                            className=\"text-sm border border-border-primary rounded px-2 py-1 bg-surface text-text-primary disabled:opacity-50\"\n                        >\n                            <option value=\"local\">Local</option>\n                            <option value=\"async\">Async</option>\n                        </select>\n                    </div>\n                    \n                    {currentExecution && (\n                        <div className=\"text-sm text-text-secondary\">\n                            Job: <span className=\"font-mono text-xs\">{currentExecution.jobId?.slice(-8)}</span>\n                        </div>\n                    )}\n                    \n                    <button\n                        onClick={() => reset()}\n                        disabled={isRunning}\n                        className=\"btn-secondary flex items-center space-x-2 text-sm font-semibold disabled:opacity-50\"\n                    >\n                        <ArrowPathIcon className=\"w-5 h-5\" />\n                        <span>Reset</span>\n                    </button>\n                    {isRunning ? (\n                        <button\n                            onClick={() => stop()}\n                            className=\"flex items-center space-x-2 bg-error text-white px-4 py-2 rounded-lg text-sm font-semibold hover:bg-error/90 transition-colors shadow-sm\"\n                        >\n                            <StopIcon className=\"w-5 h-5\" />\n                            <span>Stop</span>\n                        </button>\n                    ) : (\n                        <button\n                            onClick={() => run(stagedInput)}\n                            className=\"flex items-center space-x-2 bg-success text-white px-4 py-2 rounded-lg text-sm font-semibold hover:bg-success/90 transition-colors shadow-sm\"\n                        >\n                            <PlayIcon className=\"w-5 h-5\" />\n                            <span>{`Run ${executionMode === 'async' ? 'Async' : 'Local'}`}</span>\n                        </button>\n                    )}\n                </div>\n            </header>\n\n            <div className=\"flex-1 flex overflow-hidden\">\n                <div className=\"flex-1 overflow-y-auto p-6\">\n                     {runFeedback.length > 0 && (\n                        <div className=\"mb-4 p-3 bg-warning-bg border-l-4 border-warning text-warning text-xs rounded-r-lg\">\n                            <p className=\"font-bold\">Execution Notes:</p>\n                            <ul className=\"list-disc list-inside\">\n                                {runFeedback.map((fb, i) => <li key={i}>{fb}</li>)}\n                            </ul>\n                        </div>\n                    )}\n                    <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 xl:grid-cols-4 gap-6\">\n                        {workflow.tasks.map(task => (\n                            <TaskNode\n                                key={task.id}\n                                task={task}\n                                state={taskStates[task.id] || { status: TaskStatus.PENDING }}\n                                onClick={() => handleTaskClick(task.id)}\n                            />\n                        ))}\n                    </div>\n                </div>\n                \n                <aside className=\"w-[400px] bg-surface border-l border-border-primary overflow-y-auto\">\n                    <DataStoreViewer dataStore={dataStore} />\n                </aside>\n            </div>\n            \n            {selectedTaskForDetail && taskForModal && (\n                <TaskDetailModal\n                    isOpen={true}\n                    onClose={() => setSelectedTaskForDetail(null)}\n                    task={taskForModal}\n                    taskState={taskStateForModal}\n                    prompts={prompts}\n                />\n            )}\n        </div>\n    );\n};\n\nexport default WorkflowCanvas;\n",
      "metadata": {
        "filename": "WorkflowCanvas.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/WorkflowControls.tsx\n\n/**\n * @file WorkflowControls.tsx\n * @description This component provides the main controls for managing workflows, including selecting,\n * creating, editing, deleting, importing, and exporting workflows.\n *\n * @requires react\n * @requires ../../types\n * @requires ../icons/PlusIcon\n * @requires ../icons/MagicWandIcon\n * @requires ../icons/PencilIcon\n * @requires ../icons/TrashIcon\n * @requires ../icons/ArrowUpTrayIcon\n * @requires ../icons/ArrowDownTrayIcon\n */\n\nimport React, { useRef } from 'react';\nimport { Workflow } from '../../types';\nimport PlusIcon from '../icons/PlusIcon';\nimport MagicWandIcon from '../icons/MagicWandIcon';\nimport PencilIcon from '../icons/PencilIcon';\nimport TrashIcon from '../icons/TrashIcon';\nimport ArrowUpTrayIcon from '../icons/ArrowUpTrayIcon';\nimport ArrowDownTrayIcon from '../icons/ArrowDownTrayIcon';\n\n/**\n * @interface WorkflowControlsProps\n * @description Defines the props for the WorkflowControls component.\n * @property {Workflow[]} workflows - The list of all available workflows.\n * @property {Workflow | null} activeWorkflow - The currently selected workflow.\n * @property {(id: string) => void} onSelectWorkflow - Callback to select a workflow.\n * @property {() => void} onOpenEditor - Callback to open the workflow editor modal.\n * @property {() => void} onOpenWizard - Callback to open the workflow creation wizard.\n * @property {(id: string) => void} onDeleteWorkflow - Callback to delete a workflow.\n * @property {(workflows: Workflow[]) => void} onImportWorkflows - Callback to handle importing workflows from a file.\n */\ninterface WorkflowControlsProps {\n    workflows: Workflow[];\n    activeWorkflow: Workflow | null;\n    onSelectWorkflow: (id: string) => void;\n    onOpenEditor: () => void;\n    onOpenWizard: () => void;\n    onDeleteWorkflow: (id: string) => void;\n    onImportWorkflows: (workflows: Workflow[]) => void;\n}\n\n/**\n * A component that provides UI controls for managing workflows.\n * It allows users to switch between workflows, create new ones, and perform other management tasks.\n *\n * @param {WorkflowControlsProps} props - The props for the component.\n * @returns {JSX.Element} The rendered workflow controls panel.\n */\nconst WorkflowControls: React.FC<WorkflowControlsProps> = ({\n    workflows,\n    activeWorkflow,\n    onSelectWorkflow,\n    onOpenEditor,\n    onOpenWizard,\n    onDeleteWorkflow,\n    onImportWorkflows\n}) => {\n    const importFileRef = useRef<HTMLInputElement>(null);\n\n    const handleExport = () => {\n        if (!activeWorkflow) return alert(\"No workflow selected to export.\");\n        const data = JSON.stringify([activeWorkflow], null, 2);\n        const blob = new Blob([data], { type: \"application/json\" });\n        const url = URL.createObjectURL(blob);\n        const a = document.createElement(\"a\");\n        a.href = url;\n        a.download = `${activeWorkflow.name.replace(/\\s+/g, '_')}.json`;\n        a.click();\n        URL.revokeObjectURL(url);\n    };\n\n    const handleImportClick = () => {\n        importFileRef.current?.click();\n    };\n\n    const handleFileImport = (e: React.ChangeEvent<HTMLInputElement>) => {\n        const file = e.target.files?.[0];\n        if (!file) return;\n        const reader = new FileReader();\n        reader.onload = (event) => {\n            try {\n                const content = event.target?.result as string;\n                const importedData = JSON.parse(content);\n                if (!Array.isArray(importedData)) {\n                    throw new Error(\"Imported file must be a JSON array of workflows.\");\n                }\n                onImportWorkflows(importedData);\n            } catch (err: any) {\n                alert(`Import failed: ${err.message}`);\n            }\n        };\n        reader.readAsText(file);\n        if (e.target) e.target.value = '';\n    };\n\n    return (\n        <div className=\"p-4 bg-surface rounded-lg border border-border-primary space-y-4\">\n            <h2 className=\"text-lg font-bold text-text-primary\">Workflow Controls</h2>\n            \n            <input type=\"file\" ref={importFileRef} onChange={handleFileImport} className=\"hidden\" accept=\".json\" />\n\n            <div>\n                <label htmlFor=\"workflow-select\" className=\"block text-sm font-medium text-text-secondary mb-1\">Select Workflow</label>\n                <select\n                    id=\"workflow-select\"\n                    value={activeWorkflow?.id || ''}\n                    onChange={(e) => onSelectWorkflow(e.target.value)}\n                    className=\"input-field w-full\"\n                >\n                    <optgroup label=\"Default Workflows\">\n                        {workflows.filter(w => w.isDefault).map(wf => <option key={wf.id} value={wf.id}>{wf.name}</option>)}\n                    </optgroup>\n                    <optgroup label=\"Custom Workflows\">\n                        {workflows.filter(w => !w.isDefault).map(wf => <option key={wf.id} value={wf.id}>{wf.name}</option>)}\n                    </optgroup>\n                </select>\n            </div>\n\n            <div className=\"grid grid-cols-2 gap-2\">\n                <button onClick={onOpenEditor} className=\"btn-secondary flex items-center justify-center space-x-2 text-sm\"><PlusIcon className=\"w-4 h-4\"/><span>New</span></button>\n                <button onClick={onOpenWizard} className=\"btn-secondary flex items-center justify-center space-x-2 text-sm\"><MagicWandIcon className=\"w-4 h-4\"/><span>Wizard</span></button>\n            </div>\n            \n            {activeWorkflow && (\n                <div className=\"border-t border-border-primary pt-4 space-y-2\">\n                     <p className=\"text-xs text-text-tertiary\">{activeWorkflow.description}</p>\n                    <div className=\"grid grid-cols-2 gap-2\">\n                        <button \n                            onClick={onOpenEditor} \n                            className=\"btn-secondary flex items-center justify-center space-x-2 text-sm\"\n                            title={activeWorkflow.isDefault ? \"Clone to edit\" : \"Edit this workflow\"}\n                        >\n                            <PencilIcon className=\"w-4 h-4\"/>\n                            <span>{activeWorkflow.isDefault ? \"Clone\" : \"Edit\"}</span>\n                        </button>\n                        <button \n                            onClick={() => {\n                                if (window.confirm(`Are you sure you want to delete \"${activeWorkflow.name}\"?`)) {\n                                    onDeleteWorkflow(activeWorkflow.id);\n                                }\n                            }}\n                            disabled={activeWorkflow.isDefault}\n                            className=\"btn-secondary flex items-center justify-center space-x-2 text-sm disabled:opacity-50 disabled:cursor-not-allowed\"\n                        >\n                            <TrashIcon className=\"w-4 h-4\"/>\n                            <span>Delete</span>\n                        </button>\n                        <button onClick={handleImportClick} className=\"btn-secondary flex items-center justify-center space-x-2 text-sm\">\n                            <ArrowUpTrayIcon className=\"w-4 h-4\"/>\n                            <span>Import</span>\n                        </button>\n                        <button onClick={handleExport} className=\"btn-secondary flex items-center justify-center space-x-2 text-sm\">\n                           <ArrowDownTrayIcon className=\"w-4 h-4\"/>\n                           <span>Export</span>\n                        </button>\n                    </div>\n                </div>\n            )}\n        </div>\n    );\n};\n\nexport default WorkflowControls;\n",
      "metadata": {
        "filename": "WorkflowControls.tsx",
        "path": "/frontend/components/lab/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/modals/TaskDetailModal.tsx\n\n/**\n * @file TaskDetailModal.tsx\n * @description This component renders a modal dialog that displays the detailed configuration and execution state of a single workflow task.\n * It shows all properties of the task, and if available, the execution status, timings, results, or errors.\n * It also includes a chart renderer for tasks that output chartable data.\n *\n * @requires react\n * @requires recharts\n * @requires ../../../types\n * @requires ../../ModalShell\n */\n\nimport React from 'react';\nimport { ResponsiveContainer, BarChart, Bar, XAxis, YAxis, CartesianGrid, Tooltip, Legend } from 'recharts';\nimport { Task, TaskState, TaskType, PromptSFL } from '../../../types';\nimport ModalShell from '../../ModalShell';\n\n/**\n * A component to display a single key-value detail item.\n * @param {object} props - The component props.\n * @param {string} props.label - The label for the detail.\n * @param {any} [props.value] - The value to be displayed. Objects will be stringified.\n * @param {boolean} [props.isCode=false] - If true, the value is rendered in a code block style.\n * @returns {JSX.Element | null} The rendered detail item, or null if the value is empty.\n */\nconst DetailItem: React.FC<{ label: string; value?: any; isCode?: boolean }> = ({ label, value, isCode }) => {\n    if (value === undefined || value === null || (Array.isArray(value) && value.length === 0)) return null;\n\n    let displayValue = value;\n    if (typeof value === 'object') {\n        displayValue = JSON.stringify(value, null, 2);\n    } else {\n        displayValue = String(value);\n    }\n    \n    return (\n        <div>\n            <h4 className=\"text-sm font-semibold text-text-secondary mb-1\">{label}</h4>\n            <pre className={`p-3 rounded-md text-sm whitespace-pre-wrap break-all border ${isCode ? 'bg-surface border-border-primary text-text-primary' : 'bg-info-bg border-info text-info'}`}>\n                {displayValue}\n            </pre>\n        </div>\n    );\n};\n\n/**\n * A component to render a bar chart for task results.\n * @param {object} props - The component props.\n * @param {any[]} props.data - The data array for the chart. Expected to have `name` and `value` properties.\n * @returns {JSX.Element} A responsive bar chart or a message if data is invalid.\n */\nconst ChartRenderer: React.FC<{data: any[]}> = ({data}) => {\n    if (!Array.isArray(data) || data.length === 0) {\n        return <p className=\"text-sm text-text-tertiary\">No data available for chart.</p>;\n    }\n    const sample = data[0];\n    if (typeof sample !== 'object' || !sample.name || !sample.value) {\n         return <DetailItem label=\"Chart Data\" value={data} isCode />;\n    }\n\n    return (\n        <div className=\"h-64 w-full\">\n            <ResponsiveContainer>\n                <BarChart data={data} margin={{ top: 5, right: 20, left: -10, bottom: 5 }}>\n                    <CartesianGrid strokeDasharray=\"3 3\" />\n                    <XAxis dataKey=\"name\" />\n                    <YAxis />\n                    <Tooltip />\n                    <Legend />\n                    <Bar dataKey=\"value\" fill=\"var(--color-accent-primary)\" />\n                </BarChart>\n            </ResponsiveContainer>\n        </div>\n    )\n}\n\n/**\n * @interface TaskDetailModalProps\n * @description Defines the props for the TaskDetailModal component.\n * @property {boolean} isOpen - Whether the modal is currently open.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {Task} task - The task object whose details are to be displayed.\n * @property {TaskState} [taskState] - The current execution state of the task.\n * @property {PromptSFL[]} prompts - The library of available SFL prompts to find linked prompt details.\n */\ninterface TaskDetailModalProps {\n    isOpen: boolean;\n    onClose: () => void;\n    task: Task;\n    taskState?: TaskState;\n    prompts: PromptSFL[];\n}\n\n/**\n * A modal that displays comprehensive details about a specific workflow task.\n *\n * @param {TaskDetailModalProps} props - The props for the component.\n * @returns {JSX.Element} The rendered task detail modal.\n */\nconst TaskDetailModal: React.FC<TaskDetailModalProps> = ({ isOpen, onClose, task, taskState, prompts }) => {\n    const linkedPrompt = task.promptId ? prompts.find(p => p.id === task.promptId) : null;\n    \n    return (\n        <ModalShell isOpen={isOpen} onClose={onClose} title={`Task Details: ${task.name}`} size=\"3xl\">\n            <div className=\"space-y-6\">\n                <section>\n                    <h3 className=\"text-lg font-bold text-text-primary mb-2 border-b border-border-primary pb-2\">Configuration</h3>\n                    <div className=\"space-y-3 mt-2 text-sm\">\n                        <p><strong>ID:</strong> {task.id}</p>\n                        <p><strong>Description:</strong> {task.description}</p>\n                        <p><strong>Type:</strong> {task.type}</p>\n                        {linkedPrompt && <p><strong>Linked Prompt:</strong> {linkedPrompt.title}</p>}\n                        <DetailItem label=\"Dependencies\" value={task.dependencies} isCode />\n                        <DetailItem label=\"Input Keys\" value={task.inputKeys} isCode />\n                        <DetailItem label=\"Output Key\" value={task.outputKey} isCode />\n                        <DetailItem label=\"Prompt Template\" value={task.promptTemplate} isCode />\n                        <DetailItem label=\"Function Body\" value={task.functionBody} isCode />\n                        <DetailItem label=\"Static Value\" value={task.staticValue} isCode />\n                        <DetailItem label=\"Agent Config\" value={task.agentConfig} isCode />\n                    </div>\n                </section>\n                \n                {taskState && (\n                     <section>\n                        <h3 className=\"text-lg font-bold text-text-primary mb-2 border-b border-border-primary pb-2\">Execution State</h3>\n                         <div className=\"space-y-3 mt-2 text-sm\">\n                            <p><strong>Status:</strong> {taskState.status}</p>\n                            {taskState.startTime && <p><strong>Start Time:</strong> {new Date(taskState.startTime).toLocaleString()}</p>}\n                            {taskState.endTime && <p><strong>End Time:</strong> {new Date(taskState.endTime).toLocaleString()}</p>}\n                            {taskState.startTime && taskState.endTime && <p><strong>Duration:</strong> {((taskState.endTime - taskState.startTime)/1000).toFixed(3)} seconds</p>}\n                            \n                            {task.type === TaskType.DISPLAY_CHART && taskState.result ? (\n                                <div>\n                                    <h4 className=\"text-sm font-semibold text-text-secondary mb-1\">Chart</h4>\n                                    <ChartRenderer data={taskState.result} />\n                                </div>\n                            ) : (\n                                <DetailItem label=\"Result\" value={taskState.result} />\n                            )}\n                            \n                            <DetailItem label=\"Error\" value={taskState.error} />\n                         </div>\n                    </section>\n                )}\n                 <div className=\"flex justify-end pt-4 border-t border-border-primary\">\n                    <button onClick={onClose} className=\"btn-secondary\">Close</button>\n                </div>\n            </div>\n        </ModalShell>\n    );\n};\n\nexport default TaskDetailModal;\n",
      "metadata": {
        "filename": "TaskDetailModal.tsx",
        "path": "/frontend/components/lab/modals/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/modals/WorkflowEditorModal.tsx\n\n/**\n * @file WorkflowEditorModal.tsx\n * @description This component provides a modal interface for creating and editing workflows.\n * It allows users to define the workflow's name and description, and to add, configure, and remove individual tasks.\n *\n * @requires react\n * @requires ../../../types\n * @requires ../../../utils/generateId\n * @requires ../../ModalShell\n * @requires ../../icons/PlusIcon\n * @requires ../../icons/TrashIcon\n * @requires ../../icons/LinkIcon\n */\n\nimport React, { useState, useEffect } from 'react';\nimport { Workflow, Task, TaskType, PromptSFL } from '../../../types';\nimport { generateId } from '../../../utils/generateId';\nimport ModalShell from '../../ModalShell';\nimport PlusIcon from '../../icons/PlusIcon';\nimport TrashIcon from '../../icons/TrashIcon';\nimport LinkIcon from '../../icons/LinkIcon';\n\n/**\n * @interface WorkflowEditorModalProps\n * @description Defines the props for the WorkflowEditorModal component.\n * @property {boolean} isOpen - Whether the modal is currently open.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {(workflow: Workflow) => void} onSave - Callback function to save the workflow.\n * @property {Workflow | null} workflowToEdit - The workflow to be edited. If null, a new workflow is created.\n * @property {PromptSFL[]} prompts - The library of available SFL prompts for linking to tasks.\n */\ninterface WorkflowEditorModalProps {\n    isOpen: boolean;\n    onClose: () => void;\n    onSave: (workflow: Workflow) => void;\n    workflowToEdit: Workflow | null;\n    prompts: PromptSFL[];\n}\n\nconst emptyTask: Omit<Task, 'id'> = {\n    name: 'New Task',\n    description: '',\n    type: TaskType.GEMINI_PROMPT,\n    dependencies: [],\n    inputKeys: [],\n    outputKey: 'newResult',\n    promptTemplate: '',\n    agentConfig: { model: 'gemini-2.5-flash', temperature: 0.7 },\n    functionBody: '',\n    staticValue: '',\n    dataKey: '',\n};\n\n/**\n * A sub-component within the editor for configuring a single task.\n * @param {object} props - The component props.\n * @returns {JSX.Element} A form section for editing a task.\n */\nconst TaskEditor: React.FC<{\n    task: Task;\n    updateTask: (updatedTask: Task) => void;\n    removeTask: () => void;\n    availableDependencies: { id: string; name: string }[];\n    prompts: PromptSFL[];\n}> = ({ task, updateTask, removeTask, availableDependencies, prompts }) => {\n\n    const linkedPrompt = task.promptId ? prompts.find(p => p.id === task.promptId) : null;\n\n    const handleChange = (field: keyof Task, value: any) => {\n        updateTask({ ...task, [field]: value });\n    };\n\n    const handleDependencyChange = (depId: string) => {\n        const newDeps = task.dependencies.includes(depId)\n            ? task.dependencies.filter(d => d !== depId)\n            : [...task.dependencies, depId];\n        handleChange('dependencies', newDeps);\n    };\n\n    const handlePromptLinkChange = (e: React.ChangeEvent<HTMLSelectElement>) => {\n        const promptId = e.target.value;\n        handleChange('promptId', promptId || undefined);\n    };\n    \n    const commonInputClasses = \"input-field w-full\";\n    const labelClasses = \"block text-sm font-medium text-text-secondary mb-1\";\n\n    return (\n        <details className=\"border border-border-primary rounded-lg p-4 bg-surface\" open>\n            <summary className=\"font-semibold text-lg cursor-pointer flex justify-between items-center\">\n                <div className=\"flex items-center space-x-2\">\n                    <span>{task.name}</span>\n                    {task.promptId && <LinkIcon className=\"w-4 h-4 text-text-tertiary\" />}\n                </div>\n                <button type=\"button\" onClick={removeTask} className=\"text-error hover:text-error/80\"><TrashIcon className=\"w-5 h-5\"/></button>\n            </summary>\n            <div className=\"mt-4 space-y-4\">\n                <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n                    <div><label className={labelClasses}>Name</label><input type=\"text\" value={task.name} onChange={e => handleChange('name', e.target.value)} className={commonInputClasses} /></div>\n                    <div><label className={labelClasses}>Type</label>\n                        <select value={task.type} onChange={e => handleChange('type', e.target.value as TaskType)} className={commonInputClasses}>\n                            {Object.values(TaskType).map(t => <option key={t} value={t}>{t}</option>)}\n                        </select>\n                    </div>\n                </div>\n                <div><label className={labelClasses}>Description</label><input type=\"text\" value={task.description} onChange={e => handleChange('description', e.target.value)} className={commonInputClasses} /></div>\n\n                <div>\n                    <h4 className={labelClasses}>Dependencies</h4>\n                    <div className=\"grid grid-cols-2 md:grid-cols-3 gap-2 p-2 border rounded-md max-h-32 overflow-y-auto\">\n                        {availableDependencies.map(dep => (\n                            <div key={dep.id} className=\"flex items-center\">\n                                <input type=\"checkbox\" id={`dep-${task.id}-${dep.id}`} checked={task.dependencies.includes(dep.id)} onChange={() => handleDependencyChange(dep.id)} className=\"h-4 w-4 rounded border-border-primary text-accent-primary focus:ring-accent-primary\"/>\n                                <label htmlFor={`dep-${task.id}-${dep.id}`} className=\"ml-2 text-sm text-text-primary truncate\">{dep.name}</label>\n                            </div>\n                        ))}\n                    </div>\n                </div>\n\n                <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n                    <div><label className={labelClasses}>Input Keys (comma-separated)</label><input type=\"text\" value={task.inputKeys.join(',')} onChange={e => handleChange('inputKeys', e.target.value.split(',').map(k => k.trim()))} className={commonInputClasses} /></div>\n                    <div><label className={labelClasses}>Output Key</label><input type=\"text\" value={task.outputKey} onChange={e => handleChange('outputKey', e.target.value)} className={commonInputClasses} /></div>\n                </div>\n\n                {task.type === TaskType.GEMINI_PROMPT && (\n                    <div className=\"p-3 border border-dashed border-border-secondary rounded-md space-y-3 bg-surface-hover/50\">\n                        <div>\n                            <label className={labelClasses}>Link Library Prompt</label>\n                            <select value={task.promptId || ''} onChange={handlePromptLinkChange} className={commonInputClasses}>\n                                <option value=\"\">-- None (Manual Prompt) --</option>\n                                {prompts.map(p => <option key={p.id} value={p.id}>{p.title}</option>)}\n                            </select>\n                        </div>\n                        <div>\n                            <label className={labelClasses}>Prompt Template</label>\n                            <textarea \n                                value={linkedPrompt ? linkedPrompt.promptText : (task.promptTemplate || '')} \n                                onChange={e => handleChange('promptTemplate', e.target.value)} \n                                rows={4} \n                                className={`${commonInputClasses} font-mono text-sm`}\n                                disabled={!!linkedPrompt}\n                                placeholder={linkedPrompt ? 'This is managed by the linked prompt.' : 'Enter prompt template here...'}\n                            />\n                        </div>\n                         {!linkedPrompt && (\n                            <div>\n                                <label className={labelClasses}>Agent Config (JSON)</label>\n                                <textarea\n                                    value={task.agentConfig ? JSON.stringify(task.agentConfig, null, 2) : ''}\n                                    onChange={e => {\n                                        try { handleChange('agentConfig', JSON.parse(e.target.value)) } catch {}\n                                    }}\n                                    rows={4}\n                                    className={`${commonInputClasses} font-mono text-sm`}\n                                    placeholder='{ \"temperature\": 0.5 }'\n                                />\n                            </div>\n                        )}\n                    </div>\n                )}\n                \n                {(task.type === TaskType.GEMINI_GROUNDED || task.type === TaskType.IMAGE_ANALYSIS) && (\n                    <div><label className={labelClasses}>Prompt Template</label><textarea value={task.promptTemplate} onChange={e => handleChange('promptTemplate', e.target.value)} rows={4} className={`${commonInputClasses} font-mono text-sm`}></textarea></div>\n                )}\n                \n                {task.type === TaskType.TEXT_MANIPULATION && (\n                     <div><label className={labelClasses}>Function Body</label><textarea value={task.functionBody} onChange={e => handleChange('functionBody', e.target.value)} rows={4} className={`${commonInputClasses} font-mono text-sm`} placeholder=\"e.g., return `Hello, ${inputs.name}`\"></textarea></div>\n                )}\n                \n                {task.type === TaskType.DATA_INPUT && (\n                    <div><label className={labelClasses}>Static Value</label><textarea value={task.staticValue} onChange={e => handleChange('staticValue', e.target.value)} rows={2} className={commonInputClasses}></textarea></div>\n                )}\n                \n                {task.type === TaskType.DISPLAY_CHART && (\n                    <div><label className={labelClasses}>Data Key for Chart</label><input type=\"text\" value={task.dataKey} onChange={e => handleChange('dataKey', e.target.value)} className={commonInputClasses} /></div>\n                )}\n            </div>\n        </details>\n    );\n};\n\n/**\n * A modal for creating a new workflow or editing an existing one.\n *\n * @param {WorkflowEditorModalProps} props - The props for the component.\n * @returns {JSX.Element | null} The rendered modal editor or null if not open.\n */\nconst WorkflowEditorModal: React.FC<WorkflowEditorModalProps> = ({ isOpen, onClose, onSave, workflowToEdit, prompts }) => {\n    const [workflow, setWorkflow] = useState<Workflow | null>(null);\n\n    useEffect(() => {\n        if (workflowToEdit) {\n            if(workflowToEdit.isDefault) {\n                setWorkflow({\n                    ...workflowToEdit,\n                    id: `wf-custom-${generateId().slice(0, 8)}`,\n                    name: `${workflowToEdit.name} (Copy)`,\n                    isDefault: false,\n                });\n            } else {\n                setWorkflow(JSON.parse(JSON.stringify(workflowToEdit)));\n            }\n        } else {\n            setWorkflow({\n                id: `wf-custom-${generateId().slice(0, 8)}`,\n                name: 'New Custom Workflow',\n                description: '',\n                tasks: [],\n            });\n        }\n    }, [workflowToEdit, isOpen]);\n\n    if (!workflow) return null;\n\n    const handleWorkflowChange = (field: keyof Workflow, value: any) => {\n        setWorkflow(prev => prev ? { ...prev, [field]: value } : null);\n    };\n\n    const addTask = () => {\n        const newTask: Task = { ...emptyTask, id: `task-${generateId().slice(0, 8)}` };\n        handleWorkflowChange('tasks', [...workflow.tasks, newTask]);\n    };\n\n    const updateTask = (updatedTask: Task) => {\n        const newTasks = workflow.tasks.map(t => t.id === updatedTask.id ? updatedTask : t);\n        handleWorkflowChange('tasks', newTasks);\n    };\n\n    const removeTask = (taskId: string) => {\n        const newTasks = workflow.tasks.filter(t => t.id !== taskId);\n        const cleanedTasks = newTasks.map(t => ({\n            ...t,\n            dependencies: t.dependencies.filter(d => d !== taskId)\n        }));\n        handleWorkflowChange('tasks', cleanedTasks);\n    };\n\n    const handleSubmit = () => {\n        onSave(workflow);\n    };\n    \n    const commonInputClasses = \"input-field w-full\";\n    const labelClasses = \"block text-sm font-medium text-text-secondary mb-1\";\n\n    return (\n        <ModalShell isOpen={isOpen} onClose={onClose} title={workflowToEdit && !workflowToEdit.isDefault ? 'Edit Workflow' : 'Create Workflow'} size=\"4xl\">\n            <div className=\"space-y-6\">\n                <div className=\"p-4 border border-border-primary rounded-lg space-y-4 bg-surface\">\n                     <div><label className={labelClasses}>Workflow Name</label><input type=\"text\" value={workflow.name} onChange={(e) => handleWorkflowChange('name', e.target.value)} className={commonInputClasses} /></div>\n                     <div><label className={labelClasses}>Workflow Description</label><textarea value={workflow.description} onChange={(e) => handleWorkflowChange('description', e.target.value)} rows={2} className={commonInputClasses} /></div>\n                </div>\n\n                <div className=\"space-y-4\">\n                    <h3 className=\"text-xl font-semibold\">Tasks</h3>\n                    {workflow.tasks.map(task => (\n                        <TaskEditor\n                            key={task.id}\n                            task={task}\n                            updateTask={updateTask}\n                            removeTask={() => removeTask(task.id)}\n                            availableDependencies={workflow.tasks.filter(t => t.id !== task.id).map(t => ({id: t.id, name: t.name}))}\n                            prompts={prompts}\n                        />\n                    ))}\n                    <button type=\"button\" onClick={addTask} className=\"w-full flex items-center justify-center space-x-2 py-2 border-2 border-dashed border-border-secondary rounded-lg text-text-tertiary hover:bg-surface-hover\">\n                        <PlusIcon className=\"w-5 h-5\"/>\n                        <span>Add Task</span>\n                    </button>\n                </div>\n\n                 <div className=\"flex justify-end space-x-3 pt-4 border-t border-border-primary mt-6\">\n                    <button type=\"button\" onClick={onClose} className=\"btn-secondary\">Cancel</button>\n                    <button type=\"button\" onClick={handleSubmit} className=\"btn-primary\">Save Workflow</button>\n                </div>\n            </div>\n        </ModalShell>\n    );\n};\n\nexport default WorkflowEditorModal;\n",
      "metadata": {
        "filename": "WorkflowEditorModal.tsx",
        "path": "/frontend/components/lab/modals/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/lab/modals/WorkflowWizardModal.tsx\n\n/**\n * @file WorkflowWizardModal.tsx\n * @description This component provides a user-friendly wizard for creating a new workflow from a high-level goal.\n * It takes a natural language description from the user, uses an AI service to generate a structured workflow,\n * and then presents the generated workflow in an editor for refinement before saving.\n *\n * @requires react\n * @requires ../../../types\n * @requires ../../../services/geminiService\n * @requires ../../ModalShell\n * @requires ./WorkflowEditorModal\n */\n\nimport React, { useState } from 'react';\nimport { Workflow, PromptSFL } from '../../../types';\nimport { generateWorkflowFromGoal } from '../../../services/geminiService';\nimport ModalShell from '../../ModalShell';\nimport WorkflowEditorModal from './WorkflowEditorModal';\n\n/**\n * @interface WorkflowWizardModalProps\n * @description Defines the props for the WorkflowWizardModal component.\n * @property {boolean} isOpen - Whether the modal is currently open.\n * @property {() => void} onClose - Callback function to close the modal.\n * @property {(workflow: Workflow) => void} onSave - Callback function to save the created workflow.\n * @property {PromptSFL[]} prompts - The library of available SFL prompts, passed to the editor.\n */\ninterface WorkflowWizardModalProps {\n    isOpen: boolean;\n    onClose: () => void;\n    onSave: (workflow: Workflow) => void;\n    prompts: PromptSFL[];\n}\n\ntype WizardStep = 'input' | 'loading' | 'refinement' | 'error';\n\n/**\n * A modal wizard for creating workflows from a natural language goal.\n *\n * @param {WorkflowWizardModalProps} props - The props for the component.\n * @returns {JSX.Element} The rendered wizard modal.\n */\nconst WorkflowWizardModal: React.FC<WorkflowWizardModalProps> = ({ isOpen, onClose, onSave, prompts }) => {\n    const [step, setStep] = useState<WizardStep>('input');\n    const [goal, setGoal] = useState('');\n    const [errorMessage, setErrorMessage] = useState('');\n    const [generatedWorkflow, setGeneratedWorkflow] = useState<Workflow | null>(null);\n\n    const handleGenerate = async () => {\n        if (!goal.trim()) {\n            setErrorMessage('Please describe your workflow goal.');\n            return;\n        }\n        setStep('loading');\n        setErrorMessage('');\n        try {\n            const workflow = await generateWorkflowFromGoal(goal);\n            setGeneratedWorkflow(workflow);\n            setStep('refinement');\n        } catch (error: any) {\n            setErrorMessage(error.message || 'An unknown error occurred.');\n            setStep('error');\n        }\n    };\n    \n    const handleCloseAndReset = () => {\n        setStep('input');\n        setGoal('');\n        setErrorMessage('');\n        setGeneratedWorkflow(null);\n        onClose();\n    };\n\n    const renderContent = () => {\n        switch (step) {\n            case 'input':\n                return (\n                    <div className=\"space-y-4\">\n                        <p className=\"text-text-secondary\">Describe the multi-step process you want to automate. The AI will generate a structured workflow with all the necessary tasks, inputs, and outputs.</p>\n                        <textarea\n                            value={goal}\n                            onChange={(e) => setGoal(e.target.value)}\n                            rows={5}\n                            placeholder=\"e.g., 'Take a user-provided article URL, fetch its content, summarize it, and then translate the summary into Spanish.'\"\n                            className=\"input-field w-full\"\n                        />\n                        {errorMessage && <p className=\"text-error text-sm\">{errorMessage}</p>}\n                        <div className=\"flex justify-end space-x-2\">\n                             <button onClick={handleCloseAndReset} className=\"btn-secondary\">Cancel</button>\n                             <button onClick={handleGenerate} className=\"btn-primary\">Generate Workflow</button>\n                        </div>\n                    </div>\n                );\n            case 'loading':\n                 return (\n                    <div className=\"flex flex-col items-center justify-center p-8 text-center h-48\">\n                        <div className=\"spinner mb-4\"></div>\n                        <p className=\"text-lg text-text-primary\">Generating workflow...</p>\n                    </div>\n                );\n            case 'refinement':\n                return (\n                    <WorkflowEditorModal\n                        isOpen={true}\n                        onClose={handleCloseAndReset}\n                        onSave={onSave}\n                        workflowToEdit={generatedWorkflow}\n                        prompts={prompts}\n                    />\n                );\n            case 'error':\n                 return (\n                    <div className=\"text-center p-4 bg-error-bg border border-error rounded-lg\">\n                        <p className=\"font-semibold text-error\">Generation Failed</p>\n                        <p className=\"text-error text-sm mt-1\">{errorMessage}</p>\n                        <button onClick={() => setStep('input')} className=\"btn-secondary mt-4\">Try Again</button>\n                    </div>\n                 );\n        }\n    };\n\n    if (step === 'refinement') {\n        return renderContent();\n    }\n\n    return (\n        <ModalShell isOpen={isOpen} onClose={handleCloseAndReset} title=\"AI Workflow Wizard\">\n            {renderContent()}\n        </ModalShell>\n    );\n};\n\nexport default WorkflowWizardModal;\n",
      "metadata": {
        "filename": "WorkflowWizardModal.tsx",
        "path": "/frontend/components/lab/modals/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/settings/ProviderSetupPage.test.tsx\n\n/**\n * @file ProviderSetupPage.test.tsx\n * @description Unit tests for the ProviderSetupPage component\n */\n\nimport React from 'react';\nimport { render, screen, fireEvent, waitFor } from '@testing-library/react';\nimport '@testing-library/jest-dom';\nimport ProviderSetupPage from './ProviderSetupPage';\n\n// Mock localStorage\nconst mockLocalStorage = {\n  getItem: jest.fn(),\n  setItem: jest.fn(),\n  removeItem: jest.fn(),\n  clear: jest.fn()\n};\n\nObject.defineProperty(window, 'localStorage', {\n  value: mockLocalStorage\n});\n\ndescribe('ProviderSetupPage', () => {\n  beforeEach(() => {\n    // Clear all mocks before each test\n    jest.clearAllMocks();\n    render(<ProviderSetupPage />);\n  });\n\n  describe('Rendering', () => {\n    test('renders the main title', () => {\n      expect(screen.getByText('AI Provider Configuration')).toBeInTheDocument();\n    });\n\n    test('renders provider selection section', () => {\n      expect(screen.getByText('Select AI Provider')).toBeInTheDocument();\n      expect(screen.getByText('Choose your preferred AI provider to configure API access.')).toBeInTheDocument();\n    });\n\n    test('renders all three provider options', () => {\n      expect(screen.getByText('Google Gemini')).toBeInTheDocument();\n      expect(screen.getByText('OpenAI')).toBeInTheDocument();\n      expect(screen.getByText('OpenRouter')).toBeInTheDocument();\n    });\n\n    test('renders API key configuration section', () => {\n      expect(screen.getByText('API Key Configuration')).toBeInTheDocument();\n      expect(screen.getByLabelText('API Key')).toBeInTheDocument();\n      expect(screen.getByText('Validate API Key')).toBeInTheDocument();\n    });\n\n    test('renders getting started information', () => {\n      expect(screen.getByText('Getting Started')).toBeInTheDocument();\n    });\n  });\n\n  describe('Form Interactions', () => {\n    test('Google provider is selected by default', () => {\n      const googleRadio = screen.getByDisplayValue('google');\n      expect(googleRadio).toBeChecked();\n    });\n\n    test('can select different providers', () => {\n      const openaiRadio = screen.getByDisplayValue('openai');\n      const openrouterRadio = screen.getByDisplayValue('openrouter');\n      \n      fireEvent.click(openaiRadio);\n      expect(openaiRadio).toBeChecked();\n      \n      fireEvent.click(openrouterRadio);\n      expect(openrouterRadio).toBeChecked();\n    });\n\n    test('API key input accepts text', () => {\n      const apiKeyInput = screen.getByLabelText('API Key');\n      fireEvent.change(apiKeyInput, { target: { value: 'test-api-key' } });\n      expect(apiKeyInput).toHaveValue('test-api-key');\n    });\n\n    test('validate button is clickable', () => {\n      const validateButton = screen.getByText('Validate API Key');\n      expect(validateButton).toBeEnabled();\n      fireEvent.click(validateButton);\n      // Note: In future iterations, this will trigger validation logic\n    });\n  });\n\n  describe('Accessibility', () => {\n    test('has proper form labels', () => {\n      expect(screen.getByLabelText('API Key')).toBeInTheDocument();\n    });\n\n    test('radio buttons have proper names', () => {\n      const radioButtons = screen.getAllByRole('radio');\n      radioButtons.forEach(radio => {\n        expect(radio).toHaveAttribute('name', 'provider');\n      });\n    });\n\n    test('form elements have proper ARIA attributes', () => {\n      const apiKeyInput = screen.getByLabelText('API Key');\n      expect(apiKeyInput).toHaveAttribute('type', 'password');\n    });\n  });\n\n  describe('State Management', () => {\n    test('initializes with default state values', () => {\n      const googleRadio = screen.getByDisplayValue('google');\n      const apiKeyInput = screen.getByLabelText('API Key');\n      \n      expect(googleRadio).toBeChecked();\n      expect(apiKeyInput).toHaveValue('');\n    });\n\n    test('updates state when provider selection changes', () => {\n      const openaiRadio = screen.getByDisplayValue('openai');\n      const googleRadio = screen.getByDisplayValue('google');\n      \n      fireEvent.click(openaiRadio);\n      expect(openaiRadio).toBeChecked();\n      expect(googleRadio).not.toBeChecked();\n      \n      fireEvent.click(googleRadio);\n      expect(googleRadio).toBeChecked();\n      expect(openaiRadio).not.toBeChecked();\n    });\n\n    test('updates state when API key input changes', () => {\n      const apiKeyInput = screen.getByLabelText('API Key');\n      \n      fireEvent.change(apiKeyInput, { target: { value: 'test-key-123' } });\n      expect(apiKeyInput).toHaveValue('test-key-123');\n      \n      fireEvent.change(apiKeyInput, { target: { value: 'updated-key-456' } });\n      expect(apiKeyInput).toHaveValue('updated-key-456');\n    });\n  });\n\n  describe('LocalStorage Integration', () => {\n    test('attempts to load settings from localStorage on mount', () => {\n      expect(mockLocalStorage.getItem).toHaveBeenCalledWith('sfl-ai-provider');\n      expect(mockLocalStorage.getItem).toHaveBeenCalledWith('sfl-api-key');\n    });\n\n    test('saves provider to localStorage when changed', async () => {\n      const openaiRadio = screen.getByDisplayValue('openai');\n      \n      fireEvent.click(openaiRadio);\n      \n      await waitFor(() => {\n        expect(mockLocalStorage.setItem).toHaveBeenCalledWith('sfl-ai-provider', 'openai');\n      });\n    });\n\n    test('saves API key to localStorage when changed', async () => {\n      const apiKeyInput = screen.getByLabelText('API Key');\n      \n      fireEvent.change(apiKeyInput, { target: { value: 'test-api-key' } });\n      \n      await waitFor(() => {\n        expect(mockLocalStorage.setItem).toHaveBeenCalledWith('sfl-api-key', 'test-api-key');\n      });\n    });\n\n    test('removes API key from localStorage when cleared', async () => {\n      const apiKeyInput = screen.getByLabelText('API Key');\n      \n      // First set a value\n      fireEvent.change(apiKeyInput, { target: { value: 'test-key' } });\n      await waitFor(() => {\n        expect(mockLocalStorage.setItem).toHaveBeenCalledWith('sfl-api-key', 'test-key');\n      });\n\n      // Then clear it\n      fireEvent.change(apiKeyInput, { target: { value: '' } });\n      await waitFor(() => {\n        expect(mockLocalStorage.removeItem).toHaveBeenCalledWith('sfl-api-key');\n      });\n    });\n\n    test('handles localStorage errors gracefully', () => {\n      mockLocalStorage.getItem.mockImplementation(() => {\n        throw new Error('localStorage unavailable');\n      });\n\n      // Component should still render without crashing\n      render(<ProviderSetupPage />);\n      expect(screen.getByText('AI Provider Configuration')).toBeInTheDocument();\n    });\n\n    test('initializes with saved values from localStorage', () => {\n      mockLocalStorage.getItem.mockImplementation((key) => {\n        if (key === 'sfl-ai-provider') return 'openai';\n        if (key === 'sfl-api-key') return 'saved-api-key';\n        return null;\n      });\n\n      render(<ProviderSetupPage />);\n      \n      const openaiRadio = screen.getByDisplayValue('openai');\n      const apiKeyInput = screen.getByLabelText('API Key');\n      \n      expect(openaiRadio).toBeChecked();\n      expect(apiKeyInput).toHaveValue('saved-api-key');\n    });\n\n    test('ignores invalid provider values from localStorage', () => {\n      mockLocalStorage.getItem.mockImplementation((key) => {\n        if (key === 'sfl-ai-provider') return 'invalid-provider';\n        return null;\n      });\n\n      render(<ProviderSetupPage />);\n      \n      // Should fall back to default 'google' provider\n      const googleRadio = screen.getByDisplayValue('google');\n      expect(googleRadio).toBeChecked();\n    });\n  });\n});\n",
      "metadata": {
        "filename": "ProviderSetupPage.test.tsx",
        "path": "/frontend/components/settings/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/components/settings/ProviderSetupPage.tsx\n\n/**\n * @file ProviderSetupPage.tsx\n * @description This component provides the AI Provider Configuration interface.\n * It allows users to select AI providers (Google, OpenAI, OpenRouter), \n * enter API keys, and validate them. This is the foundational component\n * for the multi-provider AI integration system.\n *\n * @requires react\n * @requires ../icons/CogIcon\n */\n\nimport React, { useState, useEffect } from 'react';\nimport CogIcon from '../icons/CogIcon';\nimport ArrowPathIcon from '../icons/ArrowPathIcon';\nimport CheckCircleIcon from '../icons/CheckCircleIcon';\nimport XCircleIcon from '../icons/XCircleIcon';\nimport { AIProvider, validateApiKey, listModels } from '../../services/aiService';\n\n/**\n * @interface ProviderSetupPageProps\n * @description Defines the props for the `ProviderSetupPage` component.\n */\ninterface ProviderSetupPageProps {\n  /** Callback called when setup is successfully completed */\n  onSetupComplete?: () => void;\n}\n\n/**\n * Validation status type for API key validation\n */\ntype ValidationStatus = 'idle' | 'validating' | 'valid' | 'invalid';\n\n/**\n * The main Provider Setup Page component.\n * Provides UI for configuring AI provider settings including provider selection,\n * API key input, and validation functionality.\n *\n * @param {ProviderSetupPageProps} props - The props for the component (currently none).\n * @returns {JSX.Element} The rendered provider setup page.\n */\nconst ProviderSetupPage: React.FC<ProviderSetupPageProps> = ({ onSetupComplete }) => {\n  // State management with localStorage integration\n  const [selectedProvider, setSelectedProvider] = useState<AIProvider>('google');\n  const [apiKey, setApiKey] = useState<string>('');\n  const [validationStatus, setValidationStatus] = useState<ValidationStatus>('idle');\n  const [availableModels, setAvailableModels] = useState<string[]>([]);\n  const [selectedModel, setSelectedModel] = useState<string>('');\n  const [validationError, setValidationError] = useState<string>('');\n  const [isLoadingModels, setIsLoadingModels] = useState<boolean>(false);\n\n  // Load state from localStorage on component mount\n  useEffect(() => {\n    try {\n      const savedProvider = localStorage.getItem('sfl-ai-provider') as AIProvider;\n      const savedApiKey = localStorage.getItem('sfl-api-key');\n      const savedModel = localStorage.getItem('sfl-selected-model');\n      \n      if (savedProvider && ['google', 'openai', 'openrouter'].includes(savedProvider)) {\n        setSelectedProvider(savedProvider);\n      }\n      \n      if (savedApiKey) {\n        setApiKey(savedApiKey);\n      }\n      \n      if (savedModel) {\n        setSelectedModel(savedModel);\n      }\n    } catch (error) {\n      console.warn('Failed to load settings from localStorage:', error);\n      // Continue with default values if localStorage is unavailable\n    }\n  }, []);\n\n  // Save state to localStorage whenever selectedProvider or apiKey changes\n  useEffect(() => {\n    try {\n      localStorage.setItem('sfl-ai-provider', selectedProvider);\n    } catch (error) {\n      console.warn('Failed to save provider to localStorage:', error);\n    }\n  }, [selectedProvider]);\n\n  useEffect(() => {\n    try {\n      if (apiKey) {\n        localStorage.setItem('sfl-api-key', apiKey);\n      } else {\n        localStorage.removeItem('sfl-api-key');\n      }\n    } catch (error) {\n      console.warn('Failed to save API key to localStorage:', error);\n    }\n  }, [apiKey]);\n\n  // Save selected model to localStorage\n  useEffect(() => {\n    try {\n      if (selectedModel) {\n        localStorage.setItem('sfl-selected-model', selectedModel);\n      } else {\n        localStorage.removeItem('sfl-selected-model');\n      }\n    } catch (error) {\n      console.warn('Failed to save selected model to localStorage:', error);\n    }\n  }, [selectedModel]);\n\n  // Event handlers\n  const handleProviderChange = (event: React.ChangeEvent<HTMLInputElement>) => {\n    const provider = event.target.value as AIProvider;\n    setSelectedProvider(provider);\n    // Reset validation status and model selection when provider changes\n    setValidationStatus('idle');\n    setAvailableModels([]);\n    setSelectedModel('');\n    setValidationError('');\n  };\n\n  const handleApiKeyChange = (event: React.ChangeEvent<HTMLInputElement>) => {\n    setApiKey(event.target.value);\n    // Reset validation status when API key changes\n    if (validationStatus !== 'idle') {\n      setValidationStatus('idle');\n      setAvailableModels([]);\n      setSelectedModel('');\n      setValidationError('');\n    }\n  };\n\n  const handleModelChange = (event: React.ChangeEvent<HTMLSelectElement>) => {\n    setSelectedModel(event.target.value);\n  };\n\n  // API Key Validation Handler (UX-01-C)\n  const handleValidate = async () => {\n    if (!apiKey.trim()) {\n      setValidationError('API key is required');\n      return;\n    }\n\n    setValidationStatus('validating');\n    setValidationError('');\n    setIsLoadingModels(false);\n\n    try {\n      // Validate API key\n      await validateApiKey(selectedProvider, apiKey);\n      setValidationStatus('valid');\n      \n      // Upon successful validation, fetch available models (UX-01-D)\n      setIsLoadingModels(true);\n      try {\n        const models = await listModels(selectedProvider, apiKey);\n        setAvailableModels(models);\n        \n        // Auto-select first model if none is currently selected\n        if (models.length > 0 && !selectedModel) {\n          setSelectedModel(models[0]);\n        }\n      } catch (modelError) {\n        console.warn('Failed to fetch models, but API key is valid:', modelError);\n        // Don't change validation status - key is still valid\n        setAvailableModels([]);\n      } finally {\n        setIsLoadingModels(false);\n      }\n\n      // Notify parent component that setup is complete\n      if (onSetupComplete) {\n        onSetupComplete();\n      }\n    } catch (error) {\n      setValidationStatus('invalid');\n      setValidationError(error instanceof Error ? error.message : 'Validation failed');\n      setAvailableModels([]);\n      setSelectedModel('');\n    }\n  };\n  return (\n    <div className=\"max-w-4xl mx-auto space-y-6\">\n      {/* Page Header */}\n      <div className=\"flex items-center space-x-3 mb-8\">\n        <CogIcon className=\"w-8 h-8 text-accent-primary\" />\n        <h1 className=\"text-3xl font-bold text-text-primary\">\n          AI Provider Configuration\n        </h1>\n      </div>\n\n      {/* Main Configuration Card */}\n      <div className=\"bg-surface rounded-lg border border-border-primary p-6 space-y-8\">\n        \n        {/* Provider Selection Section */}\n        <div>\n          <h2 className=\"text-xl font-semibold text-text-primary mb-4\">\n            Select AI Provider\n          </h2>\n          <p className=\"text-text-secondary mb-6\">\n            Choose your preferred AI provider to configure API access.\n          </p>\n          \n          <div className=\"space-y-4\">\n            {/* Google Provider Option */}\n            <label className=\"flex items-center p-4 border border-border-secondary rounded-md hover:bg-surface-hover transition-colors cursor-pointer\">\n              <input\n                type=\"radio\"\n                name=\"provider\"\n                value=\"google\"\n                checked={selectedProvider === 'google'}\n                onChange={handleProviderChange}\n                className=\"w-4 h-4 text-accent-primary bg-surface border-border-interactive focus:ring-accent-primary focus:ring-2 focus:ring-offset-2 focus:ring-offset-surface\"\n              />\n              <div className=\"ml-3\">\n                <div className=\"text-text-primary font-medium\">Google Gemini</div>\n                <div className=\"text-text-tertiary text-sm\">\n                  Access to Google's Gemini models including Flash and Pro versions\n                </div>\n              </div>\n            </label>\n\n            {/* OpenAI Provider Option */}\n            <label className=\"flex items-center p-4 border border-border-secondary rounded-md hover:bg-surface-hover transition-colors cursor-pointer\">\n              <input\n                type=\"radio\"\n                name=\"provider\"\n                value=\"openai\"\n                checked={selectedProvider === 'openai'}\n                onChange={handleProviderChange}\n                className=\"w-4 h-4 text-accent-primary bg-surface border-border-interactive focus:ring-accent-primary focus:ring-2 focus:ring-offset-2 focus:ring-offset-surface\"\n              />\n              <div className=\"ml-3\">\n                <div className=\"text-text-primary font-medium\">OpenAI</div>\n                <div className=\"text-text-tertiary text-sm\">\n                  Access to OpenAI's GPT models including GPT-4 and GPT-3.5\n                </div>\n              </div>\n            </label>\n\n            {/* OpenRouter Provider Option */}\n            <label className=\"flex items-center p-4 border border-border-secondary rounded-md hover:bg-surface-hover transition-colors cursor-pointer\">\n              <input\n                type=\"radio\"\n                name=\"provider\"\n                value=\"openrouter\"\n                checked={selectedProvider === 'openrouter'}\n                onChange={handleProviderChange}\n                className=\"w-4 h-4 text-accent-primary bg-surface border-border-interactive focus:ring-2 focus:ring-accent-primary focus:ring-offset-2 focus:ring-offset-surface\"\n              />\n              <div className=\"ml-3\">\n                <div className=\"text-text-primary font-medium\">OpenRouter</div>\n                <div className=\"text-text-tertiary text-sm\">\n                  Access to multiple models through OpenRouter's unified API\n                </div>\n              </div>\n            </label>\n          </div>\n        </div>\n\n        {/* API Key Configuration Section */}\n        <div>\n          <h2 className=\"text-xl font-semibold text-text-primary mb-4\">\n            API Key Configuration\n          </h2>\n          <p className=\"text-text-secondary mb-6\">\n            Enter your API key for the selected provider to enable AI model access.\n          </p>\n          \n          <div className=\"space-y-4\">\n            {/* API Key Input */}\n            <div>\n              <label htmlFor=\"apiKey\" className=\"block text-sm font-medium text-text-primary mb-2\">\n                API Key\n              </label>\n              <input\n                type=\"password\"\n                id=\"apiKey\"\n                name=\"apiKey\"\n                value={apiKey}\n                onChange={handleApiKeyChange}\n                placeholder=\"Enter your API key...\"\n                className=\"w-full px-4 py-3 bg-surface border border-border-secondary rounded-md text-text-primary placeholder-text-tertiary focus:ring-2 focus:ring-accent-primary focus:border-accent-primary transition-colors\"\n              />\n              <p className=\"mt-2 text-sm text-text-tertiary\">\n                Your API key is stored locally and never sent to our servers.\n              </p>\n            </div>\n\n            {/* Validation Button */}\n            <div className=\"flex justify-start\">\n              <button\n                type=\"button\"\n                onClick={handleValidate}\n                disabled={!apiKey.trim() || validationStatus === 'validating'}\n                className=\"flex items-center space-x-2 px-6 py-2 bg-primary-action text-text-primary font-medium rounded-md hover:bg-primary-hover focus:outline-none focus:ring-2 focus:ring-accent-primary focus:ring-offset-2 focus:ring-offset-surface transition-colors disabled:opacity-50 disabled:cursor-not-allowed\"\n              >\n                {validationStatus === 'validating' && (\n                  <ArrowPathIcon className=\"w-4 h-4 animate-spin\" />\n                )}\n                <span>\n                  {validationStatus === 'validating' ? 'Validating...' : 'Validate API Key'}\n                </span>\n              </button>\n            </div>\n\n            {/* Validation Status Display */}\n            {validationStatus !== 'idle' && (\n              <div className=\"flex items-center space-x-2\">\n                {validationStatus === 'validating' && (\n                  <>\n                    <ArrowPathIcon className=\"w-5 h-5 text-accent-primary animate-spin\" />\n                    <span className=\"text-accent-primary font-medium\">Validating API key...</span>\n                  </>\n                )}\n                {validationStatus === 'valid' && (\n                  <>\n                    <CheckCircleIcon className=\"w-5 h-5 text-green-500\" />\n                    <span className=\"text-green-500 font-medium\">API key is valid</span>\n                    {isLoadingModels && (\n                      <>\n                        <ArrowPathIcon className=\"w-4 h-4 text-accent-primary animate-spin ml-4\" />\n                        <span className=\"text-accent-primary\">Loading models...</span>\n                      </>\n                    )}\n                  </>\n                )}\n                {validationStatus === 'invalid' && (\n                  <>\n                    <XCircleIcon className=\"w-5 h-5 text-red-500\" />\n                    <div className=\"flex flex-col\">\n                      <span className=\"text-red-500 font-medium\">API key validation failed</span>\n                      {validationError && (\n                        <span className=\"text-red-400 text-sm mt-1\">{validationError}</span>\n                      )}\n                    </div>\n                  </>\n                )}\n              </div>\n            )}\n\n            {/* Model Selection Dropdown (UX-01-D) */}\n            {validationStatus === 'valid' && availableModels.length > 0 && (\n              <div>\n                <label htmlFor=\"modelSelect\" className=\"block text-sm font-medium text-text-primary mb-2\">\n                  Select Model\n                </label>\n                <select\n                  id=\"modelSelect\"\n                  name=\"modelSelect\"\n                  value={selectedModel}\n                  onChange={handleModelChange}\n                  disabled={isLoadingModels}\n                  className=\"w-full px-4 py-3 bg-surface border border-border-secondary rounded-md text-text-primary focus:ring-2 focus:ring-accent-primary focus:border-accent-primary transition-colors disabled:opacity-50 disabled:cursor-not-allowed\"\n                >\n                  <option value=\"\">Choose a model...</option>\n                  {availableModels.map((model) => (\n                    <option key={model} value={model}>\n                      {model}\n                    </option>\n                  ))}\n                </select>\n                {selectedModel && (\n                  <p className=\"mt-2 text-sm text-text-tertiary\">\n                    Selected model: <span className=\"font-medium text-text-secondary\">{selectedModel}</span>\n                  </p>\n                )}\n              </div>\n            )}\n          </div>\n        </div>\n\n        {/* Status Messages */}\n        <div className=\"border-t border-border-secondary pt-6\">\n          {validationStatus === 'idle' && (\n            <div className=\"text-sm text-text-tertiary\">\n              Select a provider and enter your API key to begin validation.\n            </div>\n          )}\n          {validationStatus === 'valid' && availableModels.length === 0 && !isLoadingModels && (\n            <div className=\"text-sm text-yellow-600\">\n              API key is valid, but no models could be loaded. You can still proceed with manual model specification.\n            </div>\n          )}\n          {validationStatus === 'valid' && selectedModel && (\n            <div className=\"text-sm text-green-600\">\n              Configuration complete! You're ready to use {selectedProvider} with the {selectedModel} model.\n            </div>\n          )}\n        </div>\n      </div>\n\n      {/* Additional Information Card */}\n      <div className=\"bg-surface rounded-lg border border-border-primary p-6\">\n        <h3 className=\"text-lg font-semibold text-text-primary mb-3\">\n          Getting Started\n        </h3>\n        <div className=\"space-y-3 text-text-secondary\">\n          <p>\n            <strong className=\"text-text-primary\">1. Choose your provider:</strong> Select the AI service you want to use based on your needs and preferences.\n          </p>\n          <p>\n            <strong className=\"text-text-primary\">2. Obtain an API key:</strong> Visit your provider's website to create an account and generate an API key.\n          </p>\n          <p>\n            <strong className=\"text-text-primary\">3. Configure access:</strong> Enter your API key and validate it to ensure proper connectivity.\n          </p>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default ProviderSetupPage;\n",
      "metadata": {
        "filename": "ProviderSetupPage.tsx",
        "path": "/frontend/components/settings/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/config/modelCapabilities.ts\n\n/**\n * @file modelCapabilities.ts\n * @description Comprehensive model capabilities and provider configuration definitions\n * Contains parameter constraints, model information, and provider-specific settings\n */\n\nimport { ProviderConfig, ModelInfo, ParameterPreset, AIProvider } from '../types/aiProvider';\n\n/**\n * Google Gemini models configuration\n */\nconst GEMINI_MODELS: ModelInfo[] = [\n  {\n    id: 'gemini-2.5-flash',\n    name: 'Gemini 2.5 Flash',\n    provider: 'google',\n    description: 'Fast and efficient model for most tasks',\n    contextLength: 1000000,\n    supportedParameters: ['temperature', 'maxTokens', 'topK', 'topP', 'systemInstruction'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 8192, step: 1, default: 1024 },\n      topK: { min: 1, max: 40, step: 1, default: 20 },\n      topP: { min: 0.0, max: 1.0, step: 0.05, default: 0.95 },\n    },\n    pricing: { input: 0.075, output: 0.30 },\n  },\n  {\n    id: 'gemini-1.5-pro',\n    name: 'Gemini 1.5 Pro',\n    provider: 'google',\n    description: 'Advanced model for complex reasoning tasks',\n    contextLength: 2000000,\n    supportedParameters: ['temperature', 'maxTokens', 'topK', 'topP', 'systemInstruction'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 8192, step: 1, default: 1024 },\n      topK: { min: 1, max: 40, step: 1, default: 20 },\n      topP: { min: 0.0, max: 1.0, step: 0.05, default: 0.95 },\n    },\n    pricing: { input: 1.25, output: 5.00 },\n  },\n  {\n    id: 'gemini-1.5-flash',\n    name: 'Gemini 1.5 Flash',\n    provider: 'google',\n    description: 'Balanced speed and performance',\n    contextLength: 1000000,\n    supportedParameters: ['temperature', 'maxTokens', 'topK', 'topP', 'systemInstruction'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 8192, step: 1, default: 1024 },\n      topK: { min: 1, max: 40, step: 1, default: 20 },\n      topP: { min: 0.0, max: 1.0, step: 0.05, default: 0.95 },\n    },\n    pricing: { input: 0.075, output: 0.30 },\n  },\n];\n\n/**\n * OpenAI models configuration\n */\nconst OPENAI_MODELS: ModelInfo[] = [\n  {\n    id: 'gpt-4o',\n    name: 'GPT-4 Omni',\n    provider: 'openai',\n    description: 'Most capable GPT-4 model with multimodal abilities',\n    contextLength: 128000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'presence_penalty', 'frequency_penalty', 'systemMessage'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 4096, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      presence_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n      frequency_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n    },\n    pricing: { input: 2.50, output: 10.00 },\n  },\n  {\n    id: 'gpt-4o-mini',\n    name: 'GPT-4 Omni Mini',\n    provider: 'openai',\n    description: 'Affordable and intelligent small model',\n    contextLength: 128000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'presence_penalty', 'frequency_penalty', 'systemMessage'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 16384, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      presence_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n      frequency_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n    },\n    pricing: { input: 0.15, output: 0.60 },\n  },\n  {\n    id: 'o1-preview',\n    name: 'O1 Preview',\n    provider: 'openai',\n    description: 'Advanced reasoning model for complex tasks',\n    contextLength: 128000,\n    supportedParameters: ['maxTokens'], // O1 models don't support temperature/sampling\n    constraints: {\n      maxTokens: { min: 1, max: 32768, step: 1, default: 1024 },\n    },\n    pricing: { input: 15.00, output: 60.00 },\n  },\n];\n\n/**\n * Anthropic Claude models configuration\n */\nconst ANTHROPIC_MODELS: ModelInfo[] = [\n  {\n    id: 'claude-3-5-sonnet-20241022',\n    name: 'Claude 3.5 Sonnet',\n    provider: 'anthropic',\n    description: 'Most intelligent Claude model',\n    contextLength: 200000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'top_k', 'system'],\n    constraints: {\n      temperature: { min: 0.0, max: 1.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 8192, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      top_k: { min: 0, max: 200, step: 1, default: 200 },\n    },\n    pricing: { input: 3.00, output: 15.00 },\n  },\n  {\n    id: 'claude-3-haiku-20240307',\n    name: 'Claude 3 Haiku',\n    provider: 'anthropic',\n    description: 'Fast and cost-effective model',\n    contextLength: 200000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'top_k', 'system'],\n    constraints: {\n      temperature: { min: 0.0, max: 1.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 4096, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      top_k: { min: 0, max: 200, step: 1, default: 200 },\n    },\n    pricing: { input: 0.25, output: 1.25 },\n  },\n];\n\n/**\n * OpenRouter models configuration (subset of popular models)\n */\nconst OPENROUTER_MODELS: ModelInfo[] = [\n  {\n    id: 'openai/gpt-4o',\n    name: 'GPT-4 Omni (OpenRouter)',\n    provider: 'openrouter',\n    description: 'GPT-4 Omni via OpenRouter',\n    contextLength: 128000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'presence_penalty', 'frequency_penalty'],\n    constraints: {\n      temperature: { min: 0.0, max: 2.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 4096, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      presence_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n      frequency_penalty: { min: -2.0, max: 2.0, step: 0.1, default: 0.0 },\n    },\n    pricing: { input: 2.50, output: 10.00 },\n  },\n  {\n    id: 'anthropic/claude-3.5-sonnet',\n    name: 'Claude 3.5 Sonnet (OpenRouter)',\n    provider: 'openrouter',\n    description: 'Claude 3.5 Sonnet via OpenRouter',\n    contextLength: 200000,\n    supportedParameters: ['temperature', 'maxTokens', 'top_p', 'top_k'],\n    constraints: {\n      temperature: { min: 0.0, max: 1.0, step: 0.1, default: 1.0 },\n      maxTokens: { min: 1, max: 8192, step: 1, default: 1024 },\n      top_p: { min: 0.0, max: 1.0, step: 0.05, default: 1.0 },\n      top_k: { min: 0, max: 200, step: 1, default: 200 },\n    },\n    pricing: { input: 3.00, output: 15.00 },\n  },\n];\n\n/**\n * Provider configurations\n */\nexport const PROVIDER_CONFIGS: Record<AIProvider, ProviderConfig> = {\n  google: {\n    provider: 'google',\n    name: 'Google Gemini',\n    description: 'Google\\'s multimodal AI models',\n    apiKeyRequired: true,\n    models: GEMINI_MODELS,\n    defaultParameters: {\n      temperature: 1.0,\n      maxTokens: 1024,\n      topK: 20,\n      topP: 0.95,\n    },\n    supportedFeatures: ['text', 'multimodal', 'code', 'reasoning'],\n  },\n  openai: {\n    provider: 'openai',\n    name: 'OpenAI',\n    description: 'OpenAI\\'s GPT models',\n    apiKeyRequired: true,\n    models: OPENAI_MODELS,\n    defaultParameters: {\n      temperature: 1.0,\n      maxTokens: 1024,\n      top_p: 1.0,\n      presence_penalty: 0.0,\n      frequency_penalty: 0.0,\n    },\n    supportedFeatures: ['text', 'multimodal', 'code', 'reasoning', 'function-calling'],\n  },\n  anthropic: {\n    provider: 'anthropic',\n    name: 'Anthropic Claude',\n    description: 'Anthropic\\'s Claude models',\n    apiKeyRequired: true,\n    models: ANTHROPIC_MODELS,\n    defaultParameters: {\n      temperature: 1.0,\n      maxTokens: 1024,\n      top_p: 1.0,\n      top_k: 200,\n    },\n    supportedFeatures: ['text', 'reasoning', 'analysis', 'writing'],\n  },\n  openrouter: {\n    provider: 'openrouter',\n    name: 'OpenRouter',\n    description: 'Access to multiple AI models via OpenRouter',\n    apiKeyRequired: true,\n    baseUrl: 'https://openrouter.ai/api/v1',\n    models: OPENROUTER_MODELS,\n    defaultParameters: {\n      temperature: 1.0,\n      maxTokens: 1024,\n      top_p: 1.0,\n    },\n    supportedFeatures: ['text', 'multimodal', 'code', 'reasoning', 'multiple-providers'],\n  },\n};\n\n/**\n * Parameter presets for quick configuration\n */\nexport const PARAMETER_PRESETS: ParameterPreset[] = [\n  {\n    name: 'Creative',\n    description: 'High creativity for writing and brainstorming',\n    provider: 'google',\n    parameters: {\n      temperature: 1.5,\n      topK: 40,\n      topP: 0.9,\n    },\n  },\n  {\n    name: 'Balanced',\n    description: 'Balanced creativity and consistency',\n    provider: 'google',\n    parameters: {\n      temperature: 1.0,\n      topK: 20,\n      topP: 0.95,\n    },\n  },\n  {\n    name: 'Precise',\n    description: 'Low creativity for factual and analytical tasks',\n    provider: 'google',\n    parameters: {\n      temperature: 0.2,\n      topK: 5,\n      topP: 0.8,\n    },\n  },\n  {\n    name: 'Creative (OpenAI)',\n    description: 'High creativity for OpenAI models',\n    provider: 'openai',\n    parameters: {\n      temperature: 1.5,\n      top_p: 0.9,\n      presence_penalty: 0.6,\n      frequency_penalty: 0.3,\n    },\n  },\n  {\n    name: 'Balanced (OpenAI)',\n    description: 'Balanced settings for OpenAI models',\n    provider: 'openai',\n    parameters: {\n      temperature: 1.0,\n      top_p: 1.0,\n      presence_penalty: 0.0,\n      frequency_penalty: 0.0,\n    },\n  },\n  {\n    name: 'Precise (OpenAI)',\n    description: 'Low temperature for factual tasks',\n    provider: 'openai',\n    parameters: {\n      temperature: 0.2,\n      top_p: 0.8,\n      presence_penalty: 0.0,\n      frequency_penalty: 0.1,\n    },\n  },\n];\n\n/**\n * Get model information by ID and provider\n */\nexport function getModelInfo(provider: AIProvider, modelId: string): ModelInfo | undefined {\n  return PROVIDER_CONFIGS[provider].models.find(model => model.id === modelId);\n}\n\n/**\n * Get all models for a provider\n */\nexport function getProviderModels(provider: AIProvider): ModelInfo[] {\n  return PROVIDER_CONFIGS[provider].models;\n}\n\n/**\n * Get parameter constraints for a specific model\n */\nexport function getParameterConstraints(provider: AIProvider, modelId: string) {\n  const model = getModelInfo(provider, modelId);\n  return model?.constraints || {};\n}\n\n/**\n * Get presets for a specific provider\n */\nexport function getProviderPresets(provider: AIProvider): ParameterPreset[] {\n  return PARAMETER_PRESETS.filter(preset => preset.provider === provider);\n}\n\n/**\n * Validate parameters against model constraints\n */\nexport function validateParameters(provider: AIProvider, modelId: string, parameters: any): { valid: boolean; errors: string[] } {\n  const constraints = getParameterConstraints(provider, modelId);\n  const errors: string[] = [];\n\n  Object.entries(parameters).forEach(([key, value]) => {\n    const constraint = constraints[key as keyof typeof constraints];\n    if (constraint && typeof value === 'number') {\n      if (value < constraint.min || value > constraint.max) {\n        errors.push(`${key} must be between ${constraint.min} and ${constraint.max}`);\n      }\n    }\n  });\n\n  return {\n    valid: errors.length === 0,\n    errors,\n  };\n}\n",
      "metadata": {
        "filename": "modelCapabilities.ts",
        "path": "/frontend/config/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/constants.ts\n\n/**\n * @file constants.ts\n * @description This file exports constant values used throughout the frontend application.\n * This includes predefined lists for SFL parameters, initial state objects for prompts and workflows,\n * and other shared constants to ensure consistency and avoid magic strings.\n * \n * @requires ./types\n * @since 0.5.1\n */\n\nimport { SFLField, SFLTenor, SFLMode, PromptSFL } from './types';\n\n/**\n * @constant {string[]} TASK_TYPES\n * @description A predefined list of common task types that can be assigned to an SFL prompt's 'Field'.\n * Used to populate dropdowns in the UI.\n */\nexport const TASK_TYPES = [\n  \"Explanation\", \"Summarization\", \"Code Generation\", \"Creative Writing\", \n  \"Translation\", \"Brainstorming\", \"Question Answering\", \"Data Analysis\", \n  \"Comparison\", \"Instruction\", \"Dialogue Generation\", \"Outline Creation\"\n];\n\n/**\n * @constant {string[]} AI_PERSONAS\n * @description A predefined list of AI personas that can be assigned to an SFL prompt's 'Tenor'.\n * Used to populate dropdowns in the UI.\n */\nexport const AI_PERSONAS = [\n  \"Expert\", \"Friendly Assistant\", \"Sarcastic Bot\", \"Neutral Reporter\", \n  \"Creative Muse\", \"Teacher/Tutor\", \"Devil's Advocate\", \"Philosopher\", \"Historian\"\n];\n\n/**\n * @constant {string[]} TARGET_AUDIENCES\n * @description A predefined list of target audiences for an SFL prompt's 'Tenor'.\n * Used to populate selection options in the UI.\n */\nexport const TARGET_AUDIENCES = [\n  \"General Public\", \"Beginners\", \"Intermediates\", \"Experts\", \"Children (5-7 years)\", \n  \"Teenagers (13-17 years)\", \"Software Developers\", \"Academic Researchers\", \n  \"Business Professionals\", \"Policy Makers\"\n];\n\n/**\n * @constant {string[]} DESIRED_TONES\n * @description A predefined list of desired tones for an SFL prompt's 'Tenor'.\n * Used to populate dropdowns in the UI.\n */\nexport const DESIRED_TONES = [\n  \"Formal\", \"Informal\", \"Humorous\", \"Serious\", \"Empathetic\", \"Concise\", \n  \"Detailed\", \"Persuasive\", \"Objective\", \"Enthusiastic\", \"Critical\", \"Neutral\"\n];\n\n/**\n * @constant {string[]} OUTPUT_FORMATS\n * @description A predefined list of output formats for an SFL prompt's 'Mode'.\n * Used to populate dropdowns in the UI.\n */\nexport const OUTPUT_FORMATS = [\n  \"Plain Text\", \"Markdown\", \"JSON\", \"XML\", \"Python Code\", \"JavaScript Code\", \n  \"HTML\", \"Bullet Points\", \"Numbered List\", \"Poem\", \"Short Story\", \"Email\", \n  \"Report\", \"Spreadsheet (CSV-like)\", \"Slide Presentation Outline\"\n];\n\n/**\n * @constant {string[]} LENGTH_CONSTRAINTS\n * @description A predefined list of length constraints for an SFL prompt's 'Mode'.\n * Used to populate dropdowns in the UI.\n */\nexport const LENGTH_CONSTRAINTS = [\n  \"Single Sentence\", \"Short Paragraph (~50 words)\", \"Medium Paragraph (~150 words)\", \n  \"Long Paragraph (~300 words)\", \"Multiple Paragraphs (~500+ words)\", \n  \"Concise (as needed)\", \"Detailed (as needed)\", \"No Specific Limit\"\n];\n\n/**\n * @constant {string[]} POPULAR_TAGS\n * @description A list of popular tags displayed in the sidebar for quick filtering of prompts.\n */\nexport const POPULAR_TAGS = [\"#summarization\", \"#expert-persona\", \"#python-code\", \"#formal-tone\", \"#technical\", \"#json\"];\n\n/**\n * @constant {SFLField} SFL_EMPTY_FIELD\n * @description Provides a default, empty object for the 'Field' part of an SFL prompt.\n * Ensures that new prompts have a consistent starting structure.\n */\nexport const SFL_EMPTY_FIELD: SFLField = {\n  topic: \"\", taskType: TASK_TYPES[0] || \"\", domainSpecifics: \"\", keywords: \"\"\n};\n\n/**\n * @constant {SFLTenor} SFL_EMPTY_TENOR\n * @description Provides a default, empty object for the 'Tenor' part of an SFL prompt.\n */\nexport const SFL_EMPTY_TENOR: SFLTenor = {\n  aiPersona: AI_PERSONAS[0] || \"\", targetAudience: [], \n  desiredTone: DESIRED_TONES[0] || \"\", interpersonalStance: \"\"\n};\n\n/**\n * @constant {SFLMode} SFL_EMPTY_MODE\n * @description Provides a default, empty object for the 'Mode' part of an SFL prompt.\n */\nexport const SFL_EMPTY_MODE: SFLMode = {\n  outputFormat: OUTPUT_FORMATS[0] || \"\", rhetoricalStructure: \"\", \n  lengthConstraint: LENGTH_CONSTRAINTS[0] || \"\", textualDirectives: \"\"\n};\n\n/**\n * @constant {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>} INITIAL_PROMPT_SFL\n * @description The default state for a new, unsaved SFL prompt. Used to initialize the prompt creation form.\n */\nexport const INITIAL_PROMPT_SFL: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'> = {\n  title: \"\",\n  promptText: \"\",\n  sflField: { ...SFL_EMPTY_FIELD },\n  sflTenor: { ...SFL_EMPTY_TENOR },\n  sflMode: { ...SFL_EMPTY_MODE },\n  exampleOutput: \"\",\n  notes: \"\",\n  sourceDocument: undefined,\n};\n",
      "metadata": {
        "filename": "constants.ts",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/hooks/useProviderValidation.ts\n\n/**\n * @file useProviderValidation.ts\n * @description React hook for managing AI provider validation and routing logic\n * @since 0.6.0\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport {\n  isApplicationReady,\n  checkProviderHealth,\n  type AIProvider,\n  type ProviderHealthResponse,\n} from '../services/providerService';\n\nexport interface UseProviderValidationResult {\n  /** Whether the application is ready (has at least one valid provider) */\n  isReady: boolean;\n  /** Whether we're currently checking provider status */\n  isLoading: boolean;\n  /** Error message if validation failed */\n  error: string | null;\n  /** The preferred provider if available */\n  preferredProvider: AIProvider | null;\n  /** Whether the user needs to configure providers */\n  requiresSetup: boolean;\n  /** Function to manually refresh provider status */\n  refresh: () => Promise<void>;\n  /** Function to check if setup is complete and redirect if necessary */\n  checkSetupComplete: () => Promise<boolean>;\n}\n\n/**\n * Hook for managing AI provider validation and routing logic\n */\nexport function useProviderValidation(): UseProviderValidationResult {\n  const [isReady, setIsReady] = useState<boolean>(false);\n  const [isLoading, setIsLoading] = useState<boolean>(true);\n  const [error, setError] = useState<string | null>(null);\n  const [preferredProvider, setPreferredProvider] = useState<AIProvider | null>(null);\n  const [requiresSetup, setRequiresSetup] = useState<boolean>(true);\n\n  /**\n   * Refresh provider validation status\n   */\n  const refresh = useCallback(async () => {\n    setIsLoading(true);\n    setError(null);\n    \n    try {\n      const health = await checkProviderHealth();\n      \n      setIsReady(health.healthy);\n      setPreferredProvider(health.preferredProvider);\n      setRequiresSetup(health.requiresSetup);\n    } catch (err) {\n      const errorMessage = err instanceof Error ? err.message : 'Unknown error';\n      setError(errorMessage);\n      setIsReady(false);\n      setPreferredProvider(null);\n      setRequiresSetup(true);\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n\n  /**\n   * Check if setup is complete (used for navigation logic)\n   */\n  const checkSetupComplete = useCallback(async (): Promise<boolean> => {\n    try {\n      const ready = await isApplicationReady();\n      if (ready !== isReady) {\n        // Refresh state if it changed\n        await refresh();\n      }\n      return ready;\n    } catch (err) {\n      console.error('Error checking setup completion:', err);\n      return false;\n    }\n  }, [isReady, refresh]);\n\n  // Initial load\n  useEffect(() => {\n    refresh();\n  }, [refresh]);\n\n  return {\n    isReady,\n    isLoading,\n    error,\n    preferredProvider,\n    requiresSetup,\n    refresh,\n    checkSetupComplete,\n  };\n}\n\n/**\n * Hook for checking if providers need setup (lightweight version)\n * This can be used for quick checks without full validation\n */\nexport function useProviderSetupCheck() {\n  const [needsSetup, setNeedsSetup] = useState<boolean | null>(null);\n  const [isChecking, setIsChecking] = useState<boolean>(true);\n\n  const checkSetup = useCallback(async () => {\n    setIsChecking(true);\n    try {\n      const ready = await isApplicationReady();\n      setNeedsSetup(!ready);\n    } catch (err) {\n      console.error('Error checking provider setup:', err);\n      setNeedsSetup(true); // Default to requiring setup on error\n    } finally {\n      setIsChecking(false);\n    }\n  }, []);\n\n  useEffect(() => {\n    checkSetup();\n  }, [checkSetup]);\n\n  return {\n    needsSetup,\n    isChecking,\n    recheckSetup: checkSetup,\n  };\n}\n",
      "metadata": {
        "filename": "useProviderValidation.ts",
        "path": "/frontend/hooks/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/hooks/useWorkflowManager.ts\n\n/**\n * @file useWorkflowManager.ts\n * @description This custom hook manages the state and persistence of workflows.\n * It handles loading default and custom workflows, saving changes to local storage,\n * and providing functions to add, update, and delete custom workflows.\n *\n * @requires react\n * @requires ../types\n * @requires ../constants\n * @since 0.5.1\n */\n\nimport { useState, useEffect, useCallback } from 'react';\nimport { Workflow } from '../types';\n\n/**\n * @constant {string} LOCAL_STORAGE_KEY - The key used to store and retrieve custom workflows from the browser's local storage.\n * @private\n */\nconst LOCAL_STORAGE_KEY = 'sfl-custom-workflows';\n\n/**\n * A custom hook to manage the state of both default and custom workflows.\n * It initializes the state by loading default workflows from constants and custom workflows\n * from local storage. It provides a set of memoized functions to interact with the\n * custom workflows, ensuring that any changes are persisted.\n *\n * @returns {{\n *   workflows: Workflow[];\n *   saveWorkflow: (workflow: Workflow) => void;\n *   deleteWorkflow: (id: string) => void;\n *   isLoading: boolean;\n *   saveCustomWorkflows: (workflows: Workflow[]) => void;\n * }} An object containing the list of all workflows, loading state, and functions to manage them.\n *\n * @example\n * const { workflows, saveWorkflow, deleteWorkflow, isLoading } = useWorkflowManager();\n *\n * if (isLoading) {\n *   return <p>Loading workflows...</p>;\n * }\n *\n * return (\n *   <WorkflowList\n *     workflows={workflows}\n *     onSave={saveWorkflow}\n *     onDelete={deleteWorkflow}\n *   />\n * );\n */\nexport const useWorkflowManager = () => {\n    /**\n     * @state\n     * @description The combined list of default and custom workflows.\n     */\n    const [workflows, setWorkflows] = useState<Workflow[]>([]);\n    \n    /**\n     * @state\n     * @description A boolean flag indicating if the initial load of workflows from local storage is in progress.\n     */\n    const [isLoading, setIsLoading] = useState(true);\n\n    /**\n     * @effect\n     * @description On initial mount, this effect loads the default workflows from JSON file and any custom workflows\n     * saved in local storage. It handles potential parsing errors by clearing the invalid\n     * local storage entry and falling back to just the default workflows.\n     */\n    useEffect(() => {\n        const loadWorkflows = async () => {\n            try {\n                // Load default workflows from JSON file\n                const defaultResponse = await fetch('/default-workflows.json');\n                const defaultWorkflows = await defaultResponse.json();\n                \n                // Load custom workflows from localStorage\n                const savedWorkflowsRaw = localStorage.getItem(LOCAL_STORAGE_KEY);\n                const savedWorkflows = savedWorkflowsRaw ? JSON.parse(savedWorkflowsRaw) : [];\n                \n                if (!Array.isArray(savedWorkflows)) {\n                     throw new Error(\"Invalid data in localStorage\");\n                }\n\n                const defaultWfs = defaultWorkflows.map(wf => ({ ...wf, isDefault: true }));\n                const customWfs = savedWorkflows.map(wf => ({...wf, isDefault: false }));\n\n                setWorkflows([...defaultWfs, ...customWfs]);\n\n            } catch (error) {\n                console.error(\"Failed to load workflows:\", error);\n                // Fallback to empty defaults if JSON load fails\n                setWorkflows([]);\n                localStorage.removeItem(LOCAL_STORAGE_KEY);\n            } finally {\n                setIsLoading(false);\n            }\n        };\n        \n        loadWorkflows();\n    }, []);\n\n    /**\n     * @function\n     * @description Saves an array of custom workflows to local storage and updates the component state.\n     * @param {Workflow[]} customWorkflows - The array of custom workflows to persist.\n     */\n    const saveCustomWorkflows = useCallback((customWorkflows: Workflow[]) => {\n        try {\n            const workflowsToSave = customWorkflows.filter(wf => !wf.isDefault);\n            localStorage.setItem(LOCAL_STORAGE_KEY, JSON.stringify(workflowsToSave));\n            \n            // Update state by combining current default workflows with new custom ones\n            setWorkflows(prevWorkflows => {\n                const defaultWfs = prevWorkflows.filter(wf => wf.isDefault);\n                return [\n                    ...defaultWfs,\n                    ...workflowsToSave.map(wf => ({...wf, isDefault: false}))\n                ];\n            });\n        } catch (error) {\n            console.error(\"Failed to save workflows to localStorage:\", error);\n        }\n    }, []);\n\n    /**\n     * @function\n     * @description Adds a new custom workflow or updates an existing one.\n     * It ensures the `isDefault` flag is set to `false` and then persists the changes.\n     * @param {Workflow} workflowToSave - The workflow object to save.\n     */\n    const saveWorkflow = useCallback((workflowToSave: Workflow) => {\n        setWorkflows(prevWorkflows => {\n            const newWorkflow = { ...workflowToSave, isDefault: false };\n            const existingIndex = prevWorkflows.findIndex(wf => wf.id === newWorkflow.id && !wf.isDefault);\n            \n            let updatedCustomWorkflows;\n            if (existingIndex > -1) {\n                updatedCustomWorkflows = prevWorkflows.filter(wf => !wf.isDefault).map(wf => wf.id === newWorkflow.id ? newWorkflow : wf);\n            } else {\n                updatedCustomWorkflows = [...prevWorkflows.filter(wf => !wf.isDefault), newWorkflow];\n            }\n            \n            saveCustomWorkflows(updatedCustomWorkflows);\n            return [\n                ...prevWorkflows.filter(wf => wf.isDefault),\n                ...updatedCustomWorkflows\n            ];\n        });\n    }, [saveCustomWorkflows]);\n    \n    /**\n     * @function\n     * @description Deletes a custom workflow by its ID. Default workflows cannot be deleted.\n     * @param {string} workflowId - The ID of the custom workflow to delete.\n     */\n    const deleteWorkflow = useCallback((workflowId: string) => {\n        setWorkflows(prevWorkflows => {\n            const updatedCustomWorkflows = prevWorkflows.filter(wf => wf.id !== workflowId && !wf.isDefault);\n            saveCustomWorkflows(updatedCustomWorkflows);\n            return [\n                ...prevWorkflows.filter(wf => wf.isDefault),\n                ...updatedCustomWorkflows\n            ];\n        });\n    }, [saveCustomWorkflows]);\n\n    return { workflows, saveWorkflow, deleteWorkflow, isLoading, saveCustomWorkflows };\n};\n",
      "metadata": {
        "filename": "useWorkflowManager.ts",
        "path": "/frontend/hooks/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/hooks/useWorkflowRunner.ts\n\n/**\n * @file useWorkflowRunner.ts\n * @description This custom hook encapsulates the logic for running a workflow.\n * It manages the state of the workflow execution, including the data store, the status of each task,\n * and whether the workflow is currently running. It provides functions to run and reset the workflow.\n *\n * @requires react\n * @requires ../types\n * @requires ../services/workflowEngine\n */\n\nimport { useState, useCallback, useRef, useEffect } from 'react';\nimport { Workflow, DataStore, TaskStateMap, TaskStatus, Task, PromptSFL, WorkflowExecution } from '../types';\nimport { topologicalSort, executeTask } from '../services/workflowEngine';\n\n/**\n * A custom hook to manage the execution of a workflow.\n * It orchestrates the running of tasks in the correct topological order,\n * manages state transitions for each task, and handles the flow of data\n * through the workflow's `DataStore`.\n *\n * @param {Workflow | null} workflow - The workflow object to be executed. If null, the hook remains idle.\n * @param {PromptSFL[]} prompts - The library of available SFL prompts, used for tasks that reference them.\n * @returns {{\n *   dataStore: DataStore;\n *   taskStates: TaskStateMap;\n *   isRunning: boolean;\n *   run: (stagedUserInput?: Record<string, any>) => Promise<void>;\n *   reset: () => void;\n *   runFeedback: string[];\n * }} An object containing the state of the workflow run and functions to control it.\n *\n * @example\n * const { dataStore, taskStates, isRunning, run, reset } = useWorkflowRunner(myWorkflow, allPrompts);\n *\n * // To run the workflow:\n * <button onClick={() => run({ text: \"Initial user text\" })} disabled={isRunning}>\n *   {isRunning ? 'Running...' : 'Run Workflow'}\n * </button>\n *\n * // To reset the state:\n * <button onClick={reset}>Reset</button>\n *\n * // To display task status:\n * <div>\n *   {myWorkflow.tasks.map(task => (\n *     <p key={task.id}>\n *       {task.name}: {taskStates[task.id]?.status || 'PENDING'}\n *     </p>\n *   ))}\n * </div>\n */\nexport const useWorkflowRunner = (workflow: Workflow | null, prompts: PromptSFL[]) => {\n    /**\n     * @state\n     * @description The central data repository for the workflow run.\n     * It stores the outputs of all completed tasks, keyed by their `outputKey`.\n     */\n    const [dataStore, setDataStore] = useState<DataStore>({});\n    \n    /**\n     * @state\n     * @description A map from task IDs to their current execution state, including status, results, and errors.\n     */\n    const [taskStates, setTaskStates] = useState<TaskStateMap>({});\n    \n    /**\n     * @state\n     * @description A boolean flag indicating whether the workflow is currently executing.\n     */\n    const [isRunning, setIsRunning] = useState(false);\n    \n    /**\n     * @state\n     * @description An array of feedback messages generated during the workflow run, such as warnings about dependencies.\n     */\n    const [runFeedback, setRunFeedback] = useState<string[]>([]);\n\n    /**\n     * @state\n     * @description Current workflow execution information when running asynchronously\n     */\n    const [currentExecution, setCurrentExecution] = useState<WorkflowExecution | null>(null);\n\n    /**\n     * @state\n     * @description Execution mode - 'local' for client-side execution, 'async' for server-side async execution\n     */\n    const [executionMode, setExecutionMode] = useState<'local' | 'async'>('local');\n\n    /**\n     * @ref\n     * @description WebSocket connection for real-time updates\n     */\n    const wsRef = useRef<WebSocket | null>(null);\n\n    /**\n     * @ref\n     * @description Cancellation token for stopping workflow execution\n     */\n    const cancellationRef = useRef<{ cancelled: boolean }>({ cancelled: false });\n\n    /**\n     * @function\n     * @description Connects to WebSocket for real-time updates\n     */\n    const connectWebSocket = useCallback((jobId: string) => {\n        if (wsRef.current?.readyState === WebSocket.OPEN) {\n            wsRef.current.close();\n        }\n\n        const wsUrl = `ws://localhost:4000/ws`;\n        wsRef.current = new WebSocket(wsUrl);\n\n        wsRef.current.onopen = () => {\n            console.log('WebSocket connected');\n            // Subscribe to job updates\n            wsRef.current?.send(JSON.stringify({\n                type: 'subscribe',\n                jobId: jobId\n            }));\n        };\n\n        wsRef.current.onmessage = (event) => {\n            try {\n                const message = JSON.parse(event.data);\n                handleWebSocketMessage(message);\n            } catch (error) {\n                console.error('Failed to parse WebSocket message:', error);\n            }\n        };\n\n        wsRef.current.onclose = () => {\n            console.log('WebSocket disconnected');\n        };\n\n        wsRef.current.onerror = (error) => {\n            console.error('WebSocket error:', error);\n        };\n    }, []);\n\n    /**\n     * @function\n     * @description Handles incoming WebSocket messages\n     */\n    const handleWebSocketMessage = useCallback((message: any) => {\n        switch (message.type) {\n            case 'workflow_progress':\n                if (message.status === 'running') {\n                    setIsRunning(true);\n                }\n                break;\n            \n            case 'task_status':\n                if (message.taskId) {\n                    setTaskStates(prev => ({\n                        ...prev,\n                        [message.taskId]: {\n                            status: message.status === 'active' ? TaskStatus.RUNNING :\n                                   message.status === 'completed' ? TaskStatus.COMPLETED :\n                                   message.status === 'failed' ? TaskStatus.FAILED :\n                                   TaskStatus.PENDING,\n                            result: message.result,\n                            error: message.error,\n                            startTime: message.status === 'active' ? Date.now() : prev[message.taskId]?.startTime,\n                            endTime: message.status === 'completed' || message.status === 'failed' ? Date.now() : undefined,\n                        }\n                    }));\n\n                    // Update data store if task completed\n                    if (message.status === 'completed' && message.result !== undefined) {\n                        setDataStore(prev => {\n                            const task = workflow?.tasks.find(t => t.id === message.taskId);\n                            if (task) {\n                                return { ...prev, [task.outputKey]: message.result };\n                            }\n                            return prev;\n                        });\n                    }\n                }\n                break;\n            \n            case 'workflow_complete':\n                setIsRunning(false);\n                if (message.result?.dataStore) {\n                    setDataStore(message.result.dataStore);\n                }\n                break;\n            \n            case 'workflow_failed':\n                setIsRunning(false);\n                setRunFeedback(prev => [...prev, `Workflow failed: ${message.error}`]);\n                break;\n            \n            case 'workflow_stopped':\n                setIsRunning(false);\n                setRunFeedback(prev => [...prev, `Workflow stopped: ${message.reason || 'User cancelled'}`]);\n                break;\n        }\n    }, [workflow]);\n\n    /**\n     * @function\n     * @description Disconnects WebSocket\n     */\n    const disconnectWebSocket = useCallback(() => {\n        if (wsRef.current) {\n            wsRef.current.close();\n            wsRef.current = null;\n        }\n    }, []);\n\n    /**\n     * @function\n     * @description Cleanup WebSocket on unmount\n     */\n    useEffect(() => {\n        return () => {\n            disconnectWebSocket();\n        };\n    }, [disconnectWebSocket]);\n    \n    /**\n     * @function\n     * @description Initializes or resets the state of all tasks in the workflow to PENDING.\n     * Also clears the data store and any run feedback.\n     * @param {Task[]} tasks - The array of tasks from the current workflow.\n     */\n    const initializeStates = useCallback((tasks: Task[]) => {\n        const initialStates: TaskStateMap = {};\n        for (const task of tasks) {\n            initialStates[task.id] = { status: TaskStatus.PENDING };\n        }\n        setTaskStates(initialStates);\n        setDataStore({});\n        setRunFeedback([]);\n    }, []);\n\n    /**\n     * @function\n     * @description Stops the currently running workflow execution\n     */\n    const stop = useCallback(async () => {\n        if (!isRunning) return;\n        \n        // Set cancellation flag for local execution\n        cancellationRef.current.cancelled = true;\n        \n        // For async execution, send stop request to backend\n        if (executionMode === 'async' && currentExecution?.jobId) {\n            try {\n                await fetch(`/api/workflows/stop/${currentExecution.jobId}`, {\n                    method: 'POST',\n                });\n            } catch (error) {\n                console.error('Failed to send stop request:', error);\n                setRunFeedback(prev => [...prev, 'Failed to send stop request to server']);\n            }\n        }\n        \n        // Update UI state immediately for better user experience\n        setIsRunning(false);\n        setRunFeedback(prev => [...prev, 'Stop requested...']);\n    }, [isRunning, executionMode, currentExecution]);\n\n    /**\n     * @function\n     * @description Resets the entire workflow execution state, setting all tasks to PENDING\n     * and clearing the data store.\n     */\n    const reset = useCallback(() => {\n        // Reset cancellation flag\n        cancellationRef.current.cancelled = false;\n        \n        disconnectWebSocket();\n        setCurrentExecution(null);\n        \n        if (workflow) {\n            initializeStates(workflow.tasks);\n        } else {\n            setTaskStates({});\n            setDataStore({});\n        }\n        setIsRunning(false);\n    }, [workflow, initializeStates, disconnectWebSocket]);\n\n    /**\n     * @function\n     * @description Executes workflow asynchronously on the server\n     */\n    const runAsync = useCallback(async (stagedUserInput: Record<string, any> = {}) => {\n        if (!workflow) {\n            setRunFeedback(['No workflow selected.']);\n            return;\n        }\n\n        try {\n            setIsRunning(true);\n            initializeStates(workflow.tasks);\n\n            // Send workflow to backend for async execution\n            const response = await fetch('/api/workflows/execute', {\n                method: 'POST',\n                headers: {\n                    'Content-Type': 'application/json',\n                },\n                body: JSON.stringify({\n                    workflow,\n                    userInput: stagedUserInput,\n                }),\n            });\n\n            if (!response.ok) {\n                throw new Error(`HTTP error! status: ${response.status}`);\n            }\n\n            const result = await response.json();\n            \n            if (result.jobId) {\n                // Connect to WebSocket for real-time updates\n                connectWebSocket(result.jobId);\n                \n                setCurrentExecution({\n                    id: result.jobId,\n                    workflowId: workflow.id,\n                    jobId: result.jobId,\n                    status: 'pending',\n                    createdAt: new Date().toISOString(),\n                    updatedAt: new Date().toISOString(),\n                });\n            }\n\n        } catch (error: any) {\n            console.error('Failed to start async workflow execution:', error);\n            setRunFeedback([`Failed to start execution: ${error.message}`]);\n            setIsRunning(false);\n        }\n    }, [workflow, initializeStates, connectWebSocket]);\n\n    /**\n     * @function\n     * @description Starts the execution of the workflow.\n     * It performs a topological sort of the tasks, then executes them sequentially,\n     * updating the task states and data store as it progresses.\n     * @param {Record<string, any>} [stagedUserInput={}] - The initial input data provided by the user,\n     * which is placed in `dataStore.userInput`.\n     * @returns {Promise<void>} A promise that resolves when the workflow has finished running (either completed or failed).\n     */\n    const run = useCallback(async (stagedUserInput: Record<string, any> = {}) => {\n        if (executionMode === 'async') {\n            return runAsync(stagedUserInput);\n        }\n\n        // Local execution (original logic)\n        if (!workflow) {\n            setRunFeedback(['No workflow selected.']);\n            return;\n        }\n        \n        // Reset cancellation flag and start execution\n        cancellationRef.current.cancelled = false;\n        setIsRunning(true);\n        initializeStates(workflow.tasks);\n\n        const { sortedTasks, feedback } = topologicalSort(workflow.tasks);\n        setRunFeedback(feedback);\n\n        if (feedback.some(f => f.includes('Cycle detected'))) {\n            setIsRunning(false);\n            return;\n        }\n        \n        const initialDataStore: DataStore = { userInput: stagedUserInput };\n        setDataStore(initialDataStore);\n\n        for (const task of sortedTasks) {\n            // Check for cancellation before processing each task\n            if (cancellationRef.current.cancelled) {\n                setTaskStates(prev => ({...prev, [task.id]: { status: TaskStatus.SKIPPED, error: 'Workflow cancelled by user.' }}));\n                setRunFeedback(prev => [...prev, 'Workflow execution cancelled by user']);\n                setIsRunning(false);\n                return;\n            }\n\n            const hasSkippedDependency = task.dependencies.some(depId => taskStates[depId]?.status === TaskStatus.FAILED || taskStates[depId]?.status === TaskStatus.SKIPPED);\n            \n            if (hasSkippedDependency) {\n                setTaskStates(prev => ({...prev, [task.id]: { status: TaskStatus.SKIPPED, error: 'Skipped due to dependency failure.' }}));\n                continue;\n            }\n\n            setTaskStates(prev => ({...prev, [task.id]: { status: TaskStatus.RUNNING, startTime: Date.now() }}));\n            \n            try {\n                const currentDataStore = await new Promise<DataStore>(resolve => setDataStore(current => { resolve(current); return current; }));\n                const result = await executeTask(task, currentDataStore, prompts);\n\n                // Check for cancellation after task execution\n                if (cancellationRef.current.cancelled) {\n                    setTaskStates(prev => ({...prev, [task.id]: { status: TaskStatus.SKIPPED, error: 'Workflow cancelled by user.', endTime: Date.now() }}));\n                    setRunFeedback(prev => [...prev, 'Workflow execution cancelled by user']);\n                    setIsRunning(false);\n                    return;\n                }\n\n                setDataStore(prev => ({ ...prev, [task.outputKey]: result }));\n                setTaskStates(prev => ({\n                    ...prev, \n                    [task.id]: { ...prev[task.id], status: TaskStatus.COMPLETED, result, endTime: Date.now() }\n                }));\n\n            } catch (error: any) {\n                console.error(`Error executing task ${task.name}:`, error);\n                setTaskStates(prev => ({\n                    ...prev,\n                    [task.id]: { ...prev[task.id], status: TaskStatus.FAILED, error: error.message, endTime: Date.now() }\n                }));\n            }\n        }\n        \n        setIsRunning(false);\n\n    }, [workflow, initializeStates, taskStates, prompts, executionMode, runAsync]);\n\n    return { \n        dataStore, \n        taskStates, \n        isRunning, \n        run, \n        stop, \n        reset, \n        runFeedback,\n        currentExecution,\n        executionMode,\n        setExecutionMode,\n    };\n};\n",
      "metadata": {
        "filename": "useWorkflowRunner.ts",
        "path": "/frontend/hooks/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/index.html\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>SFL Prompt Knowledge Base</title>\n  <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n  <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\">\n<script type=\"importmap\">\n{\n  \"imports\": {\n    \"react-dom/\": \"https://esm.sh/react-dom@^19.1.0/\",\n    \"react/\": \"https://esm.sh/react@^19.1.0/\",\n    \"react\": \"https://esm.sh/react@^19.1.0\",\n    \"recharts\": \"https://esm.sh/recharts@^2.12.7\"\n  }\n}\n</script>\n</head>\n<body class=\"bg-[#212934] text-gray-200 antialiased\">\n  <div id=\"root\"></div>\n  <script type=\"module\" src=\"/index.tsx\"></script>\n</body>\n</html>\n",
      "metadata": {
        "filename": "index.html",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/index.tsx\n\n/**\n * @file index.tsx\n * @description This is the main entry point for the SFL Prompt Studio React application.\n * It identifies the root DOM element in the `index.html` file and uses `ReactDOM.createRoot`\n * to render the main `App` component into it. The application is wrapped in `React.StrictMode`\n * to enable additional checks and warnings during development.\n *\n * @requires react\n * @requires react-dom/client\n * @requires ./App\n */\n\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\n\n/**\n * The root DOM element where the React application will be mounted.\n * @constant {HTMLElement}\n */\nconst rootElement = document.getElementById('root');\n\n// Ensure the root element exists before attempting to render the application.\nif (!rootElement) {\n  throw new Error(\"Fatal Error: Could not find the root element with ID 'root' in the DOM. The application cannot be mounted.\");\n}\n\n/**\n * The root instance for the React application, created using the concurrent rendering API.\n * @constant {ReactDOM.Root}\n */\nconst root = ReactDOM.createRoot(rootElement);\n\n// Render the top-level App component into the root.\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n",
      "metadata": {
        "filename": "index.tsx",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/postcss.config.js\n\n/** @type {import('postcss').ProcessOptions} */\nexport default {\n  plugins: {\n    tailwindcss: {},\n    autoprefixer: {},\n  },\n}\n",
      "metadata": {
        "filename": "postcss.config.js",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/aiService.ts\n\n/**\n * @file aiService.ts\n * @description Multi-provider AI service for API key validation and model listing.\n * Supports Google Gemini, OpenAI, and OpenAI-compatible providers like OpenRouter.\n * Uses direct HTTP calls to avoid dependency issues.\n */\n\n/**\n * Supported AI providers for the multi-provider service\n */\nexport type AIProvider = 'google' | 'openai' | 'openrouter';\n\n/**\n * Configuration options for AI providers\n */\nexport interface AIProviderOptions {\n  baseURL?: string;\n}\n\n/**\n * Result of API key validation\n */\nexport interface APIKeyValidationResult {\n  success: boolean;\n}\n\n/**\n * Validates an API key by making a simple request to the provider's API\n * @param provider - The AI provider to validate against\n * @param apiKey - The API key to validate\n * @param options - Optional configuration (e.g., custom baseURL)\n * @returns Promise resolving to validation result\n * @throws Error with descriptive message if validation fails\n */\nexport async function validateApiKey(\n  provider: AIProvider,\n  apiKey: string,\n  options?: AIProviderOptions\n): Promise<APIKeyValidationResult> {\n  if (!apiKey || apiKey.trim().length === 0) {\n    throw new Error('API key cannot be empty');\n  }\n\n  try {\n    switch (provider) {\n      case 'google': {\n        const response = await fetch('https://generativelanguage.googleapis.com/v1beta/models', {\n          method: 'GET',\n          headers: {\n            'x-goog-api-key': apiKey,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid Google API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('Google API key does not have permission to access Generative AI models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for Google API. Please try again later.');\n          } else {\n            throw new Error(`Google API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        return { success: true };\n      }\n\n      case 'openai': {\n        const baseURL = options?.baseURL || 'https://api.openai.com';\n        const response = await fetch(`${baseURL}/v1/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid OpenAI API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('OpenAI API key does not have permission to access models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for OpenAI API. Please try again later.');\n          } else {\n            throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        return { success: true };\n      }\n\n      case 'openrouter': {\n        const baseURL = options?.baseURL || 'https://openrouter.ai';\n        const response = await fetch(`${baseURL}/api/v1/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'HTTP-Referer': window.location.origin,\n            'X-Title': 'SFL Prompt Studio',\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid OpenRouter API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('OpenRouter API key does not have permission to access models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for OpenRouter API. Please try again later.');\n          } else {\n            throw new Error(`OpenRouter API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        return { success: true };\n      }\n\n      default: {\n        throw new Error(`Unsupported provider: ${provider}`);\n      }\n    }\n  } catch (error) {\n    if (error instanceof Error) {\n      throw error;\n    } else {\n      throw new Error(`Network error validating ${provider} API key: ${String(error)}`);\n    }\n  }\n}\n\n/**\n * Lists available models for a given provider\n * @param provider - The AI provider\n * @param apiKey - The API key for the provider\n * @param options - Optional configuration (e.g., custom baseURL)\n * @returns Promise resolving to array of model IDs\n * @throws Error if the request fails\n */\nexport async function listModels(\n  provider: AIProvider,\n  apiKey: string,\n  options?: AIProviderOptions\n): Promise<string[]> {\n  if (!apiKey || apiKey.trim().length === 0) {\n    throw new Error('API key cannot be empty');\n  }\n\n  try {\n    switch (provider) {\n      case 'google': {\n        const response = await fetch('https://generativelanguage.googleapis.com/v1beta/models', {\n          method: 'GET',\n          headers: {\n            'x-goog-api-key': apiKey,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid Google API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('Google API key does not have permission to access Generative AI models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for Google API. Please try again later.');\n          } else {\n            throw new Error(`Google API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        const data = await response.json();\n        const models = data.models\n          ?.filter((model: any) => \n            model.supportedGenerationMethods?.includes('generateContent') && \n            model.name?.includes('gemini')\n          )\n          .map((model: any) => model.name?.replace('models/', '') || model.name)\n          .sort() || [];\n\n        return models;\n      }\n\n      case 'openai': {\n        const baseURL = options?.baseURL || 'https://api.openai.com';\n        const response = await fetch(`${baseURL}/v1/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid OpenAI API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('OpenAI API key does not have permission to access models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for OpenAI API. Please try again later.');\n          } else {\n            throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        const data = await response.json();\n        const models = data.data\n          ?.filter((model: any) => \n            (model.id?.startsWith('gpt-') || model.id?.startsWith('o1-')) &&\n            !model.id?.includes('embedding') &&\n            !model.id?.includes('whisper') &&\n            !model.id?.includes('tts') &&\n            !model.id?.includes('dall-e')\n          )\n          .map((model: any) => model.id)\n          .sort() || [];\n\n        return models;\n      }\n\n      case 'openrouter': {\n        const baseURL = options?.baseURL || 'https://openrouter.ai';\n        const response = await fetch(`${baseURL}/api/v1/models`, {\n          method: 'GET',\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'HTTP-Referer': window.location.origin,\n            'X-Title': 'SFL Prompt Studio',\n            'Content-Type': 'application/json',\n          },\n        });\n\n        if (!response.ok) {\n          if (response.status === 401) {\n            throw new Error('Invalid OpenRouter API key. Please check your key and try again.');\n          } else if (response.status === 403) {\n            throw new Error('OpenRouter API key does not have permission to access models.');\n          } else if (response.status === 429) {\n            throw new Error('Rate limit exceeded for OpenRouter API. Please try again later.');\n          } else {\n            throw new Error(`OpenRouter API error: ${response.status} ${response.statusText}`);\n          }\n        }\n\n        const data = await response.json();\n        const models = data.data\n          ?.map((model: any) => model.id)\n          .sort() || [];\n\n        return models;\n      }\n\n      default: {\n        throw new Error(`Unsupported provider: ${provider}`);\n      }\n    }\n  } catch (error) {\n    if (error instanceof Error) {\n      throw error;\n    } else {\n      throw new Error(`Network error fetching models for ${provider}: ${String(error)}`);\n    }\n  }\n}\n",
      "metadata": {
        "filename": "aiService.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/geminiService.ts\n\n/**\n * @file geminiService.ts\n * @description This service module provides functions for interacting with the backend's Gemini API endpoints.\n * It handles tasks such as testing prompts, generating SFL structures from goals, and regenerating prompts based on feedback.\n *\n * @requires ../types\n */\n\nimport { PromptSFL, Workflow } from '../types';\n\n/**\n * @constant {string} API_BASE_URL - The base URL for the Gemini API endpoints.\n * @private\n */\nconst API_BASE_URL = '/api/gemini';\n\n/**\n * Sends a prompt to the Gemini API for testing.\n * This function communicates with the backend, which in turn calls the actual Gemini API.\n *\n * @param {string} promptText - The raw text of the prompt to be tested.\n * @returns {Promise<string>} A promise that resolves to the text response from the Gemini model.\n * @throws {Error} Throws an error if the API response is not ok, containing a message from the server.\n *\n * @example\n * try {\n *   const response = await testPromptWithGemini(\"Explain quantum computing in simple terms.\");\n *   console.log(response);\n * } catch (error) {\n *   console.error(\"Test failed:\", error.message);\n * }\n */\nexport const testPromptWithGemini = async (promptText: string): Promise<string> => {\n  const response = await fetch(`${API_BASE_URL}/test-prompt`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ promptText }),\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(errorData.message || 'Failed to test prompt');\n  }\n  const data = await response.json();\n  return data.text;\n};\n\n/**\n * Generates a complete SFL (Systemic Functional Linguistics) prompt structure from a high-level user goal.\n * This is used for the \"Prompt Wizard\" feature.\n *\n * @param {string} goal - A natural language string describing what the user wants the prompt to achieve.\n * @param {string} [sourceDocContent] - Optional content from a source document to provide stylistic or contextual reference.\n * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise that resolves to the generated SFL prompt object,\n * ready to be saved or further edited.\n * @throws {Error} Throws an error if the API response is not ok.\n *\n * @example\n * const goal = \"Create a Python function to sort a list of numbers.\";\n * const newPrompt = await generateSFLFromGoal(goal);\n * // newPrompt can now be used to populate the prompt editor form.\n */\nexport const generateSFLFromGoal = async (goal: string, sourceDocContent?: string): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> => {\n  console.log(`Making request to: ${API_BASE_URL}/generate-sfl`);\n  console.log('Request payload:', { goal, sourceDocContent: sourceDocContent ? '[provided]' : undefined });\n  \n  const response = await fetch(`${API_BASE_URL}/generate-sfl`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ goal, sourceDocContent }),\n  });\n\n  console.log('Response status:', response.status);\n  console.log('Response headers:', [...response.headers.entries()]);\n\n  if (!response.ok) {\n    const responseText = await response.text();\n    console.error('Error response text:', responseText.substring(0, 500));\n    \n    // Try to parse as JSON, but fallback to text message\n    try {\n      const errorData = JSON.parse(responseText);\n      throw new Error(errorData.message || 'Failed to generate SFL from goal');\n    } catch (parseError) {\n      // Response is not JSON, likely HTML error page\n      if (responseText.includes('<html>')) {\n        throw new Error('Server returned HTML instead of JSON. Check if backend server is running and proxy is configured correctly.');\n      }\n      throw new Error(`Server error: ${response.status} ${response.statusText}`);\n    }\n  }\n  \n  const responseText = await response.text();\n  console.log('Success response text:', responseText.substring(0, 200));\n  \n  try {\n    return JSON.parse(responseText);\n  } catch (parseError) {\n    console.error('Failed to parse success response as JSON:', parseError);\n    throw new Error('Server returned invalid JSON response');\n  }\n};\n\n/**\n * Takes an existing SFL prompt and a user's suggestion to regenerate and improve it.\n * The backend uses an AI model to interpret the suggestion and modify the SFL fields accordingly.\n *\n * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>} currentPrompt - The current state of the prompt to be improved.\n * @param {string} suggestion - A natural language string with instructions for improvement (e.g., \"make it more formal\").\n * @returns {Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>>} A promise that resolves to the newly regenerated SFL prompt object.\n * @throws {Error} Throws an error if the API response is not ok.\n *\n * @example\n * const suggestion = \"Change the target audience to experts in the field.\";\n * const refinedPrompt = await regenerateSFLFromSuggestion(existingPrompt, suggestion);\n * // refinedPrompt contains the AI-modified SFL structure.\n */\nexport const regenerateSFLFromSuggestion = async (\n  currentPrompt: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt' | 'geminiResponse' | 'geminiTestError' | 'isTesting'>,\n  suggestion: string\n): Promise<Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'>> => {\n  const response = await fetch(`${API_BASE_URL}/regenerate-sfl`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ currentPrompt, suggestion }),\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(errorData.message || 'Failed to regenerate SFL from suggestion');\n  }\n  return response.json();\n};\n\n/**\n * Generates a structured workflow object from a high-level user goal.\n * This is used for the \"Workflow Wizard\" feature.\n *\n * @param {string} goal - A natural language string describing the multi-step process the user wants to automate.\n * @returns {Promise<Workflow>} A promise that resolves to the generated `Workflow` object, including its tasks.\n * @throws {Error} Throws an error if the API response is not ok.\n *\n * @example\n * const goal = \"Summarize an article and then translate the summary to French.\";\n * const newWorkflow = await generateWorkflowFromGoal(goal);\n * // newWorkflow can now be saved or opened in the workflow editor.\n */\nexport const generateWorkflowFromGoal = async (goal: string): Promise<Workflow> => {\n  const response = await fetch(`${API_BASE_URL}/generate-workflow`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ goal }),\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(errorData.message || 'Failed to generate workflow from goal');\n  }\n  return response.json();\n};\n",
      "metadata": {
        "filename": "geminiService.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/promptApiService.ts\n\n/**\n * @file promptApiService.ts\n * @description This service module handles all CRUD (Create, Read, Update, Delete) operations\n * for SFL prompts by communicating with the backend API.\n *\n * @requires ../types\n */\n\nimport { PromptSFL } from '../types';\n\n/**\n * @constant {string} API_BASE_URL - The base URL for the prompt-related API endpoints.\n * It's a relative URL to leverage the Vite proxy during development.\n * @private\n */\nconst API_BASE_URL = '/api';\n\n/**\n * Fetches all SFL prompts from the backend API.\n *\n * @returns {Promise<PromptSFL[]>} A promise that resolves to an array of all prompts.\n * @throws {Error} Throws an error if the network request fails or the server returns a non-ok response.\n *\n * @example\n * async function loadPrompts() {\n *   try {\n *     const prompts = await getPrompts();\n *     setPrompts(prompts);\n *   } catch (error) {\n *     console.error(error.message);\n *   }\n * }\n */\nexport const getPrompts = async (): Promise<PromptSFL[]> => {\n  const response = await fetch(`${API_BASE_URL}/prompts`);\n  if (!response.ok) {\n    throw new Error('Failed to fetch prompts');\n  }\n  return response.json();\n};\n\n/**\n * Saves a new prompt or updates an existing one on the backend.\n * It intelligently determines whether to use a POST (create) or PUT (update) request\n * based on the presence of an `id` property in the provided prompt object.\n *\n * @param {Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'> | PromptSFL} prompt - The prompt object to save.\n * If it has an `id`, it will be an update; otherwise, it's a creation.\n * @returns {Promise<PromptSFL>} A promise that resolves to the saved prompt object, including any fields\n * generated by the backend (like `id`, `createdAt`, `updatedAt`).\n * @throws {Error} Throws an error if the network request fails or the API returns an error message.\n *\n * @example\n * // To create a new prompt:\n * const newPrompt = { title: \"New\", promptText: \"...\" };\n * const savedPrompt = await savePrompt(newPrompt);\n *\n * // To update an existing prompt:\n * const updatedPrompt = { ...existingPrompt, title: \"Updated Title\" };\n * const result = await savePrompt(updatedPrompt);\n */\nexport const savePrompt = async (prompt: Omit<PromptSFL, 'id' | 'createdAt' | 'updatedAt'> | PromptSFL): Promise<PromptSFL> => {\n  const isEditing = 'id' in prompt;\n  const url = isEditing ? `${API_BASE_URL}/prompts/${prompt.id}` : `${API_BASE_URL}/prompts`;\n  const method = isEditing ? 'PUT' : 'POST';\n\n  const response = await fetch(url, {\n    method,\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify(prompt),\n  });\n\n  if (!response.ok) {\n    const errorData = await response.json();\n    throw new Error(errorData.message || `Failed to ${isEditing ? 'update' : 'create'} prompt`);\n  }\n  return response.json();\n};\n\n/**\n * Deletes a prompt from the backend using its unique ID.\n *\n * @param {string} id - The ID of the prompt to be deleted.\n * @returns {Promise<void>} A promise that resolves when the deletion is successful.\n * @throws {Error} Throws an error if the network request fails or the server indicates the deletion was unsuccessful.\n *\n * @example\n * try {\n *   await deletePrompt('some-prompt-id');\n *   // Remove the prompt from the local state\n * } catch (error) {\n *   console.error(error.message);\n * }\n */\nexport const deletePrompt = async (id: string): Promise<void> => {\n  const response = await fetch(`${API_BASE_URL}/prompts/${id}`, {\n    method: 'DELETE',\n  });\n\n  // A 204 No Content response is also a success case for DELETE.\n  if (!response.ok && response.status !== 204) {\n    throw new Error('Failed to delete prompt');\n  }\n};\n",
      "metadata": {
        "filename": "promptApiService.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/providerConfigService.ts\n\n/**\n * @file providerConfigService.ts\n * @description This service manages AI provider configuration, including provider selection,\n * API key management, parameter persistence, and provider status tracking.\n * It provides a centralized way to manage dynamic provider switching across the application.\n *\n * @requires ../types/aiProvider\n * @requires ../config/modelCapabilities\n */\n\nimport { \n  AIProvider, \n  ActiveProviderConfig, \n  ProviderStatus, \n  ModelParameters \n} from '../types/aiProvider';\nimport { PROVIDER_CONFIGS, validateParameters } from '../config/modelCapabilities';\n\n/**\n * Event types for provider configuration changes\n */\nexport type ProviderConfigEvent = 'provider-changed' | 'parameters-changed' | 'status-updated';\n\n/**\n * Event listener callback type\n */\nexport type ConfigEventListener = (config: ActiveProviderConfig) => void;\n\n/**\n * Storage keys for localStorage persistence\n */\nconst STORAGE_KEYS = {\n  CURRENT_PROVIDER: 'sfl-current-provider',\n  CURRENT_MODEL: 'sfl-current-model',\n  PROVIDER_PARAMETERS: 'sfl-provider-parameters',\n  API_KEY_PREFIX: 'sfl-api-key-',\n  PROVIDER_STATUS: 'sfl-provider-status'\n} as const;\n\n/**\n * Default configuration values\n */\nconst DEFAULT_CONFIG: ActiveProviderConfig = {\n  provider: 'google',\n  model: 'gemini-2.5-flash',\n  parameters: PROVIDER_CONFIGS.google.defaultParameters,\n  apiKey: ''\n};\n\n/**\n * Service class for managing AI provider configuration\n */\nclass ProviderConfigService {\n  private currentConfig: ActiveProviderConfig;\n  private eventListeners: Map<ProviderConfigEvent, Set<ConfigEventListener>>;\n  private providerStatuses: Map<AIProvider, ProviderStatus>;\n\n  constructor() {\n    this.currentConfig = this.loadConfiguration();\n    this.eventListeners = new Map();\n    this.providerStatuses = new Map();\n    \n    // Initialize event listener sets\n    this.eventListeners.set('provider-changed', new Set());\n    this.eventListeners.set('parameters-changed', new Set());\n    this.eventListeners.set('status-updated', new Set());\n    \n    // Load provider statuses\n    this.initializeProviderStatuses();\n  }\n\n  /**\n   * Get the current active provider configuration\n   */\n  getCurrentConfig(): ActiveProviderConfig {\n    return { ...this.currentConfig };\n  }\n\n  /**\n   * Set the active provider\n   */\n  setProvider(provider: AIProvider): void {\n    const providerConfig = PROVIDER_CONFIGS[provider];\n    const firstModel = providerConfig.models[0];\n    \n    this.currentConfig = {\n      ...this.currentConfig,\n      provider,\n      model: firstModel.id,\n      parameters: providerConfig.defaultParameters,\n      apiKey: this.getApiKey(provider),\n      baseUrl: providerConfig.baseUrl\n    };\n    \n    this.saveConfiguration();\n    this.emit('provider-changed', this.currentConfig);\n  }\n\n  /**\n   * Set the active model for the current provider\n   */\n  setModel(modelId: string): void {\n    const providerConfig = PROVIDER_CONFIGS[this.currentConfig.provider];\n    const model = providerConfig.models.find(m => m.id === modelId);\n    \n    if (!model) {\n      throw new Error(`Model ${modelId} not found for provider ${this.currentConfig.provider}`);\n    }\n    \n    this.currentConfig = {\n      ...this.currentConfig,\n      model: modelId,\n      parameters: providerConfig.defaultParameters\n    };\n    \n    this.saveConfiguration();\n    this.emit('provider-changed', this.currentConfig);\n  }\n\n  /**\n   * Update model parameters\n   */\n  setParameters(parameters: ModelParameters): void {\n    // Validate parameters\n    const validation = validateParameters(\n      this.currentConfig.provider,\n      this.currentConfig.model,\n      parameters\n    );\n    \n    if (!validation.valid) {\n      throw new Error(`Invalid parameters: ${validation.errors.join(', ')}`);\n    }\n    \n    this.currentConfig = {\n      ...this.currentConfig,\n      parameters\n    };\n    \n    this.saveConfiguration();\n    this.emit('parameters-changed', this.currentConfig);\n  }\n\n  /**\n   * Set API key for a provider\n   */\n  setApiKey(provider: AIProvider, apiKey: string): void {\n    try {\n      if (apiKey) {\n        localStorage.setItem(`${STORAGE_KEYS.API_KEY_PREFIX}${provider}`, apiKey);\n      } else {\n        localStorage.removeItem(`${STORAGE_KEYS.API_KEY_PREFIX}${provider}`);\n      }\n      \n      // Update current config if this is the active provider\n      if (provider === this.currentConfig.provider) {\n        this.currentConfig.apiKey = apiKey;\n        this.emit('provider-changed', this.currentConfig);\n      }\n      \n      // Update provider status\n      this.updateProviderStatus(provider, {\n        hasApiKey: Boolean(apiKey),\n        lastChecked: new Date()\n      });\n      \n    } catch (error) {\n      console.warn(`Failed to save API key for ${provider}:`, error);\n    }\n  }\n\n  /**\n   * Get API key for a provider\n   */\n  getApiKey(provider: AIProvider): string {\n    try {\n      return localStorage.getItem(`${STORAGE_KEYS.API_KEY_PREFIX}${provider}`) || '';\n    } catch (error) {\n      console.warn(`Failed to load API key for ${provider}:`, error);\n      return '';\n    }\n  }\n\n  /**\n   * Check if a provider has a valid API key\n   */\n  hasApiKey(provider: AIProvider): boolean {\n    return Boolean(this.getApiKey(provider));\n  }\n\n  /**\n   * Get all configured providers\n   */\n  getConfiguredProviders(): AIProvider[] {\n    return (Object.keys(PROVIDER_CONFIGS) as AIProvider[]).filter(\n      provider => this.hasApiKey(provider)\n    );\n  }\n\n  /**\n   * Get provider status\n   */\n  getProviderStatus(provider: AIProvider): ProviderStatus {\n    return this.providerStatuses.get(provider) || {\n      provider,\n      isAvailable: false,\n      hasApiKey: this.hasApiKey(provider),\n      isValid: false,\n      lastChecked: new Date()\n    };\n  }\n\n  /**\n   * Update provider status\n   */\n  updateProviderStatus(provider: AIProvider, updates: Partial<ProviderStatus>): void {\n    const currentStatus = this.getProviderStatus(provider);\n    const newStatus = { ...currentStatus, ...updates };\n    \n    this.providerStatuses.set(provider, newStatus);\n    this.saveProviderStatuses();\n    this.emit('status-updated', this.currentConfig);\n  }\n\n  /**\n   * Validate current configuration\n   */\n  validateCurrentConfig(): { valid: boolean; errors: string[] } {\n    const errors: string[] = [];\n    \n    // Check if API key is present\n    if (!this.currentConfig.apiKey) {\n      errors.push('API key is required');\n    }\n    \n    // Validate parameters\n    const paramValidation = validateParameters(\n      this.currentConfig.provider,\n      this.currentConfig.model,\n      this.currentConfig.parameters\n    );\n    \n    if (!paramValidation.valid) {\n      errors.push(...paramValidation.errors);\n    }\n    \n    return {\n      valid: errors.length === 0,\n      errors\n    };\n  }\n\n  /**\n   * Reset configuration to defaults\n   */\n  resetToDefaults(): void {\n    this.currentConfig = { ...DEFAULT_CONFIG };\n    this.currentConfig.apiKey = this.getApiKey(this.currentConfig.provider);\n    this.saveConfiguration();\n    this.emit('provider-changed', this.currentConfig);\n  }\n\n  /**\n   * Add event listener\n   */\n  addEventListener(event: ProviderConfigEvent, listener: ConfigEventListener): void {\n    this.eventListeners.get(event)?.add(listener);\n  }\n\n  /**\n   * Remove event listener\n   */\n  removeEventListener(event: ProviderConfigEvent, listener: ConfigEventListener): void {\n    this.eventListeners.get(event)?.delete(listener);\n  }\n\n  /**\n   * Export configuration for backup/sharing\n   */\n  exportConfiguration(): { \n    provider: AIProvider; \n    model: string; \n    parameters: ModelParameters;\n    timestamp: string;\n  } {\n    return {\n      provider: this.currentConfig.provider,\n      model: this.currentConfig.model,\n      parameters: this.currentConfig.parameters,\n      timestamp: new Date().toISOString()\n    };\n  }\n\n  /**\n   * Import configuration from backup/sharing\n   */\n  importConfiguration(config: {\n    provider: AIProvider;\n    model: string;\n    parameters: ModelParameters;\n  }): void {\n    // Validate imported configuration\n    const providerConfig = PROVIDER_CONFIGS[config.provider];\n    if (!providerConfig) {\n      throw new Error(`Invalid provider: ${config.provider}`);\n    }\n    \n    const model = providerConfig.models.find(m => m.id === config.model);\n    if (!model) {\n      throw new Error(`Invalid model: ${config.model} for provider ${config.provider}`);\n    }\n    \n    const validation = validateParameters(config.provider, config.model, config.parameters);\n    if (!validation.valid) {\n      throw new Error(`Invalid parameters: ${validation.errors.join(', ')}`);\n    }\n    \n    // Apply configuration\n    this.currentConfig = {\n      provider: config.provider,\n      model: config.model,\n      parameters: config.parameters,\n      apiKey: this.getApiKey(config.provider),\n      baseUrl: providerConfig.baseUrl\n    };\n    \n    this.saveConfiguration();\n    this.emit('provider-changed', this.currentConfig);\n  }\n\n  /**\n   * Private: Load configuration from localStorage\n   */\n  private loadConfiguration(): ActiveProviderConfig {\n    try {\n      const savedProvider = localStorage.getItem(STORAGE_KEYS.CURRENT_PROVIDER) as AIProvider;\n      const savedModel = localStorage.getItem(STORAGE_KEYS.CURRENT_MODEL);\n      const savedParameters = localStorage.getItem(STORAGE_KEYS.PROVIDER_PARAMETERS);\n      \n      let config = { ...DEFAULT_CONFIG };\n      \n      // Load provider\n      if (savedProvider && PROVIDER_CONFIGS[savedProvider]) {\n        config.provider = savedProvider;\n        config.apiKey = this.getApiKey(savedProvider);\n        config.baseUrl = PROVIDER_CONFIGS[savedProvider].baseUrl;\n      }\n      \n      // Load model\n      const providerConfig = PROVIDER_CONFIGS[config.provider];\n      if (savedModel && providerConfig.models.find(m => m.id === savedModel)) {\n        config.model = savedModel;\n      } else {\n        config.model = providerConfig.models[0].id;\n      }\n      \n      // Load parameters\n      if (savedParameters) {\n        try {\n          const parsedParameters = JSON.parse(savedParameters);\n          const validation = validateParameters(config.provider, config.model, parsedParameters);\n          if (validation.valid) {\n            config.parameters = parsedParameters;\n          } else {\n            config.parameters = providerConfig.defaultParameters;\n          }\n        } catch {\n          config.parameters = providerConfig.defaultParameters;\n        }\n      } else {\n        config.parameters = providerConfig.defaultParameters;\n      }\n      \n      return config;\n    } catch (error) {\n      console.warn('Failed to load configuration from localStorage:', error);\n      return { ...DEFAULT_CONFIG };\n    }\n  }\n\n  /**\n   * Private: Save configuration to localStorage\n   */\n  private saveConfiguration(): void {\n    try {\n      localStorage.setItem(STORAGE_KEYS.CURRENT_PROVIDER, this.currentConfig.provider);\n      localStorage.setItem(STORAGE_KEYS.CURRENT_MODEL, this.currentConfig.model);\n      localStorage.setItem(STORAGE_KEYS.PROVIDER_PARAMETERS, JSON.stringify(this.currentConfig.parameters));\n    } catch (error) {\n      console.warn('Failed to save configuration to localStorage:', error);\n    }\n  }\n\n  /**\n   * Private: Initialize provider statuses\n   */\n  private initializeProviderStatuses(): void {\n    try {\n      const savedStatuses = localStorage.getItem(STORAGE_KEYS.PROVIDER_STATUS);\n      if (savedStatuses) {\n        const parsed = JSON.parse(savedStatuses);\n        Object.entries(parsed).forEach(([provider, status]) => {\n          this.providerStatuses.set(provider as AIProvider, status as ProviderStatus);\n        });\n      }\n    } catch (error) {\n      console.warn('Failed to load provider statuses:', error);\n    }\n    \n    // Initialize missing statuses\n    (Object.keys(PROVIDER_CONFIGS) as AIProvider[]).forEach(provider => {\n      if (!this.providerStatuses.has(provider)) {\n        this.providerStatuses.set(provider, {\n          provider,\n          isAvailable: false,\n          hasApiKey: this.hasApiKey(provider),\n          isValid: false,\n          lastChecked: new Date()\n        });\n      }\n    });\n  }\n\n  /**\n   * Private: Save provider statuses\n   */\n  private saveProviderStatuses(): void {\n    try {\n      const statusObject = Object.fromEntries(this.providerStatuses);\n      localStorage.setItem(STORAGE_KEYS.PROVIDER_STATUS, JSON.stringify(statusObject));\n    } catch (error) {\n      console.warn('Failed to save provider statuses:', error);\n    }\n  }\n\n  /**\n   * Private: Emit event to listeners\n   */\n  private emit(event: ProviderConfigEvent, config: ActiveProviderConfig): void {\n    const listeners = this.eventListeners.get(event);\n    if (listeners) {\n      listeners.forEach(listener => {\n        try {\n          listener(config);\n        } catch (error) {\n          console.error(`Error in ${event} listener:`, error);\n        }\n      });\n    }\n  }\n}\n\n// Create and export singleton instance\nexport const providerConfigService = new ProviderConfigService();\nexport default providerConfigService;\n",
      "metadata": {
        "filename": "providerConfigService.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/providerService.ts\n\n/**\n * @file providerService.ts\n * @description Frontend service for AI provider validation and status management\n * @since 0.6.0\n */\n\nexport type AIProvider = 'google' | 'openai' | 'openrouter' | 'anthropic';\n\nexport interface ProviderValidationResult {\n  success: boolean;\n  error?: string;\n}\n\nexport interface ProviderAvailability {\n  provider: AIProvider;\n  hasApiKey: boolean;\n  isConfigured: boolean;\n  validationResult?: ProviderValidationResult;\n}\n\nexport interface ProviderStatusResponse {\n  providers: ProviderAvailability[];\n  hasValidProvider: boolean;\n  preferredProvider: AIProvider | null;\n}\n\nexport interface ProviderHealthResponse {\n  healthy: boolean;\n  preferredProvider: AIProvider | null;\n  requiresSetup: boolean;\n}\n\nconst API_BASE = '/api';\n\n/**\n * Gets the status of all providers including validation results\n */\nexport async function getProviderStatus(): Promise<ProviderStatusResponse> {\n  const response = await fetch(`${API_BASE}/providers/status`);\n  \n  if (!response.ok) {\n    throw new Error(`Failed to get provider status: ${response.statusText}`);\n  }\n  \n  const data = await response.json();\n  \n  if (!data.success) {\n    throw new Error(data.error || 'Unknown error getting provider status');\n  }\n  \n  return data.data;\n}\n\n/**\n * Gets available providers without validation (faster)\n */\nexport async function getAvailableProviders(): Promise<{ providers: ProviderAvailability[] }> {\n  const response = await fetch(`${API_BASE}/providers/available`);\n  \n  if (!response.ok) {\n    throw new Error(`Failed to get available providers: ${response.statusText}`);\n  }\n  \n  const data = await response.json();\n  \n  if (!data.success) {\n    throw new Error(data.error || 'Unknown error getting available providers');\n  }\n  \n  return data.data;\n}\n\n/**\n * Checks if at least one provider is healthy and ready\n */\nexport async function checkProviderHealth(): Promise<ProviderHealthResponse> {\n  const response = await fetch(`${API_BASE}/providers/health`);\n  \n  if (!response.ok) {\n    throw new Error(`Failed to check provider health: ${response.statusText}`);\n  }\n  \n  const data = await response.json();\n  \n  if (!data.success) {\n    throw new Error(data.error || 'Unknown error checking provider health');\n  }\n  \n  return data.data;\n}\n\n/**\n * Gets the preferred provider based on configuration\n */\nexport async function getPreferredProvider(): Promise<{ preferredProvider: AIProvider | null; requiresSetup: boolean }> {\n  const response = await fetch(`${API_BASE}/providers/preferred`);\n  \n  const data = await response.json();\n  \n  if (!data.success) {\n    if (response.status === 404) {\n      // No valid provider available\n      return {\n        preferredProvider: null,\n        requiresSetup: true,\n      };\n    }\n    throw new Error(data.error || 'Unknown error getting preferred provider');\n  }\n  \n  return data.data;\n}\n\n/**\n * Validates a specific provider's API key\n */\nexport async function validateProvider(\n  provider: AIProvider,\n  apiKey: string,\n  baseUrl?: string\n): Promise<{ provider: AIProvider; validation: ProviderValidationResult }> {\n  const response = await fetch(`${API_BASE}/providers/validate`, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({\n      provider,\n      apiKey,\n      baseUrl,\n    }),\n  });\n  \n  if (!response.ok) {\n    throw new Error(`Failed to validate provider: ${response.statusText}`);\n  }\n  \n  const data = await response.json();\n  \n  if (!data.success) {\n    throw new Error(data.error || 'Unknown error validating provider');\n  }\n  \n  return data.data;\n}\n\n/**\n * Checks if the application is ready (has at least one valid provider)\n * This is the main function used for routing logic\n */\nexport async function isApplicationReady(): Promise<boolean> {\n  try {\n    const health = await checkProviderHealth();\n    return health.healthy;\n  } catch (error) {\n    console.error('Error checking application readiness:', error);\n    return false;\n  }\n}\n",
      "metadata": {
        "filename": "providerService.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/services/workflowEngine.ts\n\n/**\n * @file workflowEngine.ts\n * @description This module contains the core logic for executing and managing workflows.\n * It includes functions for task execution, topological sorting of tasks, and API interactions\n * for saving and retrieving workflows.\n *\n * @requires ../types\n */\n\nimport { Task, DataStore, PromptSFL, Workflow } from '../types';\n\n/**\n * @constant {string} API_BASE_URL - The base URL for the workflow-related API endpoints.\n * @private\n */\nconst API_BASE_URL = '/api/workflows';\n\n/**\n * Safely retrieves a nested value from an object using a dot-notation path.\n * This is a utility function to access data within the `DataStore`.\n *\n * @param {Record<string, any>} obj - The object to query.\n * @param {string} path - The dot-notation path to the desired value (e.g., 'userInput.text').\n * @returns {*} The value at the specified path, or `undefined` if the path is not found.\n * @example\n * const myObj = { a: { b: { c: 1 } } };\n * getNested(myObj, 'a.b.c'); // returns 1\n * getNested(myObj, 'a.d'); // returns undefined\n * @private\n */\nconst getNested = (obj: Record<string, any>, path: string): any => {\n    return path.split('.').reduce((acc, part) => acc && acc[part], obj);\n};\n\n/**\n * Replaces placeholders in a template string with values from the data store.\n * Placeholders are in the format `{{dot.notation.path}}`.\n * If the template is a single variable `{{var}}`, it returns the raw value from the data store,\n * preserving its type (e.g., an object or array). Otherwise, it performs string interpolation.\n *\n * @param {string} template - The string containing placeholders.\n * @param {DataStore} dataStore - The object containing data to fill in the template.\n * @returns {*} The processed string, or the raw value if the template was a single variable placeholder.\n * @private\n */\nconst templateString = (template: string, dataStore: DataStore): any => {\n    const singleVarMatch = template.trim().match(/^\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}$/);\n    if (singleVarMatch) {\n        const key = singleVarMatch[1];\n        const value = getNested(dataStore, key);\n        return value !== undefined ? value : template;\n    }\n\n    return template.replace(/\\{\\{\\s*([\\w\\.]+)\\s*\\}\\}/g, (match, key) => {\n        const value = getNested(dataStore, key);\n        if (value === undefined || value === null) {\n            console.warn(`Template key \"${key}\" not found in data store.`);\n            return match;\n        }\n        if (typeof value === 'object') {\n            return JSON.stringify(value, null, 2);\n        }\n        return String(value);\n    });\n};\n\n/**\n * Executes a string of JavaScript code as a function body for `TEXT_MANIPULATION` tasks.\n * The function is sandboxed and receives an `inputs` object with the resolved dependencies.\n *\n * @param {string} funcBody - The string of JavaScript code to execute.\n * @param {Record<string, any>} inputs - An object containing input values accessible to the function via `inputs.key`.\n * @returns {*} The result of the executed function.\n * @throws {Error} Throws an error if the custom function code fails during execution.\n * @private\n */\nconst executeTextManipulation = (funcBody: string, inputs: Record<string, any>): any => {\n    try {\n        const func = new Function('inputs', funcBody);\n        return func(inputs);\n    } catch (e: any) {\n        throw new Error(`Error in custom function: ${e.message}`);\n    }\n};\n\n/**\n * Executes a single workflow task.\n * It distinguishes between client-side tasks (like data input or text manipulation)\n * and server-side tasks (like Gemini API calls), handling each appropriately.\n *\n * @param {Task} task - The task object to execute.\n * @param {DataStore} dataStore - The current state of the workflow's data store, used to resolve inputs.\n * @param {PromptSFL[]} prompts - The library of available SFL prompts, needed for tasks that reference them.\n * @returns {Promise<any>} A promise that resolves with the task's output.\n * @throws {Error} Throws an error if the task execution fails, either on the client or server.\n */\nexport const executeTask = async (task: Task, dataStore: DataStore, prompts: PromptSFL[]): Promise<any> => {\n    const isClientSideTask = ['DATA_INPUT', 'TEXT_MANIPULATION', 'DISPLAY_CHART', 'SIMULATE_PROCESS'].includes(task.type);\n\n    if (isClientSideTask) {\n        const resolvedInputs = task.inputKeys.reduce((acc, key) => {\n            const simpleKey = key.split('.').pop() || key;\n            acc[simpleKey] = getNested(dataStore, key);\n            return acc;\n        }, {} as Record<string, any>);\n\n        switch (task.type) {\n            case 'DATA_INPUT':\n                if (task.staticValue && typeof task.staticValue === 'string') {\n                    return templateString(task.staticValue, dataStore);\n                }\n                return task.staticValue;\n            case 'TEXT_MANIPULATION':\n                if (!task.functionBody) throw new Error(\"Function body is missing.\");\n                return executeTextManipulation(task.functionBody, resolvedInputs);\n            case 'DISPLAY_CHART':\n                 if(!task.dataKey) throw new Error(\"Data key is missing for chart display.\");\n                 return getNested(dataStore, task.dataKey);\n            case 'SIMULATE_PROCESS':\n                return new Promise(resolve => {\n                    setTimeout(() => resolve({ status: \"ok\", message: `Simulated process for ${task.name} completed.`}), 1000)\n                });\n            default:\n                throw new Error(`Unsupported client-side task type: ${task.type}`);\n        }\n    } else {\n        // For server-side tasks, call the backend\n        const response = await fetch(`${API_BASE_URL}/run-task`, {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ task, dataStore }),\n        });\n\n        if (!response.ok) {\n            const errorData = await response.json();\n            throw new Error(errorData.message || `Failed to execute task \"${task.name}\"`);\n        }\n        return response.json();\n    }\n};\n\n/**\n * Sorts tasks in a workflow based on their dependencies using a topological sort algorithm.\n * This ensures that tasks are executed only after their dependencies have been met.\n * It also detects cycles and reports missing dependencies.\n *\n * @param {Task[]} tasks - An array of task objects from a workflow.\n * @returns {{sortedTasks: Task[], feedback: string[]}} An object containing the array of tasks in execution order,\n * and an array of feedback messages (e.g., warnings about missing dependencies or errors for cycles).\n */\nexport const topologicalSort = (tasks: Task[]): { sortedTasks: Task[], feedback: string[] } => {\n    const sortedTasks: Task[] = [];\n    const feedback: string[] = [];\n    const visited = new Set<string>();\n    const recursionStack = new Set<string>();\n    const taskMap = new Map(tasks.map(t => [t.id, t]));\n\n    function visit(taskId: string) {\n        if (recursionStack.has(taskId)) {\n            feedback.push(`Cycle detected in workflow involving task ID: ${taskId}`);\n            return;\n        }\n        if (visited.has(taskId)) {\n            return;\n        }\n\n        visited.add(taskId);\n        recursionStack.add(taskId);\n\n        const task = taskMap.get(taskId);\n        if (task) {\n            for (const depId of task.dependencies) {\n                if (taskMap.has(depId)) {\n                    visit(depId);\n                } else {\n                    feedback.push(`Warning: Task \"${task.name}\" has an unknown dependency: \"${depId}\". It will be ignored.`);\n                }\n            }\n            sortedTasks.push(task);\n        }\n        \n        recursionStack.delete(taskId);\n    }\n\n    for (const task of tasks) {\n        if (!visited.has(task.id)) {\n            visit(task.id);\n        }\n    }\n    \n    if(feedback.some(f => f.includes('Cycle detected'))) {\n       return { sortedTasks: [], feedback };\n    }\n\n    return { sortedTasks, feedback };\n};\n\n/**\n * Runs a complete workflow by executing its tasks in the correct topological order.\n * This function is a high-level orchestrator, intended for scenarios where callbacks are needed\n * to monitor the progress of a workflow run.\n *\n * @param {Task[]} tasks - The array of tasks in the workflow.\n * @param {DataStore} initialDataStore - The initial data to start the workflow with (e.g., user input).\n * @param {PromptSFL[]} prompts - A list of all available SFL prompts.\n * @param {(taskId: string, result: any) => void} onTaskComplete - A callback function executed after each task completes successfully.\n * @param {(taskId: string, error: Error) => void} onTaskError - A callback function executed when a task fails.\n * @param {(finalDataStore: DataStore) => void} onWorkflowComplete - A callback function executed after the entire workflow finishes successfully.\n * @returns {Promise<void>} A promise that resolves when the workflow execution is complete.\n */\nexport const runWorkflow = async (\n    tasks: Task[],\n    initialDataStore: DataStore,\n    prompts: PromptSFL[],\n    onTaskComplete: (taskId: string, result: any) => void,\n    onTaskError: (taskId: string, error: Error) => void,\n    onWorkflowComplete: (finalDataStore: DataStore) => void\n) => {\n    const { sortedTasks, feedback } = topologicalSort(tasks);\n    \n    if (feedback.some(f => f.includes('Cycle detected'))) {\n        const cycleError = new Error(feedback.find(f => f.includes('Cycle detected')));\n        console.error(\"Workflow has a cycle, cannot run.\", cycleError.message);\n        onTaskError(\"workflow-validation\", cycleError);\n        return;\n    }\n    if (feedback.length > 0) {\n        console.warn(\"Workflow validation warnings:\", feedback);\n    }\n\n    const dataStore: DataStore = { ...initialDataStore };\n\n    for (const task of sortedTasks) {\n        try {\n            const result = await executeTask(task, dataStore, prompts);\n            dataStore[task.outputKey] = result;\n            onTaskComplete(task.id, result);\n        } catch (error: any) {\n            console.error(`Error executing task ${task.name} (${task.id}):`, error);\n            onTaskError(task.id, error);\n            return;\n        }\n    }\n\n    onWorkflowComplete(dataStore);\n};\n\n/**\n * Saves a new workflow or updates an existing one on the backend.\n *\n * @param {{ id?: string; name: string; tasks: Task[] }} workflow - The workflow object to save.\n * @returns {Promise<{ id: string }>} A promise that resolves with the ID of the saved workflow.\n * @throws {Error} Throws an error if the API request fails.\n */\nexport const saveWorkflow = async (workflow: { id?: string; name: string; tasks: Task[] }): Promise<{ id: string }> => {\n    const url = workflow.id ? `${API_BASE_URL}/${workflow.id}` : API_BASE_URL;\n    const method = workflow.id ? 'PUT' : 'POST';\n\n    const response = await fetch(url, {\n        method,\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ name: workflow.name, tasks: workflow.tasks }),\n    });\n\n    if (!response.ok) {\n        const errorData = await response.json();\n        throw new Error(errorData.message || 'Failed to save workflow');\n    }\n    return response.json();\n};\n\n/**\n * Fetches a list of all workflows from the backend.\n *\n * @returns {Promise<{ id: string; name: string }[]>} A promise that resolves to an array of workflow metadata.\n * @throws {Error} Throws an error if the API request fails.\n */\nexport const getWorkflows = async (): Promise<{ id: string; name: string }[]> => {\n    const response = await fetch(API_BASE_URL);\n    if (!response.ok) {\n        throw new Error('Failed to fetch workflows');\n    }\n    return response.json();\n};\n\n/**\n * Fetches a single, complete workflow by its ID from the backend.\n *\n * @param {string} id - The ID of the workflow to fetch.\n * @returns {Promise<{ id: string; name: string; tasks: Task[] }>} A promise that resolves to the full workflow object.\n * @throws {Error} Throws an error if the API request fails.\n */\nexport const getWorkflowById = async (id: string): Promise<{ id: string; name: string; tasks: Task[] }> => {\n    const response = await fetch(`${API_BASE_URL}/${id}`);\n    if (!response.ok) {\n        throw new Error(`Failed to fetch workflow with id ${id}`);\n    }\n    return response.json();\n};\n\n/**\n * Deletes a workflow from the backend by its ID.\n *\n * @param {string} id - The ID of the workflow to delete.\n * @returns {Promise<void>} A promise that resolves when the deletion is successful.\n * @throws {Error} Throws an error if the API request fails.\n */\nexport const deleteWorkflow = async (id: string): Promise<void> => {\n    const response = await fetch(`${API_BASE_URL}/${id}`, { method: 'DELETE' });\n    if (!response.ok) {\n        throw new Error('Failed to delete workflow');\n    }\n};\n\n/**\n * @interface OrchestrateResponse\n * @description Represents the response from the AI orchestration API\n */\ninterface OrchestrateResponse {\n    success: boolean;\n    workflow?: Workflow;\n    error?: string;\n    validationErrors?: string[];\n}\n\n/**\n * Orchestrates a new workflow from a high-level user request using AI.\n * This function sends a natural language description to the backend AI orchestrator,\n * which automatically generates a complete, executable workflow with proper task\n * dependencies and data flow.\n *\n * @param {string} userRequest - A natural language description of what the user wants to accomplish\n * @returns {Promise<Workflow>} A promise that resolves to the generated workflow\n * @throws {Error} Throws an error if the API request fails or orchestration is unsuccessful\n * \n * @example\n * ```typescript\n * try {\n *   const workflow = await orchestrateWorkflow(\n *     \"Analyze customer feedback for sentiment and generate a summary report\"\n *   );\n *   console.log(`Generated \"${workflow.name}\" with ${workflow.tasks.length} tasks`);\n * } catch (error) {\n *   console.error('Orchestration failed:', error.message);\n * }\n * ```\n */\nexport const orchestrateWorkflow = async (userRequest: string): Promise<Workflow> => {\n    if (!userRequest?.trim()) {\n        throw new Error('User request cannot be empty');\n    }\n\n    if (userRequest.length > 2000) {\n        throw new Error('Request description is too long. Please limit to 2000 characters.');\n    }\n\n    const response = await fetch(`${API_BASE_URL}/orchestrate`, {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({ request: userRequest.trim() }),\n    });\n\n    if (!response.ok) {\n        const errorData = await response.json().catch(() => ({ error: 'Unknown error occurred' }));\n        \n        if (response.status === 400) {\n            throw new Error(errorData.error || 'Invalid request format');\n        } else if (response.status === 422) {\n            const validationMsg = errorData.validationErrors \n                ? `Workflow validation failed: ${errorData.validationErrors.join('; ')}`\n                : 'Generated workflow failed validation';\n            throw new Error(validationMsg);\n        } else if (response.status === 503) {\n            throw new Error('AI orchestration service is temporarily unavailable');\n        } else {\n            throw new Error(errorData.error || `Failed to orchestrate workflow (${response.status})`);\n        }\n    }\n\n    const result: OrchestrateResponse = await response.json();\n    \n    if (!result.success || !result.workflow) {\n        throw new Error(result.error || 'Failed to generate workflow');\n    }\n\n    return result.workflow;\n};\n",
      "metadata": {
        "filename": "workflowEngine.ts",
        "path": "/frontend/services/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/tailwind.config.js\n\n/** @type {import('tailwindcss').Config} */\nexport default {\n  content: [\n    \"./index.html\",\n    \"./*.{js,ts,jsx,tsx}\",\n    \"./components/**/*.{js,ts,jsx,tsx}\",\n    \"./hooks/**/*.{js,ts,jsx,tsx}\",\n    \"./services/**/*.{js,ts,jsx,tsx}\",\n    \"./utils/**/*.{js,ts,jsx,tsx}\",\n  ],\n  theme: {\n    extend: {\n      colors: {\n        // Enhanced Dark Theme Color System\n        // ===================================\n        \n        // Background Colors\n        'app-bg': '#1a1f2e',           // Darker primary background for better contrast\n        'surface': '#242938',          // Enhanced surface color for cards/modals\n        'surface-hover': '#2a3041',    // Hover state for interactive surfaces\n        'surface-elevated': '#2f364a', // Elevated surfaces (dropdowns, tooltips)\n        \n        // Border & Divider Colors\n        'border-primary': '#3d4458',   // Primary borders with improved contrast\n        'border-secondary': '#515873', // Secondary borders for subtle divisions\n        'border-interactive': '#6b7491', // Interactive element borders\n        \n        // Text Colors (WCAG AA Compliant)\n        'text-primary': '#e8eaed',     // Primary text - high contrast (14.2:1)\n        'text-secondary': '#a8b3c5',   // Secondary text - good contrast (7.8:1)\n        'text-tertiary': '#8692a6',    // Tertiary text - adequate contrast (4.9:1)\n        'text-disabled': '#5a6578',    // Disabled text state\n        \n        // Accent & Interactive Colors\n        'accent-primary': '#f2b547',   // Enhanced primary accent with better contrast\n        'accent-secondary': '#e09725', // Secondary accent for hover states\n        'accent-tertiary': '#cc8519',  // Tertiary accent for active states\n        \n        // Action Colors\n        'primary-action': '#d18d2e',   // Primary buttons with improved visibility\n        'primary-hover': '#e09e42',    // Primary button hover state\n        'primary-active': '#b87a1f',   // Primary button active state\n        \n        // Secondary Action Colors\n        'secondary-action': '#3d4458', // Secondary buttons matching border\n        'secondary-hover': '#495066',  // Secondary button hover\n        'secondary-active': '#313749', // Secondary button active\n        \n        // Status Colors (Accessible)\n        'success': '#4ade80',          // Success green (7.2:1 contrast)\n        'success-bg': '#0f2518',       // Success background\n        'warning': '#fbbf24',          // Warning amber (8.1:1 contrast)\n        'warning-bg': '#2d1b00',       // Warning background\n        'error': '#f87171',            // Error red (6.8:1 contrast)\n        'error-bg': '#2d1414',         // Error background\n        'info': '#60a5fa',             // Info blue (6.5:1 contrast)\n        'info-bg': '#0f1729',          // Info background\n        \n        // Focus & Selection States\n        'focus-ring': '#f2b547',       // Focus ring color matching accent\n        'selection-bg': '#2a3041',     // Text selection background\n        'selection-text': '#e8eaed',   // Text selection text color\n        \n        // Legacy color mappings for backward compatibility\n        'border-gray': '#3d4458',      // Maps to border-primary\n        'accent': '#f2b547',           // Maps to accent-primary\n        'text-secondary': '#a8b3c5',   // Updated for better contrast\n      },\n      fontFamily: {\n        'sans': ['Inter', 'ui-sans-serif', 'system-ui', '-apple-system', 'BlinkMacSystemFont', 'sans-serif'],\n      },\n    },\n  },\n  plugins: [\n    require('@tailwindcss/forms'),\n  ],\n}\n",
      "metadata": {
        "filename": "tailwind.config.js",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/types/aiProvider.ts\n\n/**\n * @file aiProvider.ts\n * @description Enhanced type definitions for AI provider management and parameter configuration\n * Provides comprehensive type safety for dynamic provider switching and parameter management\n */\n\nexport type AIProvider = 'google' | 'openai' | 'openrouter' | 'anthropic';\n\n/**\n * Base parameters that all AI providers support\n */\nexport interface BaseModelParameters {\n  /** Controls randomness in generation (0.0 to 2.0) */\n  temperature?: number;\n  /** Maximum tokens to generate */\n  maxTokens?: number;\n}\n\n/**\n * Google Gemini specific parameters\n */\nexport interface GeminiParameters extends BaseModelParameters {\n  /** Top-K sampling parameter (1 to 40) */\n  topK?: number;\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  topP?: number;\n  /** System instruction for the model */\n  systemInstruction?: string;\n  /** Safety settings for content filtering */\n  safetySettings?: Array<{\n    category: string;\n    threshold: string;\n  }>;\n}\n\n/**\n * OpenAI specific parameters\n */\nexport interface OpenAIParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Number between -2.0 and 2.0. Positive values penalize new tokens */\n  presence_penalty?: number;\n  /** Number between -2.0 and 2.0. Positive values penalize repeated tokens */\n  frequency_penalty?: number;\n  /** System message for chat models */\n  systemMessage?: string;\n  /** Number of completions to generate */\n  n?: number;\n  /** Sequences where the API will stop generating */\n  stop?: string | string[];\n}\n\n/**\n * Anthropic Claude specific parameters\n */\nexport interface AnthropicParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Top-K sampling parameter (0 to 200) */\n  top_k?: number;\n  /** System prompt for Claude */\n  system?: string;\n  /** Stop sequences */\n  stop_sequences?: string[];\n}\n\n/**\n * OpenRouter parameters (supports various provider-specific params)\n */\nexport interface OpenRouterParameters extends BaseModelParameters {\n  /** Top-P/nucleus sampling parameter (0.0 to 1.0) */\n  top_p?: number;\n  /** Top-K sampling parameter */\n  top_k?: number;\n  /** Presence penalty */\n  presence_penalty?: number;\n  /** Frequency penalty */\n  frequency_penalty?: number;\n  /** Repetition penalty */\n  repetition_penalty?: number;\n  /** Min P sampling parameter */\n  min_p?: number;\n  /** System message */\n  system?: string;\n}\n\n/**\n * Union type for all provider-specific parameters\n */\nexport type ModelParameters = \n  | GeminiParameters \n  | OpenAIParameters \n  | AnthropicParameters \n  | OpenRouterParameters;\n\n/**\n * Parameter constraints and validation rules for each provider\n */\nexport interface ParameterConstraints {\n  temperature?: { min: number; max: number; step: number; default: number };\n  maxTokens?: { min: number; max: number; step: number; default: number };\n  topK?: { min: number; max: number; step: number; default: number };\n  topP?: { min: number; max: number; step: number; default: number };\n  top_p?: { min: number; max: number; step: number; default: number };\n  top_k?: { min: number; max: number; step: number; default: number };\n  presence_penalty?: { min: number; max: number; step: number; default: number };\n  frequency_penalty?: { min: number; max: number; step: number; default: number };\n  repetition_penalty?: { min: number; max: number; step: number; default: number };\n  min_p?: { min: number; max: number; step: number; default: number };\n  n?: { min: number; max: number; step: number; default: number };\n}\n\n/**\n * Model information including its capabilities and supported parameters\n */\nexport interface ModelInfo {\n  id: string;\n  name: string;\n  provider: AIProvider;\n  description?: string;\n  contextLength: number;\n  supportedParameters: string[];\n  constraints: ParameterConstraints;\n  pricing?: {\n    input: number; // per 1K tokens\n    output: number; // per 1K tokens\n  };\n}\n\n/**\n * Provider configuration including available models and default parameters\n */\nexport interface ProviderConfig {\n  provider: AIProvider;\n  name: string;\n  description: string;\n  apiKeyRequired: boolean;\n  baseUrl?: string;\n  models: ModelInfo[];\n  defaultParameters: ModelParameters;\n  supportedFeatures: string[];\n}\n\n/**\n * Active provider configuration for runtime use\n */\nexport interface ActiveProviderConfig {\n  provider: AIProvider;\n  model: string;\n  parameters: ModelParameters;\n  apiKey: string;\n  baseUrl?: string;\n}\n\n/**\n * Provider status information\n */\nexport interface ProviderStatus {\n  provider: AIProvider;\n  isAvailable: boolean;\n  hasApiKey: boolean;\n  isValid: boolean;\n  error?: string;\n  lastChecked: Date;\n}\n\n/**\n * Parameter preset for quick configuration\n */\nexport interface ParameterPreset {\n  name: string;\n  description: string;\n  provider: AIProvider;\n  model?: string; // If model-specific\n  parameters: ModelParameters;\n}\n\n/**\n * Request configuration for AI API calls\n */\nexport interface AIRequest {\n  provider: AIProvider;\n  model: string;\n  parameters: ModelParameters;\n  prompt: string;\n  systemMessage?: string;\n  conversationHistory?: Array<{\n    role: 'user' | 'assistant' | 'system';\n    content: string;\n  }>;\n}\n",
      "metadata": {
        "filename": "aiProvider.ts",
        "path": "/frontend/types/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/types.ts\n\n/**\n * @file types.ts\n * @description This file contains all the TypeScript type definitions and interfaces used throughout the frontend application.\n * It defines the data structures for SFL prompts, workflows, tasks, and other related entities, serving as a single source of truth for the application's data model.\n */\n\n/**\n * @interface SFLField\n * @description Defines the structure for the \"Field\" component of the Systemic Functional Linguistics (SFL) framework.\n * It represents the \"what\" of the communication: the subject matter, domain, and the action being performed.\n * @property {string} topic - The high-level subject area (e.g., \"Quantum Physics\").\n * @property {string} taskType - The specific action the AI should perform (e.g., \"Summarization\").\n * @property {string} domainSpecifics - Fine-grained contextual details or constraints (e.g., \"Python 3.9, pandas\").\n * @property {string} keywords - Comma-separated terms that are central to the response.\n */\nexport interface SFLField {\n  topic: string;\n  taskType: string;\n  domainSpecifics: string;\n  keywords: string;\n}\n\n/**\n * @interface SFLTenor\n * @description Defines the structure for the \"Tenor\" component of the SFL framework.\n * It represents the \"who\" of the communication: the social roles and relationships.\n * @property {string} aiPersona - The character or role the AI should adopt (e.g., \"Expert\", \"Sarcastic Bot\").\n * @property {string[]} targetAudience - The intended recipients of the AI's response (e.g., [\"Beginners\", \"Software Developers\"]).\n * @property {string} desiredTone - The emotional and stylistic attitude of the response (e.g., \"Formal\", \"Humorous\").\n * @property {string} interpersonalStance - The social relationship between the AI and the user (e.g., \"Act as a mentor\").\n */\nexport interface SFLTenor {\n  aiPersona: string;\n  targetAudience: string[];\n  desiredTone: string;\n  interpersonalStance: string;\n}\n\n/**\n * @interface SFLMode\n * @description Defines the structure for the \"Mode\" component of the SFL framework.\n * It represents the \"how\" of the communication: the structure and format of the text.\n * @property {string} outputFormat - The required syntactical structure of the output (e.g., \"JSON\", \"Markdown\").\n * @property {string} rhetoricalStructure - The high-level organizational pattern (e.g., \"Problem-Solution\").\n * @property {string} lengthConstraint - The desired length of the response (e.g., \"Short Paragraph (~50 words)\").\n * @property {string} textualDirectives - Specific, micro-level rules about style or grammar (e.g., \"Use active voice\").\n */\nexport interface SFLMode {\n  outputFormat: string;\n  rhetoricalStructure: string;\n  lengthConstraint: string;\n  textualDirectives: string;\n}\n\n/**\n * @interface PromptSFL\n * @description Represents a complete SFL-structured prompt, combining the core prompt text with rich metadata\n * from the SFL framework and application-specific state.\n * @property {string} id - A unique identifier for the prompt.\n * @property {string} title - A user-defined title for the prompt.\n * @property {string} promptText - The main, executable text of the prompt, which may include `{{variables}}`.\n * @property {SFLField} sflField - The \"Field\" metadata for the prompt.\n * @property {SFLTenor} sflTenor - The \"Tenor\" metadata for the prompt.\n * @property {SFLMode} sflMode - The \"Mode\" metadata for the prompt.\n * @property {string} [exampleOutput] - An optional example of a desired output.\n * @property {string} [notes] - Optional user notes about the prompt.\n * @property {string} createdAt - ISO 8601 timestamp of when the prompt was created.\n * @property {string} updatedAt - ISO 8601 timestamp of the last update.\n * @property {string} [geminiResponse] - The last successful response from testing the prompt with Gemini.\n * @property {string} [geminiTestError] - The last error message from a failed Gemini test.\n * @property {boolean} [isTesting] - A transient flag indicating if the prompt is currently being tested.\n * @property {{name: string; content: string}} [sourceDocument] - An optional attached document for stylistic reference.\n */\nexport interface PromptSFL {\n  id: string;\n  title: string;\n  promptText: string;\n  sflField: SFLField;\n  sflTenor: SFLTenor;\n  sflMode: SFLMode;\n  exampleOutput?: string;\n  notes?: string;\n  createdAt: string;\n  updatedAt: string;\n  geminiResponse?: string;\n  geminiTestError?: string;\n  isTesting?: boolean;\n  sourceDocument?: {\n    name: string;\n    content: string;\n  };\n}\n\n/**\n * @interface Filters\n * @description Defines the structure for the filter state used to search and filter the list of prompts.\n * Each property corresponds to a filter control in the UI.\n */\nexport interface Filters {\n  searchTerm: string;\n  topic: string;\n  taskType: string;\n  aiPersona: string;\n  outputFormat: string;\n}\n\n/**\n * @enum {number} ModalType\n * @description Enumerates the different types of modals used across the application to manage which modal is active.\n */\nexport enum ModalType {\n  NONE,\n  CREATE_EDIT_PROMPT,\n  VIEW_PROMPT_DETAIL,\n  WIZARD,\n  HELP,\n  WORKFLOW_EDITOR,\n  WORKFLOW_WIZARD,\n  TASK_DETAIL,\n}\n\n/**\n * @enum {string} TaskType\n * @description Enumerates the different types of tasks that can be included in a workflow.\n */\nexport enum TaskType {\n  /** A task that takes static data or user input and places it in the data store. */\n  DATA_INPUT = \"DATA_INPUT\",\n  /** A task that executes a prompt using the Gemini API. */\n  GEMINI_PROMPT = \"GEMINI_PROMPT\",\n  /** A task for analyzing image data. */\n  IMAGE_ANALYSIS = \"IMAGE_ANALYSIS\",\n  /** A task that runs a custom JavaScript snippet to manipulate data. */\n  TEXT_MANIPULATION = \"TEXT_MANIPULATION\",\n  /** A task that simulates a process, useful for testing workflow structures. */\n  SIMULATE_PROCESS = \"SIMULATE_PROCESS\",\n  /** A task that prepares data for visualization as a chart. */\n  DISPLAY_CHART = \"DISPLAY_CHART\",\n  /** A task that executes a Gemini prompt with grounding on a specific data source. */\n  GEMINI_GROUNDED = \"GEMINI_GROUNDED\",\n}\n\n/**\n * @enum {string} TaskStatus\n * @description Enumerates the possible execution statuses of a workflow task during a run.\n */\nexport enum TaskStatus {\n  PENDING = \"PENDING\",\n  RUNNING = \"RUNNING\",\n  COMPLETED = \"COMPLETED\",\n  FAILED = \"FAILED\",\n  SKIPPED = \"SKIPPED\",\n}\n\n/**\n * @interface AgentConfig\n * @description Defines the configuration for an AI agent (e.g., Gemini model) used in a task.\n * @property {string} [model] - The specific model to use (e.g., 'gemini-1.5-flash').\n * @property {number} [temperature] - Controls the randomness of the output.\n * @property {number} [topK] - The top-K sampling parameter.\n * @property {number} [topP] - The top-P (nucleus) sampling parameter.\n * @property {string} [systemInstruction] - A system-level instruction for the model.\n */\nexport interface AgentConfig {\n  model?: string;\n  temperature?: number;\n  topK?: number;\n  topP?: number;\n  systemInstruction?: string;\n}\n\n/**\n * @interface Task\n * @description Represents a single, configurable step within a workflow.\n * @property {string} id - A unique identifier for the task.\n * @property {string} name - A user-defined name for the task.\n * @property {string} description - A brief description of what the task does.\n * @property {TaskType} type - The type of the task, which determines its execution logic.\n * @property {string[]} dependencies - An array of task IDs that must be completed before this task can run.\n * @property {string[]} inputKeys - An array of keys (using dot-notation) to retrieve values from the `DataStore`.\n * @property {string} outputKey - The key under which this task's result will be saved in the `DataStore`.\n * @property {Record<string, { nodeId: string; outputName: string; }>} [inputs] - Input mappings defining data dependencies between tasks.\n * @property {string} [promptId] - The ID of an SFL prompt from the library to be used by this task.\n * @property {string} [promptTemplate] - A manual prompt template, used if `promptId` is not set.\n * @property {AgentConfig} [agentConfig] - Configuration for the AI model, if applicable.\n * @property {string} [functionBody] - The JavaScript code for a `TEXT_MANIPULATION` task.\n * @property {*} [staticValue] - A static value for a `DATA_INPUT` task.\n * @property {string} [dataKey] - The key in the `DataStore` to use for a `DISPLAY_CHART` task.\n * @property {number} [positionX] - X coordinate for UI positioning in the workflow canvas.\n * @property {number} [positionY] - Y coordinate for UI positioning in the workflow canvas.\n */\nexport interface Task {\n  id: string;\n  name: string;\n  description: string;\n  type: TaskType;\n  dependencies: string[];\n  inputKeys: string[];\n  outputKey: string;\n  inputs?: Record<string, { nodeId: string; outputName: string; }>;\n  promptId?: string;\n  promptTemplate?: string;\n  agentConfig?: AgentConfig;\n  functionBody?: string;\n  staticValue?: any;\n  dataKey?: string;\n  positionX?: number;\n  positionY?: number;\n}\n\n/**\n * @interface Workflow\n * @description Represents a complete workflow, composed of metadata and a series of interconnected tasks.\n * @property {string} id - A unique identifier for the workflow.\n * @property {string} name - A user-defined name for the workflow.\n * @property {string} description - A brief description of the workflow's purpose.\n * @property {Task[]} tasks - An array of the tasks that make up the workflow.\n * @property {boolean} [isDefault] - A flag indicating if this is a read-only, default workflow.\n */\nexport interface Workflow {\n  id: string;\n  name: string;\n  description: string;\n  tasks: Task[];\n  isDefault?: boolean;\n}\n\n/**\n * @type DataStore\n * @description Represents the data store for a workflow run. It's a key-value map where keys are\n * task `outputKey`s and values are the results of those tasks.\n */\nexport type DataStore = Record<string, any>;\n\n/**\n * @interface TaskState\n * @description Defines the execution state of a single task at a specific moment during a workflow run.\n * @property {TaskStatus} status - The current execution status of the task.\n * @property {*} [result] - The output of the task upon successful completion.\n * @property {string} [error] - The error message if the task failed.\n * @property {number} [startTime] - The timestamp (in milliseconds) when the task started execution.\n * @property {number} [endTime] - The timestamp (in milliseconds) when the task finished execution.\n */\nexport interface TaskState {\n  status: TaskStatus;\n  result?: any;\n  error?: string;\n  startTime?: number;\n  endTime?: number;\n}\n\n/**\n * @type TaskStateMap\n * @description A map from task IDs to their respective `TaskState`, representing the state of the entire workflow.\n */\nexport type TaskStateMap = Record<string, TaskState>;\n\n/**\n * @interface StagedUserInput\n * @description Defines the structure for user-provided input that is staged for a workflow run.\n * This data is placed into the `DataStore` under the `userInput` key at the start of a run.\n * @property {string} [text] - Staged text input.\n * @property {{name: string; type: string; base64: string;}} [image] - Staged image input, including metadata and base64 content.\n * @property {{name: string; content: string;}} [file] - Staged text file input.\n */\nexport interface StagedUserInput {\n    text?: string;\n    image?: {\n        name: string;\n        type: string;\n        base64: string;\n    };\n    file?: {\n        name: string;\n        content: string;\n    }\n}\n\n/**\n * @interface WorkflowExecution\n * @description Represents a workflow execution record, tracking the status and results of asynchronous workflow runs.\n * @property {string} id - Unique identifier for the execution.\n * @property {string} workflowId - ID of the workflow being executed.\n * @property {string} [jobId] - BullMQ job ID for tracking the background execution.\n * @property {'pending' | 'running' | 'completed' | 'failed'} status - Current execution status.\n * @property {Record<string, any>} [result] - Final execution results when completed.\n * @property {Record<string, any>} [userInput] - Initial user input provided for the execution.\n * @property {string} [errorMessage] - Error details if the execution failed.\n * @property {string} [startedAt] - ISO timestamp when execution started.\n * @property {string} [completedAt] - ISO timestamp when execution completed or failed.\n * @property {string} createdAt - ISO timestamp when the execution record was created.\n * @property {string} updatedAt - ISO timestamp when the execution record was last updated.\n */\nexport interface WorkflowExecution {\n    id: string;\n    workflowId: string;\n    jobId?: string;\n    status: 'pending' | 'running' | 'completed' | 'failed';\n    result?: Record<string, any>;\n    userInput?: Record<string, any>;\n    errorMessage?: string;\n    startedAt?: string;\n    completedAt?: string;\n    createdAt: string;\n    updatedAt: string;\n}\n",
      "metadata": {
        "filename": "types.ts",
        "path": "/frontend/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/utils/generateId.ts\n\nimport { nanoid } from 'nanoid';\n\n/**\n * @file generateId.ts\n * @description Provides a robust function to generate a unique identifier using nanoid.\n * Nanoid generates cryptographically secure, URL-friendly, unique string IDs.\n * This utility is used throughout the application for creating unique IDs for prompts,\n * workflows, and other entities.\n * \n * @requires nanoid\n * @since 0.5.1\n */\n\n/**\n * Generates a unique identifier.\n * Uses nanoid to create a cryptographically secure, URL-friendly unique string.\n * The generated ID is safe to use in URLs, HTML attributes, and database keys.\n * \n * @returns {string} A unique, cryptographically secure string ID (typically 21 characters long).\n * \n * @example\n * ```typescript\n * const newUserId = generateId();\n * console.log(newUserId); // \"Uakgb_J5m9g-0JDMbcJqLJ\"\n * \n * const promptId = generateId();\n * const workflow = { id: generateId(), name: \"My Workflow\", ... };\n * ```\n * \n * @since 0.5.1\n */\nexport function generateId(): string {\n  return nanoid();\n}\n",
      "metadata": {
        "filename": "generateId.ts",
        "path": "/frontend/utils/"
      }
    },
    {
      "content": "File: SFL-Prompt-Studio/frontend/vite.config.ts\n\n/**\n * @file vite.config.ts\n * @description Vite configuration file for the frontend application.\n * This configuration sets up essential build tools and development server options.\n * It includes path aliases for cleaner imports (e.g., `@/components` instead of `../components`)\n * and handles the loading of environment variables.\n *\n * @requires path\n * @requires vite\n */\n\nimport path from 'path';\nimport { defineConfig, loadEnv } from 'vite';\nimport react from '@vitejs/plugin-react';\n\n/**\n * Exports the Vite configuration.\n * The configuration is returned from a function to allow access to the current `mode` (development or production).\n *\n * @param {object} config - The Vite configuration object.\n * @param {string} config.mode - The current mode ('development', 'production').\n * @returns {import('vite').UserConfig} The Vite configuration object.\n */\nexport default defineConfig(({ mode }) => {\n  // Load environment variables from .env files located in the project root.\n  // The third argument `''` ensures that all variables are loaded, not just those prefixed with `VITE_`.\n  const env = loadEnv(mode, process.cwd(), '');\n\n  return {\n    plugins: [react()],\n    resolve: {\n      /**\n       * @property {object} alias - Defines path aliases for module resolution.\n       * This allows for cleaner, absolute-like imports within the project.\n       */\n      alias: {\n        '@': path.resolve(__dirname, '.'),\n      },\n    },\n    server: {\n      /**\n       * @property {object} proxy - Proxy configuration for development server.\n       * This forwards API requests to the backend server during development.\n       */\n      proxy: {\n        '/api': {\n          target: 'http://localhost:4000',\n          changeOrigin: true,\n          secure: false,\n        },\n      },\n    },\n    define: {\n      // This section can be used to expose environment variables to the client-side code.\n      // Vite automatically exposes variables prefixed with `VITE_` via `import.meta.env`.\n      // For variables without the prefix, you would define them here, for example:\n      // 'process.env.API_KEY': JSON.stringify(env.API_KEY)\n    },\n  };\n});\n",
      "metadata": {
        "filename": "vite.config.ts",
        "path": "/frontend/"
      }
    }
  ]
}
